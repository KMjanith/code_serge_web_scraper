[
    {
        "title": "What is AWS Lambda?",
        "href": "https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
        "sections": [
            "You can use AWS Lambda to run code without provisioning or managing servers.",
            " Lambda runs your code    on a high-availability compute infrastructure and performs all of the administration of the compute resources,    including server and operating system maintenance, capacity provisioning and automatic scaling, and    logging. With Lambda, all you need to do is supply your code in one of the language runtimes that Lambda supports.",
            "You organize your code into Lambda functions. The Lambda service runs your function only when needed and scales automatically. You only pay for the compute time that you consume—there is no charge when your code is not running. For more information, see AWS Lambda Pricing.",
            "Tip",
            "To learn how to build serverless solutions, check out the Serverless Developer Guide.",
            {
                "sub_header": "When to use Lambda",
                "content": [
                    "Lambda is an ideal compute service for application scenarios that need to scale up rapidly, and scale down to      zero when not in demand. For example, you can use Lambda for:",
                    "  1.File processing: :  Use Amazon Simple Storage Service (Amazon S3) to trigger Lambda data processing in real time after an upload.",
                    "  2.Stream processing: :  Use Lambda and Amazon Kinesis to process real-time streaming data for application activity tracking, transaction order processing, clickstream analysis, data cleansing, log filtering, indexing, social media analysis, Internet of Things (IoT) device data telemetry, and metering.",
                    "  3.Web applications: :  Combine Lambda with other AWS services to build powerful web applications that automatically scale up and down and run in a highly available configuration across multiple data centers.",
                    "  4.IoT backends: :  Build serverless backends using Lambda to handle web, mobile, IoT, and third-party API requests.",
                    "  5.Mobile backends: :  Build backends using Lambda and Amazon API Gateway  to authenticate and process API requests. Use AWS Amplify to easily integrate with your iOS, Android, Web, and React Native frontends.",
                    "When using Lambda, you are responsible only for your code. Lambda manages the compute fleet that offers a      balance of memory, CPU, network, and other resources to run your code. Because Lambda manages these resources, you      cannot log in to compute instances or customize the operating system on provided        runtimes. Lambda performs operational and administrative activities on your behalf, including managing      capacity, monitoring, and logging your Lambda functions."
                ]
            },
            {
                "sub_header": "Key features",
                "content": [
                    "The following key features help you develop Lambda applications that are scalable, secure, and easily      extensible:",
                    "  1. Environment variables : \nUse environment variables to adjust your function's behavior without updating code.\n",
                    "  2.Versions : \nManage the deployment of your functions with versions, so that, for example, a new function can be used for beta testing without affecting users of the stable production version.\n",
                    "  3.Container images : \nCreate a container image for a Lambda function by using an AWS provided base image or an alternative base\n            image so that you can reuse your existing container tooling or deploy larger workloads that rely on sizable dependencies, such as machine learning.\n",
                    "  4.Layers : \nPackage libraries and other dependencies to reduce the size of deployment archives and makes it faster to deploy your code.\n",
                    "  5.Lambda extensions : \nAugment your Lambda functions with tools for monitoring, observability, security, and governance.\n",
                    "  6.Function URLs : \nAdd a dedicated HTTP(S) endpoint to your Lambda function.\n",
                    "  7.Response streaming : \nConfigure your Lambda function URLs to stream response payloads back to clients from Node.js functions, to improve time to first byte (TTFB) performance or to return larger payloads.\n",
                    "  8.Concurrency and scaling controls : \nApply fine-grained control over the scaling and responsiveness of your production applications.\n",
                    "  9.Code signing : \nVerify that only approved developers publish unaltered, trusted code in your Lambda functions \n",
                    "  10.Private networking : \nCreate a private network for resources such as databases, cache instances, or internal services.\n",
                    "  11.File system access : \nConfigure a function to mount an Amazon Elastic File System (Amazon EFS) to a local directory, so that your function code can access and modify shared resources safely and at high concurrency.\n",
                    "  12.Lambda SnapStart for Java : \nImprove startup performance for Java runtimes by up to 10x at no extra cost, typically with no changes to your function code.\n",
                    " Environment variablesUse environment variables to adjust your function's behavior without updating code.VersionsManage the deployment of your functions with versions, so that, for example, a new function can be used for beta testing without affecting users of the stable production version.Container imagesCreate a container image for a Lambda function by using an AWS provided base image or an alternative base            image so that you can reuse your existing container tooling or deploy larger workloads that rely on sizable dependencies, such as machine learning.LayersPackage libraries and other dependencies to reduce the size of deployment archives and makes it faster to deploy your code.Lambda extensionsAugment your Lambda functions with tools for monitoring, observability, security, and governance.Function URLsAdd a dedicated HTTP(S) endpoint to your Lambda function.Response streamingConfigure your Lambda function URLs to stream response payloads back to clients from Node.js functions, to improve time to first byte (TTFB) performance or to return larger payloads.Concurrency and scaling controlsApply fine-grained control over the scaling and responsiveness of your production applications.Code signingVerify that only approved developers publish unaltered, trusted code in your Lambda functions Private networkingCreate a private network for resources such as databases, cache instances, or internal services.File system accessConfigure a function to mount an Amazon Elastic File System (Amazon EFS) to a local directory, so that your function code can access and modify shared resources safely and at high concurrency.Lambda SnapStart for JavaImprove startup performance for Java runtimes by up to 10x at no extra cost, typically with no changes to your function code."
                ]
            }
        ]
    },
    {
        "title": "Example apps",
        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example-apps.html",
        "contents": [
            {
                "title": "File-processing app",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/file-processing-app.html",
                "sections": [
                    "One of the most common use cases for Lambda is to perform file processing tasks. For example, you might use a Lambda function     to automatically create PDF files from HTML files or images, or to create thumbnails when a user uploads an image.",
                    "In this example, you create an app which automatically encrypts PDF files when they are uploaded to an Amazon Simple Storage Service (Amazon S3) bucket.     To implement this app, you create the following resources:",
                    "  1.An S3 bucket for users to upload PDF files to",
                    "  2.A Lambda function in Python which reads the uploaded file and creates an encrypted, password-protected version of it",
                    "  3.A second S3 bucket for Lambda to save the encrypted file in",
                    "You also create an AWS Identity and Access Management (IAM) policy to give your Lambda function permission to perform read and write operations     on your S3 buckets.",
                    "Tip",
                    "If you’re brand new to Lambda, we recommend that you carry out the tutorial Create your first Lambda function before      creating this example app.",
                    "You can deploy your app manually by creating and configuring resources with the AWS Management Console or the AWS Command Line Interface (AWS CLI). You can     also deploy the app by using the AWS Serverless Application Model (AWS SAM). AWS SAM is an infrastructure as code (IaC) tool. With IaC, you don’t create     resources manually, but define them in code and then deploy them automatically.",
                    "If you want to learn more about using Lambda with IaC before deploying this example app, see Using Lambda with infrastructure as code (IaC).",
                    {
                        "sub_header": "Prerequisites",
                        "content": [
                            "Before you can create the example app, make sure you have the required command line tools installed.",
                            "  1.AWS CLI : You can manually deploy the resources for your app using either the AWS Management Console or the . To use the CLI, install it by following               the installation                 instructions in the AWS Command Line Interface User Guide.",
                            "  2.AWS SAM CLI : If you want to deploy the example app using AWS SAM, you need to install both the AWS CLI and the . To install the ,               follow the installation instructions               in the AWS SAM User Guide.",
                            "  3.pytest module : After you’ve deployed your app, you can test it using an automated Python test script that we provide. To use this script, install the               pytest package in you local development environment by running the following command:pip install pytest",
                            {
                                "code_example": "pip install pytest"
                            },
                            "To deploy the app using AWS SAM, Docker must also be installed on your build machine."
                        ]
                    },
                    {
                        "sub_header": "Downloading the example app files",
                        "content": [
                            "To create and test the example app, you create the following files in your project directory:",
                            "  1.lambda_function.py - the Python function code for the Lambda function that performs the file encryption",
                            "  2.requirements.txt - a manifest file defining the dependencies that your Python function code requires",
                            "  3.template.yaml - an AWS SAM template you can use to deploy the app",
                            "  4.test_pdf_encrypt.py - a test script you can use to automatically test your application",
                            "  5.pytest.ini - a configuration file for the the test script",
                            "Expand the following sections to view the code and to learn more about the role of each file in creating and testing your app. To create the       files on your local machine, either copy and paste the code below, or download the files from the aws-lambda-developer-guide GitHub repo.",
                            "Copy and paste the following code into a file named lambda_function.py.",
                            {
                                "code_example": "from pypdf import PdfReader, PdfWriter\nimport uuid\nimport os\nfrom urllib.parse import unquote_plus\nimport boto3\n\n# Create the S3 client to download and upload objects from S3\ns3_client = boto3.client('s3')\n\ndef lambda_handler(event, context):\n    # Iterate over the S3 event object and get the key for all uploaded files\n    for record in event['Records']:\n        bucket = record['s3']['bucket']['name']\n        key = unquote_plus(record['s3']['object']['key']) # Decode the S3 object key to remove any URL-encoded characters\n        download_path = f'/tmp/{uuid.uuid4()}.pdf' # Create a path in the Lambda tmp directory to save the file to \n        upload_path = f'/tmp/converted-{uuid.uuid4()}.pdf' # Create another path to save the encrypted file to\n        \n        # If the file is a PDF, encrypt it and upload it to the destination S3 bucket\n        if key.lower().endswith('.pdf'):\n            s3_client.download_file(bucket, key, download_path)\n            encrypt_pdf(download_path, upload_path)\n            encrypted_key = add_encrypted_suffix(key)\n            s3_client.upload_file(upload_path, f'{bucket}-encrypted', encrypted_key)\n\n# Define the function to encrypt the PDF file with a password\ndef encrypt_pdf(file_path, encrypted_file_path):\n    reader = PdfReader(file_path)\n    writer = PdfWriter()\n    \n    for page in reader.pages:\n        writer.add_page(page)\n\n    # Add a password to the new PDF\n    writer.encrypt(\"my-secret-password\")\n\n    # Save the new PDF to a file\n    with open(encrypted_file_path, \"wb\") as file:\n        writer.write(file)\n\n# Define a function to add a suffix to the original filename after encryption\ndef add_encrypted_suffix(original_key):\n    filename, extension = original_key.rsplit('.', 1)\n    return f'{filename}_encrypted.{extension}'"
                            },
                            "Note",
                            "In this example code, a password for the encrypted file (my-secret-password) is hardcoded into the           function code. In a production application, don't include sensitive information like passwords in your function code. Use           AWS Secrets Manager to securely store sensitive parameters.",
                            "The python function code contains three functions - the handler function that Lambda runs           when your function is invoked, and two separate function named add_encrypted_suffix and encrypt_pdf that the handler calls to perform the PDF encryption.",
                            "When your function is invoked by Amazon S3, Lambda passes a JSON formatted event argument to the function that contains details about the           event that caused the invocation. In this case, the information includes name of the S3 bucket and the object keys for the uploaded files.           To learn more about the format of event object for Amazon S3, see Process Amazon S3 event notifications with Lambda.",
                            "Your function then uses the AWS SDK for Python (Boto3) to download the PDF files specified in the event object to its local temporary storage directory, before           encrypting them using the pypdf library.",
                            "Finally, the function uses the Boto3 SDK to store the encrypted file in your S3 destination bucket.",
                            "Python function code",
                            "Copy and paste the following code into a file named lambda_function.py.",
                            {
                                "code_example": "from pypdf import PdfReader, PdfWriter\nimport uuid\nimport os\nfrom urllib.parse import unquote_plus\nimport boto3\n\n# Create the S3 client to download and upload objects from S3\ns3_client = boto3.client('s3')\n\ndef lambda_handler(event, context):\n    # Iterate over the S3 event object and get the key for all uploaded files\n    for record in event['Records']:\n        bucket = record['s3']['bucket']['name']\n        key = unquote_plus(record['s3']['object']['key']) # Decode the S3 object key to remove any URL-encoded characters\n        download_path = f'/tmp/{uuid.uuid4()}.pdf' # Create a path in the Lambda tmp directory to save the file to \n        upload_path = f'/tmp/converted-{uuid.uuid4()}.pdf' # Create another path to save the encrypted file to\n        \n        # If the file is a PDF, encrypt it and upload it to the destination S3 bucket\n        if key.lower().endswith('.pdf'):\n            s3_client.download_file(bucket, key, download_path)\n            encrypt_pdf(download_path, upload_path)\n            encrypted_key = add_encrypted_suffix(key)\n            s3_client.upload_file(upload_path, f'{bucket}-encrypted', encrypted_key)\n\n# Define the function to encrypt the PDF file with a password\ndef encrypt_pdf(file_path, encrypted_file_path):\n    reader = PdfReader(file_path)\n    writer = PdfWriter()\n    \n    for page in reader.pages:\n        writer.add_page(page)\n\n    # Add a password to the new PDF\n    writer.encrypt(\"my-secret-password\")\n\n    # Save the new PDF to a file\n    with open(encrypted_file_path, \"wb\") as file:\n        writer.write(file)\n\n# Define a function to add a suffix to the original filename after encryption\ndef add_encrypted_suffix(original_key):\n    filename, extension = original_key.rsplit('.', 1)\n    return f'{filename}_encrypted.{extension}'"
                            },
                            "Note",
                            "In this example code, a password for the encrypted file (my-secret-password) is hardcoded into the           function code. In a production application, don't include sensitive information like passwords in your function code. Use           AWS Secrets Manager to securely store sensitive parameters.",
                            "The python function code contains three functions - the handler function that Lambda runs           when your function is invoked, and two separate function named add_encrypted_suffix and encrypt_pdf that the handler calls to perform the PDF encryption.",
                            "When your function is invoked by Amazon S3, Lambda passes a JSON formatted event argument to the function that contains details about the           event that caused the invocation. In this case, the information includes name of the S3 bucket and the object keys for the uploaded files.           To learn more about the format of event object for Amazon S3, see Process Amazon S3 event notifications with Lambda.",
                            "Your function then uses the AWS SDK for Python (Boto3) to download the PDF files specified in the event object to its local temporary storage directory, before           encrypting them using the pypdf library.",
                            "Finally, the function uses the Boto3 SDK to store the encrypted file in your S3 destination bucket.",
                            "Copy and paste the following code into a file named lambda_function.py.from pypdf import PdfReader, PdfWriterimport uuidimport osfrom urllib.parse import unquote_plusimport boto3# Create the S3 client to download and upload objects from S3s3_client = boto3.client('s3')def lambda_handler(event, context):    # Iterate over the S3 event object and get the key for all uploaded files    for record in event['Records']:        bucket = record['s3']['bucket']['name']        key = unquote_plus(record['s3']['object']['key']) # Decode the S3 object key to remove any URL-encoded characters        download_path = f'/tmp/{uuid.uuid4()}.pdf' # Create a path in the Lambda tmp directory to save the file to         upload_path = f'/tmp/converted-{uuid.uuid4()}.pdf' # Create another path to save the encrypted file to                # If the file is a PDF, encrypt it and upload it to the destination S3 bucket        if key.lower().endswith('.pdf'):            s3_client.download_file(bucket, key, download_path)            encrypt_pdf(download_path, upload_path)            encrypted_key = add_encrypted_suffix(key)            s3_client.upload_file(upload_path, f'{bucket}-encrypted', encrypted_key)# Define the function to encrypt the PDF file with a passworddef encrypt_pdf(file_path, encrypted_file_path):    reader = PdfReader(file_path)    writer = PdfWriter()        for page in reader.pages:        writer.add_page(page)    # Add a password to the new PDF    writer.encrypt(\"my-secret-password\")    # Save the new PDF to a file    with open(encrypted_file_path, \"wb\") as file:        writer.write(file)# Define a function to add a suffix to the original filename after encryptiondef add_encrypted_suffix(original_key):    filename, extension = original_key.rsplit('.', 1)    return f'{filename}_encrypted.{extension}'NoteIn this example code, a password for the encrypted file (my-secret-password) is hardcoded into the           function code. In a production application, don't include sensitive information like passwords in your function code. Use           AWS Secrets Manager to securely store sensitive parameters.The python function code contains three functions - the handler function that Lambda runs           when your function is invoked, and two separate function named add_encrypted_suffix and encrypt_pdf that the handler calls to perform the PDF encryption.When your function is invoked by Amazon S3, Lambda passes a JSON formatted event argument to the function that contains details about the           event that caused the invocation. In this case, the information includes name of the S3 bucket and the object keys for the uploaded files.           To learn more about the format of event object for Amazon S3, see Process Amazon S3 event notifications with Lambda.Your function then uses the AWS SDK for Python (Boto3) to download the PDF files specified in the event object to its local temporary storage directory, before           encrypting them using the pypdf library.Finally, the function uses the Boto3 SDK to store the encrypted file in your S3 destination bucket.Python function codeCopy and paste the following code into a file named lambda_function.py.from pypdf import PdfReader, PdfWriterimport uuidimport osfrom urllib.parse import unquote_plusimport boto3# Create the S3 client to download and upload objects from S3s3_client = boto3.client('s3')def lambda_handler(event, context):    # Iterate over the S3 event object and get the key for all uploaded files    for record in event['Records']:        bucket = record['s3']['bucket']['name']        key = unquote_plus(record['s3']['object']['key']) # Decode the S3 object key to remove any URL-encoded characters        download_path = f'/tmp/{uuid.uuid4()}.pdf' # Create a path in the Lambda tmp directory to save the file to         upload_path = f'/tmp/converted-{uuid.uuid4()}.pdf' # Create another path to save the encrypted file to                # If the file is a PDF, encrypt it and upload it to the destination S3 bucket        if key.lower().endswith('.pdf'):            s3_client.download_file(bucket, key, download_path)            encrypt_pdf(download_path, upload_path)            encrypted_key = add_encrypted_suffix(key)            s3_client.upload_file(upload_path, f'{bucket}-encrypted', encrypted_key)# Define the function to encrypt the PDF file with a passworddef encrypt_pdf(file_path, encrypted_file_path):    reader = PdfReader(file_path)    writer = PdfWriter()        for page in reader.pages:        writer.add_page(page)    # Add a password to the new PDF    writer.encrypt(\"my-secret-password\")    # Save the new PDF to a file    with open(encrypted_file_path, \"wb\") as file:        writer.write(file)# Define a function to add a suffix to the original filename after encryptiondef add_encrypted_suffix(original_key):    filename, extension = original_key.rsplit('.', 1)    return f'{filename}_encrypted.{extension}'NoteIn this example code, a password for the encrypted file (my-secret-password) is hardcoded into the           function code. In a production application, don't include sensitive information like passwords in your function code. Use           AWS Secrets Manager to securely store sensitive parameters.The python function code contains three functions - the handler function that Lambda runs           when your function is invoked, and two separate function named add_encrypted_suffix and encrypt_pdf that the handler calls to perform the PDF encryption.When your function is invoked by Amazon S3, Lambda passes a JSON formatted event argument to the function that contains details about the           event that caused the invocation. In this case, the information includes name of the S3 bucket and the object keys for the uploaded files.           To learn more about the format of event object for Amazon S3, see Process Amazon S3 event notifications with Lambda.Your function then uses the AWS SDK for Python (Boto3) to download the PDF files specified in the event object to its local temporary storage directory, before           encrypting them using the pypdf library.Finally, the function uses the Boto3 SDK to store the encrypted file in your S3 destination bucket.",
                            "Copy and paste the following code into a file named requirements.txt.",
                            {
                                "code_example": "boto3\npypdf"
                            },
                            "For this example, your function code has only two dependencies that aren't part of the standard Python library -           the SDK for Python (Boto3) and the pypdf package the function uses to perform the PDF encryption.",
                            "Note",
                            "A version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.           See Runtime dependencies in Python to learn more.",
                            "requirements.txt manifest file",
                            "Copy and paste the following code into a file named requirements.txt.",
                            {
                                "code_example": "boto3\npypdf"
                            },
                            "For this example, your function code has only two dependencies that aren't part of the standard Python library -           the SDK for Python (Boto3) and the pypdf package the function uses to perform the PDF encryption.",
                            "Note",
                            "A version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.           See Runtime dependencies in Python to learn more.",
                            "Copy and paste the following code into a file named requirements.txt.boto3pypdfFor this example, your function code has only two dependencies that aren't part of the standard Python library -           the SDK for Python (Boto3) and the pypdf package the function uses to perform the PDF encryption.NoteA version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.           See Runtime dependencies in Python to learn more.requirements.txt manifest fileCopy and paste the following code into a file named requirements.txt.boto3pypdfFor this example, your function code has only two dependencies that aren't part of the standard Python library -           the SDK for Python (Boto3) and the pypdf package the function uses to perform the PDF encryption.NoteA version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.           See Runtime dependencies in Python to learn more.",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  EncryptPDFFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: EncryptPDF\n      Architectures: [x86_64]\n      CodeUri: ./\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.12\n      Timeout: 15\n      MemorySize: 256\n      LoggingConfig:\n        LogFormat: JSON\n      Policies:\n        - AmazonS3FullAccess\n      Events:\n        S3Event:\n          Type: S3\n          Properties:\n            Bucket: !Ref PDFSourceBucket\n            Events: s3:ObjectCreated:*\n\n  PDFSourceBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: EXAMPLE-BUCKET\n\n  EncryptedPDFBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: EXAMPLE-BUCKET-encrypted"
                            },
                            "The AWS SAM template defines the resources you create for your app. In this example, the template defines a Lambda function using the         AWS::Serverless::Function type and two S3 buckets using the AWS::S3::Bucket type. The bucket names specified in the         template are placeholders. Before you deploy the app using AWS SAM, you need to edit the template to rename the buckets with globally unique names that          meet the S3 bucket naming rules. This step is           explained further in Deploy the resources using AWS SAM.",
                            "The definition of the Lambda function resource configures a trigger for the function using the S3Event event property. This         trigger causes your function to be invoked whenever an object is created in your source bucket.",
                            "The function definition also specifies an AWS Identity and Access Management (IAM) policy to be attached to the function's execution role.           The AWS managed policyAmazonS3FullAccess gives your function the permissions it needs to read and write objects to Amazon S3.",
                            "AWS SAM template",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  EncryptPDFFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: EncryptPDF\n      Architectures: [x86_64]\n      CodeUri: ./\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.12\n      Timeout: 15\n      MemorySize: 256\n      LoggingConfig:\n        LogFormat: JSON\n      Policies:\n        - AmazonS3FullAccess\n      Events:\n        S3Event:\n          Type: S3\n          Properties:\n            Bucket: !Ref PDFSourceBucket\n            Events: s3:ObjectCreated:*\n\n  PDFSourceBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: EXAMPLE-BUCKET\n\n  EncryptedPDFBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: EXAMPLE-BUCKET-encrypted"
                            },
                            "The AWS SAM template defines the resources you create for your app. In this example, the template defines a Lambda function using the         AWS::Serverless::Function type and two S3 buckets using the AWS::S3::Bucket type. The bucket names specified in the         template are placeholders. Before you deploy the app using AWS SAM, you need to edit the template to rename the buckets with globally unique names that          meet the S3 bucket naming rules. This step is           explained further in Deploy the resources using AWS SAM.",
                            "The definition of the Lambda function resource configures a trigger for the function using the S3Event event property. This         trigger causes your function to be invoked whenever an object is created in your source bucket.",
                            "The function definition also specifies an AWS Identity and Access Management (IAM) policy to be attached to the function's execution role.           The AWS managed policyAmazonS3FullAccess gives your function the permissions it needs to read and write objects to Amazon S3.",
                            "Copy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Resources:  EncryptPDFFunction:    Type: AWS::Serverless::Function    Properties:      FunctionName: EncryptPDF      Architectures: [x86_64]      CodeUri: ./      Handler: lambda_function.lambda_handler      Runtime: python3.12      Timeout: 15      MemorySize: 256      LoggingConfig:        LogFormat: JSON      Policies:        - AmazonS3FullAccess      Events:        S3Event:          Type: S3          Properties:            Bucket: !Ref PDFSourceBucket            Events: s3:ObjectCreated:*  PDFSourceBucket:    Type: AWS::S3::Bucket    Properties:      BucketName: EXAMPLE-BUCKET  EncryptedPDFBucket:    Type: AWS::S3::Bucket    Properties:      BucketName: EXAMPLE-BUCKET-encryptedThe AWS SAM template defines the resources you create for your app. In this example, the template defines a Lambda function using the         AWS::Serverless::Function type and two S3 buckets using the AWS::S3::Bucket type. The bucket names specified in the         template are placeholders. Before you deploy the app using AWS SAM, you need to edit the template to rename the buckets with globally unique names that          meet the S3 bucket naming rules. This step is           explained further in Deploy the resources using AWS SAM.The definition of the Lambda function resource configures a trigger for the function using the S3Event event property. This         trigger causes your function to be invoked whenever an object is created in your source bucket.The function definition also specifies an AWS Identity and Access Management (IAM) policy to be attached to the function's execution role.           The AWS managed policyAmazonS3FullAccess gives your function the permissions it needs to read and write objects to Amazon S3.AWS SAM templateCopy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Resources:  EncryptPDFFunction:    Type: AWS::Serverless::Function    Properties:      FunctionName: EncryptPDF      Architectures: [x86_64]      CodeUri: ./      Handler: lambda_function.lambda_handler      Runtime: python3.12      Timeout: 15      MemorySize: 256      LoggingConfig:        LogFormat: JSON      Policies:        - AmazonS3FullAccess      Events:        S3Event:          Type: S3          Properties:            Bucket: !Ref PDFSourceBucket            Events: s3:ObjectCreated:*  PDFSourceBucket:    Type: AWS::S3::Bucket    Properties:      BucketName: EXAMPLE-BUCKET  EncryptedPDFBucket:    Type: AWS::S3::Bucket    Properties:      BucketName: EXAMPLE-BUCKET-encryptedThe AWS SAM template defines the resources you create for your app. In this example, the template defines a Lambda function using the         AWS::Serverless::Function type and two S3 buckets using the AWS::S3::Bucket type. The bucket names specified in the         template are placeholders. Before you deploy the app using AWS SAM, you need to edit the template to rename the buckets with globally unique names that          meet the S3 bucket naming rules. This step is           explained further in Deploy the resources using AWS SAM.The definition of the Lambda function resource configures a trigger for the function using the S3Event event property. This         trigger causes your function to be invoked whenever an object is created in your source bucket.The function definition also specifies an AWS Identity and Access Management (IAM) policy to be attached to the function's execution role.           The AWS managed policyAmazonS3FullAccess gives your function the permissions it needs to read and write objects to Amazon S3.",
                            "Copy and paste the following code into a file named test_pdf_encrypt.py.",
                            {
                                "code_example": "import boto3\nimport json\nimport pytest\nimport time\nimport os\n\n@pytest.fixture\ndef lambda_client():\n    return boto3.client('lambda')\n    \n@pytest.fixture\ndef s3_client():\n    return boto3.client('s3')\n\n@pytest.fixture\ndef logs_client():\n    return boto3.client('logs')\n\n@pytest.fixture(scope='session')\ndef cleanup():\n    # Create a new S3 client for cleanup\n    s3_client = boto3.client('s3')\n\n    yield\n    # Cleanup code will be executed after all tests have finished\n\n    # Delete test.pdf from the source bucket\n    source_bucket = 'EXAMPLE-BUCKET'\n    source_file_key = 'test.pdf'\n    s3_client.delete_object(Bucket=source_bucket, Key=source_file_key)\n    print(f\"\\nDeleted {source_file_key} from {source_bucket}\")\n\n    # Delete test_encrypted.pdf from the destination bucket\n    destination_bucket = 'EXAMPLE-BUCKET-encrypted'\n    destination_file_key = 'test_encrypted.pdf'\n    s3_client.delete_object(Bucket=destination_bucket, Key=destination_file_key)\n    print(f\"Deleted {destination_file_key} from {destination_bucket}\")\n        \n\n@pytest.mark.order(1)\ndef test_source_bucket_available(s3_client):\n    s3_bucket_name = 'EXAMPLE-BUCKET'\n    file_name = 'test.pdf'\n    file_path = os.path.join(os.path.dirname(__file__), file_name)\n\n    file_uploaded = False\n    try:\n        s3_client.upload_file(file_path, s3_bucket_name, file_name)\n        file_uploaded = True\n    except:\n        print(\"Error: couldn't upload file\")\n\n    assert file_uploaded, \"Could not upload file to S3 bucket\"\n\n    \n\n@pytest.mark.order(2)\ndef test_lambda_invoked(logs_client):\n\n    # Wait for a few seconds to make sure the logs are available\n    time.sleep(5)\n\n    # Get the latest log stream for the specified log group\n    log_streams = logs_client.describe_log_streams(\n        logGroupName='/aws/lambda/EncryptPDF',\n        orderBy='LastEventTime',\n        descending=True,\n        limit=1\n    )\n\n    latest_log_stream_name = log_streams['logStreams'][0]['logStreamName']\n\n    # Retrieve the log events from the latest log stream\n    log_events = logs_client.get_log_events(\n        logGroupName='/aws/lambda/EncryptPDF',\n        logStreamName=latest_log_stream_name\n    )\n\n    success_found = False\n    for event in log_events['events']:\n        message = json.loads(event['message'])\n        status = message.get('record', {}).get('status')\n        if status == 'success':\n            success_found = True\n            break\n\n    assert success_found, \"Lambda function execution did not report 'success' status in logs.\"\n\n@pytest.mark.order(3)\ndef test_encrypted_file_in_bucket(s3_client):\n    # Specify the destination S3 bucket and the expected converted file key\n    destination_bucket = 'EXAMPLE-BUCKET-encrypted'\n    converted_file_key = 'test_encrypted.pdf'\n\n    try:\n        # Attempt to retrieve the metadata of the converted file from the destination S3 bucket\n        s3_client.head_object(Bucket=destination_bucket, Key=converted_file_key)\n    except s3_client.exceptions.ClientError as e:\n        # If the file is not found, the test will fail\n        pytest.fail(f\"Converted file '{converted_file_key}' not found in the destination bucket: {str(e)}\")\n\ndef test_cleanup(cleanup):\n    # This test uses the cleanup fixture and will be executed last\n    pass"
                            },
                            "The automated test script executes three test functions to confirm correct operation of your app:",
                            "  1.The test test_source_bucket_available confirms that your source bucket has been successfully created             by uploading a test PDF file to the bucket.",
                            "  2.The test test_lambda_invoked interrogates the latest CloudWatch Logs log stream for your function to confirm that             when you uploaded the test file, your Lambda function ran and reported success.",
                            "  3.The test test_encrypted_file_in_bucket confirms that your destination bucket contains the encrypted test_encrypted.pdf             file.",
                            "After all these tests have run, the script runs an additional cleanup step to delete the test.pdf and test_encrypted.pdf files from         both your source and destination buckets.",
                            "As with the AWS SAM template, the bucket names specified in this file are placeholders. Before running the test, you need to edit this file           with your app's real bucket names. This step is explained further in Testing the app with the automated script",
                            "Automated test script",
                            "Copy and paste the following code into a file named test_pdf_encrypt.py.",
                            {
                                "code_example": "import boto3\nimport json\nimport pytest\nimport time\nimport os\n\n@pytest.fixture\ndef lambda_client():\n    return boto3.client('lambda')\n    \n@pytest.fixture\ndef s3_client():\n    return boto3.client('s3')\n\n@pytest.fixture\ndef logs_client():\n    return boto3.client('logs')\n\n@pytest.fixture(scope='session')\ndef cleanup():\n    # Create a new S3 client for cleanup\n    s3_client = boto3.client('s3')\n\n    yield\n    # Cleanup code will be executed after all tests have finished\n\n    # Delete test.pdf from the source bucket\n    source_bucket = 'EXAMPLE-BUCKET'\n    source_file_key = 'test.pdf'\n    s3_client.delete_object(Bucket=source_bucket, Key=source_file_key)\n    print(f\"\\nDeleted {source_file_key} from {source_bucket}\")\n\n    # Delete test_encrypted.pdf from the destination bucket\n    destination_bucket = 'EXAMPLE-BUCKET-encrypted'\n    destination_file_key = 'test_encrypted.pdf'\n    s3_client.delete_object(Bucket=destination_bucket, Key=destination_file_key)\n    print(f\"Deleted {destination_file_key} from {destination_bucket}\")\n        \n\n@pytest.mark.order(1)\ndef test_source_bucket_available(s3_client):\n    s3_bucket_name = 'EXAMPLE-BUCKET'\n    file_name = 'test.pdf'\n    file_path = os.path.join(os.path.dirname(__file__), file_name)\n\n    file_uploaded = False\n    try:\n        s3_client.upload_file(file_path, s3_bucket_name, file_name)\n        file_uploaded = True\n    except:\n        print(\"Error: couldn't upload file\")\n\n    assert file_uploaded, \"Could not upload file to S3 bucket\"\n\n    \n\n@pytest.mark.order(2)\ndef test_lambda_invoked(logs_client):\n\n    # Wait for a few seconds to make sure the logs are available\n    time.sleep(5)\n\n    # Get the latest log stream for the specified log group\n    log_streams = logs_client.describe_log_streams(\n        logGroupName='/aws/lambda/EncryptPDF',\n        orderBy='LastEventTime',\n        descending=True,\n        limit=1\n    )\n\n    latest_log_stream_name = log_streams['logStreams'][0]['logStreamName']\n\n    # Retrieve the log events from the latest log stream\n    log_events = logs_client.get_log_events(\n        logGroupName='/aws/lambda/EncryptPDF',\n        logStreamName=latest_log_stream_name\n    )\n\n    success_found = False\n    for event in log_events['events']:\n        message = json.loads(event['message'])\n        status = message.get('record', {}).get('status')\n        if status == 'success':\n            success_found = True\n            break\n\n    assert success_found, \"Lambda function execution did not report 'success' status in logs.\"\n\n@pytest.mark.order(3)\ndef test_encrypted_file_in_bucket(s3_client):\n    # Specify the destination S3 bucket and the expected converted file key\n    destination_bucket = 'EXAMPLE-BUCKET-encrypted'\n    converted_file_key = 'test_encrypted.pdf'\n\n    try:\n        # Attempt to retrieve the metadata of the converted file from the destination S3 bucket\n        s3_client.head_object(Bucket=destination_bucket, Key=converted_file_key)\n    except s3_client.exceptions.ClientError as e:\n        # If the file is not found, the test will fail\n        pytest.fail(f\"Converted file '{converted_file_key}' not found in the destination bucket: {str(e)}\")\n\ndef test_cleanup(cleanup):\n    # This test uses the cleanup fixture and will be executed last\n    pass"
                            },
                            "The automated test script executes three test functions to confirm correct operation of your app:",
                            "  1.The test test_source_bucket_available confirms that your source bucket has been successfully created             by uploading a test PDF file to the bucket.",
                            "  2.The test test_lambda_invoked interrogates the latest CloudWatch Logs log stream for your function to confirm that             when you uploaded the test file, your Lambda function ran and reported success.",
                            "  3.The test test_encrypted_file_in_bucket confirms that your destination bucket contains the encrypted test_encrypted.pdf             file.",
                            "After all these tests have run, the script runs an additional cleanup step to delete the test.pdf and test_encrypted.pdf files from         both your source and destination buckets.",
                            "As with the AWS SAM template, the bucket names specified in this file are placeholders. Before running the test, you need to edit this file           with your app's real bucket names. This step is explained further in Testing the app with the automated script",
                            "Copy and paste the following code into a file named test_pdf_encrypt.py.import boto3import jsonimport pytestimport timeimport os@pytest.fixturedef lambda_client():    return boto3.client('lambda')    @pytest.fixturedef s3_client():    return boto3.client('s3')@pytest.fixturedef logs_client():    return boto3.client('logs')@pytest.fixture(scope='session')def cleanup():    # Create a new S3 client for cleanup    s3_client = boto3.client('s3')    yield    # Cleanup code will be executed after all tests have finished    # Delete test.pdf from the source bucket    source_bucket = 'EXAMPLE-BUCKET'    source_file_key = 'test.pdf'    s3_client.delete_object(Bucket=source_bucket, Key=source_file_key)    print(f\"\\nDeleted {source_file_key} from {source_bucket}\")    # Delete test_encrypted.pdf from the destination bucket    destination_bucket = 'EXAMPLE-BUCKET-encrypted'    destination_file_key = 'test_encrypted.pdf'    s3_client.delete_object(Bucket=destination_bucket, Key=destination_file_key)    print(f\"Deleted {destination_file_key} from {destination_bucket}\")        @pytest.mark.order(1)def test_source_bucket_available(s3_client):    s3_bucket_name = 'EXAMPLE-BUCKET'    file_name = 'test.pdf'    file_path = os.path.join(os.path.dirname(__file__), file_name)    file_uploaded = False    try:        s3_client.upload_file(file_path, s3_bucket_name, file_name)        file_uploaded = True    except:        print(\"Error: couldn't upload file\")    assert file_uploaded, \"Could not upload file to S3 bucket\"    @pytest.mark.order(2)def test_lambda_invoked(logs_client):    # Wait for a few seconds to make sure the logs are available    time.sleep(5)    # Get the latest log stream for the specified log group    log_streams = logs_client.describe_log_streams(        logGroupName='/aws/lambda/EncryptPDF',        orderBy='LastEventTime',        descending=True,        limit=1    )    latest_log_stream_name = log_streams['logStreams'][0]['logStreamName']    # Retrieve the log events from the latest log stream    log_events = logs_client.get_log_events(        logGroupName='/aws/lambda/EncryptPDF',        logStreamName=latest_log_stream_name    )    success_found = False    for event in log_events['events']:        message = json.loads(event['message'])        status = message.get('record', {}).get('status')        if status == 'success':            success_found = True            break    assert success_found, \"Lambda function execution did not report 'success' status in logs.\"@pytest.mark.order(3)def test_encrypted_file_in_bucket(s3_client):    # Specify the destination S3 bucket and the expected converted file key    destination_bucket = 'EXAMPLE-BUCKET-encrypted'    converted_file_key = 'test_encrypted.pdf'    try:        # Attempt to retrieve the metadata of the converted file from the destination S3 bucket        s3_client.head_object(Bucket=destination_bucket, Key=converted_file_key)    except s3_client.exceptions.ClientError as e:        # If the file is not found, the test will fail        pytest.fail(f\"Converted file '{converted_file_key}' not found in the destination bucket: {str(e)}\")def test_cleanup(cleanup):    # This test uses the cleanup fixture and will be executed last    passThe automated test script executes three test functions to confirm correct operation of your app:The test test_source_bucket_available confirms that your source bucket has been successfully created             by uploading a test PDF file to the bucket.The test test_lambda_invoked interrogates the latest CloudWatch Logs log stream for your function to confirm that             when you uploaded the test file, your Lambda function ran and reported success.The test test_encrypted_file_in_bucket confirms that your destination bucket contains the encrypted test_encrypted.pdf             file.After all these tests have run, the script runs an additional cleanup step to delete the test.pdf and test_encrypted.pdf files from         both your source and destination buckets.As with the AWS SAM template, the bucket names specified in this file are placeholders. Before running the test, you need to edit this file           with your app's real bucket names. This step is explained further in Testing the app with the automated scriptAutomated test scriptCopy and paste the following code into a file named test_pdf_encrypt.py.import boto3import jsonimport pytestimport timeimport os@pytest.fixturedef lambda_client():    return boto3.client('lambda')    @pytest.fixturedef s3_client():    return boto3.client('s3')@pytest.fixturedef logs_client():    return boto3.client('logs')@pytest.fixture(scope='session')def cleanup():    # Create a new S3 client for cleanup    s3_client = boto3.client('s3')    yield    # Cleanup code will be executed after all tests have finished    # Delete test.pdf from the source bucket    source_bucket = 'EXAMPLE-BUCKET'    source_file_key = 'test.pdf'    s3_client.delete_object(Bucket=source_bucket, Key=source_file_key)    print(f\"\\nDeleted {source_file_key} from {source_bucket}\")    # Delete test_encrypted.pdf from the destination bucket    destination_bucket = 'EXAMPLE-BUCKET-encrypted'    destination_file_key = 'test_encrypted.pdf'    s3_client.delete_object(Bucket=destination_bucket, Key=destination_file_key)    print(f\"Deleted {destination_file_key} from {destination_bucket}\")        @pytest.mark.order(1)def test_source_bucket_available(s3_client):    s3_bucket_name = 'EXAMPLE-BUCKET'    file_name = 'test.pdf'    file_path = os.path.join(os.path.dirname(__file__), file_name)    file_uploaded = False    try:        s3_client.upload_file(file_path, s3_bucket_name, file_name)        file_uploaded = True    except:        print(\"Error: couldn't upload file\")    assert file_uploaded, \"Could not upload file to S3 bucket\"    @pytest.mark.order(2)def test_lambda_invoked(logs_client):    # Wait for a few seconds to make sure the logs are available    time.sleep(5)    # Get the latest log stream for the specified log group    log_streams = logs_client.describe_log_streams(        logGroupName='/aws/lambda/EncryptPDF',        orderBy='LastEventTime',        descending=True,        limit=1    )    latest_log_stream_name = log_streams['logStreams'][0]['logStreamName']    # Retrieve the log events from the latest log stream    log_events = logs_client.get_log_events(        logGroupName='/aws/lambda/EncryptPDF',        logStreamName=latest_log_stream_name    )    success_found = False    for event in log_events['events']:        message = json.loads(event['message'])        status = message.get('record', {}).get('status')        if status == 'success':            success_found = True            break    assert success_found, \"Lambda function execution did not report 'success' status in logs.\"@pytest.mark.order(3)def test_encrypted_file_in_bucket(s3_client):    # Specify the destination S3 bucket and the expected converted file key    destination_bucket = 'EXAMPLE-BUCKET-encrypted'    converted_file_key = 'test_encrypted.pdf'    try:        # Attempt to retrieve the metadata of the converted file from the destination S3 bucket        s3_client.head_object(Bucket=destination_bucket, Key=converted_file_key)    except s3_client.exceptions.ClientError as e:        # If the file is not found, the test will fail        pytest.fail(f\"Converted file '{converted_file_key}' not found in the destination bucket: {str(e)}\")def test_cleanup(cleanup):    # This test uses the cleanup fixture and will be executed last    passThe automated test script executes three test functions to confirm correct operation of your app:The test test_source_bucket_available confirms that your source bucket has been successfully created             by uploading a test PDF file to the bucket.The test test_lambda_invoked interrogates the latest CloudWatch Logs log stream for your function to confirm that             when you uploaded the test file, your Lambda function ran and reported success.The test test_encrypted_file_in_bucket confirms that your destination bucket contains the encrypted test_encrypted.pdf             file.After all these tests have run, the script runs an additional cleanup step to delete the test.pdf and test_encrypted.pdf files from         both your source and destination buckets.As with the AWS SAM template, the bucket names specified in this file are placeholders. Before running the test, you need to edit this file           with your app's real bucket names. This step is explained further in Testing the app with the automated script",
                            "Copy and paste the following code into a file named pytest.ini.",
                            {
                                "code_example": "[pytest]\nmarkers =\n    order: specify test execution order"
                            },
                            "This is needed to specify the order in which the tests in the test_pdf_encrypt.py script run.",
                            "Test script configuration file",
                            "Copy and paste the following code into a file named pytest.ini.",
                            {
                                "code_example": "[pytest]\nmarkers =\n    order: specify test execution order"
                            },
                            "This is needed to specify the order in which the tests in the test_pdf_encrypt.py script run.",
                            "Copy and paste the following code into a file named pytest.ini.[pytest]markers =    order: specify test execution orderThis is needed to specify the order in which the tests in the test_pdf_encrypt.py script run.Test script configuration fileCopy and paste the following code into a file named pytest.ini.[pytest]markers =    order: specify test execution orderThis is needed to specify the order in which the tests in the test_pdf_encrypt.py script run."
                        ]
                    },
                    {
                        "sub_header": "Deploying the app",
                        "content": [
                            "You can create and deploy the resources for this example app either manually or by using AWS SAM. In a production environment, we       recommend that you use an IaC tool like AWS SAM to quickly and repeatably deploy whole serverless applications without using manual processes.",
                            "For this example, follow the console or AWS CLI instructions to learn how to configure each AWS resource separately, or skip ahead to        Deploy the resources using AWS SAM to quickly deploy the app using a few CLI commands.",
                            {
                                "sub_header": "Deploy the resources manually",
                                "content": [
                                    "To deploy your app manually, you carry out the following steps:",
                                    "  1.Create source and destination Amazon S3 buckets",
                                    "  2.Create a Lambda function that encrypts a PDF file and saves the encrypted version to an S3 bucket",
                                    "  3.Configure a Lambda trigger that invokes your function when objects are uploaded to your source bucket",
                                    "Follow the instructions in the following paragraphs to create and configure your resources.",
                                    {
                                        "sub_header": "Create two S3 buckets",
                                        "content": [
                                            "First create two S3 buckets. The first bucket is the source bucket you will upload your PDF files to. The second bucket is used by     Lambda to save the encrypted file when you invoke your function.",
                                            "  1.Console : SOURCEBUCKET-encrypted",
                                            "  2.AWS CLI : region",
                                            "ConsoleTo create the S3 buckets (console)Open the Buckets page of the Amazon S3 console.Choose Create bucket.Under General configuration, do the following:For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules.                     Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-). For AWS Region, choose the AWS Region                     closest to your geographical location. Later in the deployment process, you must create your Lambda function in the same AWS Region, so                     make a note of the region you chose.Leave all other options set to their default values and choose Create bucket.Repeat steps 1 to 4 to create your destination bucket. For Bucket name, enter SOURCEBUCKET-encrypted,                 where SOURCEBUCKET is the name of the source bucket you just created.AWS CLITo create the Amazon S3 buckets (AWS CLI)Run the following CLI command to create your source bucket. The name you choose for your bucket must be globally unique and                 follow the Amazon S3 Bucket naming rules.                 Names can only contain lower case letters, numbers, dots (.), and hyphens (-). For region and LocationConstraint,                 choose the AWS Region closest to your geographical                 location.aws s3api create-bucket --bucket SOURCEBUCKET --region us-west-2 \\--create-bucket-configuration LocationConstraint=us-west-2Later in the tutorial, you must create your Lambda function in the same AWS Region as your source bucket, so make a note of the                 region you chose.Run the following command to create your destination bucket. For the bucket name, you must use SOURCEBUCKET-encrypted,                 where SOURCEBUCKET is the name of the source bucket you created in step 1. For region                 and LocationConstraint, choose the same AWS Region you used to create your source bucket.aws s3api create-bucket --bucket SOURCEBUCKET-encrypted --region us-west-2 \\--create-bucket-configuration LocationConstraint=us-west-2",
                                            "anchor",
                                            "anchor",
                                            "To create the S3 buckets (console)",
                                            "  1 : Open the Buckets page of the Amazon S3 console.",
                                            "  2 : Choose Create bucket.",
                                            "  3 : Under General configuration, do the following:For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules.                     Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-). For AWS Region, choose the AWS Region                     closest to your geographical location. Later in the deployment process, you must create your Lambda function in the same AWS Region, so                     make a note of the region you chose.",
                                            "  4 : Leave all other options set to their default values and choose Create bucket.",
                                            "  5 : Repeat steps 1 to 4 to create your destination bucket. For Bucket name, enter SOURCEBUCKET-encrypted,                 where SOURCEBUCKET is the name of the source bucket you just created."
                                        ]
                                    },
                                    {
                                        "sub_header": "Create an execution role (AWS CLI only)",
                                        "content": [
                                            "An execution role is an IAM role that grants a Lambda function permission to access AWS services and resources. When you create a function       using the Lambda console, Lambda automatically creates an execution role. You only need to create a role manually if you choose to deploy the app       using the AWS CLI. To give your function read and write access to Amazon S3, you attach the       AWS managed policyAmazonS3FullAccess.",
                                            "  1.Console : \nThis step is only required if you choose to deploy your app using the AWS CLI.\n",
                                            "  2.AWS CLI : AmazonS3FullAccess",
                                            "ConsoleThis step is only required if you choose to deploy your app using the AWS CLI.AWS CLITo create an execution role and attach the AmazonS3FullAccess managed policy (AWS CLI)Save the following JSON in a file named trust-policy.json. This trust policy allows Lambda to use the role’s                permissions by giving the service principal lambda.amazonaws.com permission to call the AWS Security Token Service (AWS STS) AssumeRole                action.{  \"Version\": \"2012-10-17\",  \"Statement\": [    {      \"Effect\": \"Allow\",      \"Principal\": {        \"Service\": \"lambda.amazonaws.com\"      },      \"Action\": \"sts:AssumeRole\"    }  ]}From the directory you saved the JSON trust policy document in, run the following CLI command to create the execution role.aws iam create-role --role-name LambdaS3Role --assume-role-policy-document file://trust-policy.jsonTo attach the AmazonS3FullAccess managed policy, run the following CLI command.aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess",
                                            "anchor",
                                            "anchor",
                                            "This step is only required if you choose to deploy your app using the AWS CLI."
                                        ]
                                    },
                                    {
                                        "sub_header": "Create the function deployment package",
                                        "content": [
                                            "To create your function, you create a deployment package containing your function code and its dependencies. For this       application, your function code uses a separate library for the PDF encryption.",
                                            "To create the deployment package",
                                            "  1 : Navigate to the project directory containing the lambda_function.py and requirements.txt           files you created or downloaded from GitHub earlier and create a new directory named package.",
                                            " 2 : Install the dependencies specified in the requirements.txt file in your package directory by running the following command. ",
                                            {
                                                "code_example": "pip install -r requirements.txt --target ./package/"
                                            },
                                            " 3 : Create a .zip file containing your application code and its dependencies. In Linux or MacOS, run the following commands from your           command line interface.  In Windows, use your preferred zip tool to create the lambda_function.zip file. Make sure that your         lambda_function.py file and the folders containing your dependencies are all at the root of the .zip file.",
                                            {
                                                "code_example": "cd package\nzip -r ../lambda_function.zip .\ncd ..\nzip lambda_function.zip lambda_function.py"
                                            },
                                            "You can also create your deployment package using a Python virtual environment. See Working with .zip file archives for Python Lambda functions"
                                        ]
                                    },
                                    {
                                        "sub_header": "Create the Lambda function",
                                        "content": [
                                            "You now use the deployment package you created in the previous step to deploy your Lambda function.",
                                            "  1.Console : EncryptPDF",
                                            "  2.AWS CLI : lambda_function.zip",
                                            "ConsoleTo create the function (console)To create your Lambda function using the console, you first create a basic function containing some ‘Hello world’ code. You then           replace this code with your own function code by uploading the.zip file you created in the previous step.To ensure that your function doesn't time out when encrypting large PDF files, you configure the function's memory and timeout settings.           You also set the function's log format to JSON. Configuring JSON formatted logs is necessary when using the provided test script so it can read the           function's invocation status from CloudWatch Logs to confirm successful invocation.Open the Functions page of the Lambda console.Make sure you're working in the same AWS Region you created your S3 bucket in. You can change your region using the drop-down             list at the top of the screen.Choose Create function.Choose Author from scratch.Under Basic information, do the following:For Function name, enter EncryptPDF.For Runtime choose Python 3.12.For Architecture, choose x86_64.Choose Create function.To upload the function code (console)In the Code source pane, choose Upload from.Choose .zip file.Choose Upload.In the file selector, select your .zip file and choose Open.Choose Save.To configure the function memory and timeout (console)Select the Configuration tab for your function.In the General configuration pane, choose Edit.Set Memory to 256 MB and Timeout to 15 seconds.Choose Save.To configure the log format (console)Select the Configuration tab for your function.Select Monitoring and operations tools.In the Logging configuration pane, choose Edit.For Logging configuration, select JSON.Choose Save.AWS CLITo create the function (AWS CLI)Run the following command from the directory containing your lambda_function.zip             file.For the region parameter, replace us-west-2 with the region you created your             S3 buckets in.aws lambda create-function --function-name EncryptPDF \\--zip-file fileb://lambda_function.zip --handler lambda_function.lambda_handler \\--runtime python3.12 --timeout 15 --memory-size 256 \\--role arn:aws:iam::123456789012:role/LambdaS3Role --region us-west-2 \\--logging-config LogFormat=JSON",
                                            "anchor",
                                            "anchor",
                                            "To create the function (console)",
                                            "To create your Lambda function using the console, you first create a basic function containing some ‘Hello world’ code. You then           replace this code with your own function code by uploading the.zip file you created in the previous step.",
                                            "To ensure that your function doesn't time out when encrypting large PDF files, you configure the function's memory and timeout settings.           You also set the function's log format to JSON. Configuring JSON formatted logs is necessary when using the provided test script so it can read the           function's invocation status from CloudWatch Logs to confirm successful invocation.",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Make sure you're working in the same AWS Region you created your S3 bucket in. You can change your region using the drop-down             list at the top of the screen.",
                                            "  3 : Choose Create function.",
                                            "  4 : Choose Author from scratch.",
                                            "  5 : Under Basic information, do the following:For Function name, enter EncryptPDF.For Runtime choose Python 3.12.For Architecture, choose x86_64.",
                                            "  6 : Choose Create function.",
                                            "To upload the function code (console)",
                                            "  1 : In the Code source pane, choose Upload from.",
                                            "  2 : Choose .zip file.",
                                            "  3 : Choose Upload.",
                                            "  4 : In the file selector, select your .zip file and choose Open.",
                                            "  5 : Choose Save.",
                                            "To configure the function memory and timeout (console)",
                                            "  1 : Select the Configuration tab for your function.",
                                            "  2 : In the General configuration pane, choose Edit.",
                                            "  3 : Set Memory to 256 MB and Timeout to 15 seconds.",
                                            "  4 : Choose Save.",
                                            "To configure the log format (console)",
                                            "  1 : Select the Configuration tab for your function.",
                                            "  2 : Select Monitoring and operations tools.",
                                            "  3 : In the Logging configuration pane, choose Edit.",
                                            "  4 : For Logging configuration, select JSON.",
                                            "  5 : Choose Save."
                                        ]
                                    },
                                    {
                                        "sub_header": "Configure an Amazon S3 trigger to invoke the function",
                                        "content": [
                                            "For your Lambda function to run when you upload a file to your source bucket, you need to configure a trigger for your function. You can     configure the Amazon S3 trigger using either the console or the AWS CLI.",
                                            "Important",
                                            "This procedure configures the S3 bucket to invoke your function every time that an object is created in the bucket. Be sure to       configure this only on the source bucket. If your Lambda function creates objects in the same bucket that invokes it, your function can be         invoked continuously in a loop. This can result         in un expected charges being billed to your AWS account.",
                                            "  1.Console : EncryptPDF",
                                            "  2.AWS CLI : source-account",
                                            "ConsoleTo configure the Amazon S3 trigger (console)Open the Functions page of the Lambda console and choose your function (EncryptPDF).Choose Add trigger.Select S3.Under Bucket, select your source bucket.Under Event types, select All object create events.Under Recursive invocation, select the check box to acknowledge that using the same S3 bucket for input                 and output is not recommended. You can learn more about recursive invocation patterns in Lambda by reading                Recursive patterns that cause run-away Lambda functions                in Serverless Land.Choose Add.When you create a trigger using the Lambda console, Lambda automatically creates a resource based policy                 to give the service you select permission to invoke your function. AWS CLITo configure the Amazon S3 trigger (AWS CLI)For your Amazon S3 source bucket to invoke your function when you add a file, you first need to configure permissions for your                 function using a resource based policy.                 A resource-based policy statement gives other AWS services permission to invoke your function. To give Amazon S3 permission to invoke                 your function, run the following CLI command. Be sure to replace the source-account parameter with your own AWS account ID and to                 use your own source bucket name.aws lambda add-permission --function-name EncryptPDF \\--principal s3.amazonaws.com --statement-id s3invoke --action \"lambda:InvokeFunction\" \\--source-arn arn:aws:s3:::SOURCEBUCKET \\--source-account 123456789012The policy you define with this command allows Amazon S3 to invoke your function only when an action takes place on your source bucket.NoteAlthough S3 bucket names are globally unique, when using resource-based policies it is best practice to specify that the                 bucket must belong to your account.  This is because if you delete a bucket, it is possible for another AWS account to create a                 bucket with the same Amazon Resource Name (ARN).Save the following JSON in a file named notification.json. When applied to your source bucket, this JSON                 configures the bucket to send a notification to your Lambda function every time a new object is added. Replace the AWS account               number and AWS Region in the Lambda function ARN with your own account number and region.{\"LambdaFunctionConfigurations\": [    {      \"Id\": \"EncryptPDFEventConfiguration\",      \"LambdaFunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:EncryptPDF\",      \"Events\": [ \"s3:ObjectCreated:Put\" ]    }  ]}Run the following CLI command to apply the notification settings in the JSON file you created to your source bucket. Replace                 SOURCEBUCKET with the name of your own source bucket.aws s3api put-bucket-notification-configuration --bucket SOURCEBUCKET \\--notification-configuration file://notification.jsonTo learn more about the put-bucket-notification-configuration command and the                 notification-configuration option, see put-bucket-notification-configuration                 in the AWS CLI Command Reference.",
                                            "anchor",
                                            "anchor",
                                            "To configure the Amazon S3 trigger (console)",
                                            "  1 : Open the Functions page of the Lambda console and choose your function (EncryptPDF).",
                                            "  2 : Choose Add trigger.",
                                            "  3 : Select S3.",
                                            "  4 : Under Bucket, select your source bucket.",
                                            "  5 : Under Event types, select All object create events.",
                                            "  6 : Under Recursive invocation, select the check box to acknowledge that using the same S3 bucket for input                 and output is not recommended. You can learn more about recursive invocation patterns in Lambda by reading                Recursive patterns that cause run-away Lambda functions                in Serverless Land.",
                                            "  7 : Choose Add.When you create a trigger using the Lambda console, Lambda automatically creates a resource based policy                 to give the service you select permission to invoke your function. "
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Deploy the resources using AWS SAM",
                                "content": [
                                    "To deploy the example app using the AWS SAM CLI, carry out the following steps.",
                                    "Make sure that you have         installed the latest version of the           CLI and that Docker is installed on your build machine.",
                                    "  1 : Edit the template.yaml file to specify the name of your             S3 buckets. S3 buckets must have globally unique names that meet the S3 bucket naming rules.Replace the bucket name EXAMPLE-BUCKET with a name of your choice consisting of lowercase letters, numbers, dots (.), and hyphens (-). For the destination           bucket, replace EXAMPLE-BUCKET-encrypted with <source-bucket-name>-encrypted, where <source-bucket> is the name           you chose for your source bucket.",
                                    " 2 : Run the following command from the directory in which you saved your template.yaml, lambda_function.py,             and requirements.txtfiles. This command gathers the build artifacts for your application and places them in the proper format and location to deploy them. Specifying           the --use-container option builds your function inside a Lambda-like Docker container. We use it here so you don't need to have Python 3.12          installed on your local machine for the build to work.During the build process, AWS SAM looks for the Lambda function code in the location you specified with the CodeUri           property in the template. In this case, we specified the current directory as the location (./).If a requirements.txt file is present, AWS SAM uses it to gather the specified dependencies. By default, AWS SAM creates a .zip             deployment package with your function code and dependencies. You can also choose to deploy your function as a container image using the             PackageType           property.",
                                    {
                                        "code_example": "sam build --use-container"
                                    },
                                    " 3 : To deploy your application and create the Lambda and Amazon S3 resources specified in your AWS SAM template, run the following             command. Using the --guided flag means that AWS SAM will show you prompts to guide you through the deployment process. For this             deployment, accept the default options by pressing Enter.",
                                    {
                                        "code_example": "sam deploy --guided"
                                    },
                                    "During the deployment process, AWS SAM creates the following resources in your AWS account:",
                                    "  1.An AWS CloudFormation stack             named sam-app",
                                    "  2.A Lambda function with the name EncryptPDF",
                                    "  3.Two S3 buckets with the names you chose when you edited the template.yaml AWS SAM template file",
                                    "  4.An IAM execution role for your function with the name format sam-app-EncryptPDFFunctionRole-2qGaapHFWOQ8",
                                    "When AWS SAM finishes creating your resources, you should see the following message:",
                                    "Successfully created/updated stack - sam-app in us-west-2"
                                ]
                            }
                        ]
                    },
                    {
                        "sub_header": "Testing the app",
                        "content": [
                            "To test your app, you upload a PDF file to your source bucket, and confirm that Lambda creates an encrypted version of the file in your       destination bucket. In this example, you can either test this manually using the console or the AWS CLI, or by using the provided test script.",
                            "For production applications, you can use traditional test methods and techniques, such as unit testing, to confirm the       correct functioning of your Lambda function code. Best practice is also to conduct tests like those in the provided test script which perform integration       testing with real, cloud-based resources. Integration testing in the cloud confirms that your infrastructure has been correctly deployed and that events flow       between different services as expected. To learn more, see How to test serverless functions and applications.",
                            {
                                "sub_header": "Testing the app manually",
                                "content": [
                                    "You can test your function manually by adding a PDF file to           your Amazon S3 source bucket. When you add your file to the source bucket, your Lambda function should be automatically invoked and should store an encrypted           version of the file in your target bucket.",
                                    "  1.Console : filename_encrypted.pdf",
                                    "  2.AWS CLI : --bucket",
                                    "ConsoleTo test your app by uploading a file (console)To upload a PDF file to your S3 bucket, do the following:Open the Buckets page of the Amazon S3 console and choose your source bucket.Choose Upload.Choose Add files and use the file selector to choose the PDF file you want to upload.Choose Open, then choose Upload.Verify that Lambda has saved an encrypted version of your PDF file in your target bucket by doing the following:Navigate back to the Buckets page of the Amazon S3 console and choose your destination bucket.In the Objects pane, you should now see a file with name format filename_encrypted.pdf (where                         filename.pdf was the name of the file you uploaded to your source bucket).                        To download your encrypted PDF, select the file, then choose Download.Confirm that you can open the downloaded file with the password your Lambda function protected it with (my-secret-password).AWS CLITo test your app by uploading a file (AWS CLI)From the directory containing the PDF file you want to upload, run the following CLI command. Replace the --bucket                     parameter with the name of your source bucket. For the --key and --body parameters, use the filename of                     your test file.aws s3api put-object --bucket SOURCEBUCKET --key test.pdf --body ./test.pdfVerify that your function has created an encrypted version of your file and saved it to your target S3 bucket. Run the                     following CLI command, replacing SOURCEBUCKET-encrypted with the name of your own destination bucket.aws s3api list-objects-v2 --bucket SOURCEBUCKET-encryptedIf your function runs successfully, you’ll see output similar to the following. Your target bucket should contain a file with the                     name format <your_test_file>_encrypted.pdf, where <your_test_file>                     is the name of the file you uploaded.{    \"Contents\": [        {            \"Key\": \"test_encrypted.pdf\",            \"LastModified\": \"2023-06-07T00:15:50+00:00\",            \"ETag\": \"\\\"7781a43e765a8301713f533d70968a1e\\\"\",            \"Size\": 2763,            \"StorageClass\": \"STANDARD\"        }    ]}To download the file that Lambda saved in your destination bucket, run the following CLI command. Replace the --bucket                     parameter with the name of your destination bucket. For the --key parameter, use the filename <your_test_file>_encrypted.pdf,                     where <your_test_file> is the name of the the test file you uploaded.aws s3api get-object --bucket SOURCEBUCKET-encrypted --key test_encrypted.pdf my_encrypted_file.pdfThis command downloads the file to your current directory and saves it as my_encrypted_file.pdf.Confirm the you can open the downloaded file with the password your Lambda function protected it with (my-secret-password).",
                                    "anchor",
                                    "anchor",
                                    "To test your app by uploading a file (console)",
                                    "  1 : To upload a PDF file to your S3 bucket, do the following:Open the Buckets page of the Amazon S3 console and choose your source bucket.Choose Upload.Choose Add files and use the file selector to choose the PDF file you want to upload.Choose Open, then choose Upload.",
                                    "  2 : Verify that Lambda has saved an encrypted version of your PDF file in your target bucket by doing the following:Navigate back to the Buckets page of the Amazon S3 console and choose your destination bucket.In the Objects pane, you should now see a file with name format filename_encrypted.pdf (where                         filename.pdf was the name of the file you uploaded to your source bucket).                        To download your encrypted PDF, select the file, then choose Download.Confirm that you can open the downloaded file with the password your Lambda function protected it with (my-secret-password)."
                                ]
                            },
                            {
                                "sub_header": "Testing the app with the automated script",
                                "content": [
                                    "To test your app using the provided test script, first ensure that the pytest module is installed in your local environment. You can install       pytest by running the following command:",
                                    "pip install pytest",
                                    "You also need to edit the code in the test_pdf_encrypt.py file to replace the placeholder bucket names with the names of           your Amazon S3 source and destination buckets. Make the following changes to test_pdf_encrypt.py:",
                                    "  1.In the test_source_bucket_available function, replace EXAMPLE-BUCKET with the name of your source bucket.",
                                    "  2.In the test_encrypted_file_in_bucket function, replace EXAMPLE-BUCKET-encrypted with <source-bucket>-encrypted,            where <source-bucket> is the name of your source bucket.",
                                    "  3.In the cleanup function, replace EXAMPLE-BUCKET with the name of your source bucket, and replace               EXAMPLE-BUCKET-encrypted with ≪source-bucket>-encrypted, where <source-bucket> is the name of your source bucket.",
                                    "To run the tests do the following:",
                                    "  1.Save a PDF file named test.pdfin the directory containing the test_pdf_encrypt.py and pytest.ini             files.",
                                    "  2.Open a terminal or shell program and run the following command from the directory containing the test files.pytest -s -v",
                                    {
                                        "code_example": "pytest -s -v"
                                    },
                                    "When the test completes, you should see output like the following:",
                                    "============================================================== test session starts =========================================================platform linux -- Python 3.12.2, pytest-7.2.2, pluggy-1.0.0 -- /usr/bin/python3cachedir: .pytest_cachehypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/pdf_encrypt_app/.hypothesis/examples')Test order randomisation NOT enabled. Enable with --random-order or --random-order-bucket=<bucket_type>rootdir: /home/pdf_encrypt_app, configfile: pytest.iniplugins: anyio-3.7.1, hypothesis-6.70.0, localserver-0.7.1, random-order-1.1.0collected 4 itemstest_pdf_encrypt.py::test_source_bucket_available PASSEDtest_pdf_encrypt.py::test_lambda_invoked PASSEDtest_pdf_encrypt.py::test_encrypted_file_in_bucket PASSEDtest_pdf_encrypt.py::test_cleanup PASSEDDeleted test.pdf from EXAMPLE-BUCKETDeleted test_encrypted.pdf from EXAMPLE-BUCKET-encrypted=============================================================== 4 passed in 7.32s =========================================================="
                                ]
                            }
                        ]
                    },
                    {
                        "sub_header": "Next steps",
                        "content": [
                            "Now you've created this example app, you can use the provided code as a basis to create other types of file-processing application. Modify the     code in the lambda_function.py file to implement the file-processing logic for your use case.",
                            "Many typical file-processing use cases involve image processing. When using Python, the most popular image-processing libraries like       pillow typically contain C or C++ components. In order to ensure that your function's deployment package is     compatible with the Lambda execution environment, it's important to use the correct source distribution binary.",
                            "When deploying your resources with AWS SAM, you need to take some extra steps to include the right source distribution in your deployment package. Because AWS SAM won't install dependencies     for a different platform than your build machine, specifying the correct source distribution (.whl file) in your requirements.txt       file won't work if your build machine uses an operating system or architecture that's different from the Lambda execution environment. Instead, you should do one of the following:",
                            "  1.Use the --use-container option when running sam build. When you specify this option, AWS SAM downloads a container base image that's         compatible with the Lambda execution environment and builds your function's deployment package in a Docker container using that image. To learn more, see           Building a Lambda           function inside of a provided container.",
                            "  2.Build your function's .zip deployment package yourself using the correct source distribution binary and save the .zip file in the directory you specify as the           CodeUri in the AWS SAM template. To learn more about building .zip deployment packages for Python using binary distributions, see           Creating a .zip deployment package with dependencies and Creating .zip deployment packages with native libraries."
                        ]
                    }
                ]
            },
            {
                "title": "Scheduled-maintenance app",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/scheduled-task-app.html",
                "sections": [
                    "You can use AWS Lambda to replace scheduled processes such as automated system backups, file conversions, and maintenance tasks.   In this example, you create a serverless application that performs regular scheduled maintenance on a DynamoDB table by deleting old entries. The app uses EventBridge Scheduler to invoke a   Lambda function on a cron schedule. When invoked, the function queries the table for items older than one year, and deletes them. The function logs each deleted item  in CloudWatch Logs.",
                    "To implement this example, first create a DynamoDB table and populate it with some test data for your function to query. Then, create a Python Lambda function with   an EventBridge Scheduler trigger and an IAM execution role that gives the function permission to read, and delete, items from your table.",
                    "Tip",
                    "If you’re new to Lambda, we recommend that you complete the tutorial Create your first Lambda function before      creating this example app.",
                    "You can deploy your app manually by creating and configuring resources with the AWS Management Console. You can     also deploy the app by using the AWS Serverless Application Model (AWS SAM). AWS SAM is an infrastructure as code (IaC) tool. With IaC, you don’t create     resources manually, but define them in code and then deploy them automatically.",
                    "If you want to learn more about using Lambda with IaC before deploying this example app, see Using Lambda with infrastructure as code (IaC).",
                    {
                        "sub_header": "Prerequisites",
                        "content": [
                            "Before you can create the example app, make sure you have the required command line tools and programs installed.",
                            "  1.Python : To populate the DynamoDB table you create to test your app, this example uses a  script and a CSV file to write data into the table. Make sure you have          version 3.8 or later installed on your machine.",
                            "  2.AWS SAM CLI : If you want to create the DynamoDB table and deploy the example app using AWS SAM, you need to install the .           Follow the installation instructions           in the AWS SAM User Guide.",
                            "  3.AWS CLI : To use the provided Python script to populate your test table, you need to have installed and configured the . This is because the script uses           the AWS SDK for Python (Boto3), which needs access to your AWS Identity and Access Management (IAM) credentials. You also need the  installed to deploy resources using AWS SAM. Install the CLI by following           the installation instructions in the AWS Command Line Interface User Guide.",
                            "  4.Docker : To deploy the app using AWS SAM,  must also be installed on your build machine. Follow the instructions in Install  Engine         on the  documentation website."
                        ]
                    },
                    {
                        "sub_header": "Downloading the example app files",
                        "content": [
                            "To create the example database and the scheduled-maintenance app, you need to create the following files in your project directory:",
                            "Example database files",
                            "  1.template.yaml - an AWS SAM template you can use to create the DynamoDB table",
                            "  2.sample_data.csv - a CSV file containing sample data to load into your table",
                            "  3.load_sample_data.py - a Python script that writes the data in the CSV file into the table",
                            "Scheduled-maintenance app files",
                            "  1.lambda_function.py - the Python function code for the Lambda function that performs the database maintenance",
                            "  2.requirements.txt - a manifest file defining the dependencies that your Python function code requires",
                            "  3.template.yaml - an AWS SAM template you can use to deploy the app",
                            "Test file",
                            "  1.test_app.py - a Python script that scans the table and confirms successful operation of your function by outputting all records older than one year",
                            "Expand the following sections to view the code and to learn more about the role of each file in creating and testing your app. To create the       files on your local machine, copy and paste the code below.",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: SAM Template for DynamoDB Table with Order_number as Partition Key and Date as Sort Key\n\nResources:\n  MyDynamoDBTable:\n    Type: AWS::DynamoDB::Table\n    DeletionPolicy: Retain\n    UpdateReplacePolicy: Retain\n    Properties:\n      TableName: MyOrderTable\n      BillingMode: PAY_PER_REQUEST\n      AttributeDefinitions:\n        - AttributeName: Order_number\n          AttributeType: S\n        - AttributeName: Date\n          AttributeType: S\n      KeySchema:\n        - AttributeName: Order_number\n          KeyType: HASH\n        - AttributeName: Date\n          KeyType: RANGE\n      SSESpecification:\n        SSEEnabled: true\n      GlobalSecondaryIndexes:\n        - IndexName: Date-index\n          KeySchema:\n            - AttributeName: Date\n              KeyType: HASH\n          Projection:\n            ProjectionType: ALL\n      PointInTimeRecoverySpecification:\n        PointInTimeRecoveryEnabled: true\n\nOutputs:\n  TableName:\n    Description: DynamoDB Table Name\n    Value: !Ref MyDynamoDBTable\n  TableArn:\n    Description: DynamoDB Table ARN\n    Value: !GetAtt MyDynamoDBTable.Arn"
                            },
                            "Note",
                            "AWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the           example database and another to create the app itself. Save them in separate sub-directories in your project folder.",
                            "This AWS SAM template defines the DynamoDB table resource you create to test your app. The table uses a primary key of Order_number with a sort           key of Date. In order for your Lambda function to find items directly by date, we also define a Global Secondary Index         named Date-index.",
                            "To learn more about creating and configuring a DynamoDB table using the AWS::DynamoDB::Table resource, see AWS::DynamoDB::Table in           the AWS CloudFormation User Guide.",
                            "AWS SAM template (example DynamoDB table)",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: SAM Template for DynamoDB Table with Order_number as Partition Key and Date as Sort Key\n\nResources:\n  MyDynamoDBTable:\n    Type: AWS::DynamoDB::Table\n    DeletionPolicy: Retain\n    UpdateReplacePolicy: Retain\n    Properties:\n      TableName: MyOrderTable\n      BillingMode: PAY_PER_REQUEST\n      AttributeDefinitions:\n        - AttributeName: Order_number\n          AttributeType: S\n        - AttributeName: Date\n          AttributeType: S\n      KeySchema:\n        - AttributeName: Order_number\n          KeyType: HASH\n        - AttributeName: Date\n          KeyType: RANGE\n      SSESpecification:\n        SSEEnabled: true\n      GlobalSecondaryIndexes:\n        - IndexName: Date-index\n          KeySchema:\n            - AttributeName: Date\n              KeyType: HASH\n          Projection:\n            ProjectionType: ALL\n      PointInTimeRecoverySpecification:\n        PointInTimeRecoveryEnabled: true\n\nOutputs:\n  TableName:\n    Description: DynamoDB Table Name\n    Value: !Ref MyDynamoDBTable\n  TableArn:\n    Description: DynamoDB Table ARN\n    Value: !GetAtt MyDynamoDBTable.Arn"
                            },
                            "Note",
                            "AWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the           example database and another to create the app itself. Save them in separate sub-directories in your project folder.",
                            "This AWS SAM template defines the DynamoDB table resource you create to test your app. The table uses a primary key of Order_number with a sort           key of Date. In order for your Lambda function to find items directly by date, we also define a Global Secondary Index         named Date-index.",
                            "To learn more about creating and configuring a DynamoDB table using the AWS::DynamoDB::Table resource, see AWS::DynamoDB::Table in           the AWS CloudFormation User Guide.",
                            "Copy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Description: SAM Template for DynamoDB Table with Order_number as Partition Key and Date as Sort KeyResources:  MyDynamoDBTable:    Type: AWS::DynamoDB::Table    DeletionPolicy: Retain    UpdateReplacePolicy: Retain    Properties:      TableName: MyOrderTable      BillingMode: PAY_PER_REQUEST      AttributeDefinitions:        - AttributeName: Order_number          AttributeType: S        - AttributeName: Date          AttributeType: S      KeySchema:        - AttributeName: Order_number          KeyType: HASH        - AttributeName: Date          KeyType: RANGE      SSESpecification:        SSEEnabled: true      GlobalSecondaryIndexes:        - IndexName: Date-index          KeySchema:            - AttributeName: Date              KeyType: HASH          Projection:            ProjectionType: ALL      PointInTimeRecoverySpecification:        PointInTimeRecoveryEnabled: trueOutputs:  TableName:    Description: DynamoDB Table Name    Value: !Ref MyDynamoDBTable  TableArn:    Description: DynamoDB Table ARN    Value: !GetAtt MyDynamoDBTable.ArnNoteAWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the           example database and another to create the app itself. Save them in separate sub-directories in your project folder.This AWS SAM template defines the DynamoDB table resource you create to test your app. The table uses a primary key of Order_number with a sort           key of Date. In order for your Lambda function to find items directly by date, we also define a Global Secondary Index         named Date-index.To learn more about creating and configuring a DynamoDB table using the AWS::DynamoDB::Table resource, see AWS::DynamoDB::Table in           the AWS CloudFormation User Guide.AWS SAM template (example DynamoDB table)Copy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Description: SAM Template for DynamoDB Table with Order_number as Partition Key and Date as Sort KeyResources:  MyDynamoDBTable:    Type: AWS::DynamoDB::Table    DeletionPolicy: Retain    UpdateReplacePolicy: Retain    Properties:      TableName: MyOrderTable      BillingMode: PAY_PER_REQUEST      AttributeDefinitions:        - AttributeName: Order_number          AttributeType: S        - AttributeName: Date          AttributeType: S      KeySchema:        - AttributeName: Order_number          KeyType: HASH        - AttributeName: Date          KeyType: RANGE      SSESpecification:        SSEEnabled: true      GlobalSecondaryIndexes:        - IndexName: Date-index          KeySchema:            - AttributeName: Date              KeyType: HASH          Projection:            ProjectionType: ALL      PointInTimeRecoverySpecification:        PointInTimeRecoveryEnabled: trueOutputs:  TableName:    Description: DynamoDB Table Name    Value: !Ref MyDynamoDBTable  TableArn:    Description: DynamoDB Table ARN    Value: !GetAtt MyDynamoDBTable.ArnNoteAWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the           example database and another to create the app itself. Save them in separate sub-directories in your project folder.This AWS SAM template defines the DynamoDB table resource you create to test your app. The table uses a primary key of Order_number with a sort           key of Date. In order for your Lambda function to find items directly by date, we also define a Global Secondary Index         named Date-index.To learn more about creating and configuring a DynamoDB table using the AWS::DynamoDB::Table resource, see AWS::DynamoDB::Table in           the AWS CloudFormation User Guide.",
                            "Copy and paste the following code into a file named sample_data.csv.",
                            {
                                "code_example": "Date,Order_number,CustomerName,ProductID,Quantity,TotalAmount\n2023-09-01,ORD001,Alejandro Rosalez,PROD123,2,199.98\n2023-09-01,ORD002,Akua Mansa,PROD456,1,49.99\n2023-09-02,ORD003,Ana Carolina Silva,PROD789,3,149.97\n2023-09-03,ORD004,Arnav Desai,PROD123,1,99.99\n2023-10-01,ORD005,Carlos Salazar,PROD456,2,99.98\n2023-10-02,ORD006,Diego Ramirez,PROD789,1,49.99\n2023-10-03,ORD007,Efua Owusu,PROD123,4,399.96\n2023-10-04,ORD008,John Stiles,PROD456,2,99.98\n2023-10-05,ORD009,Jorge Souza,PROD789,3,149.97\n2023-10-06,ORD010,Kwaku Mensah,PROD123,1,99.99\n2023-11-01,ORD011,Li Juan,PROD456,5,249.95\n2023-11-02,ORD012,Marcia Oliveria,PROD789,2,99.98\n2023-11-03,ORD013,Maria Garcia,PROD123,3,299.97\n2023-11-04,ORD014,Martha Rivera,PROD456,1,49.99\n2023-11-05,ORD015,Mary Major,PROD789,4,199.96\n2023-12-01,ORD016,Mateo Jackson,PROD123,2,199.99\n2023-12-02,ORD017,Nikki Wolf,PROD456,3,149.97\n2023-12-03,ORD018,Pat Candella,PROD789,1,49.99\n2023-12-04,ORD019,Paulo Santos,PROD123,5,499.95\n2023-12-05,ORD020,Richard Roe,PROD456,2,99.98\n2024-01-01,ORD021,Saanvi Sarkar,PROD789,3,149.97\n2024-01-02,ORD022,Shirley Rodriguez,PROD123,1,99.99\n2024-01-03,ORD023,Sofia Martinez,PROD456,4,199.96\n2024-01-04,ORD024,Terry Whitlock,PROD789,2,99.98\n2024-01-05,ORD025,Wang Xiulan,PROD123,3,299.97"
                            },
                            "This file contains some example test data to populate your DynamoDB table with in a standard comma-separated values (CSV) format.",
                            "Sample database data file",
                            "Copy and paste the following code into a file named sample_data.csv.",
                            {
                                "code_example": "Date,Order_number,CustomerName,ProductID,Quantity,TotalAmount\n2023-09-01,ORD001,Alejandro Rosalez,PROD123,2,199.98\n2023-09-01,ORD002,Akua Mansa,PROD456,1,49.99\n2023-09-02,ORD003,Ana Carolina Silva,PROD789,3,149.97\n2023-09-03,ORD004,Arnav Desai,PROD123,1,99.99\n2023-10-01,ORD005,Carlos Salazar,PROD456,2,99.98\n2023-10-02,ORD006,Diego Ramirez,PROD789,1,49.99\n2023-10-03,ORD007,Efua Owusu,PROD123,4,399.96\n2023-10-04,ORD008,John Stiles,PROD456,2,99.98\n2023-10-05,ORD009,Jorge Souza,PROD789,3,149.97\n2023-10-06,ORD010,Kwaku Mensah,PROD123,1,99.99\n2023-11-01,ORD011,Li Juan,PROD456,5,249.95\n2023-11-02,ORD012,Marcia Oliveria,PROD789,2,99.98\n2023-11-03,ORD013,Maria Garcia,PROD123,3,299.97\n2023-11-04,ORD014,Martha Rivera,PROD456,1,49.99\n2023-11-05,ORD015,Mary Major,PROD789,4,199.96\n2023-12-01,ORD016,Mateo Jackson,PROD123,2,199.99\n2023-12-02,ORD017,Nikki Wolf,PROD456,3,149.97\n2023-12-03,ORD018,Pat Candella,PROD789,1,49.99\n2023-12-04,ORD019,Paulo Santos,PROD123,5,499.95\n2023-12-05,ORD020,Richard Roe,PROD456,2,99.98\n2024-01-01,ORD021,Saanvi Sarkar,PROD789,3,149.97\n2024-01-02,ORD022,Shirley Rodriguez,PROD123,1,99.99\n2024-01-03,ORD023,Sofia Martinez,PROD456,4,199.96\n2024-01-04,ORD024,Terry Whitlock,PROD789,2,99.98\n2024-01-05,ORD025,Wang Xiulan,PROD123,3,299.97"
                            },
                            "This file contains some example test data to populate your DynamoDB table with in a standard comma-separated values (CSV) format.",
                            "Copy and paste the following code into a file named sample_data.csv.Date,Order_number,CustomerName,ProductID,Quantity,TotalAmount2023-09-01,ORD001,Alejandro Rosalez,PROD123,2,199.982023-09-01,ORD002,Akua Mansa,PROD456,1,49.992023-09-02,ORD003,Ana Carolina Silva,PROD789,3,149.972023-09-03,ORD004,Arnav Desai,PROD123,1,99.992023-10-01,ORD005,Carlos Salazar,PROD456,2,99.982023-10-02,ORD006,Diego Ramirez,PROD789,1,49.992023-10-03,ORD007,Efua Owusu,PROD123,4,399.962023-10-04,ORD008,John Stiles,PROD456,2,99.982023-10-05,ORD009,Jorge Souza,PROD789,3,149.972023-10-06,ORD010,Kwaku Mensah,PROD123,1,99.992023-11-01,ORD011,Li Juan,PROD456,5,249.952023-11-02,ORD012,Marcia Oliveria,PROD789,2,99.982023-11-03,ORD013,Maria Garcia,PROD123,3,299.972023-11-04,ORD014,Martha Rivera,PROD456,1,49.992023-11-05,ORD015,Mary Major,PROD789,4,199.962023-12-01,ORD016,Mateo Jackson,PROD123,2,199.992023-12-02,ORD017,Nikki Wolf,PROD456,3,149.972023-12-03,ORD018,Pat Candella,PROD789,1,49.992023-12-04,ORD019,Paulo Santos,PROD123,5,499.952023-12-05,ORD020,Richard Roe,PROD456,2,99.982024-01-01,ORD021,Saanvi Sarkar,PROD789,3,149.972024-01-02,ORD022,Shirley Rodriguez,PROD123,1,99.992024-01-03,ORD023,Sofia Martinez,PROD456,4,199.962024-01-04,ORD024,Terry Whitlock,PROD789,2,99.982024-01-05,ORD025,Wang Xiulan,PROD123,3,299.97This file contains some example test data to populate your DynamoDB table with in a standard comma-separated values (CSV) format.Sample database data fileCopy and paste the following code into a file named sample_data.csv.Date,Order_number,CustomerName,ProductID,Quantity,TotalAmount2023-09-01,ORD001,Alejandro Rosalez,PROD123,2,199.982023-09-01,ORD002,Akua Mansa,PROD456,1,49.992023-09-02,ORD003,Ana Carolina Silva,PROD789,3,149.972023-09-03,ORD004,Arnav Desai,PROD123,1,99.992023-10-01,ORD005,Carlos Salazar,PROD456,2,99.982023-10-02,ORD006,Diego Ramirez,PROD789,1,49.992023-10-03,ORD007,Efua Owusu,PROD123,4,399.962023-10-04,ORD008,John Stiles,PROD456,2,99.982023-10-05,ORD009,Jorge Souza,PROD789,3,149.972023-10-06,ORD010,Kwaku Mensah,PROD123,1,99.992023-11-01,ORD011,Li Juan,PROD456,5,249.952023-11-02,ORD012,Marcia Oliveria,PROD789,2,99.982023-11-03,ORD013,Maria Garcia,PROD123,3,299.972023-11-04,ORD014,Martha Rivera,PROD456,1,49.992023-11-05,ORD015,Mary Major,PROD789,4,199.962023-12-01,ORD016,Mateo Jackson,PROD123,2,199.992023-12-02,ORD017,Nikki Wolf,PROD456,3,149.972023-12-03,ORD018,Pat Candella,PROD789,1,49.992023-12-04,ORD019,Paulo Santos,PROD123,5,499.952023-12-05,ORD020,Richard Roe,PROD456,2,99.982024-01-01,ORD021,Saanvi Sarkar,PROD789,3,149.972024-01-02,ORD022,Shirley Rodriguez,PROD123,1,99.992024-01-03,ORD023,Sofia Martinez,PROD456,4,199.962024-01-04,ORD024,Terry Whitlock,PROD789,2,99.982024-01-05,ORD025,Wang Xiulan,PROD123,3,299.97This file contains some example test data to populate your DynamoDB table with in a standard comma-separated values (CSV) format.",
                            "Copy and paste the following code into a file named load_sample_data.py.",
                            {
                                "code_example": "import boto3\nimport csv\nfrom decimal import Decimal\n\n# Initialize the DynamoDB client\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('MyOrderTable') \nprint(\"DDB client initialized.\")\n\ndef load_data_from_csv(filename):\n    with open(filename, 'r') as file:\n        csv_reader = csv.DictReader(file)\n        for row in csv_reader:\n            item = {\n                'Order_number': row['Order_number'],\n                'Date': row['Date'],\n                'CustomerName': row['CustomerName'],\n                'ProductID': row['ProductID'],\n                'Quantity': int(row['Quantity']),\n                'TotalAmount': Decimal(str(row['TotalAmount']))\n            }\n            table.put_item(Item=item)\n            print(f\"Added item: {item['Order_number']} - {item['Date']}\")\n\nif __name__ == \"__main__\":\n    load_data_from_csv('sample_data.csv')\n    print(\"Data loading completed.\")"
                            },
                            "This Python script first uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table. It then iterates over each row in the example-data CSV file, creates an item from that row, and            writes the item to the DynamoDB table using the boto3 SDK.",
                            "Python script to load sample data",
                            "Copy and paste the following code into a file named load_sample_data.py.",
                            {
                                "code_example": "import boto3\nimport csv\nfrom decimal import Decimal\n\n# Initialize the DynamoDB client\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('MyOrderTable') \nprint(\"DDB client initialized.\")\n\ndef load_data_from_csv(filename):\n    with open(filename, 'r') as file:\n        csv_reader = csv.DictReader(file)\n        for row in csv_reader:\n            item = {\n                'Order_number': row['Order_number'],\n                'Date': row['Date'],\n                'CustomerName': row['CustomerName'],\n                'ProductID': row['ProductID'],\n                'Quantity': int(row['Quantity']),\n                'TotalAmount': Decimal(str(row['TotalAmount']))\n            }\n            table.put_item(Item=item)\n            print(f\"Added item: {item['Order_number']} - {item['Date']}\")\n\nif __name__ == \"__main__\":\n    load_data_from_csv('sample_data.csv')\n    print(\"Data loading completed.\")"
                            },
                            "This Python script first uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table. It then iterates over each row in the example-data CSV file, creates an item from that row, and            writes the item to the DynamoDB table using the boto3 SDK.",
                            "Copy and paste the following code into a file named load_sample_data.py.import boto3import csvfrom decimal import Decimal# Initialize the DynamoDB clientdynamodb = boto3.resource('dynamodb')table = dynamodb.Table('MyOrderTable') print(\"DDB client initialized.\")def load_data_from_csv(filename):    with open(filename, 'r') as file:        csv_reader = csv.DictReader(file)        for row in csv_reader:            item = {                'Order_number': row['Order_number'],                'Date': row['Date'],                'CustomerName': row['CustomerName'],                'ProductID': row['ProductID'],                'Quantity': int(row['Quantity']),                'TotalAmount': Decimal(str(row['TotalAmount']))            }            table.put_item(Item=item)            print(f\"Added item: {item['Order_number']} - {item['Date']}\")if __name__ == \"__main__\":    load_data_from_csv('sample_data.csv')    print(\"Data loading completed.\")This Python script first uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table. It then iterates over each row in the example-data CSV file, creates an item from that row, and            writes the item to the DynamoDB table using the boto3 SDK.Python script to load sample dataCopy and paste the following code into a file named load_sample_data.py.import boto3import csvfrom decimal import Decimal# Initialize the DynamoDB clientdynamodb = boto3.resource('dynamodb')table = dynamodb.Table('MyOrderTable') print(\"DDB client initialized.\")def load_data_from_csv(filename):    with open(filename, 'r') as file:        csv_reader = csv.DictReader(file)        for row in csv_reader:            item = {                'Order_number': row['Order_number'],                'Date': row['Date'],                'CustomerName': row['CustomerName'],                'ProductID': row['ProductID'],                'Quantity': int(row['Quantity']),                'TotalAmount': Decimal(str(row['TotalAmount']))            }            table.put_item(Item=item)            print(f\"Added item: {item['Order_number']} - {item['Date']}\")if __name__ == \"__main__\":    load_data_from_csv('sample_data.csv')    print(\"Data loading completed.\")This Python script first uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table. It then iterates over each row in the example-data CSV file, creates an item from that row, and            writes the item to the DynamoDB table using the boto3 SDK.",
                            "Copy and paste the following code into a file named lambda_function.py.",
                            {
                                "code_example": "import boto3\nfrom datetime import datetime, timedelta\nfrom boto3.dynamodb.conditions import Key, Attr\nimport logging\n\nlogger = logging.getLogger()\nlogger.setLevel(\"INFO\")\n\ndef lambda_handler(event, context):\n    # Initialize the DynamoDB client\n    dynamodb = boto3.resource('dynamodb')\n    \n    # Specify the table name\n    table_name = 'MyOrderTable'\n    table = dynamodb.Table(table_name)\n    \n    # Get today's date\n    today = datetime.now()\n    \n    # Calculate the date one year ago\n    one_year_ago = (today - timedelta(days=365)).strftime('%Y-%m-%d')\n    \n    # Scan the table using a global secondary index\n    response = table.scan(\n        IndexName='Date-index',\n        FilterExpression='#date < :one_year_ago',\n        ExpressionAttributeNames={\n            '#date': 'Date'\n        },\n        ExpressionAttributeValues={\n            ':one_year_ago': one_year_ago\n        }\n    )\n    \n     # Delete old items\n    with table.batch_writer() as batch:\n        for item in response['Items']:\n            Order_number = item['Order_number']\n            batch.delete_item(\n                Key={\n                    'Order_number': Order_number,\n                    'Date': item['Date']\n                }\n            )\n            logger.info(f'deleted order number {Order_number}')\n    \n    # Check if there are more items to scan\n    while 'LastEvaluatedKey' in response:\n        response = table.scan(\n            IndexName='DateIndex',\n            FilterExpression='#date < :one_year_ago',\n            ExpressionAttributeNames={\n                '#date': 'Date'\n            },\n            ExpressionAttributeValues={\n                ':one_year_ago': one_year_ago\n            },\n            ExclusiveStartKey=response['LastEvaluatedKey']\n        )\n        \n        # Delete old items\n        with table.batch_writer() as batch:\n            for item in response['Items']:\n                batch.delete_item(\n                    Key={\n                        'Order_number': item['Order_number'],\n                        'Date': item['Date']\n                    }\n                )\n    \n    return {\n        'statusCode': 200,\n        'body': 'Cleanup completed successfully'\n    }"
                            },
                            "The Python function code contains the handler function (lambda_handler) that Lambda runs when your function is     invoked.",
                            "When the function is invoked by EventBridge Scheduler, it uses the AWS SDK for Python (Boto3) to create a connection to the DynamoDB table on which the scheduled maintenance task is to be performed.     It then uses the Python datetime library to calculate the date one year ago, before scanning the table for items older than this and deleting them.",
                            "Note that responses from DynamoDB query and scan operations are limited to a maximum of 1 MB in size. If the response is larger than 1 MB, DynamoDB paginates the       data and returns a LastEvaluatedKey element in the response. To ensure that our function processes all the records in the table, we check for the presence of this key       and continue performing table scans from the last evaluated position until the whole table has been scanned.",
                            "Python function code",
                            "Copy and paste the following code into a file named lambda_function.py.",
                            {
                                "code_example": "import boto3\nfrom datetime import datetime, timedelta\nfrom boto3.dynamodb.conditions import Key, Attr\nimport logging\n\nlogger = logging.getLogger()\nlogger.setLevel(\"INFO\")\n\ndef lambda_handler(event, context):\n    # Initialize the DynamoDB client\n    dynamodb = boto3.resource('dynamodb')\n    \n    # Specify the table name\n    table_name = 'MyOrderTable'\n    table = dynamodb.Table(table_name)\n    \n    # Get today's date\n    today = datetime.now()\n    \n    # Calculate the date one year ago\n    one_year_ago = (today - timedelta(days=365)).strftime('%Y-%m-%d')\n    \n    # Scan the table using a global secondary index\n    response = table.scan(\n        IndexName='Date-index',\n        FilterExpression='#date < :one_year_ago',\n        ExpressionAttributeNames={\n            '#date': 'Date'\n        },\n        ExpressionAttributeValues={\n            ':one_year_ago': one_year_ago\n        }\n    )\n    \n     # Delete old items\n    with table.batch_writer() as batch:\n        for item in response['Items']:\n            Order_number = item['Order_number']\n            batch.delete_item(\n                Key={\n                    'Order_number': Order_number,\n                    'Date': item['Date']\n                }\n            )\n            logger.info(f'deleted order number {Order_number}')\n    \n    # Check if there are more items to scan\n    while 'LastEvaluatedKey' in response:\n        response = table.scan(\n            IndexName='DateIndex',\n            FilterExpression='#date < :one_year_ago',\n            ExpressionAttributeNames={\n                '#date': 'Date'\n            },\n            ExpressionAttributeValues={\n                ':one_year_ago': one_year_ago\n            },\n            ExclusiveStartKey=response['LastEvaluatedKey']\n        )\n        \n        # Delete old items\n        with table.batch_writer() as batch:\n            for item in response['Items']:\n                batch.delete_item(\n                    Key={\n                        'Order_number': item['Order_number'],\n                        'Date': item['Date']\n                    }\n                )\n    \n    return {\n        'statusCode': 200,\n        'body': 'Cleanup completed successfully'\n    }"
                            },
                            "The Python function code contains the handler function (lambda_handler) that Lambda runs when your function is     invoked.",
                            "When the function is invoked by EventBridge Scheduler, it uses the AWS SDK for Python (Boto3) to create a connection to the DynamoDB table on which the scheduled maintenance task is to be performed.     It then uses the Python datetime library to calculate the date one year ago, before scanning the table for items older than this and deleting them.",
                            "Note that responses from DynamoDB query and scan operations are limited to a maximum of 1 MB in size. If the response is larger than 1 MB, DynamoDB paginates the       data and returns a LastEvaluatedKey element in the response. To ensure that our function processes all the records in the table, we check for the presence of this key       and continue performing table scans from the last evaluated position until the whole table has been scanned.",
                            "Copy and paste the following code into a file named lambda_function.py.import boto3from datetime import datetime, timedeltafrom boto3.dynamodb.conditions import Key, Attrimport logginglogger = logging.getLogger()logger.setLevel(\"INFO\")def lambda_handler(event, context):    # Initialize the DynamoDB client    dynamodb = boto3.resource('dynamodb')        # Specify the table name    table_name = 'MyOrderTable'    table = dynamodb.Table(table_name)        # Get today's date    today = datetime.now()        # Calculate the date one year ago    one_year_ago = (today - timedelta(days=365)).strftime('%Y-%m-%d')        # Scan the table using a global secondary index    response = table.scan(        IndexName='Date-index',        FilterExpression='#date < :one_year_ago',        ExpressionAttributeNames={            '#date': 'Date'        },        ExpressionAttributeValues={            ':one_year_ago': one_year_ago        }    )         # Delete old items    with table.batch_writer() as batch:        for item in response['Items']:            Order_number = item['Order_number']            batch.delete_item(                Key={                    'Order_number': Order_number,                    'Date': item['Date']                }            )            logger.info(f'deleted order number {Order_number}')        # Check if there are more items to scan    while 'LastEvaluatedKey' in response:        response = table.scan(            IndexName='DateIndex',            FilterExpression='#date < :one_year_ago',            ExpressionAttributeNames={                '#date': 'Date'            },            ExpressionAttributeValues={                ':one_year_ago': one_year_ago            },            ExclusiveStartKey=response['LastEvaluatedKey']        )                # Delete old items        with table.batch_writer() as batch:            for item in response['Items']:                batch.delete_item(                    Key={                        'Order_number': item['Order_number'],                        'Date': item['Date']                    }                )        return {        'statusCode': 200,        'body': 'Cleanup completed successfully'    }The Python function code contains the handler function (lambda_handler) that Lambda runs when your function is     invoked.When the function is invoked by EventBridge Scheduler, it uses the AWS SDK for Python (Boto3) to create a connection to the DynamoDB table on which the scheduled maintenance task is to be performed.     It then uses the Python datetime library to calculate the date one year ago, before scanning the table for items older than this and deleting them.Note that responses from DynamoDB query and scan operations are limited to a maximum of 1 MB in size. If the response is larger than 1 MB, DynamoDB paginates the       data and returns a LastEvaluatedKey element in the response. To ensure that our function processes all the records in the table, we check for the presence of this key       and continue performing table scans from the last evaluated position until the whole table has been scanned.Python function codeCopy and paste the following code into a file named lambda_function.py.import boto3from datetime import datetime, timedeltafrom boto3.dynamodb.conditions import Key, Attrimport logginglogger = logging.getLogger()logger.setLevel(\"INFO\")def lambda_handler(event, context):    # Initialize the DynamoDB client    dynamodb = boto3.resource('dynamodb')        # Specify the table name    table_name = 'MyOrderTable'    table = dynamodb.Table(table_name)        # Get today's date    today = datetime.now()        # Calculate the date one year ago    one_year_ago = (today - timedelta(days=365)).strftime('%Y-%m-%d')        # Scan the table using a global secondary index    response = table.scan(        IndexName='Date-index',        FilterExpression='#date < :one_year_ago',        ExpressionAttributeNames={            '#date': 'Date'        },        ExpressionAttributeValues={            ':one_year_ago': one_year_ago        }    )         # Delete old items    with table.batch_writer() as batch:        for item in response['Items']:            Order_number = item['Order_number']            batch.delete_item(                Key={                    'Order_number': Order_number,                    'Date': item['Date']                }            )            logger.info(f'deleted order number {Order_number}')        # Check if there are more items to scan    while 'LastEvaluatedKey' in response:        response = table.scan(            IndexName='DateIndex',            FilterExpression='#date < :one_year_ago',            ExpressionAttributeNames={                '#date': 'Date'            },            ExpressionAttributeValues={                ':one_year_ago': one_year_ago            },            ExclusiveStartKey=response['LastEvaluatedKey']        )                # Delete old items        with table.batch_writer() as batch:            for item in response['Items']:                batch.delete_item(                    Key={                        'Order_number': item['Order_number'],                        'Date': item['Date']                    }                )        return {        'statusCode': 200,        'body': 'Cleanup completed successfully'    }The Python function code contains the handler function (lambda_handler) that Lambda runs when your function is     invoked.When the function is invoked by EventBridge Scheduler, it uses the AWS SDK for Python (Boto3) to create a connection to the DynamoDB table on which the scheduled maintenance task is to be performed.     It then uses the Python datetime library to calculate the date one year ago, before scanning the table for items older than this and deleting them.Note that responses from DynamoDB query and scan operations are limited to a maximum of 1 MB in size. If the response is larger than 1 MB, DynamoDB paginates the       data and returns a LastEvaluatedKey element in the response. To ensure that our function processes all the records in the table, we check for the presence of this key       and continue performing table scans from the last evaluated position until the whole table has been scanned.",
                            "Copy and paste the following code into a file named requirements.txt.",
                            {
                                "code_example": "boto3"
                            },
                            "For this example, your function code has only one dependency that isn't part of the standard Python library -           the SDK for Python (Boto3) that the function uses to scan and delete items from the DynamoDB table.",
                            "Note",
                            "A version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.             See Runtime dependencies in Python to learn more.",
                            "requirements.txt manifest file",
                            "Copy and paste the following code into a file named requirements.txt.",
                            {
                                "code_example": "boto3"
                            },
                            "For this example, your function code has only one dependency that isn't part of the standard Python library -           the SDK for Python (Boto3) that the function uses to scan and delete items from the DynamoDB table.",
                            "Note",
                            "A version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.             See Runtime dependencies in Python to learn more.",
                            "Copy and paste the following code into a file named requirements.txt.boto3For this example, your function code has only one dependency that isn't part of the standard Python library -           the SDK for Python (Boto3) that the function uses to scan and delete items from the DynamoDB table.NoteA version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.             See Runtime dependencies in Python to learn more.requirements.txt manifest fileCopy and paste the following code into a file named requirements.txt.boto3For this example, your function code has only one dependency that isn't part of the standard Python library -           the SDK for Python (Boto3) that the function uses to scan and delete items from the DynamoDB table.NoteA version of the SDK for Python (Boto3) is included as part of the Lambda runtime, so your code would run without adding Boto3 to your             function's deployment package. However, to maintain full control of your function's dependencies and avoid possible issues with             version misalignment, best practice for Python is to include all function dependencies in your function's deployment package.             See Runtime dependencies in Python to learn more.",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: SAM Template for Lambda function and EventBridge Scheduler rule\n\nResources:\n  MyLambdaFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: ScheduledDBMaintenance\n      CodeUri: ./\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.11\n      Architectures:\n        - x86_64\n      Events:\n        ScheduleEvent:\n          Type: ScheduleV2\n          Properties:\n            ScheduleExpression: cron(0 3 1 * ? *)\n            Description: Run on the first day of every month at 03:00 AM\n      Policies:\n        - CloudWatchLogsFullAccess\n        - Statement:\n            - Effect: Allow\n              Action:\n                - dynamodb:Scan\n                - dynamodb:BatchWriteItem\n              Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/MyOrderTable'\n\n  LambdaLogGroup:\n    Type: AWS::Logs::LogGroup\n    Properties:\n      LogGroupName: !Sub /aws/lambda/${MyLambdaFunction}\n      RetentionInDays: 30\n\nOutputs:\n  LambdaFunctionName:\n    Description: Lambda Function Name\n    Value: !Ref MyLambdaFunction\n  LambdaFunctionArn:\n    Description: Lambda Function ARN\n    Value: !GetAtt MyLambdaFunction.Arn"
                            },
                            "Note",
                            "AWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the             example database and another to create the app itself. Save them in separate sub-directories in your project folder.",
                            "This AWS SAM template defines the resources for your app. We define the Lambda function using the AWS::Serverless::Function resource. The EventBridge Scheduler schedule and the           trigger to invoke the Lambda function are created by using the Events property of this resource using a type of ScheduleV2. To learn more about defining EventBridge Scheduler schedules in AWS SAM templates,           see ScheduleV2 in the           AWS Serverless Application Model Developer Guide.",
                            "In addition to the Lambda function and the EventBridge Scheduler schedule, we also define a CloudWatch log group for your function to send records of deleted items to.",
                            "AWS SAM template (scheduled-maintenance app)",
                            "Copy and paste the following code into a file named template.yaml.",
                            {
                                "code_example": "AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: SAM Template for Lambda function and EventBridge Scheduler rule\n\nResources:\n  MyLambdaFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: ScheduledDBMaintenance\n      CodeUri: ./\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.11\n      Architectures:\n        - x86_64\n      Events:\n        ScheduleEvent:\n          Type: ScheduleV2\n          Properties:\n            ScheduleExpression: cron(0 3 1 * ? *)\n            Description: Run on the first day of every month at 03:00 AM\n      Policies:\n        - CloudWatchLogsFullAccess\n        - Statement:\n            - Effect: Allow\n              Action:\n                - dynamodb:Scan\n                - dynamodb:BatchWriteItem\n              Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/MyOrderTable'\n\n  LambdaLogGroup:\n    Type: AWS::Logs::LogGroup\n    Properties:\n      LogGroupName: !Sub /aws/lambda/${MyLambdaFunction}\n      RetentionInDays: 30\n\nOutputs:\n  LambdaFunctionName:\n    Description: Lambda Function Name\n    Value: !Ref MyLambdaFunction\n  LambdaFunctionArn:\n    Description: Lambda Function ARN\n    Value: !GetAtt MyLambdaFunction.Arn"
                            },
                            "Note",
                            "AWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the             example database and another to create the app itself. Save them in separate sub-directories in your project folder.",
                            "This AWS SAM template defines the resources for your app. We define the Lambda function using the AWS::Serverless::Function resource. The EventBridge Scheduler schedule and the           trigger to invoke the Lambda function are created by using the Events property of this resource using a type of ScheduleV2. To learn more about defining EventBridge Scheduler schedules in AWS SAM templates,           see ScheduleV2 in the           AWS Serverless Application Model Developer Guide.",
                            "In addition to the Lambda function and the EventBridge Scheduler schedule, we also define a CloudWatch log group for your function to send records of deleted items to.",
                            "Copy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Description: SAM Template for Lambda function and EventBridge Scheduler ruleResources:  MyLambdaFunction:    Type: AWS::Serverless::Function    Properties:      FunctionName: ScheduledDBMaintenance      CodeUri: ./      Handler: lambda_function.lambda_handler      Runtime: python3.11      Architectures:        - x86_64      Events:        ScheduleEvent:          Type: ScheduleV2          Properties:            ScheduleExpression: cron(0 3 1 * ? *)            Description: Run on the first day of every month at 03:00 AM      Policies:        - CloudWatchLogsFullAccess        - Statement:            - Effect: Allow              Action:                - dynamodb:Scan                - dynamodb:BatchWriteItem              Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/MyOrderTable'  LambdaLogGroup:    Type: AWS::Logs::LogGroup    Properties:      LogGroupName: !Sub /aws/lambda/${MyLambdaFunction}      RetentionInDays: 30Outputs:  LambdaFunctionName:    Description: Lambda Function Name    Value: !Ref MyLambdaFunction  LambdaFunctionArn:    Description: Lambda Function ARN    Value: !GetAtt MyLambdaFunction.ArnNoteAWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the             example database and another to create the app itself. Save them in separate sub-directories in your project folder.This AWS SAM template defines the resources for your app. We define the Lambda function using the AWS::Serverless::Function resource. The EventBridge Scheduler schedule and the           trigger to invoke the Lambda function are created by using the Events property of this resource using a type of ScheduleV2. To learn more about defining EventBridge Scheduler schedules in AWS SAM templates,           see ScheduleV2 in the           AWS Serverless Application Model Developer Guide.In addition to the Lambda function and the EventBridge Scheduler schedule, we also define a CloudWatch log group for your function to send records of deleted items to.AWS SAM template (scheduled-maintenance app)Copy and paste the following code into a file named template.yaml.AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Description: SAM Template for Lambda function and EventBridge Scheduler ruleResources:  MyLambdaFunction:    Type: AWS::Serverless::Function    Properties:      FunctionName: ScheduledDBMaintenance      CodeUri: ./      Handler: lambda_function.lambda_handler      Runtime: python3.11      Architectures:        - x86_64      Events:        ScheduleEvent:          Type: ScheduleV2          Properties:            ScheduleExpression: cron(0 3 1 * ? *)            Description: Run on the first day of every month at 03:00 AM      Policies:        - CloudWatchLogsFullAccess        - Statement:            - Effect: Allow              Action:                - dynamodb:Scan                - dynamodb:BatchWriteItem              Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/MyOrderTable'  LambdaLogGroup:    Type: AWS::Logs::LogGroup    Properties:      LogGroupName: !Sub /aws/lambda/${MyLambdaFunction}      RetentionInDays: 30Outputs:  LambdaFunctionName:    Description: Lambda Function Name    Value: !Ref MyLambdaFunction  LambdaFunctionArn:    Description: Lambda Function ARN    Value: !GetAtt MyLambdaFunction.ArnNoteAWS SAM templates use a standard naming convention of template.yaml. In this example, you have two template files - one to create the             example database and another to create the app itself. Save them in separate sub-directories in your project folder.This AWS SAM template defines the resources for your app. We define the Lambda function using the AWS::Serverless::Function resource. The EventBridge Scheduler schedule and the           trigger to invoke the Lambda function are created by using the Events property of this resource using a type of ScheduleV2. To learn more about defining EventBridge Scheduler schedules in AWS SAM templates,           see ScheduleV2 in the           AWS Serverless Application Model Developer Guide.In addition to the Lambda function and the EventBridge Scheduler schedule, we also define a CloudWatch log group for your function to send records of deleted items to.",
                            "Copy and paste the following code into a file named test_app.py.",
                            {
                                "code_example": "import boto3\nfrom datetime import datetime, timedelta\nimport json\n\n# Initialize the DynamoDB client\ndynamodb = boto3.resource('dynamodb')\n\n# Specify your table name\ntable_name = 'YourTableName'\ntable = dynamodb.Table(table_name)\n\n# Get the current date\ncurrent_date = datetime.now()\n\n# Calculate the date one year ago\none_year_ago = current_date - timedelta(days=365)\n\n# Convert the date to string format (assuming the date in DynamoDB is stored as a string)\none_year_ago_str = one_year_ago.strftime('%Y-%m-%d')\n\n# Scan the table\nresponse = table.scan(\n    FilterExpression='#date < :one_year_ago',\n    ExpressionAttributeNames={\n        '#date': 'Date'\n    },\n    ExpressionAttributeValues={\n        ':one_year_ago': one_year_ago_str\n    }\n)\n\n# Process the results\nold_records = response['Items']\n\n# Continue scanning if we have more items (pagination)\nwhile 'LastEvaluatedKey' in response:\n    response = table.scan(\n        FilterExpression='#date < :one_year_ago',\n        ExpressionAttributeNames={\n            '#date': 'Date'\n        },\n        ExpressionAttributeValues={\n            ':one_year_ago': one_year_ago_str\n        },\n        ExclusiveStartKey=response['LastEvaluatedKey']\n    )\n    old_records.extend(response['Items'])\n\nfor record in old_records:\n    print(json.dumps(record))\n\n# The total number of old records should be zero.\nprint(f\"Total number of old records: {len(old_records)}\")\n"
                            },
                            "This test script uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table and scan for items older than one year. To confirm if the Lambda function           has run successfully, at the end of the test, the function prints the number of records older than one year still in the table. If the Lambda function was successful,           the number of old records in the table should be zero.        ",
                            "Test script",
                            "Copy and paste the following code into a file named test_app.py.",
                            {
                                "code_example": "import boto3\nfrom datetime import datetime, timedelta\nimport json\n\n# Initialize the DynamoDB client\ndynamodb = boto3.resource('dynamodb')\n\n# Specify your table name\ntable_name = 'YourTableName'\ntable = dynamodb.Table(table_name)\n\n# Get the current date\ncurrent_date = datetime.now()\n\n# Calculate the date one year ago\none_year_ago = current_date - timedelta(days=365)\n\n# Convert the date to string format (assuming the date in DynamoDB is stored as a string)\none_year_ago_str = one_year_ago.strftime('%Y-%m-%d')\n\n# Scan the table\nresponse = table.scan(\n    FilterExpression='#date < :one_year_ago',\n    ExpressionAttributeNames={\n        '#date': 'Date'\n    },\n    ExpressionAttributeValues={\n        ':one_year_ago': one_year_ago_str\n    }\n)\n\n# Process the results\nold_records = response['Items']\n\n# Continue scanning if we have more items (pagination)\nwhile 'LastEvaluatedKey' in response:\n    response = table.scan(\n        FilterExpression='#date < :one_year_ago',\n        ExpressionAttributeNames={\n            '#date': 'Date'\n        },\n        ExpressionAttributeValues={\n            ':one_year_ago': one_year_ago_str\n        },\n        ExclusiveStartKey=response['LastEvaluatedKey']\n    )\n    old_records.extend(response['Items'])\n\nfor record in old_records:\n    print(json.dumps(record))\n\n# The total number of old records should be zero.\nprint(f\"Total number of old records: {len(old_records)}\")\n"
                            },
                            "This test script uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table and scan for items older than one year. To confirm if the Lambda function           has run successfully, at the end of the test, the function prints the number of records older than one year still in the table. If the Lambda function was successful,           the number of old records in the table should be zero.        ",
                            "Copy and paste the following code into a file named test_app.py.import boto3from datetime import datetime, timedeltaimport json# Initialize the DynamoDB clientdynamodb = boto3.resource('dynamodb')# Specify your table nametable_name = 'YourTableName'table = dynamodb.Table(table_name)# Get the current datecurrent_date = datetime.now()# Calculate the date one year agoone_year_ago = current_date - timedelta(days=365)# Convert the date to string format (assuming the date in DynamoDB is stored as a string)one_year_ago_str = one_year_ago.strftime('%Y-%m-%d')# Scan the tableresponse = table.scan(    FilterExpression='#date < :one_year_ago',    ExpressionAttributeNames={        '#date': 'Date'    },    ExpressionAttributeValues={        ':one_year_ago': one_year_ago_str    })# Process the resultsold_records = response['Items']# Continue scanning if we have more items (pagination)while 'LastEvaluatedKey' in response:    response = table.scan(        FilterExpression='#date < :one_year_ago',        ExpressionAttributeNames={            '#date': 'Date'        },        ExpressionAttributeValues={            ':one_year_ago': one_year_ago_str        },        ExclusiveStartKey=response['LastEvaluatedKey']    )    old_records.extend(response['Items'])for record in old_records:    print(json.dumps(record))# The total number of old records should be zero.print(f\"Total number of old records: {len(old_records)}\")This test script uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table and scan for items older than one year. To confirm if the Lambda function           has run successfully, at the end of the test, the function prints the number of records older than one year still in the table. If the Lambda function was successful,           the number of old records in the table should be zero.        Test scriptCopy and paste the following code into a file named test_app.py.import boto3from datetime import datetime, timedeltaimport json# Initialize the DynamoDB clientdynamodb = boto3.resource('dynamodb')# Specify your table nametable_name = 'YourTableName'table = dynamodb.Table(table_name)# Get the current datecurrent_date = datetime.now()# Calculate the date one year agoone_year_ago = current_date - timedelta(days=365)# Convert the date to string format (assuming the date in DynamoDB is stored as a string)one_year_ago_str = one_year_ago.strftime('%Y-%m-%d')# Scan the tableresponse = table.scan(    FilterExpression='#date < :one_year_ago',    ExpressionAttributeNames={        '#date': 'Date'    },    ExpressionAttributeValues={        ':one_year_ago': one_year_ago_str    })# Process the resultsold_records = response['Items']# Continue scanning if we have more items (pagination)while 'LastEvaluatedKey' in response:    response = table.scan(        FilterExpression='#date < :one_year_ago',        ExpressionAttributeNames={            '#date': 'Date'        },        ExpressionAttributeValues={            ':one_year_ago': one_year_ago_str        },        ExclusiveStartKey=response['LastEvaluatedKey']    )    old_records.extend(response['Items'])for record in old_records:    print(json.dumps(record))# The total number of old records should be zero.print(f\"Total number of old records: {len(old_records)}\")This test script uses the AWS SDK for Python (Boto3) to create a connection to your DynamoDB table and scan for items older than one year. To confirm if the Lambda function           has run successfully, at the end of the test, the function prints the number of records older than one year still in the table. If the Lambda function was successful,           the number of old records in the table should be zero.        "
                        ]
                    },
                    {
                        "sub_header": "Creating and populating the example DynamoDB table",
                        "content": [
                            "To test your scheduled-maintenance app, you first create a DynamoDB table and populate it with some sample data. You can create the table either manually using the       AWS Management Console or by using AWS SAM. We recommend that you use AWS SAM to quickly create and configure the table using a few AWS CLI commands.",
                            "  1.Console : MyOrderTable",
                            "  2.AWS SAM : template.yaml",
                            "ConsoleTo create the DynamoDB tableOpen the Tables page of the DynamoDB console.Choose Create table.Create the table by doing the following:Under Table details, for Table name, enter MyOrderTable.For Partition key, enter Order_number and leave the type as String.For Sort key, enter Date and leave the type as String.Leave Table settings set to Default settings and choose Create table.When your table has finished creating and its Status shows as Active, create a global secondary index (GSI) by doing the               following. Your app will use this GSI to search for items directly by date to determine what to delete.Choose MyOrderTable from the list of tables.Choose the Indexes tab.Under Global secondary indexes, choose Create index.Under Index details, enter Date for the Partition key and leave the                   Data type set to String.For Index name, enter Date-index.Leave all other parameters set to their default values, scroll to the bottom of the page, and choose Create index.AWS SAMTo create the DynamoDB tableNavigate to the folder you saved the template.yaml file for the DynamoDB table in. Note that this example uses two                 template.yaml files. Make sure they are saved in separate sub-folders and that you are in the correct folder containing                 the template to create your DynamoDB table.Run the following command.sam buildThis command gathers the build artifacts for the resources you want to deploy and places them in the proper format and                 location to deploy them.To create the DynamoDB resource specified in the template.yaml file, run the following command.sam deploy --guidedUsing the --guided flag means that AWS SAM will show you prompts to guide you through the deployment process. For this deployment,                 enter a Stack name of cron-app-test-db, and accept the defaults for all other options by using Enter.When AWS SAM has finished creating the DynamoDB resource, you should see the following message.Successfully created/updated stack - cron-app-test-db in us-west-2You can additionally confirm that the DynamoDB table has been created by opening the Tables page of the DynamoDB console.                 You should see a table named MyOrderTable.",
                            "anchor",
                            "anchor",
                            "To create the DynamoDB table",
                            "  1 : Open the Tables page of the DynamoDB console.",
                            "  2 : Choose Create table.",
                            "  3 : Create the table by doing the following:Under Table details, for Table name, enter MyOrderTable.For Partition key, enter Order_number and leave the type as String.For Sort key, enter Date and leave the type as String.Leave Table settings set to Default settings and choose Create table.",
                            "  4 : When your table has finished creating and its Status shows as Active, create a global secondary index (GSI) by doing the               following. Your app will use this GSI to search for items directly by date to determine what to delete.Choose MyOrderTable from the list of tables.Choose the Indexes tab.Under Global secondary indexes, choose Create index.Under Index details, enter Date for the Partition key and leave the                   Data type set to String.For Index name, enter Date-index.Leave all other parameters set to their default values, scroll to the bottom of the page, and choose Create index.",
                            "After you've created your table, you next add some sample data to test your app. The CSV file sample_data.csv you downloaded     earlier contains a number of example entries comprised of order numbers, dates, and customer and order information. Use the provided python script     load_sample_data.py to add this data to your table.",
                            "To add the sample data to the table",
                            "  1 : Navigate to the directory containing the sample_data.csv and load_sample_data.py files. If these files are in         separate directories, move them so they're saved in the same location.",
                            " 2 : Create a Python virtual environment to run the script in by running the following command. We recommend that you use a virtual environment because in a following         step you'll need to install the AWS SDK for Python (Boto3). ",
                            {
                                "code_example": "python -m venv venv"
                            },
                            " 3 : Activate the virtual environment by running the following command. ",
                            {
                                "code_example": "source venv/bin/activate"
                            },
                            " 4 : Install the SDK for Python (Boto3) in your virtual environment by running the following command. The script uses this library to connect to your DynamoDB table and add the items. ",
                            {
                                "code_example": "pip install boto3"
                            },
                            " 5 : Run the script to populate the table by running the following command. If the script runs successfully, it should print each item to the console as it loads it and report Data loading completed.",
                            {
                                "code_example": "python load_sample_data.py"
                            },
                            " 6 : Deactivate the virtual environment by running the following command. ",
                            {
                                "code_example": "deactivate"
                            },
                            "  7 : You can verify that the data has been loaded to your DynamoDB table by doing the following:Open the Explore items page of the DynamoDB console and select your table (MyOrderTable).In the Items returned pane, you should see the 25 items from the CSV file that the script added to the table."
                        ]
                    },
                    {
                        "sub_header": "Creating the scheduled-maintenance app",
                        "content": [
                            "You can create and deploy the resources for this example app step by step using the AWS Management Console or by using AWS SAM. In a production environment, we       recommend that you use an Infrustracture-as-Code (IaC) tool like AWS SAM to repeatably deploy serverless applications without using manual processes.",
                            "For this example, follow the console instructions to learn how to configure each AWS resource separately, or follow the AWS SAM instructions     to quickly deploy the app using AWS CLI commands.",
                            "  1.Console : .zip",
                            "  2.AWS SAM : template.yaml",
                            "ConsoleTo create the function using the AWS Management ConsoleFirst, create a function containing basic starter code. You then                 replace this code with your own function code by either copying and pasting the code directly in the Lambda code editor, or by uploading your code                as a .zip package. For this task, we recommend simply copying and pasting the code.Open the Functions page of the Lambda console.Choose Create function.Choose Author from scratch.Under Basic information, do the following:For Function name, enter ScheduledDBMaintenance.For Runtime choose the latest Python version.For Architecture, choose x86_64.Choose Create function.After your function is created, you can configure your function with the provided function code.In the Code source pane, replace the Hello world code that Lambda created with the Python function code from                        the lambda_function.py file that you saved earlier.In the DEPLOY section, choose Deploy to update your function's code:To configure the function memory and timeout (console)Select the Configuration tab for your function.In the General configuration pane, choose Edit.Set Memory to 256 MB and Timeout to 15 seconds.                  If you are processing a large table with many records, for example in the case of a production environment,                  you might consider setting Timeout to a larger number. This gives your function                  more time to scan, and clean the database.Choose Save.To configure the log format (console)You can configure Lambda functions to output logs in either unstructured text or JSON format. We recommend that you use JSON format for logs to                   make it easier to search and filter log data. To learn more about Lambda log configuration options, see Configuring advanced logging controls for Lambda functions.Select the Configuration tab for your function.Select Monitoring and operations tools.In the Logging configuration pane, choose Edit.For Logging configuration, select JSON.Choose Save.To set Up IAM permissionsTo give your function the permissions it needs to read and delete DynamoDB items, you need to add a policy to your function's                     execution role defining the necessary permissions.Open the Configuration tab, then choose                        Permissions from the left navigation bar.Choose the role name under Execution role.In the IAM console, choose Add permissions, then                        Create inline policy.Use the JSON editor and enter the following policy:{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"dynamodb:Scan\",                \"dynamodb:DeleteItem\",                \"dynamodb:BatchWriteItem\"            ],            \"Resource\": \"arn:aws:dynamodb:*:*:table/MyOrderTable\"        }    ]}Name the policy DynamoDBCleanupPolicy, then create it.To set up EventBridge Scheduler as a trigger (console)Open the EventBridge console.In the left navigation pane, choose Schedulers under the                        Scheduler section.Choose Create schedule.Configure the schedule by doing the following:Under Schedule name, enter a name for your schedule (for example, DynamoDBCleanupSchedule).Under Schedule pattern, choose Recurring schedule.For Schedule type leave the default as Cron-based schedule,                          then enter the following schedule details:Minutes: 0Hours: 3Day of month: 1Month: *Day of the week: ?Year: *When evaluated, this cron expression runs on the first day of every month at 03:00 AM.For Flexible time window, select Off.Choose Next.Configure the trigger for your Lambda function by doing the following:In the Target detail pane, leave Target API set to Templated targets,                         then select AWS Lambda Invoke.Under Invoke, select your Lambda function (ScheduledDBMaintenance) from the dropdown list.Leave the Payload empty and choose Next.Scroll down to Permissions and select Create a new role for this schedule.                            When you create a new EventBridge Scheduler schedule using the console, EventBridge Scheduler creates a new policy with the required                          permissions the schedule needs to invoke your function. For more information about managing your schedule permissions, see                          Cron-based schedules.                          in the EventBridge Scheduler User Guide.Choose Next.Review your settings and choose Create schedule to complete creation of the schedule and Lambda trigger.AWS SAMTo deploy the app using AWS SAMNavigate to the folder you saved the template.yaml file for the app in. Note that this example uses two template.yaml files.               Make sure they are saved in separate sub-folders and that you are in the correct folder containing the template to create the app.Copy the lambda_function.py and requirements.txt files you downloaded earlier to the same folder. The code location specified in the                 AWS SAM template is ./, meaning the current location. AWS SAM will search in this folder for the Lambda function code when you try to deploy the app.Run the following command.sam build --use-containerThis command gathers the build artifacts for the resources you want to deploy and places them in the proper format and                 location to deploy them. Specifying the --use-container option builds your function inside a Lambda-like Docker container.                 We use it here so you don't need to have Python 3.12 installed on your local machine for the build to work.To create the Lambda and EventBridge Scheduler resources specified in the template.yaml file, run the following command.sam deploy --guidedUsing the --guided flag means that AWS SAM will show you prompts to guide you through the deployment process. For this deployment,                 enter a Stack name of cron-maintenance-app, and accept the defaults for all other options by using Enter.When AWS SAM has finished creating the Lambda and EventBridge Scheduler resources, you should see the following message.Successfully created/updated stack - cron-maintenance-app in us-west-2You can additionally confirm that the Lambda function has been created by opening the Functions page of the Lambda console.                 You should see a function named ScheduledDBMaintenance.",
                            "anchor",
                            "anchor",
                            "To create the function using the AWS Management Console",
                            "First, create a function containing basic starter code. You then                 replace this code with your own function code by either copying and pasting the code directly in the Lambda code editor, or by uploading your code                as a .zip package. For this task, we recommend simply copying and pasting the code.",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Choose Create function.",
                            "  3 : Choose Author from scratch.",
                            "  4 : Under Basic information, do the following:For Function name, enter ScheduledDBMaintenance.For Runtime choose the latest Python version.For Architecture, choose x86_64.",
                            "  5 : Choose Create function.",
                            "  6 : After your function is created, you can configure your function with the provided function code.In the Code source pane, replace the Hello world code that Lambda created with the Python function code from                        the lambda_function.py file that you saved earlier.In the DEPLOY section, choose Deploy to update your function's code:",
                            "To configure the function memory and timeout (console)",
                            "  1 : Select the Configuration tab for your function.",
                            "  2 : In the General configuration pane, choose Edit.",
                            "  3 : Set Memory to 256 MB and Timeout to 15 seconds.                  If you are processing a large table with many records, for example in the case of a production environment,                  you might consider setting Timeout to a larger number. This gives your function                  more time to scan, and clean the database.",
                            "  4 : Choose Save.",
                            "To configure the log format (console)",
                            "You can configure Lambda functions to output logs in either unstructured text or JSON format. We recommend that you use JSON format for logs to                   make it easier to search and filter log data. To learn more about Lambda log configuration options, see Configuring advanced logging controls for Lambda functions.",
                            "  1 : Select the Configuration tab for your function.",
                            "  2 : Select Monitoring and operations tools.",
                            "  3 : In the Logging configuration pane, choose Edit.",
                            "  4 : For Logging configuration, select JSON.",
                            "  5 : Choose Save.",
                            "To set Up IAM permissions",
                            "To give your function the permissions it needs to read and delete DynamoDB items, you need to add a policy to your function's                     execution role defining the necessary permissions.",
                            "  1 : Open the Configuration tab, then choose                        Permissions from the left navigation bar.",
                            "  2 : Choose the role name under Execution role.",
                            "  3 : In the IAM console, choose Add permissions, then                        Create inline policy.",
                            " 4 : Use the JSON editor and enter the following policy: ",
                            {
                                "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:Scan\",\n                \"dynamodb:DeleteItem\",\n                \"dynamodb:BatchWriteItem\"\n            ],\n            \"Resource\": \"arn:aws:dynamodb:*:*:table/MyOrderTable\"\n        }\n    ]\n}"
                            },
                            "  5 : Name the policy DynamoDBCleanupPolicy, then create it.",
                            "To set up EventBridge Scheduler as a trigger (console)",
                            "  1 : Open the EventBridge console.",
                            "  2 : In the left navigation pane, choose Schedulers under the                        Scheduler section.",
                            "  3 : Choose Create schedule.",
                            "  4 : Configure the schedule by doing the following:Under Schedule name, enter a name for your schedule (for example, DynamoDBCleanupSchedule).Under Schedule pattern, choose Recurring schedule.For Schedule type leave the default as Cron-based schedule,                          then enter the following schedule details:Minutes: 0Hours: 3Day of month: 1Month: *Day of the week: ?Year: *When evaluated, this cron expression runs on the first day of every month at 03:00 AM.For Flexible time window, select Off.",
                            "  5 : Choose Next.",
                            "  6 : Configure the trigger for your Lambda function by doing the following:In the Target detail pane, leave Target API set to Templated targets,                         then select AWS Lambda Invoke.Under Invoke, select your Lambda function (ScheduledDBMaintenance) from the dropdown list.Leave the Payload empty and choose Next.Scroll down to Permissions and select Create a new role for this schedule.                            When you create a new EventBridge Scheduler schedule using the console, EventBridge Scheduler creates a new policy with the required                          permissions the schedule needs to invoke your function. For more information about managing your schedule permissions, see                          Cron-based schedules.                          in the EventBridge Scheduler User Guide.Choose Next.",
                            "  7 : Review your settings and choose Create schedule to complete creation of the schedule and Lambda trigger."
                        ]
                    },
                    {
                        "sub_header": "Testing the app",
                        "content": [
                            "      To test that your schedule correctly triggers your function, and that your function correctly cleans records      from the database, you can temporarily modify your schedule to run once at a specific time. You can then run sam deploy again to      reset your recurrence schedule to run once a month.    ",
                            "To run the application using the AWS Management Console",
                            "  1 : Navigate back to the EventBridge Scheduler console page.",
                            "  2 : Choose your schedule, then choose Edit.",
                            "  3 : In the Schedule pattern section, under Recurrence, choose One-time schedule.",
                            "  4 :           Set your invocation time to a few minutes from now, review your settings, then choose Save.        ",
                            "      After the schedule runs and invokes its target, you run the test_app.py script to verify that your function successfully removed all old records      from the DynamoDB table.    ",
                            "To verify that old records are deleted using a Python script",
                            "  1 :           In your command line windown, navigate to the folder where you saved test_app.py.        ",
                            " 2 :           Run the script.                   If successful, you will see the following output.        Total number of old records: 0",
                            {
                                "code_example": "python test_app.py"
                            }
                        ]
                    },
                    {
                        "sub_header": "Next steps",
                        "content": [
                            "      You can now modify the EventBridge Scheduler schedule to meet your partifuclar application requirements. EventBridge Scheduler supports the following schedule expressions: cron, rate, and one-time schedules.    ",
                            "      For more information about EventBridge Scheduler schedule expresssions, see Schedule types in the      EventBridge Scheduler User Guide.    "
                        ]
                    }
                ]
            }
        ],
        "sections": [
            "The following examples provide function code and  infrastructure as code (IaC) templates to quickly create and deploy serverless apps that implement some common Lambda uses cases. The  examples also include code examples and instructions to test the apps after you deploy them.",
            "For each of the example apps, we provide instructions to either create and configure resources manually using the AWS Management Console, or to   use the AWS Serverless Application Model to deploy the resources using IaC. Follow the console intructions to learn more about configuring the individual AWS   resources for each app, or use to AWS SAM to quickly deploy resources as you would in a production environment.",
            "You can use the provided examples as a basis for your own serverless applications by modifying the provided function code and templates   for your own use case.",
            "We're continuing to create new examples, so check back again to find more severless apps for common Lambda use cases.",
            {
                "sub_header": "Example apps",
                "content": [
                    "  1.Example serverless file-processing appCreate a serverless app to automatically perform a file-processing task when an object is uploaded to an Amazon S3 bucket. In this         example, when a PDF file is uploaded, the app encrypts the file and saves it to another S3 bucket.",
                    "  2.Example scheduled cron task appCreate an app to perform a scheduled task using a cron schedule. In this example, the app performs maintenance on a         Amazon DynamoDB table by deleting entries more than 12 months old."
                ]
            }
        ]
    },
    {
        "title": "Building with TypeScript",
        "href": "https://docs.aws.amazon.com/lambda/latest/dg/lambda-typescript.html",
        "contents": [
            {
                "title": "Handler",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-handler.html",
                "sections": [
                    "The Lambda function handler is the method in your function code that processes events. When your function is  invoked, Lambda runs the handler method. Your function runs until the handler returns a response, exits, or times out.",
                    "Topics",
                    {
                        "sub_header": "Typescript handler basics",
                        "content": [
                            "Example TypeScript handler",
                            "This example function logs the contents of the event object and returns the location of the        logs. Note the following:",
                            "  1.Before using this code in a Lambda function, you must add the @types/aws-lambda package as a development dependency. This package contains the type definitions for Lambda. When @types/aws-lambda is installed, the import statement (import ... from 'aws-lambda') imports the type definitions. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.",
                            "  2.The handler in this example is an ES module and must be designated as such in your package.json file or by using the .mjs file extension. For more information, see  see Designating a function handler as an ES module.",
                            {
                                "code_example": "import { Handler } from 'aws-lambda';\n\nexport const handler: Handler = async (event, context) => {\n    console.log('EVENT: \\n' + JSON.stringify(event, null, 2));\n    return context.logStreamName;\n};"
                            },
                            "The runtime passes arguments to the handler method. The first argument is the event object,      which contains information from the invoker. The invoker passes this information as a JSON-formatted string when it      calls Invoke, and the runtime converts it to an object. When an AWS service invokes your function, the event      structure varies by service. With TypeScript, we recommend using type      annotations for the event object. For more information, see Using types for the event object.",
                            "The second argument is the context object, which contains information      about the invocation, function, and execution environment. In the preceding example, the function gets the name of      the log stream from the context object and returns it to the invoker.",
                            "You can also use a callback argument, which is a function that you can call in non-async handlers to send a response.      We recommend that you use async/await instead of callbacks. Async/await provides improved readability, error handling,      and efficiency. For more information about the differences between async/await and callbacks, see      Using callbacks."
                        ]
                    },
                    {
                        "sub_header": "Using async/await",
                        "content": [
                            "If your code performs an asynchronous task, use the async/await pattern to make sure that the handler finishes running. Async/await is a concise and readable way to write asynchronous code in Node.js, without the need for nested callbacks or chaining promises. With async/await, you can write code that reads like synchronous code, while still being asynchronous and non-blocking.",
                            "The async keyword marks a function as asynchronous, and the await keyword pauses the execution of the function until a Promise is resolved.",
                            "Example  TypeScript function – asynchronous",
                            "This example uses fetch, which is available in the nodejs18.x runtime. Note the following:",
                            "  1.Before using this code in a Lambda function, you must add the @types/aws-lambda package as a development dependency. This package contains the type definitions for Lambda. When @types/aws-lambda is installed, the import statement (import ... from 'aws-lambda') imports the type definitions. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.",
                            "  2.The handler in this example is an ES module and must be designated as such in your package.json file or by using the .mjs file extension. For more information, see  see Designating a function handler as an ES module.",
                            {
                                "code_example": "import { APIGatewayProxyEvent, APIGatewayProxyResult } from 'aws-lambda';\nconst url = 'https://aws.amazon.com/';\nexport const lambdaHandler = async (event: APIGatewayProxyEvent): Promise<APIGatewayProxyResult> => {\n    try {\n        // fetch is available with Node.js 18\n        const res = await fetch(url);\n        return {\n            statusCode: res.status,\n            body: JSON.stringify({\n                message: await res.text(),\n            }),\n        };\n    } catch (err) {\n        console.log(err);\n        return {\n            statusCode: 500,\n            body: JSON.stringify({\n                message: 'some error happened',\n            }),\n        };\n    }\n};"
                            }
                        ]
                    },
                    {
                        "sub_header": "Using callbacks",
                        "content": [
                            "We recommend that you use async/await to declare the function handler instead of using callbacks. Async/await is a better choice for several reasons:",
                            "  1.Readability: :  Async/await code is easier to read and understand than callback code, which can quickly become difficult to follow and result in callback hell.",
                            "  2.Debugging and error handling: :  Debugging callback-based code can be difficult. The call stack can become hard to follow and errors can easily be swallowed. With async/await, you can use try/catch blocks to handle errors.",
                            "  3.Efficiency: :  Callbacks often require switching between different parts of the code. Async/await can reduce the number of context switches, resulting in more efficient code.",
                            "When you use callbacks in your handler, the function continues to execute until the event loop is empty or the    function times out. The response isn't sent to the invoker until all event loop tasks are finished. If the    function times out, an error is returned instead. You can configure the runtime to send the response immediately    by setting context.callbackWaitsForEmptyEventLoop to false.",
                            "The callback function takes two      arguments: an Error and a response. The response object must be compatible with        JSON.stringify.",
                            "Example TypeScript function with callback",
                            "This sample function receives an event from Amazon API Gateway, logs the event and context objects, and then returns a response to API Gateway. Note the following:",
                            "  1.Before using this code in a Lambda function, you must add the @types/aws-lambda package as a development dependency. This package contains the type definitions for Lambda. When @types/aws-lambda is installed, the import statement (import ... from 'aws-lambda') imports the type definitions. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.",
                            "  2.The handler in this example is an ES module and must be designated as such in your package.json file or by using the .mjs file extension. For more information, see  see Designating a function handler as an ES module.",
                            {
                                "code_example": "import { Context, APIGatewayProxyCallback, APIGatewayEvent } from 'aws-lambda';\n\nexport const lambdaHandler = (event: APIGatewayEvent, context: Context, callback: APIGatewayProxyCallback): void => {\n    console.log(`Event: ${JSON.stringify(event, null, 2)}`);\n    console.log(`Context: ${JSON.stringify(context, null, 2)}`);\n    callback(null, {\n        statusCode: 200,\n        body: JSON.stringify({\n            message: 'hello world',\n        }),\n    });\n};"
                            }
                        ]
                    },
                    {
                        "sub_header": "Using types for the event object",
                        "content": [
                            "We recommend that you don’t use the any type for the handler arguments and return type because you lose the ability to check types. Instead, generate an event using the sam local generate-event AWS Serverless Application Model CLI command, or use an open-source definition from the @types/aws-lambda package.",
                            "Generating an event using the sam local generate-event command",
                            " 1 : Generate an  Amazon Simple Storage Service (Amazon S3) proxy event. ",
                            {
                                "code_example": "sam local generate-event s3 put >> S3PutEvent.json"
                            },
                            " 2 : Use the quicktype utility to generate type definitions from the S3PutEvent.json file. ",
                            {
                                "code_example": "npm install -g quicktype\nquicktype S3PutEvent.json -o S3PutEvent.ts"
                            },
                            " 3 : Use the generated types in your code. ",
                            {
                                "code_example": "import { S3PutEvent } from './S3PutEvent';\n\nexport const lambdaHandler = async (event: S3PutEvent): Promise<void> => {\n  event.Records.map((record) => console.log(record.s3.object.key));\n};"
                            },
                            "Generating an event using an open-source definition from the @types/aws-lambda package",
                            " 1 : Add the @types/aws-lambda package as a development dependency. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda"
                            },
                            " 2 : Use the types in your code. ",
                            {
                                "code_example": "import { S3Event } from \"aws-lambda\";\n\nexport const lambdaHandler = async (event: S3Event): Promise<void> => {\n  event.Records.map((record) => console.log(record.s3.object.key));\n};"
                            }
                        ]
                    },
                    {
                        "sub_header": "Code best practices for Typescript Lambda functions",
                        "content": [
                            "Adhere to the guidelines in the following list to use best coding practices when building your Lambda functions:",
                            "  1.Separate the Lambda handler from your core logic. :  This allows you to make          a more unit-testable function. In Node.js this may look like: exports.myHandler = function(event, context, callback) {\tvar foo = event.foo;\tvar bar = event.bar;\tvar result = MyLambdaFunction (foo, bar);\tcallback(null, result);}function MyLambdaFunction (foo, bar) {\t// MyLambdaFunction logic here}",
                            {
                                "code_example": "exports.myHandler = function(event, context, callback) {\n\tvar foo = event.foo;\n\tvar bar = event.bar;\n\tvar result = MyLambdaFunction (foo, bar);\n\n\tcallback(null, result);\n}\n\nfunction MyLambdaFunction (foo, bar) {\n\t// MyLambdaFunction logic here\n}"
                            },
                            "  2.Control the dependencies in your function's deployment package.  :  The          AWS Lambda execution environment contains a number of libraries. For the Node.js and Python runtimes, these include the AWS SDKs.          To enable the latest set of features and security updates, Lambda will periodically update these libraries.          These updates may introduce subtle changes to the behavior of your Lambda function. To have full control of the          dependencies your function uses, package all of your dependencies with your deployment package. ",
                            "  3.Minimize the complexity of your dependencies. :  Prefer simpler frameworks          that load quickly on execution environment startup.",
                            "  4.Minimize your deployment package size to its runtime necessities.  :  This          will reduce the amount of time that it takes for your deployment package to be downloaded and unpacked ahead          of invocation.",
                            "  1.Take advantage of execution environment reuse to improve the performance of your\n        function. :  Initialize SDK clients and database connections outside of the function handler, and        cache static assets locally in the /tmp directory. Subsequent invocations processed by        the same instance of your function can reuse these resources. This saves cost by reducing function run time.To avoid potential data leaks across invocations, don’t use the execution environment to store user data,        events, or other information with security implications. If your function relies on a mutable state that can’t        be stored in memory within the handler, consider creating a separate function or separate versions of a        function for each user.",
                            "  2.Use a keep-alive directive to maintain persistent connections. :  Lambda purges idle connections over time. Attempting to reuse an idle connection when invoking a function will result in a connection error. To maintain your persistent connection, use the keep-alive directive associated with your runtime. For an example, see Reusing Connections with Keep-Alive in Node.js.",
                            "  3.Use environment variables to pass operational parameters to your function. :  For example, if        you are writing to an Amazon S3 bucket, instead of hard-coding the bucket name you are writing to, configure the        bucket name as an environment variable.",
                            "  4.Avoid using recursive invocations :  in your Lambda function, where the function        invokes itself or initiates a process that may invoke the function again. This could lead to unintended volume of        function invocations and escalated costs. If you see an unintended volume of invocations, set the function reserved concurrency        to 0 immediately to throttle all invocations to the function, while you update the        code.",
                            "  5.Do not use non-documented, non-public APIs :  in your Lambda function code.        For AWS Lambda managed runtimes, Lambda periodically applies security and functional updates to Lambda's internal APIs.        These internal API updates may be backwards-incompatible, leading to unintended consequences such as invocation        failures if your function has a dependency on these non-public APIs. See        the API reference for a list of        publicly available APIs.",
                            "  6.Write idempotent code. :  Writing idempotent code for your functions ensures that        duplicate events are handled the same way. Your code should properly validate events and gracefully handle        duplicate events. For more information, see        How do I make          my Lambda function idempotent?."
                        ]
                    }
                ]
            },
            {
                "title": "Deploy .zip file archives",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-package.html",
                "sections": [
                    "Before you can deploy TypeScript code to AWS Lambda, you need to transpile it into JavaScript. This page explains three ways to build and deploy TypeScript code to Lambda with .zip file archives:",
                    "  1.Using AWS Serverless Application Model (AWS SAM)",
                    "  2.Using the AWS Cloud Development Kit (AWS CDK)",
                    "  3.Using the AWS Command Line Interface (AWS CLI) and esbuild",
                    "AWS SAM and AWS CDK simplify building and deploying TypeScript functions. The AWS SAM template specification provides a simple and clean syntax to describe the Lambda functions, APIs, permissions, configurations, and events that make up your serverless application. The AWS CDK lets you build reliable, scalable, cost-effective applications in the cloud with the considerable expressive power of a programming language. The AWS CDK is intended for moderately to highly experienced AWS users. Both the AWS CDK and the AWS SAM use esbuild to transpile TypeScript code into JavaScript.",
                    {
                        "sub_header": "Using AWS SAM to deploy TypeScript code to Lambda",
                        "content": [
                            "Follow the steps below to download, build, and deploy a sample Hello World TypeScript application using the AWS SAM. This application implements a basic API backend. It consists of an Amazon API Gateway endpoint and a Lambda function. When you send a GET request to the API Gateway endpoint, the Lambda function is invoked. The function returns a hello world message.",
                            "Note",
                            "AWS SAM uses esbuild to create Node.js Lambda functions from TypeScript code. esbuild support is currently in public preview. During public preview, esbuild support may be subject to backwards incompatible changes.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.AWS CLI version 2",
                            "  2.AWS SAM CLI version 1.75 or later",
                            "  3.Node.js 18.x",
                            "Deploy a sample AWS SAM application",
                            " 1 : Initialize the application using the Hello World TypeScript template. ",
                            {
                                "code_example": "sam init --app-template hello-world-typescript --name sam-app --package-type Zip --runtime nodejs18.x"
                            },
                            " 2 : (Optional) The sample application includes configurations for commonly used tools, such as ESLlint for code linting and Jest for unit testing. To run lint and test commands: ",
                            {
                                "code_example": "cd sam-app/hello-world\nnpm install\nnpm run lint\nnpm run test"
                            },
                            " 3 : Build the app. ",
                            {
                                "code_example": "cd sam-app\nsam build"
                            },
                            " 4 : Deploy the app. ",
                            {
                                "code_example": "sam deploy --guided"
                            },
                            "  5 : Follow the on-screen prompts. To accept the default options provided in the interactive experience, respond with Enter.",
                            " 6 : The output shows the endpoint for the REST API. Open the endpoint in a browser to test the function. You should see this response: ",
                            {
                                "code_example": "{\"message\":\"hello world\"}"
                            },
                            " 7 : This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing. ",
                            {
                                "code_example": "sam delete"
                            }
                        ]
                    },
                    {
                        "sub_header": "Using the AWS CDK to deploy TypeScript code to Lambda",
                        "content": [
                            "Follow the steps below to build and deploy a sample TypeScript application using the AWS CDK. This application implements a basic API backend. It consists of an API Gateway endpoint and a Lambda function. When you send a GET request to the API Gateway endpoint, the Lambda function is invoked. The function returns a hello world message.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.AWS CLI version 2",
                            "  2.AWS CDK version 2",
                            "  3.Node.js 18.x",
                            "  4.Either Docker or esbuild",
                            "Deploy a sample AWS CDK application",
                            " 1 : Create a project directory for your new application. ",
                            {
                                "code_example": "mkdir hello-world\ncd hello-world"
                            },
                            " 2 : Initialize the app. ",
                            {
                                "code_example": "cdk init app --language typescript"
                            },
                            " 3 : Add the @types/aws-lambda package as a development dependency. This package contains the type definitions for Lambda. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda"
                            },
                            "  4 : Open the lib directory. You should see a file called hello-world-stack.ts. Create two new files in this directory: hello-world.function.ts and hello-world.ts.",
                            " 5 : Open hello-world.function.ts and add the following code to the file. This is the code for the Lambda function.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository. ",
                            {
                                "code_example": "import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';\n\nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n    console.log(`Event: ${JSON.stringify(event, null, 2)}`);\n    console.log(`Context: ${JSON.stringify(context, null, 2)}`);\n    return {\n        statusCode: 200,\n        body: JSON.stringify({\n            message: 'hello world',\n        }),\n    };\n};"
                            },
                            " 6 : Open hello-world.ts and add the following code to the file. This contains the NodejsFunction construct, which creates the Lambda function, and the LambdaRestApi construct, which creates the REST API. The NodejsFunction construct assumes the following by default:Your function handler is called handler.The .ts file that contains the function code (hello-world.function.ts) is in the same directory as the .ts file that contains the construct (hello-world.ts). The construct uses the construct's ID (\"hello-world\") and the name of the Lambda handler file (\"function\") to find the function code. For example, if your function code is in a file called hello-world.my-function.ts, the hello-world.ts file must reference the function code like this:const helloFunction = new NodejsFunction(this, 'my-function');You can change this behavior and configure other esbuild parameters. For more information, see Configuring esbuild in the AWS CDK API reference.",
                            {
                                "code_example": "import { Construct } from 'constructs';\nimport { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport { LambdaRestApi } from 'aws-cdk-lib/aws-apigateway';\n  \nexport class HelloWorld extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const helloFunction = new NodejsFunction(this, 'function');\n    new LambdaRestApi(this, 'apigw', {\n      handler: helloFunction,\n    });\n  }\n}"
                            },
                            " 7 : Open hello-world-stack.ts. This is the code that defines your AWS CDK stack. Replace the code with the following: ",
                            {
                                "code_example": "import { Stack, StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { HelloWorld } from './hello-world';\n  \nexport class HelloWorldStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    new HelloWorld(this, 'hello-world');\n  }\n}"
                            },
                            " 8 : from the hello-world directory containing your cdk.json file, deploy your           application. ",
                            {
                                "code_example": "cdk deploy"
                            },
                            " 9 : The AWS CDK builds and packages the Lambda function using esbuild, and then deploys the function to the Lambda runtime. The output shows the endpoint for the REST API. Open the endpoint in a browser to test the function. You should see this response: This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing.",
                            {
                                "code_example": "{\"message\":\"hello world\"}"
                            }
                        ]
                    },
                    {
                        "sub_header": "Using the AWS CLI and esbuild to deploy TypeScript code to Lambda",
                        "content": [
                            "The following example demonstrates how to transpile and deploy TypeScript code to Lambda using esbuild and the AWS CLI. esbuild produces one JavaScript file with all dependencies. This is the only file that you need to add to the .zip archive.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.AWS CLI version 2",
                            "  2.Node.js 18.x",
                            "  3.An execution role for the Lambda function",
                            "  4.For Windows users, a zip file utility such as 7zip.",
                            "Deploy a sample function",
                            "  1 : On your local machine, create a project directory for your new function. ",
                            " 2 : Create a new Node.js project with npm or a package manager of your choice. ",
                            {
                                "code_example": "npm init"
                            },
                            " 3 : Add the @types/aws-lambda and esbuild packages as development dependencies. The @types/aws-lambda package contains the type definitions for Lambda. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda esbuild"
                            },
                            " 4 : Create a new file called index.ts. Add the following code to the new file. This is the code for the Lambda function. The function returns a hello world message. The function doesn’t create any API Gateway resources.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository. ",
                            {
                                "code_example": "import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';\n\nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n  console.log(`Event: ${JSON.stringify(event, null, 2)}`);\n  console.log(`Context: ${JSON.stringify(context, null, 2)}`);\n  return {\n      statusCode: 200,\n      body: JSON.stringify({\n          message: 'hello world',\n      }),\n   };\n};"
                            },
                            " 5 : Add a build script to the package.json file. This configures esbuild to automatically create the .zip deployment package. For more information, see Build scripts in the esbuild documentation.Linux and MacOS WindowsIn this example, the \"postbuild\" command uses the 7zip utility to       create your .zip file. Use your own preferred Windows zip utility and modify the command as necessary.\"scripts\": {  \"prebuild\": \"del /q dist\",  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\",  \"postbuild\": \"cd dist && 7z a -tzip index.zip index.js*\"},anchoranchorLinux and MacOSWindows ",
                            {
                                "code_example": "\"scripts\": {\n  \"prebuild\": \"rm -rf dist\",\n  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\",\n  \"postbuild\": \"cd dist && zip -r index.zip index.js*\"\n},"
                            },
                            " 6 : Build the package. ",
                            {
                                "code_example": "npm run build"
                            },
                            " 7 : Create a Lambda function using the .zip deployment package. Replace the highlighted text with the Amazon Resource Name (ARN) of your execution role. ",
                            {
                                "code_example": "aws lambda create-function --function-name hello-world --runtime \"nodejs18.x\" --role arn:aws:iam::123456789012:role/lambda-ex --zip-file \"fileb://dist/index.zip\" --handler index.handler"
                            },
                            " 8 : Run a test event to confirm that the function returns the following response. If you want to invoke this function using API Gateway, create and configure a REST API. ",
                            {
                                "code_example": "{\n  \"statusCode\": 200,\n  \"body\": \"{\\\"message\\\":\\\"hello world\\\"}\"\n}"
                            }
                        ]
                    }
                ]
            },
            {
                "title": "Deploy container images",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-image.html",
                "sections": [
                    "You can deploy your TypeScript code to an AWS Lambda function as a Node.js container image. AWS provides base images for Node.js to help you build the container image. These base images are preloaded with a language runtime and other components that are required to run the image on Lambda. AWS provides a Dockerfile for each of the base images to help with building your container image.",
                    "If you use a community or private enterprise base image, you must add the Node.js runtime interface client (RIC) to the base image to make it compatible with Lambda.",
                    "Lambda provides a runtime interface emulator for local testing. The AWS base images for Node.js include the runtime interface emulator. If you use an alternative base image, such as an Alpine Linux or Debian image, you can build the emulator into your image or install it on your local machine.",
                    {
                        "sub_header": "Using a Node.js base image to build and package TypeScript function code",
                        "content": [
                            "To complete the steps in this section, you must have the following:",
                            "  1.AWS CLI version 2",
                            "  2.Docker",
                            "  3.Node.js 22.x",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.AWS CLI version 2",
                            "  2.Docker",
                            "  3.Node.js 22.x",
                            "To complete the steps in this section, you must have the following:AWS CLI version 2DockerNode.js 22.xPrerequisitesTo complete the steps in this section, you must have the following:AWS CLI version 2DockerNode.js 22.x",
                            "To create an image from an AWS base image for Lambda",
                            "  1 : On your local machine, create a project directory for your new function.",
                            " 2 : Create a new Node.js project with npm or a package manager of your choice. ",
                            {
                                "code_example": "npm init"
                            },
                            " 3 : Add the @types/aws-lambda and esbuild packages as development dependencies. The @types/aws-lambda package contains the type definitions for Lambda. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda esbuild"
                            },
                            " 4 : Add a build script to the package.json file. ",
                            {
                                "code_example": "  \"scripts\": {\n  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\"\n}"
                            },
                            " 5 : Create a new file called index.ts. Add the following sample code to the new file. This is the code for the Lambda function. The function returns a hello world message.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository. ",
                            {
                                "code_example": "import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';\n\nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n    console.log(`Event: ${JSON.stringify(event, null, 2)}`);\n    console.log(`Context: ${JSON.stringify(context, null, 2)}`);\n    return {\n        statusCode: 200,\n        body: JSON.stringify({\n            message: 'hello world',\n        }),\n    };\n};"
                            },
                            " 6 : Create a new Dockerfile with the following configuration:Set the FROM property to the URI of the base image.Set the CMD argument to specify the Lambda function handler.The following example Dockerfile uses a multi-stage build. The first step transpiles the TypeScript code into JavaScript. The second step produces a container image that contains only JavaScript files and production dependencies.Note that the example Dockerfile does not include a USER instruction. When you deploy a container image to Lambda, Lambda automatically defines a default Linux user with least-privileged permissions. This is different from standard Docker behavior which defaults to the root user when no USER instruction is provided.Example  Dockerfile ",
                            {
                                "code_example": "FROM public.ecr.aws/lambda/nodejs:22 as builder\nWORKDIR /usr/app\nCOPY package.json index.ts  ./\nRUN npm install\nRUN npm run build\n    \nFROM public.ecr.aws/lambda/nodejs:22\nWORKDIR ${LAMBDA_TASK_ROOT}\nCOPY --from=builder /usr/app/dist/* ./\nCMD [\"index.handler\"]"
                            },
                            " 7 : Build the Docker image with the docker build command. The          following example names the image docker-image and gives it the test tag. NoteThe command specifies the --platform linux/amd64 option to ensure that your container is compatible with the Lambda execution environment regardless of the         architecture of your build machine. If you intend to create a Lambda function using the ARM64 instruction set architecture, be sure to change the command to use the --platform linux/arm64        option instead.",
                            {
                                "code_example": "docker build --platform linux/amd64 -t docker-image:test ."
                            },
                            "Creating an image from a base image",
                            "To create an image from an AWS base image for Lambda",
                            "  1 : On your local machine, create a project directory for your new function.",
                            " 2 : Create a new Node.js project with npm or a package manager of your choice. ",
                            {
                                "code_example": "npm init"
                            },
                            " 3 : Add the @types/aws-lambda and esbuild packages as development dependencies. The @types/aws-lambda package contains the type definitions for Lambda. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda esbuild"
                            },
                            " 4 : Add a build script to the package.json file. ",
                            {
                                "code_example": "  \"scripts\": {\n  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\"\n}"
                            },
                            " 5 : Create a new file called index.ts. Add the following sample code to the new file. This is the code for the Lambda function. The function returns a hello world message.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository. ",
                            {
                                "code_example": "import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';\n\nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n    console.log(`Event: ${JSON.stringify(event, null, 2)}`);\n    console.log(`Context: ${JSON.stringify(context, null, 2)}`);\n    return {\n        statusCode: 200,\n        body: JSON.stringify({\n            message: 'hello world',\n        }),\n    };\n};"
                            },
                            " 6 : Create a new Dockerfile with the following configuration:Set the FROM property to the URI of the base image.Set the CMD argument to specify the Lambda function handler.The following example Dockerfile uses a multi-stage build. The first step transpiles the TypeScript code into JavaScript. The second step produces a container image that contains only JavaScript files and production dependencies.Note that the example Dockerfile does not include a USER instruction. When you deploy a container image to Lambda, Lambda automatically defines a default Linux user with least-privileged permissions. This is different from standard Docker behavior which defaults to the root user when no USER instruction is provided.Example  Dockerfile ",
                            {
                                "code_example": "FROM public.ecr.aws/lambda/nodejs:22 as builder\nWORKDIR /usr/app\nCOPY package.json index.ts  ./\nRUN npm install\nRUN npm run build\n    \nFROM public.ecr.aws/lambda/nodejs:22\nWORKDIR ${LAMBDA_TASK_ROOT}\nCOPY --from=builder /usr/app/dist/* ./\nCMD [\"index.handler\"]"
                            },
                            " 7 : Build the Docker image with the docker build command. The          following example names the image docker-image and gives it the test tag. NoteThe command specifies the --platform linux/amd64 option to ensure that your container is compatible with the Lambda execution environment regardless of the         architecture of your build machine. If you intend to create a Lambda function using the ARM64 instruction set architecture, be sure to change the command to use the --platform linux/arm64        option instead.",
                            {
                                "code_example": "docker build --platform linux/amd64 -t docker-image:test ."
                            },
                            "To create an image from an AWS base image for LambdaOn your local machine, create a project directory for your new function.Create a new Node.js project with npm or a package manager of your choice.npm initAdd the @types/aws-lambda and esbuild packages as development dependencies. The @types/aws-lambda package contains the type definitions for Lambda.npm install -D @types/aws-lambda esbuildAdd a build script to the package.json file.  \"scripts\": {  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\"}Create a new file called index.ts. Add the following sample code to the new file. This is the code for the Lambda function. The function returns a hello world message.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';export const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {    console.log(`Event: ${JSON.stringify(event, null, 2)}`);    console.log(`Context: ${JSON.stringify(context, null, 2)}`);    return {        statusCode: 200,        body: JSON.stringify({            message: 'hello world',        }),    };};Create a new Dockerfile with the following configuration:Set the FROM property to the URI of the base image.Set the CMD argument to specify the Lambda function handler.The following example Dockerfile uses a multi-stage build. The first step transpiles the TypeScript code into JavaScript. The second step produces a container image that contains only JavaScript files and production dependencies.Note that the example Dockerfile does not include a USER instruction. When you deploy a container image to Lambda, Lambda automatically defines a default Linux user with least-privileged permissions. This is different from standard Docker behavior which defaults to the root user when no USER instruction is provided.Example  DockerfileFROM public.ecr.aws/lambda/nodejs:22 as builderWORKDIR /usr/appCOPY package.json index.ts  ./RUN npm installRUN npm run build    FROM public.ecr.aws/lambda/nodejs:22WORKDIR ${LAMBDA_TASK_ROOT}COPY --from=builder /usr/app/dist/* ./CMD [\"index.handler\"]Build the Docker image with the docker build command. The          following example names the image docker-image and gives it the test tag.docker build --platform linux/amd64 -t docker-image:test .NoteThe command specifies the --platform linux/amd64 option to ensure that your container is compatible with the Lambda execution environment regardless of the         architecture of your build machine. If you intend to create a Lambda function using the ARM64 instruction set architecture, be sure to change the command to use the --platform linux/arm64        option instead.Creating an image from a base imageTo create an image from an AWS base image for LambdaOn your local machine, create a project directory for your new function.Create a new Node.js project with npm or a package manager of your choice.npm initAdd the @types/aws-lambda and esbuild packages as development dependencies. The @types/aws-lambda package contains the type definitions for Lambda.npm install -D @types/aws-lambda esbuildAdd a build script to the package.json file.  \"scripts\": {  \"build\": \"esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js\"}Create a new file called index.ts. Add the following sample code to the new file. This is the code for the Lambda function. The function returns a hello world message.NoteThe import statement imports the type definitions from @types/aws-lambda. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.import { Context, APIGatewayProxyResult, APIGatewayEvent } from 'aws-lambda';export const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {    console.log(`Event: ${JSON.stringify(event, null, 2)}`);    console.log(`Context: ${JSON.stringify(context, null, 2)}`);    return {        statusCode: 200,        body: JSON.stringify({            message: 'hello world',        }),    };};Create a new Dockerfile with the following configuration:Set the FROM property to the URI of the base image.Set the CMD argument to specify the Lambda function handler.The following example Dockerfile uses a multi-stage build. The first step transpiles the TypeScript code into JavaScript. The second step produces a container image that contains only JavaScript files and production dependencies.Note that the example Dockerfile does not include a USER instruction. When you deploy a container image to Lambda, Lambda automatically defines a default Linux user with least-privileged permissions. This is different from standard Docker behavior which defaults to the root user when no USER instruction is provided.Example  DockerfileFROM public.ecr.aws/lambda/nodejs:22 as builderWORKDIR /usr/appCOPY package.json index.ts  ./RUN npm installRUN npm run build    FROM public.ecr.aws/lambda/nodejs:22WORKDIR ${LAMBDA_TASK_ROOT}COPY --from=builder /usr/app/dist/* ./CMD [\"index.handler\"]Build the Docker image with the docker build command. The          following example names the image docker-image and gives it the test tag.docker build --platform linux/amd64 -t docker-image:test .NoteThe command specifies the --platform linux/amd64 option to ensure that your container is compatible with the Lambda execution environment regardless of the         architecture of your build machine. If you intend to create a Lambda function using the ARM64 instruction set architecture, be sure to change the command to use the --platform linux/arm64        option instead.",
                            " 1 : Start the Docker image with the docker run command. In this example,              docker-image is the image name and test is the tag. This command runs the image as a container and creates a local endpoint at            localhost:9000/2015-03-31/functions/function/invocations.NoteIf you built the Docker image for the ARM64 instruction set architecture, be sure to use the --platform linux/arm64 option instead of --platform linux/amd64.",
                            {
                                "code_example": "docker run --platform linux/amd64 -p 9000:8080 docker-image:test"
                            },
                            " 2 : From a new terminal window, post an event to the local endpoint.Linux/macOSIn Linux and macOS, run the following curl command: This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'PowerShellIn PowerShell, run the following Invoke-WebRequest command:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{}' -ContentType \"application/json\"This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{\"payload\":\"hello world!\"}' -ContentType \"application/json\"",
                            {
                                "code_example": "curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{}'"
                            },
                            " 3 : Get the container ID. ",
                            {
                                "code_example": "docker ps"
                            },
                            " 4 : Use the docker kill command to stop the container. In this command, replace 3766c4ab331c with the container ID from the previous step. ",
                            {
                                "code_example": "docker kill 3766c4ab331c"
                            },
                            "(Optional) Test the image locally",
                            " 1 : Start the Docker image with the docker run command. In this example,              docker-image is the image name and test is the tag. This command runs the image as a container and creates a local endpoint at            localhost:9000/2015-03-31/functions/function/invocations.NoteIf you built the Docker image for the ARM64 instruction set architecture, be sure to use the --platform linux/arm64 option instead of --platform linux/amd64.",
                            {
                                "code_example": "docker run --platform linux/amd64 -p 9000:8080 docker-image:test"
                            },
                            " 2 : From a new terminal window, post an event to the local endpoint.Linux/macOSIn Linux and macOS, run the following curl command: This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'PowerShellIn PowerShell, run the following Invoke-WebRequest command:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{}' -ContentType \"application/json\"This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{\"payload\":\"hello world!\"}' -ContentType \"application/json\"anchoranchorLinux/macOSPowerShellIn Linux and macOS, run the following curl command: This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'",
                            {
                                "code_example": "curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{}'"
                            },
                            " 3 : Get the container ID. ",
                            {
                                "code_example": "docker ps"
                            },
                            " 4 : Use the docker kill command to stop the container. In this command, replace 3766c4ab331c with the container ID from the previous step. ",
                            {
                                "code_example": "docker kill 3766c4ab331c"
                            },
                            "Start the Docker image with the docker run command. In this example,              docker-image is the image name and test is the tag.docker run --platform linux/amd64 -p 9000:8080 docker-image:testThis command runs the image as a container and creates a local endpoint at            localhost:9000/2015-03-31/functions/function/invocations.NoteIf you built the Docker image for the ARM64 instruction set architecture, be sure to use the --platform linux/arm64 option instead of --platform linux/amd64.From a new terminal window, post an event to the local endpoint.Linux/macOSIn Linux and macOS, run the following curl command:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{}'This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'PowerShellIn PowerShell, run the following Invoke-WebRequest command:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{}' -ContentType \"application/json\"This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{\"payload\":\"hello world!\"}' -ContentType \"application/json\"Get the container ID.docker psUse the docker kill command to stop the container. In this command, replace 3766c4ab331c with the container ID from the previous step.docker kill 3766c4ab331c(Optional) Test the image locallyStart the Docker image with the docker run command. In this example,              docker-image is the image name and test is the tag.docker run --platform linux/amd64 -p 9000:8080 docker-image:testThis command runs the image as a container and creates a local endpoint at            localhost:9000/2015-03-31/functions/function/invocations.NoteIf you built the Docker image for the ARM64 instruction set architecture, be sure to use the --platform linux/arm64 option instead of --platform linux/amd64.From a new terminal window, post an event to the local endpoint.Linux/macOSIn Linux and macOS, run the following curl command:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{}'This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'PowerShellIn PowerShell, run the following Invoke-WebRequest command:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{}' -ContentType \"application/json\"This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:Invoke-WebRequest -Uri \"http://localhost:9000/2015-03-31/functions/function/invocations\" -Method Post -Body '{\"payload\":\"hello world!\"}' -ContentType \"application/json\"anchoranchorLinux/macOSPowerShellIn Linux and macOS, run the following curl command:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{}'This command invokes the function with an empty event and returns a response. If you're using your own function code rather than the sample function code, you might want to invoke the function with a JSON payload. Example:curl \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'Get the container ID.docker psUse the docker kill command to stop the container. In this command, replace 3766c4ab331c with the container ID from the previous step.docker kill 3766c4ab331c",
                            "To upload the image to Amazon ECR and create the Lambda function",
                            " 1 : Run the get-login-password command to authenticate the Docker CLI to your Amazon ECR registry.Set the --region value to the AWS Region where you want to create the Amazon ECR repository.Replace 111122223333 with your AWS account ID. ",
                            {
                                "code_example": "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 111122223333.dkr.ecr.us-east-1.amazonaws.com"
                            },
                            " 2 : Create a repository in Amazon ECR using the create-repository command. NoteThe Amazon ECR repository must be in the same AWS Region as the Lambda function.If successful, you see a response like this:{    \"repository\": {        \"repositoryArn\": \"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\",        \"registryId\": \"111122223333\",        \"repositoryName\": \"hello-world\",        \"repositoryUri\": \"111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world\",        \"createdAt\": \"2023-03-09T10:39:01+00:00\",        \"imageTagMutability\": \"MUTABLE\",        \"imageScanningConfiguration\": {            \"scanOnPush\": true        },        \"encryptionConfiguration\": {            \"encryptionType\": \"AES256\"        }    }}",
                            {
                                "code_example": "aws ecr create-repository --repository-name hello-world --region us-east-1 --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE"
                            },
                            "  3 : Copy the repositoryUri from the output in the previous step.",
                            " 4 : Run the docker tag command to tag your local image into your Amazon ECR repository as the latest version. In this command:docker-image:test is the name and tag of your Docker image. This is the image name and tag that you specified in the docker build command.Replace <ECRrepositoryUri> with the repositoryUri that you copied. Make sure to include :latest at the end of the URI. Example:docker tag docker-image:test 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest",
                            {
                                "code_example": "docker tag docker-image:test <ECRrepositoryUri>:latest"
                            },
                            " 5 : Run the docker push command to deploy your local image to the Amazon ECR repository. Make sure to include :latest at the end of the repository URI. ",
                            {
                                "code_example": "docker push 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest"
                            },
                            "  6 : Create an execution role for the function, if you don't already have one. You need the Amazon Resource Name (ARN) of the role in the next step.",
                            " 7 : Create the Lambda function. For ImageUri, specify the repository URI from earlier. Make sure to include :latest at the end of the URI. NoteYou can create a function using an image in a different AWS account, as long as the image is in the same Region as the Lambda function. For more information, see  Amazon ECR cross-account permissions.",
                            {
                                "code_example": "aws lambda create-function \\\n  --function-name hello-world \\\n  --package-type Image \\\n  --code ImageUri=111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\\n  --role arn:aws:iam::111122223333:role/lambda-ex"
                            },
                            " 8 : Invoke the function. You should see a response like this:{  \"ExecutedVersion\": \"$LATEST\",   \"StatusCode\": 200}",
                            {
                                "code_example": "aws lambda invoke --function-name hello-world response.json"
                            },
                            "  9 : To see the output of the function, check the response.json file.",
                            "To update the function code, you must build the image again, upload the new image to the Amazon ECR repository, and then use the update-function-code command to deploy the image to the Lambda function.",
                            "Lambda resolves the image tag to a specific image digest. This means that if you point the image tag that was used to deploy the function to a new image in Amazon ECR, Lambda doesn't automatically update the function to use the new image.",
                            "To deploy the new image to the same Lambda function, you must use the update-function-code command, even if the image tag in Amazon ECR remains the same. In the following example, the --publish option creates a new version of the function using the updated container image.",
                            {
                                "code_example": "aws lambda update-function-code \\\n  --function-name hello-world \\\n  --image-uri 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\\n  --publish"
                            },
                            "Deploying the image",
                            "To upload the image to Amazon ECR and create the Lambda function",
                            " 1 : Run the get-login-password command to authenticate the Docker CLI to your Amazon ECR registry.Set the --region value to the AWS Region where you want to create the Amazon ECR repository.Replace 111122223333 with your AWS account ID. ",
                            {
                                "code_example": "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 111122223333.dkr.ecr.us-east-1.amazonaws.com"
                            },
                            " 2 : Create a repository in Amazon ECR using the create-repository command. NoteThe Amazon ECR repository must be in the same AWS Region as the Lambda function.If successful, you see a response like this:{    \"repository\": {        \"repositoryArn\": \"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\",        \"registryId\": \"111122223333\",        \"repositoryName\": \"hello-world\",        \"repositoryUri\": \"111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world\",        \"createdAt\": \"2023-03-09T10:39:01+00:00\",        \"imageTagMutability\": \"MUTABLE\",        \"imageScanningConfiguration\": {            \"scanOnPush\": true        },        \"encryptionConfiguration\": {            \"encryptionType\": \"AES256\"        }    }}",
                            {
                                "code_example": "aws ecr create-repository --repository-name hello-world --region us-east-1 --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE"
                            },
                            "  3 : Copy the repositoryUri from the output in the previous step.",
                            " 4 : Run the docker tag command to tag your local image into your Amazon ECR repository as the latest version. In this command:docker-image:test is the name and tag of your Docker image. This is the image name and tag that you specified in the docker build command.Replace <ECRrepositoryUri> with the repositoryUri that you copied. Make sure to include :latest at the end of the URI. Example:docker tag docker-image:test 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest",
                            {
                                "code_example": "docker tag docker-image:test <ECRrepositoryUri>:latest"
                            },
                            " 5 : Run the docker push command to deploy your local image to the Amazon ECR repository. Make sure to include :latest at the end of the repository URI. ",
                            {
                                "code_example": "docker push 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest"
                            },
                            "  6 : Create an execution role for the function, if you don't already have one. You need the Amazon Resource Name (ARN) of the role in the next step.",
                            " 7 : Create the Lambda function. For ImageUri, specify the repository URI from earlier. Make sure to include :latest at the end of the URI. NoteYou can create a function using an image in a different AWS account, as long as the image is in the same Region as the Lambda function. For more information, see  Amazon ECR cross-account permissions.",
                            {
                                "code_example": "aws lambda create-function \\\n  --function-name hello-world \\\n  --package-type Image \\\n  --code ImageUri=111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\\n  --role arn:aws:iam::111122223333:role/lambda-ex"
                            },
                            " 8 : Invoke the function. You should see a response like this:{  \"ExecutedVersion\": \"$LATEST\",   \"StatusCode\": 200}",
                            {
                                "code_example": "aws lambda invoke --function-name hello-world response.json"
                            },
                            "  9 : To see the output of the function, check the response.json file.",
                            "To update the function code, you must build the image again, upload the new image to the Amazon ECR repository, and then use the update-function-code command to deploy the image to the Lambda function.",
                            "Lambda resolves the image tag to a specific image digest. This means that if you point the image tag that was used to deploy the function to a new image in Amazon ECR, Lambda doesn't automatically update the function to use the new image.",
                            "To deploy the new image to the same Lambda function, you must use the update-function-code command, even if the image tag in Amazon ECR remains the same. In the following example, the --publish option creates a new version of the function using the updated container image.",
                            {
                                "code_example": "aws lambda update-function-code \\\n  --function-name hello-world \\\n  --image-uri 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\\n  --publish"
                            },
                            "To upload the image to Amazon ECR and create the Lambda functionRun the get-login-password command to authenticate the Docker CLI to your Amazon ECR registry.Set the --region value to the AWS Region where you want to create the Amazon ECR repository.Replace 111122223333 with your AWS account ID.aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 111122223333.dkr.ecr.us-east-1.amazonaws.comCreate a repository in Amazon ECR using the create-repository command.aws ecr create-repository --repository-name hello-world --region us-east-1 --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLENoteThe Amazon ECR repository must be in the same AWS Region as the Lambda function.If successful, you see a response like this:{    \"repository\": {        \"repositoryArn\": \"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\",        \"registryId\": \"111122223333\",        \"repositoryName\": \"hello-world\",        \"repositoryUri\": \"111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world\",        \"createdAt\": \"2023-03-09T10:39:01+00:00\",        \"imageTagMutability\": \"MUTABLE\",        \"imageScanningConfiguration\": {            \"scanOnPush\": true        },        \"encryptionConfiguration\": {            \"encryptionType\": \"AES256\"        }    }}Copy the repositoryUri from the output in the previous step.Run the docker tag command to tag your local image into your Amazon ECR repository as the latest version. In this command:docker-image:test is the name and tag of your Docker image. This is the image name and tag that you specified in the docker build command.Replace <ECRrepositoryUri> with the repositoryUri that you copied. Make sure to include :latest at the end of the URI.docker tag docker-image:test <ECRrepositoryUri>:latestExample:docker tag docker-image:test 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latestRun the docker push command to deploy your local image to the Amazon ECR repository. Make sure to include :latest at the end of the repository URI.docker push 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latestCreate an execution role for the function, if you don't already have one. You need the Amazon Resource Name (ARN) of the role in the next step.Create the Lambda function. For ImageUri, specify the repository URI from earlier. Make sure to include :latest at the end of the URI.aws lambda create-function \\  --function-name hello-world \\  --package-type Image \\  --code ImageUri=111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\  --role arn:aws:iam::111122223333:role/lambda-exNoteYou can create a function using an image in a different AWS account, as long as the image is in the same Region as the Lambda function. For more information, see  Amazon ECR cross-account permissions.Invoke the function.aws lambda invoke --function-name hello-world response.jsonYou should see a response like this:{  \"ExecutedVersion\": \"$LATEST\",   \"StatusCode\": 200}To see the output of the function, check the response.json file.To update the function code, you must build the image again, upload the new image to the Amazon ECR repository, and then use the update-function-code command to deploy the image to the Lambda function.Lambda resolves the image tag to a specific image digest. This means that if you point the image tag that was used to deploy the function to a new image in Amazon ECR, Lambda doesn't automatically update the function to use the new image.To deploy the new image to the same Lambda function, you must use the update-function-code command, even if the image tag in Amazon ECR remains the same. In the following example, the --publish option creates a new version of the function using the updated container image.aws lambda update-function-code \\  --function-name hello-world \\  --image-uri 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\  --publishDeploying the imageTo upload the image to Amazon ECR and create the Lambda functionRun the get-login-password command to authenticate the Docker CLI to your Amazon ECR registry.Set the --region value to the AWS Region where you want to create the Amazon ECR repository.Replace 111122223333 with your AWS account ID.aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 111122223333.dkr.ecr.us-east-1.amazonaws.comCreate a repository in Amazon ECR using the create-repository command.aws ecr create-repository --repository-name hello-world --region us-east-1 --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLENoteThe Amazon ECR repository must be in the same AWS Region as the Lambda function.If successful, you see a response like this:{    \"repository\": {        \"repositoryArn\": \"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\",        \"registryId\": \"111122223333\",        \"repositoryName\": \"hello-world\",        \"repositoryUri\": \"111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world\",        \"createdAt\": \"2023-03-09T10:39:01+00:00\",        \"imageTagMutability\": \"MUTABLE\",        \"imageScanningConfiguration\": {            \"scanOnPush\": true        },        \"encryptionConfiguration\": {            \"encryptionType\": \"AES256\"        }    }}Copy the repositoryUri from the output in the previous step.Run the docker tag command to tag your local image into your Amazon ECR repository as the latest version. In this command:docker-image:test is the name and tag of your Docker image. This is the image name and tag that you specified in the docker build command.Replace <ECRrepositoryUri> with the repositoryUri that you copied. Make sure to include :latest at the end of the URI.docker tag docker-image:test <ECRrepositoryUri>:latestExample:docker tag docker-image:test 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latestRun the docker push command to deploy your local image to the Amazon ECR repository. Make sure to include :latest at the end of the repository URI.docker push 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latestCreate an execution role for the function, if you don't already have one. You need the Amazon Resource Name (ARN) of the role in the next step.Create the Lambda function. For ImageUri, specify the repository URI from earlier. Make sure to include :latest at the end of the URI.aws lambda create-function \\  --function-name hello-world \\  --package-type Image \\  --code ImageUri=111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\  --role arn:aws:iam::111122223333:role/lambda-exNoteYou can create a function using an image in a different AWS account, as long as the image is in the same Region as the Lambda function. For more information, see  Amazon ECR cross-account permissions.Invoke the function.aws lambda invoke --function-name hello-world response.jsonYou should see a response like this:{  \"ExecutedVersion\": \"$LATEST\",   \"StatusCode\": 200}To see the output of the function, check the response.json file.To update the function code, you must build the image again, upload the new image to the Amazon ECR repository, and then use the update-function-code command to deploy the image to the Lambda function.Lambda resolves the image tag to a specific image digest. This means that if you point the image tag that was used to deploy the function to a new image in Amazon ECR, Lambda doesn't automatically update the function to use the new image.To deploy the new image to the same Lambda function, you must use the update-function-code command, even if the image tag in Amazon ECR remains the same. In the following example, the --publish option creates a new version of the function using the updated container image.aws lambda update-function-code \\  --function-name hello-world \\  --image-uri 111122223333.dkr.ecr.us-east-1.amazonaws.com/hello-world:latest \\  --publish"
                        ]
                    }
                ]
            },
            {
                "title": "Layers",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-layers.html",
                "sections": [
                    "A Lambda layer is a .zip  file archive that contains supplementary code or data. Layers usually contain library dependencies, a  custom runtime, or configuration files. Creating a layer involves  three general steps:",
                    "  1 : Package your layer content. This means creating a .zip file archive that contains the dependencies        you want to use in your functions.",
                    "  2 : Create the layer in Lambda.",
                    "  3 : Add the layer to your functions.",
                    "This topic contains steps and guidance on how to properly package and create a Node.js  Lambda layer with external library dependencies. Additionally, this topic explains how use your layer with a function written in TypeScript.",
                    {
                        "sub_header": "Prerequisites",
                        "content": [
                            "To follow the steps in this section, you must have the following:",
                            "  1.Node.js 20 and the npm package manager. For more information about installing Node.js, see Installing Node.js via package manager in the Node.js     documentation.",
                            "  2.AWS CLI version 2",
                            "Throughout this topic, we reference the layer-nodejs   sample application in the aws-lambda-developer-guide GitHub repository. This application contains scripts   that will package the lodash library into a Lambda layer. The layer   directory contains the scripts to generate the layer. The application also contains a TypeScript sample   function in the function-ts directory that uses the dependency from the layer.   After creating a layer, you can transpile, deploy and invoke the corresponding function to verify that everything   works. This document walks through how to create, package, deploy and test this layer using the TypeScript sample function.",
                            " This sample application uses the Node.js 20 runtime. If you add additional dependencies to your    layer, they must be compatible with Node.js 20."
                        ]
                    },
                    {
                        "sub_header": "Node.js layer compatibility with the Lambda runtime environment",
                        "content": [
                            "When you package code in a Node.js layer, you specify the Lambda runtime environments that the code is compatible with. To   assess code compatibility with a runtime, consider what versions of Node.js, what operating systems, and what   instruction set architectures the code is designed for.",
                            "Lambda Node.js runtimes specify their Node.js version and operating system. In this document, you will use the Node.js   20 runtime, which is based on AL2023. For more information about runtime versions, see Supported runtimes. When you create a Lambda function, you specify the instruction set architecture. In this   document, you will use the arm64 architecture. For more information about architectures in Lambda, see Selecting and configuring an instruction set architecture for your Lambda function.",
                            "When you use code provided in a package, each package maintainer independently defines their compatibility. Most   Node.js development is designed to work independently of operating system and instruction set architecture.   Additionally, breaking incompatibilities with new Node.js versions are not that common. Expect to spend more of your   time assessing compatibility between packages than assessing package compatibility with Node.js version,   operating system, or instruction set architecture.",
                            "Sometimes Node.js packages include compiled code, which require you to consider operating system and    instruction set architecture compatibility. If you do need to assess code compatibility for your packages, you will need to inspect the   packages and their documentation. Packages in NPM can specify their compatibility through the engines,   os, and cpu fields of their package.json manifest file. For more information   about package.json files, see package.json in the NPM documentation."
                        ]
                    },
                    {
                        "sub_header": "Layer paths for Node.js runtimes",
                        "content": [
                            "When you add a layer to a function, Lambda loads the layer content into the execution environment.    If your layer packages dependencies in specific folder paths,    the Node.js execution environment will recognize the modules, and you can reference the modules from your    function code.",
                            "To ensure that your modules are picked up, package them into your layer .zip file in one of the following folder paths.   These files are stored in /opt, and the folder paths are loaded into the PATH environment variable.",
                            "  1.nodejs/node_modules",
                            "  2.nodejs/nodeX/node_modules",
                            "For example, the resulting layer .zip file that you create in this tutorial has the   following directory structure:",
                            "layer_content.zip└ nodejs    └ node20        └ node_modules            └ lodash            └ <other potential dependencies>            └ ...",
                            "You will put the lodash library   in the nodejs/node20/node_modules directory. This   ensures that Lambda can locate the library during function invocations."
                        ]
                    },
                    {
                        "sub_header": "Packaging the layer content",
                        "content": [
                            "In this example, you package the lodash library in a layer .zip file. Complete the following steps  to install and package the layer content.",
                            "To install and package your layer content",
                            " 1 : Clone the      aws-lambda-developer-guide repository from GitHub, which contains the sample     code that you need in the sample-apps/layer-nodejs directory. ",
                            {
                                "code_example": "git clone https://github.com/awsdocs/aws-lambda-developer-guide.git"
                            },
                            " 2 : Navigate to the layer directory of the layer-nodejs sample     app. This directory contains the scripts that you use to create and package the layer     properly. ",
                            {
                                "code_example": "cd aws-lambda-developer-guide/sample-apps/layer-nodejs/layer"
                            },
                            "  3 : Ensure the package.json file lists lodash. This file    defines the dependencies that you want to include in the layer. You can update this file to include    any dependencies that you want in your layer. Note The package.json used in this step is not stored or used with your dependencies after they are      uploaded to a Lambda layer. It is only used in the layer packaging process, and does not      specify a run command and compatibility as the file would in a Node.js application or published package.",
                            " 4 : Ensure that you have shell permission to run the scripts in the layer directory. ",
                            {
                                "code_example": "chmod 744 1-install.sh && chmod 744 2-package.sh"
                            },
                            " 5 : Run the 1-install.sh script using the following command: This script runs npm install, which reads your package.json and downloads the dependencies defined inside of it.Example 1-install.shnpm install .",
                            {
                                "code_example": "./1-install.sh"
                            },
                            " 6 : Run the 2-package.sh script using the following command:  This script copies the contents from the node_modules directory into a new directory named     nodejs/node20. It then zips the contents of the nodejs directory into a file named     layer_content.zip. This is the .zip file for your layer. You can unzip the file and verify     that it contains the correct file structure, as shown in the Layer paths for Node.js runtimes section. Example 2-package.shmkdir -p nodejs/node20cp -r node_modules nodejs/node20/zip -r layer_content.zip nodejs",
                            {
                                "code_example": "./2-package.sh"
                            }
                        ]
                    },
                    {
                        "sub_header": "Creating the layer",
                        "content": [
                            "Take the layer_content.zip file that you   generated in the previous section and upload it as a Lambda layer. You can upload a layer using   the AWS Management Console or the Lambda API via the AWS Command Line Interface (AWS CLI). When you upload your layer .zip   file, in the following PublishLayerVersion AWS CLI command, specify   nodejs20.x as the compatible runtime and arm64 as the compatible   architecture.",
                            "aws lambda publish-layer-version --layer-name nodejs-lodash-layer \\    --zip-file fileb://layer_content.zip \\    --compatible-runtimes nodejs20.x \\    --compatible-architectures \"arm64\"",
                            "From the response, note the LayerVersionArn, which looks like   arn:aws:lambda:us-east-1:123456789012:layer:nodejs-lodash-layer:1.   You'll need this Amazon Resource Name (ARN) in the next step of this tutorial, when you add   the layer to your function."
                        ]
                    },
                    {
                        "sub_header": "Adding the layer to your function",
                        "content": [
                            "Deploy a sample Lambda function that uses the lodash library in its function code, then attach the   layer you created. To create a Lambda function using function code written in TypeScript, you must transpile the   TypeScript to JavaScript for use by the Node.js runtime. For more information about this process, see Define Lambda function handler in TypeScript. For better compatibility, use tsc to transpile your TypeScript module when you   distribute your dependencies with layers. If you bundle your dependencies, consider using esbuild. For more   information about bundling with esbuild, see Deploy transpiled TypeScript code in Lambda with .zip file archives.",
                            "To deploy the function, you need an execution role. For more   information, see   Defining Lambda function permissions with an execution role. If you don't have an existing execution role,   follow the steps in the collapsible section. Otherwise, skip to the next section to deploy the   function.",
                            "To create an execution role",
                            "  1 : Open the roles page in the IAM console.",
                            "  2 : Choose Create role.",
                            "  3 : Create a role with the following properties.Trusted entity – Lambda.Permissions – AWSLambdaBasicExecutionRole.Role name – lambda-role.The AWSLambdaBasicExecutionRole policy has the permissions that the function needs to      write logs to CloudWatch Logs.",
                            "(Optional) Create an execution role",
                            "To create an execution role",
                            "  1 : Open the roles page in the IAM console.",
                            "  2 : Choose Create role.",
                            "  3 : Create a role with the following properties.Trusted entity – Lambda.Permissions – AWSLambdaBasicExecutionRole.Role name – lambda-role.The AWSLambdaBasicExecutionRole policy has the permissions that the function needs to      write logs to CloudWatch Logs.",
                            "To create an execution roleOpen the roles page in the IAM console.Choose Create role.Create a role with the following properties.Trusted entity – Lambda.Permissions – AWSLambdaBasicExecutionRole.Role name – lambda-role.The AWSLambdaBasicExecutionRole policy has the permissions that the function needs to      write logs to CloudWatch Logs.(Optional) Create an execution roleTo create an execution roleOpen the roles page in the IAM console.Choose Create role.Create a role with the following properties.Trusted entity – Lambda.Permissions – AWSLambdaBasicExecutionRole.Role name – lambda-role.The AWSLambdaBasicExecutionRole policy has the permissions that the function needs to      write logs to CloudWatch Logs.",
                            "The sample function code uses the lodash _.findLastIndex method to read through an array of objects. It   compares the objects against a criteria to find the index of a match. Then, it returns the index and value of the   object in the Lambda response.",
                            "import { Handler } from 'aws-lambda';import * as _ from 'lodash';type User = {  user: string;  active: boolean;}type UserResult = {  statusCode: number;  body: string;}const users: User[] = [  { 'user': 'Carlos', 'active': true },  { 'user': 'Gil-dong', 'active': false },  { 'user': 'Pat', 'active': false }];export const handler: Handler<any, UserResult> = async (): Promise<UserResult> => {  let out = _.findLastIndex(users, (user: User) => { return user.user == 'Pat'; });  const response = {    statusCode: 200,    body: JSON.stringify(out + \", \" + users[out].user),  };  return response;};",
                            "To deploy the Lambda function",
                            " 1 : Navigate to the function-ts/ directory of the layer-nodejs sample application. If you're currently in the     layer/ directory of the layer-nodejs sample application, then run the following command: ",
                            {
                                "code_example": "cd ../function-ts"
                            },
                            " 2 : Install the development dependencies listed in the package.json using the following command: ",
                            {
                                "code_example": "npm install"
                            },
                            " 3 : Run the build task defined in the package.json to transpile and package your function code into a .zip file. Use the following command: ",
                            {
                                "code_example": "npm run build"
                            },
                            " 4 : Deploy the function. In the following AWS CLI command, replace the --role     parameter with your execution role ARN: ",
                            {
                                "code_example": "aws lambda create-function --function-name nodejs_function_with_layer \\\n    --runtime nodejs20.x \\\n    --architectures \"arm64\" \\\n    --handler index.handler \\\n    --role arn:aws:iam::123456789012:role/lambda-role \\\n    --zip-file fileb://dist/index.zip"
                            },
                            " 5 : Attach the layer to your function. In the following AWS CLI command, replace the     --layers parameter with the layer version ARN that you noted earlier: ",
                            {
                                "code_example": "aws lambda update-function-configuration --function-name nodejs_function_with_layer \\\n    --cli-binary-format raw-in-base64-out \\\n    --layers \"arn:aws:lambda:us-east-1:123456789012:layer:nodejs-lodash-layer:1\""
                            },
                            " 6 : Invoke your function to verify it works using the following AWS CLI command: You should see output that looks like this:{    \"StatusCode\": 200,    \"ExecutedVersion\": \"$LATEST\"}The output response.json file contains details about the     response.",
                            {
                                "code_example": "aws lambda invoke --function-name nodejs_function_with_layer \\\n    --cli-binary-format raw-in-base64-out \\\n    --payload '{}' response.json"
                            },
                            "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                            "To delete the Lambda layer",
                            "  1 : Open the Layers page of the Lambda console.",
                            "  2 : Select the layer that you created.",
                            "  3 : Choose Delete, then choose Delete again.",
                            "To delete the Lambda function",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Select the function that you created.",
                            "  3 : Choose Actions, Delete.",
                            "  4 : Type delete in the text input field and choose Delete.",
                            "(Optional) Clean up your resources",
                            "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                            "To delete the Lambda layer",
                            "  1 : Open the Layers page of the Lambda console.",
                            "  2 : Select the layer that you created.",
                            "  3 : Choose Delete, then choose Delete again.",
                            "To delete the Lambda function",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Select the function that you created.",
                            "  3 : Choose Actions, Delete.",
                            "  4 : Type delete in the text input field and choose Delete.",
                            "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.To delete the Lambda layerOpen the Layers page of the Lambda console.Select the layer that you created.Choose Delete, then choose Delete again.To delete the Lambda functionOpen the Functions page of the Lambda console.Select the function that you created.Choose Actions, Delete.Type delete in the text input field and choose Delete.(Optional) Clean up your resourcesYou can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.To delete the Lambda layerOpen the Layers page of the Lambda console.Select the layer that you created.Choose Delete, then choose Delete again.To delete the Lambda functionOpen the Functions page of the Lambda console.Select the function that you created.Choose Actions, Delete.Type delete in the text input field and choose Delete."
                        ]
                    }
                ]
            },
            {
                "title": "Context",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-context.html",
                "sections": [
                    "When Lambda runs your function, it passes a context object to the handler.    This object provides methods and properties that provide information about the invocation, function, and execution    environment.",
                    "Context methods",
                    "  1.getRemainingTimeInMillis() – Returns the number of milliseconds left before the execution times out.",
                    "Context properties",
                    "  1.functionName – The name of the Lambda function.",
                    "  2.functionVersion – The version of the function.",
                    "  3.invokedFunctionArn – The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker    specified a version number or alias.",
                    "  4.memoryLimitInMB – The amount of memory that's allocated for the function.",
                    "  5.awsRequestId – The identifier of the invocation request.",
                    "  6.logGroupName – The log group for the function.",
                    "  7.logStreamName – The log stream for the function instance.",
                    "  8.identity – (mobile apps) Information about the Amazon Cognito identity that authorized the request.cognitoIdentityId – The authenticated Amazon Cognito identity.cognitoIdentityPoolId – The Amazon Cognito identity pool that authorized the invocation.",
                    "  9.cognitoIdentityId – The authenticated Amazon Cognito identity.",
                    "  10.cognitoIdentityPoolId – The Amazon Cognito identity pool that authorized the invocation.",
                    "  11.clientContext – (mobile apps) Client context that's provided to Lambda by the client application.client.installation_idclient.app_titleclient.app_version_nameclient.app_version_codeclient.app_package_nameenv.platform_versionenv.platformenv.makeenv.modelenv.localeCustom – Custom values that are set by the client application. ",
                    "  12.client.installation_id",
                    "  13.client.app_title",
                    "  14.client.app_version_name",
                    "  15.client.app_version_code",
                    "  16.client.app_package_name",
                    "  17.env.platform_version",
                    "  18.env.platform",
                    "  19.env.make",
                    "  20.env.model",
                    "  21.env.locale",
                    "  22.Custom – Custom values that are set by the client application. ",
                    "  23.callbackWaitsForEmptyEventLoop – Set to false to send the response right away when the        callback runs, instead of waiting for the Node.js event loop to        be empty. If this is false, any outstanding events continue to run during the next invocation.",
                    "You can use the @types/aws-lambda npm package to work with the context object.",
                    "Example index.ts file",
                    "The following example function logs context information and returns the location of the logs.",
                    "Note",
                    "Before using this code in a Lambda function, you must add the @types/aws-lambda package as a development dependency. This package contains the type definitions for Lambda. When @types/aws-lambda is installed, the import statement (import ... from 'aws-lambda') imports the type definitions. It does not import the aws-lambda NPM package, which is an unrelated third-party tool. For more information, see aws-lambda in the DefinitelyTyped GitHub repository.",
                    {
                        "code_example": "import { Context } from 'aws-lambda';\nexport const lambdaHandler = async (event: string, context: Context): Promise<string> => {\n  console.log('Remaining time: ', context.getRemainingTimeInMillis());\n  console.log('Function name: ', context.functionName);\n  return context.logStreamName;\n};"
                    }
                ]
            },
            {
                "title": "Logging",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-logging.html",
                "sections": [
                    "AWS Lambda automatically monitors Lambda functions and sends log entries to Amazon CloudWatch. Your Lambda function     comes with a CloudWatch Logs log group and a log stream for each instance of your function. The Lambda runtime environment     sends details about each invocation and other output from your function's     code to the log stream. For more information about CloudWatch Logs, see Using CloudWatch Logs with Lambda.",
                    "To output logs from your function code, you can use methods on the console object. For more detailed logging, you can use any logging library that writes to stdout or stderr.",
                    "Sections",
                    {
                        "sub_header": "Using logging tools and libraries",
                        "content": [
                            "Powertools for AWS Lambda (TypeScript) is a developer toolkit to implement Serverless best       practices and increase developer velocity. The Logger utility       provides a Lambda optimized logger which includes additional information about function context across all your functions with output structured as JSON. Use this       utility to do the following:",
                            "  1.Capture key fields from the Lambda context, cold start and structures logging output as JSON",
                            "  2.Log Lambda invocation events when instructed (disabled by default)",
                            "  3.Print all the logs only for a percentage of invocations via log sampling (disabled by default)",
                            "  4.Append additional keys to structured log at any point in time",
                            "  5.Use a custom log formatter (Bring Your Own Formatter) to output logs in a structure compatible with your organization’s Logging RFC"
                        ]
                    },
                    {
                        "sub_header": "Using Powertools for AWS Lambda (TypeScript) and AWS SAM for structured logging",
                        "content": [
                            "Follow the steps below to download, build, and deploy a sample Hello World TypeScript application with integrated Powertools for AWS Lambda (TypeScript) modules using the AWS SAM. This application implements a       basic API backend and uses Powertools for emitting logs, metrics, and traces. It consists of an Amazon API Gateway endpoint and a Lambda function.       When you send a GET request to the API Gateway endpoint, the Lambda function invokes, sends logs and metrics using Embedded Metric Format to CloudWatch, and       sends traces to AWS X-Ray. The function returns a hello world message.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.Node.js 18.x or later",
                            "  2.AWS CLI version 2",
                            "  3.AWS SAM CLI version 1.75 or later. If you have an older version of the AWS SAM CLI, see Upgrading the AWS SAM CLI.",
                            "Deploy a sample AWS SAM application",
                            " 1 : Initialize the application using the Hello World TypeScript template. ",
                            {
                                "code_example": "sam init --app-template hello-world-powertools-typescript --name sam-app --package-type Zip --runtime nodejs18.x"
                            },
                            " 2 : Build the app. ",
                            {
                                "code_example": "cd sam-app && sam build"
                            },
                            " 3 : Deploy the app. ",
                            {
                                "code_example": "sam deploy --guided"
                            },
                            "  4 : Follow the on-screen prompts. To accept the default options provided in the interactive experience, press Enter.NoteFor HelloWorldFunction may not have authorization defined, Is this okay?, make sure to enter y.",
                            " 5 : Get the URL of the deployed application: ",
                            {
                                "code_example": "aws cloudformation describe-stacks --stack-name sam-app --query 'Stacks[0].Outputs[?OutputKey==`HelloWorldApi`].OutputValue' --output text"
                            },
                            " 6 : Invoke the API endpoint: If successful, you'll see this response:{\"message\":\"hello world\"}",
                            {
                                "code_example": "curl <URL_FROM_PREVIOUS_STEP>"
                            },
                            " 7 : To get the logs for the function, run sam logs. For more information, see Working with logs in the AWS Serverless Application Model Developer Guide. The log output looks like this:2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.552000 START RequestId: 70693159-7e94-4102-a2af-98a6343fb8fb Version: $LATEST2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.594000 2022-08-31T09:33:10.557Z 70693159-7e94-4102-a2af-98a6343fb8fb INFO {\"_aws\":{\"Timestamp\":1661938390556,\"CloudWatchMetrics\":[{\"Namespace\":\"sam-app\",\"Dimensions\":[[\"service\"]],\"Metrics\":[{\"Name\":\"ColdStart\",\"Unit\":\"Count\"}]}]},\"service\":\"helloWorld\",\"ColdStart\":1}2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.595000 2022-08-31T09:33:10.595Z 70693159-7e94-4102-a2af-98a6343fb8fb INFO {\"level\":\"INFO\",\"message\":\"This is an INFO log - sending HTTP 200 - hello world response\",\"service\":\"helloWorld\",\"timestamp\":\"2022-08-31T09:33:10.594Z\"}2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.655000 2022-08-31T09:33:10.655Z 70693159-7e94-4102-a2af-98a6343fb8fb INFO {\"_aws\":{\"Timestamp\":1661938390655,\"CloudWatchMetrics\":[{\"Namespace\":\"sam-app\",\"Dimensions\":[[\"service\"]],\"Metrics\":[]}]},\"service\":\"helloWorld\"}2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.754000 END RequestId: 70693159-7e94-4102-a2af-98a6343fb8fb2023/01/31/[$LATEST]4d53e8d279824834a1ccd35511a4949c 2022-08-31T09:33:10.754000 REPORT RequestId: 70693159-7e94-4102-a2af-98a6343fb8fb Duration: 201.55 ms Billed Duration: 202 ms Memory Size: 128 MB Max Memory Used: 66 MB Init Duration: 252.42 msXRAY TraceId: 1-630f2ad5-1de22b6d29a658a466e7ecf5 SegmentId: 567c116658fbf11a Sampled: true",
                            {
                                "code_example": "sam logs --stack-name sam-app"
                            },
                            " 8 : This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing. ",
                            {
                                "code_example": "sam delete"
                            },
                            {
                                "sub_header": "Managing log retention",
                                "content": [
                                    "Log groups aren't deleted automatically when you delete a function. To avoid storing logs indefinitely, delete    the log group, or configure a retention period after which CloudWatch automatically deletes the logs. To set up log retention, add the following to your AWS SAM template:",
                                    "Resources:  HelloWorldFunction:    Type: AWS::Serverless::Function    Properties:    # Omitting other properties    LogGroup:    Type: AWS::Logs::LogGroup    Properties:      LogGroupName: !Sub \"/aws/lambda/${HelloWorldFunction}\"      RetentionInDays: 7"
                                ]
                            }
                        ]
                    },
                    {
                        "sub_header": "Using Powertools for AWS Lambda (TypeScript) and the AWS CDK for structured logging",
                        "content": [
                            "Follow the steps below to download, build, and deploy a sample Hello World TypeScript application with integrated Powertools for AWS Lambda (TypeScript) modules using the AWS CDK. This application implements a               basic API backend and uses Powertools for emitting logs, metrics, and traces. It consists of an Amazon API Gateway endpoint and a Lambda function.               When you send a GET request to the API Gateway endpoint, the Lambda function invokes, sends logs and metrics using Embedded Metric Format to CloudWatch, and               sends traces to AWS X-Ray. The function returns a hello world message.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.Node.js 18.x or later",
                            "  2.AWS CLI version 2",
                            "  3.AWS CDK version 2",
                            "  4.AWS SAM CLI version 1.75 or later. If you have an older version of the AWS SAM CLI, see Upgrading the AWS SAM CLI.",
                            "Deploy a sample AWS CDK application",
                            " 1 : Create a project directory for your new application. ",
                            {
                                "code_example": "mkdir hello-world\ncd hello-world"
                            },
                            " 2 : Initialize the app. ",
                            {
                                "code_example": "cdk init app --language typescript"
                            },
                            " 3 : Add the @types/aws-lambda package as a development dependency. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda"
                            },
                            " 4 : Install the Powertools Logger utility. ",
                            {
                                "code_example": "npm install @aws-lambda-powertools/logger"
                            },
                            "  5 : Open the lib directory. You should see a file called hello-world-stack.ts. Create new two new files in this directory: hello-world.function.ts and hello-world.ts.",
                            " 6 : Open hello-world.function.ts and add the following code to the file. This is the code for the Lambda function. ",
                            {
                                "code_example": "import { APIGatewayEvent, APIGatewayProxyResult, Context } from 'aws-lambda';\nimport { Logger } from '@aws-lambda-powertools/logger';\nconst logger = new Logger();\n  \nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n  logger.info('This is an INFO log - sending HTTP 200 - hello world response');\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      message: 'hello world',\n    }),\n  };\n};"
                            },
                            " 7 : Open hello-world.ts and add the following code to the file. This contains the NodejsFunction construct, which creates the Lambda function, configures environment variables for Powertools, and sets log retention to one week. It also includes the LambdaRestApi construct, which creates the REST API. ",
                            {
                                "code_example": "import { Construct } from 'constructs';\nimport { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport { LambdaRestApi } from 'aws-cdk-lib/aws-apigateway';\nimport { RetentionDays } from 'aws-cdk-lib/aws-logs';\nimport { CfnOutput } from 'aws-cdk-lib';\n  \nexport class HelloWorld extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const helloFunction = new NodejsFunction(this, 'function', {\n      environment: {\n        Powertools_SERVICE_NAME: 'helloWorld',\n        LOG_LEVEL: 'INFO',\n      },\n      logRetention: RetentionDays.ONE_WEEK,\n    });\n    const api = new LambdaRestApi(this, 'apigw', {\n      handler: helloFunction,\n    });\n    new CfnOutput(this, 'apiUrl', {\n      exportName: 'apiUrl',\n      value: api.url,\n    });\n  }\n}"
                            },
                            " 8 : Open hello-world-stack.ts. This is the code that defines your AWS CDK stack. Replace the code with the following: ",
                            {
                                "code_example": "import { Stack, StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { HelloWorld } from './hello-world';\n    \nexport class HelloWorldStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    new HelloWorld(this, 'hello-world');\n  }\n}"
                            },
                            " 9 : Go back to the project directory. ",
                            {
                                "code_example": "cd hello-world"
                            },
                            " 10 : Deploy your application. ",
                            {
                                "code_example": "cdk deploy"
                            },
                            " 11 : Get the URL of the deployed application: ",
                            {
                                "code_example": "aws cloudformation describe-stacks --stack-name HelloWorldStack --query 'Stacks[0].Outputs[?ExportName==`apiUrl`].OutputValue' --output text"
                            },
                            " 12 : Invoke the API endpoint: If successful, you'll see this response:{\"message\":\"hello world\"}",
                            {
                                "code_example": "curl <URL_FROM_PREVIOUS_STEP>"
                            },
                            " 13 : To get the logs for the function, run sam logs. For more information, see Working with logs in the AWS Serverless Application Model Developer Guide. The log output looks like this:2023/01/31/[$LATEST]2ca67f180dcd4d3e88b5d68576740c8e 2022-08-31T14:48:37.047000 START RequestId: 19ad1007-ff67-40ce-9afe-0af0a9eb512c Version: $LATEST2023/01/31/[$LATEST]2ca67f180dcd4d3e88b5d68576740c8e 2022-08-31T14:48:37.050000 {\"level\": \"INFO\",\"message\": \"This is an INFO log - sending HTTP 200 - hello world response\",\"service\": \"helloWorld\",\"timestamp\": \"2022-08-31T14:48:37.048Z\",\"xray_trace_id\": \"1-630f74c4-2b080cf77680a04f2362bcf2\"}2023/01/31/[$LATEST]2ca67f180dcd4d3e88b5d68576740c8e 2022-08-31T14:48:37.082000 END RequestId: 19ad1007-ff67-40ce-9afe-0af0a9eb512c2023/01/31/[$LATEST]2ca67f180dcd4d3e88b5d68576740c8e 2022-08-31T14:48:37.082000 REPORT RequestId: 19ad1007-ff67-40ce-9afe-0af0a9eb512c Duration: 34.60 ms Billed Duration: 35 ms Memory Size: 128 MB Max Memory Used: 57 MB Init Duration: 173.48 ms",
                            {
                                "code_example": "sam logs --stack-name HelloWorldStack"
                            },
                            " 14 : This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing. ",
                            {
                                "code_example": "cdk destroy"
                            }
                        ]
                    },
                    {
                        "sub_header": "Viewing logs in the Lambda console",
                        "content": [
                            "You can use the Lambda console to view log output after you invoke a Lambda function.",
                            "If your code can be tested from the embedded Code editor, you will find logs in the execution results. When you use the console test feature to invoke a function, you'll find Log output in the Details section."
                        ]
                    },
                    {
                        "sub_header": "Viewing logs in the CloudWatch console",
                        "content": [
                            "You can use the Amazon CloudWatch console to view logs for all Lambda function invocations.",
                            "To view logs on the CloudWatch console",
                            "  1 : Open the Log groups page on the CloudWatch console.",
                            "  2 : Choose the log group for your function (/aws/lambda/your-function-name).",
                            "  3 : Choose a log stream.",
                            "Each log stream corresponds to an instance of your function. A log stream appears when you update your Lambda function, and when additional instances are created to handle multiple concurrent invocations. To find logs for a specific invocation, we recommend instrumenting your function with AWS X-Ray. X-Ray records details about the request and the log stream in the trace."
                        ]
                    }
                ]
            },
            {
                "title": "Tracing",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/typescript-tracing.html",
                "sections": [
                    "Lambda integrates with AWS X-Ray to help you trace, debug, and optimize Lambda applications. You can use X-Ray    to trace a request as it traverses resources in your application, which may include Lambda functions and other AWS    services.",
                    "To send tracing data to X-Ray, you can use one of three SDK libraries:",
                    "  1.AWS Distro for OpenTelemetry (ADOT) – A secure, production-ready,        AWS-supported distribution of the OpenTelemetry (OTel) SDK.",
                    "  2.AWS X-Ray SDK for Node.js – An SDK        for generating and sending trace data to X-Ray.",
                    "  3.Powertools for AWS Lambda (TypeScript) – A developer toolkit to implement       Serverless best practices and increase developer velocity.",
                    "Each of the SDKs offer ways to send your telemetry data to the X-Ray service.    You can then use X-Ray to view, filter, and gain insights into your application's performance metrics to identify    issues and opportunities for optimization.",
                    "Important",
                    "The X-Ray and Powertools for AWS Lambda SDKs are part of a tightly integrated instrumentation solution offered by AWS. The ADOT Lambda Layers are part of an industry-wide standard for tracing instrumentation that collect more data in general, but may not be suited for all use cases. You can implement end-to-end tracing in X-Ray using either solution. To learn more about choosing between them, see Choosing between the AWS Distro for Open Telemetry and X-Ray SDKs.",
                    "Sections",
                    {
                        "sub_header": "Using Powertools for AWS Lambda (TypeScript) and AWS SAM for tracing",
                        "content": [
                            "Follow the steps below to download, build, and deploy a sample Hello World TypeScript application with integrated Powertools for AWS Lambda (TypeScript) modules using the AWS SAM. This application implements a       basic API backend and uses Powertools for emitting logs, metrics, and traces. It consists of an Amazon API Gateway endpoint and a Lambda function.       When you send a GET request to the API Gateway endpoint, the Lambda function invokes, sends logs and metrics using Embedded Metric Format to CloudWatch, and       sends traces to AWS X-Ray. The function returns a hello world message.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.Node.js 18.x or later",
                            "  2.AWS CLI version 2",
                            "  3.AWS SAM CLI version 1.75 or later. If you have an older version of the AWS SAM CLI, see Upgrading the AWS SAM CLI.",
                            "Deploy a sample AWS SAM application",
                            " 1 : Initialize the application using the Hello World TypeScript template. ",
                            {
                                "code_example": "sam init --app-template hello-world-powertools-typescript --name sam-app --package-type Zip --runtime nodejs18.x --no-tracing"
                            },
                            " 2 : Build the app. ",
                            {
                                "code_example": "cd sam-app && sam build"
                            },
                            " 3 : Deploy the app. ",
                            {
                                "code_example": "sam deploy --guided"
                            },
                            "  4 : Follow the on-screen prompts. To accept the default options provided in the interactive experience, press Enter.NoteFor HelloWorldFunction may not have authorization defined, Is this okay?, make sure to enter y.",
                            " 5 : Get the URL of the deployed application: ",
                            {
                                "code_example": "aws cloudformation describe-stacks --stack-name sam-app --query 'Stacks[0].Outputs[?OutputKey==`HelloWorldApi`].OutputValue' --output text"
                            },
                            " 6 : Invoke the API endpoint: If successful, you'll see this response:{\"message\":\"hello world\"}",
                            {
                                "code_example": "curl <URL_FROM_PREVIOUS_STEP>"
                            },
                            " 7 : To get the traces for the function, run  . The trace output looks like this:XRay Event [revision 1] at (2023-01-31T11:29:40.527000) with id (1-11a2222-111a222222cb33de3b95daf9) and duration (0.483s)  - 0.425s - sam-app/Prod [HTTP: 200]    - 0.422s - Lambda [HTTP: 200]  - 0.406s - sam-app-HelloWorldFunction-Xyzv11a1bcde [HTTP: 200]  - 0.172s - sam-app-HelloWorldFunction-Xyzv11a1bcde    - 0.179s - Initialization    - 0.112s - Invocation      - 0.052s - ## app.lambdaHandler        - 0.001s - ### MySubSegment    - 0.059s - Overhead",
                            {
                                "code_example": "sam traces"
                            },
                            " 8 : This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing. ",
                            {
                                "code_example": "sam delete"
                            },
                            "X-Ray doesn't trace all requests to your application. X-Ray applies a sampling algorithm    to ensure that tracing is efficient, while still providing a representative sample of all requests. The sampling rate is    1 request per second and 5 percent of additional requests. You can't configure the X-Ray sampling rate for your functions."
                        ]
                    },
                    {
                        "sub_header": "Using Powertools for AWS Lambda (TypeScript) and the AWS CDK for tracing",
                        "content": [
                            "Follow the steps below to download, build, and deploy a sample Hello World TypeScript application with integrated Powertools for AWS Lambda (TypeScript) modules using the AWS CDK. This application implements a               basic API backend and uses Powertools for emitting logs, metrics, and traces. It consists of an Amazon API Gateway endpoint and a Lambda function.               When you send a GET request to the API Gateway endpoint, the Lambda function invokes, sends logs and metrics using Embedded Metric Format to CloudWatch, and               sends traces to AWS X-Ray. The function returns a hello world message.",
                            "Prerequisites",
                            "To complete the steps in this section, you must have the following:",
                            "  1.Node.js 18.x or later",
                            "  2.AWS CLI version 2",
                            "  3.AWS CDK version 2",
                            "  4.AWS SAM CLI version 1.75 or later. If you have an older version of the AWS SAM CLI, see Upgrading the AWS SAM CLI.",
                            "Deploy a sample AWS Cloud Development Kit (AWS CDK) application",
                            " 1 : Create a project directory for your new application. ",
                            {
                                "code_example": "mkdir hello-world\ncd hello-world"
                            },
                            " 2 : Initialize the app. ",
                            {
                                "code_example": "cdk init app --language typescript"
                            },
                            " 3 : Add the @types/aws-lambda package as a development dependency. ",
                            {
                                "code_example": "npm install -D @types/aws-lambda"
                            },
                            " 4 : Install the Powertools Tracer utility. ",
                            {
                                "code_example": "npm install @aws-lambda-powertools/tracer"
                            },
                            "  5 : Open the lib directory. You should see a file called hello-world-stack.ts. Create new two new files in this directory: hello-world.function.ts and hello-world.ts.",
                            " 6 : Open hello-world.function.ts and add the following code to the file. This is the code for the Lambda function. ",
                            {
                                "code_example": "import { APIGatewayEvent, APIGatewayProxyResult, Context } from 'aws-lambda';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\nconst tracer = new Tracer();\n\nexport const handler = async (event: APIGatewayEvent, context: Context): Promise<APIGatewayProxyResult> => {\n  // Get facade segment created by Lambda\n  const segment = tracer.getSegment();\n\n  // Create subsegment for the function and set it as active\n  const handlerSegment = segment.addNewSubsegment(`## ${process.env._HANDLER}`);\n  tracer.setSegment(handlerSegment);\n\n  // Annotate the subsegment with the cold start and serviceName\n  tracer.annotateColdStart();\n  tracer.addServiceNameAnnotation();\n\n  // Add annotation for the awsRequestId\n  tracer.putAnnotation('awsRequestId', context.awsRequestId);\n  // Create another subsegment and set it as active\n  const subsegment = handlerSegment.addNewSubsegment('### MySubSegment');\n  tracer.setSegment(subsegment);\n  let response: APIGatewayProxyResult = {\n    statusCode: 200,\n    body: JSON.stringify({\n      message: 'hello world',\n    }),\n  };\n  // Close subsegments (the Lambda one is closed automatically)\n  subsegment.close(); // (### MySubSegment)\n  handlerSegment.close(); // (## index.handler)\n\n  // Set the facade segment as active again (the one created by Lambda)\n  tracer.setSegment(segment);\n  return response;\n};"
                            },
                            " 7 : Open hello-world.ts and add the following code to the file. This contains the NodejsFunction construct, which creates the Lambda function, configures environment variables for Powertools, and sets log retention to one week. It also includes the LambdaRestApi construct, which creates the REST API. ",
                            {
                                "code_example": "import { Construct } from 'constructs';\nimport { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport { LambdaRestApi } from 'aws-cdk-lib/aws-apigateway';\nimport { CfnOutput } from 'aws-cdk-lib';\nimport { Tracing } from 'aws-cdk-lib/aws-lambda';\n\nexport class HelloWorld extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const helloFunction = new NodejsFunction(this, 'function', {\n      environment: {\n        POWERTOOLS_SERVICE_NAME: 'helloWorld',\n      },\n      tracing: Tracing.ACTIVE,\n    });\n    const api = new LambdaRestApi(this, 'apigw', {\n      handler: helloFunction,\n    });\n    new CfnOutput(this, 'apiUrl', {\n      exportName: 'apiUrl',\n      value: api.url,\n    });\n  }\n}"
                            },
                            " 8 : Open hello-world-stack.ts. This is the code that defines your AWS CDK stack. Replace the code with the following: ",
                            {
                                "code_example": "import { Stack, StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { HelloWorld } from './hello-world';\n  \nexport class HelloWorldStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    new HelloWorld(this, 'hello-world');\n  }\n}"
                            },
                            " 9 : Deploy your application. ",
                            {
                                "code_example": "cd ..\ncdk deploy"
                            },
                            " 10 : Get the URL of the deployed application: ",
                            {
                                "code_example": "aws cloudformation describe-stacks --stack-name HelloWorldStack --query 'Stacks[0].Outputs[?ExportName==`apiUrl`].OutputValue' --output text"
                            },
                            " 11 : Invoke the API endpoint: If successful, you'll see this response:{\"message\":\"hello world\"}",
                            {
                                "code_example": "curl <URL_FROM_PREVIOUS_STEP>"
                            },
                            " 12 : To get the traces for the function, run  . The trace output looks like this:XRay Event [revision 1] at (2023-01-31T11:50:06.997000) with id (1-11a2222-111a222222cb33de3b95daf9) and duration (0.449s)  - 0.350s - HelloWorldStack-helloworldfunction111A2BCD-Xyzv11a1bcde [HTTP: 200]  - 0.157s - HelloWorldStack-helloworldfunction111A2BCD-Xyzv11a1bcde    - 0.169s - Initialization    - 0.058s - Invocation      - 0.055s - ## index.handler        - 0.000s - ### MySubSegment    - 0.099s - Overhead",
                            {
                                "code_example": "sam traces"
                            },
                            " 13 : This is a public API endpoint that is accessible over the internet. We recommend that you delete the endpoint after testing. ",
                            {
                                "code_example": "cdk destroy"
                            }
                        ]
                    },
                    {
                        "sub_header": "Interpreting an X-Ray trace",
                        "content": [
                            "After you've configured active tracing, you can observe specific requests    through your application. The     X-Ray trace map provides information about your application and all its components. The following example shows a trace from    the sample application:"
                        ]
                    }
                ]
            }
        ],
        "sections": [
            "You can use the Node.js runtime to run TypeScript code in AWS Lambda. Because Node.js doesn't run TypeScript code natively, you must first     transpile your TypeScript code into JavaScript. Then, use the JavaScript files to deploy your function code to Lambda. Your code runs in an     environment that includes the AWS SDK for JavaScript, with credentials from an AWS Identity and Access Management (IAM) role that you manage. To learn more     about the SDK versions included with the Node.js runtimes, see Runtime-included SDK versions.",
            "Lambda supports the following Node.js runtimes.",
            "NameIdentifierOperating systemDeprecation dateBlock function createBlock function updateNode.js 22nodejs22.xAmazon Linux 2023            Not scheduled                        Not scheduled                        Not scheduled            Node.js 20nodejs20.xAmazon Linux 2023            Not scheduled                        Not scheduled                        Not scheduled            Node.js 18nodejs18.xAmazon Linux 2            Jul 31, 2025                        Sep 1, 2025                        Oct 1, 2025            ",
            "Topics",
            {
                "sub_header": "Setting up a TypeScript development environment",
                "content": [
                    "Use a local integrated development environment (IDE), text editor, or AWS Cloud9 to write your TypeScript function code. You can’t create TypeScript code on the Lambda console.",
                    "To transpile your TypeScript code, set up a compiler such as esbuild or Microsoft's TypeScript compiler (tsc) , which is bundled with the TypeScript distribution. You can use the AWS Serverless Application Model (AWS SAM) or the AWS Cloud Development Kit (AWS CDK) to simplify building and deploying TypeScript code. Both tools use esbuild to transpile TypeScript code into JavaScript.",
                    "When using esbuild, consider the following:",
                    "  1.There are several TypeScript caveats.",
                    "  2.tsconfig.json : You must configure your TypeScript transpilation settings to match the Node.js runtime that you plan to use. For more information, see Target in the esbuild documentation. For an example of a  file that demonstrates how to target a specific Node.js version supported by Lambda, refer to the TypeScript GitHub repository.",
                    "  3.tsconfig.json : esbuild doesn’t perform type checks. To check types, use the tsc compiler. Run tsc -noEmit or add a \"noEmit\" parameter to your  file, as shown in the following example. This configures tsc to not emit JavaScript files. After checking types, use esbuild to convert the TypeScript files into JavaScript.",
                    "Example  tsconfig.json",
                    {
                        "code_example": " {\n  \"compilerOptions\": {\n    \"target\": \"es2020\",\n    \"strict\": true,\n    \"preserveConstEnums\": true,\n    \"noEmit\": true,\n    \"sourceMap\": false,\n    \"module\":\"commonjs\",\n    \"moduleResolution\":\"node\",\n    \"esModuleInterop\": true, \n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true, \n    \"isolatedModules\": true, \n  },\n  \"exclude\": [\"node_modules\", \"**/*.test.ts\"]\n}"
                    }
                ]
            }
        ]
    },
    {
        "title": "Integrating other services",
        "href": "https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html",
        "contents": [
            {
                "title": "Apache Kafka",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka.html",
                "contents": [
                    {
                        "title": "Configure event source",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka-configure.html",
                        "sections": [
                            "Before you create an event source mapping for your self-managed Apache Kafka cluster, you need to ensure that your cluster and the VPC     it resides in are correctly configured. You also need to make sure that your Lambda function's execution role has     the necessary IAM permissions.",
                            "Follow the instructions in the following sections to configure your self-managed Apache Kafka cluster and Lambda function. To learn how to     create the event source mapping, see Adding a Kafka cluster as an event source.",
                            "Topics",
                            {
                                "sub_header": "Kafka cluster authentication",
                                "content": [
                                    "Lambda supports several methods to authenticate with your self-managed Apache Kafka cluster. Make sure that you configure the      Kafka cluster to use one of these supported authentication methods. For more information about Kafka security, see      the Security section of the Kafka      documentation.",
                                    {
                                        "sub_header": "SASL/SCRAM authentication",
                                        "content": [
                                            "Lambda supports Simple Authentication and Security Layer/Salted Challenge Response Authentication Mechanism        (SASL/SCRAM) authentication with Transport Layer Security (TLS) encryption (SASL_SSL). Lambda sends the encrypted credentials to authenticate with        the cluster. Lambda doesn't support SASL/SCRAM with plaintext (SASL_PLAINTEXT). For more information about SASL/SCRAM authentication, see RFC 5802.",
                                            "Lambda also supports SASL/PLAIN authentication. Because this mechanism uses clear text credentials, the connection to the        server must use TLS encryption to ensure that the credentials are protected.",
                                            "For SASL authentication, you store the sign-in credentials as a secret in AWS Secrets Manager. For more information        about using Secrets Manager, see Tutorial: Create and retrieve a secret in the AWS Secrets Manager User Guide.",
                                            "Important",
                                            "To use Secrets Manager for authentication, secrets must be stored in the same AWS region as your Lambda function."
                                        ]
                                    },
                                    {
                                        "sub_header": "Mutual TLS authentication",
                                        "content": [
                                            "Mutual TLS (mTLS) provides two-way authentication between the client and server. The client sends a        certificate to the server for the server to verify the client, and the server sends a certificate to the client        for the client to verify the server. ",
                                            "In self-managed Apache Kafka, Lambda acts as the client. You configure a client certificate (as a secret in Secrets Manager) to        authenticate Lambda with your Kafka brokers. The client certificate must be signed by a CA in the server's trust        store.",
                                            "The Kafka cluster sends a server certificate to Lambda to authenticate the Kafka brokers with Lambda. The        server certificate can be a public CA certificate or a private CA/self-signed certificate. The public CA        certificate must be signed by a certificate authority (CA) that's in the Lambda trust store. For a private        CA/self-signed certificate, you configure the server root CA certificate (as a secret in Secrets Manager). Lambda uses        the root certificate to verify the Kafka brokers.",
                                            "For more information about mTLS, see         Introducing mutual TLS authentication for Amazon MSK as an event source."
                                        ]
                                    },
                                    {
                                        "sub_header": "Configuring the client certificate secret",
                                        "content": [
                                            "The CLIENT_CERTIFICATE_TLS_AUTH secret requires a certificate field and a private key field. For an        encrypted private key, the secret requires a private key password. Both the certificate and private key must be        in PEM format.",
                                            "Note",
                                            "Lambda supports the PBES1 (but not        PBES2) private key encryption algorithms.",
                                            "The certificate field must contain a list of certificates, beginning with the client certificate, followed        by any intermediate certificates, and ending with the root certificate. Each certificate must start on a new        line with the following structure:",
                                            "-----BEGIN CERTIFICATE-----          <certificate contents>-----END CERTIFICATE-----      ",
                                            "Secrets Manager supports secrets up to 65,536 bytes, which is enough space for long certificate chains.",
                                            "The private key must be in PKCS #8        format, with the following structure:",
                                            "-----BEGIN PRIVATE KEY-----           <private key contents>-----END PRIVATE KEY-----            ",
                                            "For an encrypted private key, use the following structure:",
                                            "-----BEGIN ENCRYPTED PRIVATE KEY-----            <private key contents>-----END ENCRYPTED PRIVATE KEY-----           ",
                                            "The following example shows the contents of a secret for mTLS authentication using an encrypted private key.        For an encrypted private key, include the private key password in the secret.",
                                            "{\"privateKeyPassword\":\"testpassword\",\"certificate\":\"-----BEGIN CERTIFICATE-----MIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw...j0Lh4/+1HfgyE2KlmII36dg4IMzNjAFEBZiCRoPimO40s1cRqtFHXoal0QQbIlxkcmUuiAii9R0=-----END CERTIFICATE----------BEGIN CERTIFICATE-----MIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb...rQoiowbbk5wXCheYSANQIfTZ6weQTgiCHCCbuuMKNVS95FkXm0vqVD/YpXKwA/noc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==-----END CERTIFICATE-----\",\"privateKey\":\"-----BEGIN ENCRYPTED PRIVATE KEY-----MIIFKzBVBgkqhkiG9w0BBQ0wSDAnBgkqhkiG9w0BBQwwGgQUiAFcK5hT/X7Kjmgp...QrSekqF+kWzmB6nAfSzgO9IaoAaytLvNgGTckWeUkWn/V0Ck+LdGUXzAC4RxZnoQzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==-----END ENCRYPTED PRIVATE KEY-----\"}"
                                        ]
                                    },
                                    {
                                        "sub_header": "Configuring the server root CA certificate secret",
                                        "content": [
                                            "You create this secret if your Kafka brokers use TLS encryption with certificates signed by a private CA.        You can use TLS encryption for VPC, SASL/SCRAM, SASL/PLAIN, or mTLS authentication.",
                                            "The server root CA certificate secret requires a field that contains the Kafka broker's root CA certificate        in PEM format. The following example shows the structure of the secret.",
                                            "{\"certificate\":\"-----BEGIN CERTIFICATE-----MIID7zCCAtegAwIBAgIBADANBgkqhkiG9w0BAQsFADCBmDELMAkGA1UEBhMCVVMxEDAOBgNVBAgTB0FyaXpvbmExEzARBgNVBAcTClNjb3R0c2RhbGUxJTAjBgNVBAoTHFN0YXJmaWVsZCBUZWNobm9sb2dpZXMsIEluYy4xOzA5BgNVBAMTMlN0YXJmaWVsZCBTZXJ2aWNlcyBSb290IENlcnRpZmljYXRlIEF1dG...-----END CERTIFICATE-----\"}"
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "API access and Lambda function permissions",
                                "content": [
                                    "In addition to accessing your self-managed Kafka cluster, your Lambda function needs permissions to perform      various API actions. You add these permissions to the function's execution role. If your users need access to any API actions, add the required permissions to the      identity policy for the AWS Identity and Access Management (IAM) user or role.",
                                    {
                                        "sub_header": "Required Lambda function permissions",
                                        "content": [
                                            "To create and store logs in a log group in Amazon CloudWatch Logs, your Lambda function must have the following        permissions in its execution role:",
                                            "  1.logs:CreateLogGroup",
                                            "  2.logs:CreateLogStream",
                                            "  3.logs:PutLogEvents"
                                        ]
                                    },
                                    {
                                        "sub_header": "Optional Lambda function permissions",
                                        "content": [
                                            "Your Lambda function might also need permissions to:",
                                            "  1.Describe your Secrets Manager secret.",
                                            "  2.Access your AWS Key Management Service (AWS KMS) customer managed key.",
                                            "  3.Access your Amazon VPC.",
                                            "  4.Send records of failed invocations to a destination.",
                                            {
                                                "sub_header": "Secrets Manager and AWS KMS permissions",
                                                "content": [
                                                    "Depending on the type of access control that you're configuring for your Kafka brokers, your Lambda function          might need permission to access your Secrets Manager secret or to decrypt your AWS KMS customer managed key. To access these          resources, your function's execution role must have the following permissions:",
                                                    "  1.secretsmanager:GetSecretValue",
                                                    "  2.kms:Decrypt"
                                                ]
                                            },
                                            {
                                                "sub_header": "VPC permissions",
                                                "content": [
                                                    "If only users within a VPC can access your self-managed Apache Kafka cluster, your Lambda function must have permission to          access your Amazon VPC resources. These resources include your VPC, subnets, security groups, and network          interfaces. To access these resources, your function's execution role must have the following          permissions:",
                                                    "  1.ec2:CreateNetworkInterface",
                                                    "  2.ec2:DescribeNetworkInterfaces",
                                                    "  3.ec2:DescribeVpcs",
                                                    "  4.ec2:DeleteNetworkInterface",
                                                    "  5.ec2:DescribeSubnets",
                                                    "  6.ec2:DescribeSecurityGroups"
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding permissions to your execution role",
                                        "content": [
                                            "To access other AWS services that your self-managed Apache Kafka cluster uses, Lambda uses the permissions policies that you        define in your Lambda function's execution role.",
                                            "By default, Lambda is not permitted to perform the required or optional actions for a self-managed Apache Kafka cluster. You        must create and define these actions in an IAM trust policy for your execution role. This example shows how you might create a policy that allows        Lambda to access your Amazon VPC resources.",
                                            "{        \"Version\":\"2012-10-17\",        \"Statement\":[           {              \"Effect\":\"Allow\",              \"Action\":[                 \"ec2:CreateNetworkInterface\",                 \"ec2:DescribeNetworkInterfaces\",                 \"ec2:DescribeVpcs\",                 \"ec2:DeleteNetworkInterface\",                 \"ec2:DescribeSubnets\",                 \"ec2:DescribeSecurityGroups\"              ],              \"Resource\":\"*\"           }        ]     }"
                                        ]
                                    },
                                    {
                                        "sub_header": "Granting users access with an IAM policy",
                                        "content": [
                                            "By default, users and roles don't have permission to perform event source API operations. To grant access to users in your        organization or account, you create or update an identity-based policy. For more information, see Controlling access to AWS resources          using policies in the IAM User Guide."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Configure network security",
                                "content": [
                                    "To give Lambda full access to self-managed Apache Kafka through your event source mapping, either your cluster must use a public endpoint             (public IP address), or you must provide access to the Amazon VPC you created the cluster in.",
                                    "When you use self-managed Apache Kafka with Lambda, create AWS PrivateLink VPC endpoints that provide your function            access to the resources in your Amazon VPC.",
                                    "Note",
                                    "AWS PrivateLink VPC endpoints are required for functions with event source mappings that use the default (on-demand) mode                for event pollers. If your event source mapping uses                 provisioned mode, you don't need to configure AWS PrivateLink VPC endpoints.",
                                    "Create an endpoint to provide access to the following resources:",
                                    "  1.                    Lambda — Create an endpoint for the Lambda service principal.                ",
                                    "  2.                    AWS STS — Create an endpoint for the AWS STS in order for a service principal to assume a role on your behalf.                ",
                                    "  3.                    Secrets Manager — If your cluster uses Secrets Manager to store credentials, create an endpoint for Secrets Manager.                ",
                                    "Alternatively, configure a NAT gateway on each public subnet in the Amazon VPC. For more information,             see Enable internet access for VPC-connected Lambda functions.",
                                    "When you create an event source mapping for self-managed Apache Kafka, Lambda checks whether Elastic Network Interfaces (ENIs)             are already present for the subnets and security groups configured for your Amazon VPC. If Lambda finds existing ENIs, it             attempts to re-use them. Otherwise, Lambda creates new ENIs to connect to the event source and invoke your function.",
                                    "Note",
                                    "Lambda functions always run inside VPCs owned by the Lambda service. Your function's VPC configuration                does not affect the event source mapping. Only the networking configuration of the event source's determines                 how Lambda connects to your event source.",
                                    "Configure the security groups for the Amazon VPC containing your cluster. By default,            self-managed Apache Kafka uses the following ports: 9092.",
                                    "  1.Inbound rules – Allow all traffic on the default cluster port for the security group associated with your event source.",
                                    "  2.Outbound rules – Allow all traffic on port 443 for all destinations. Allow all traffic on the default cluster port                    for the security group associated with your event source.",
                                    "  3.Amazon VPC endpoint inbound rules — If you are using an Amazon VPC endpoint, the security group associated with your Amazon VPC endpoint must allow inbound traffic                    on port 443 from the cluster security group.",
                                    "If your cluster uses authentication, you can also restrict the endpoint policy for the Secrets Manager endpoint.             To call the Secrets Manager API, Lambda uses your function role, not the Lambda service principal.",
                                    "Example VPC endpoint policy — Secrets Manager endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"secretsmanager:GetSecretValue\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"AWS\": [\n                      \"arn:aws::iam::123456789012:role/my-role\"\n                  ]\n              },\n              \"Resource\": \"arn:aws::secretsmanager:us-west-2:123456789012:secret:my-secret\"\n          }\n      ]\n  }"
                                    },
                                    "When you use Amazon VPC endpoints, AWS routes your API calls to invoke your function using the endpoint's Elastic Network Interface (ENI).            The Lambda service principal needs to call lambda:InvokeFunction on any roles and functions that use those ENIs.",
                                    "By default, Amazon VPC endpoints have open IAM policies that allow broad access to resources. Best practice is to restrict these            policies to perform the needed actions using that endpoint. To ensure that your event source mapping is able to invoke your Lambda            function, the VPC endpoint policy must allow the Lambda service principal to call sts:AssumeRole and            lambda:InvokeFunction. Restricting your VPC endpoint policies to allow only API calls originating within your organization            prevents the event source mapping from functioning properly, so \"Resource\": \"*\" is required in these policies.",
                                    "The following example VPC endpoint policies show how to grant the required access to the Lambda service principal for the            AWS STS and Lambda endpoints.",
                                    "Example VPC Endpoint policy — AWS STS endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"sts:AssumeRole\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n    }"
                                    },
                                    "Example VPC Endpoint policy — Lambda endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"lambda:InvokeFunction\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n  }"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Process messages",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka-process.html",
                        "sections": [
                            "Note",
                            "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                            "Topics",
                            {
                                "sub_header": "Adding a Kafka cluster as an event source",
                                "content": [
                                    "To create an event source mapping, add your Kafka      cluster as a Lambda function trigger using the Lambda      console, an AWS SDK, or the AWS Command Line Interface (AWS CLI).",
                                    "This section describes how to create an event source mapping using the Lambda console and the AWS CLI.",
                                    {
                                        "sub_header": "Prerequisites",
                                        "content": [
                                            "  1.A self-managed Apache Kafka cluster. Lambda supports Apache Kafka version 0.10.1.0 and later.",
                                            "  2.An execution role with permission to access the AWS resources that your self-managed Kafka            cluster uses."
                                        ]
                                    },
                                    {
                                        "sub_header": "Customizable consumer group ID",
                                        "content": [
                                            "When setting up Kafka as an event source, you can specify a consumer group ID. This consumer group ID is an    existing identifier for the Kafka consumer group that you want your Lambda function to join. You can use this feature to seamlessly migrate any    ongoing Kafka record processing setups from other consumers to Lambda.",
                                            "If you specify a consumer group ID and there are other active pollers within that consumer group, Kafka distributes messages across      all consumers. In other words, Lambda doesn't receive all message for the Kafka topic. If you want Lambda to handle all messages in the      topic, turn off any other pollers in that consumer group.",
                                            "Additionally, if you specify a consumer group ID, and Kafka finds a valid existing consumer group with the same ID, Lambda ignores the      StartingPosition parameter for your event source mapping. Instead, Lambda begins processing records according to the committed      offset of the consumer group. If you specify a consumer group ID, and Kafka cannot find an existing consumer group, then Lambda configures your      event source with the specified StartingPosition.",
                                            "The consumer group ID that you specify must be unique among all your Kafka event sources. After creating a Kafka event source mapping      with the consumer group ID specified, you cannot update this value."
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding a self-managed Kafka cluster (console)",
                                        "content": [
                                            "Follow these steps to add your self-managed Apache Kafka cluster and a Kafka topic as a trigger for your Lambda function.",
                                            "To add an Apache Kafka trigger to your Lambda function (console)",
                                            "  1 : Open the Functions page of the Lambda            console.",
                                            "  2 : Choose the name of your Lambda function.",
                                            "  3 : Under Function overview, choose Add trigger.",
                                            "  4 : Under Trigger configuration, do the following:Choose the Apache Kafka trigger type.For Bootstrap servers, enter the host and port pair address of a Kafka broker                in your cluster, and then choose Add. Repeat for each Kafka broker in the                cluster.For Topic name, enter the name of the Kafka topic used to store records in the                cluster.(Optional) For Batch size, enter the maximum number of records to receive in a                single batch.For Batch window, enter the maximum amount of seconds that Lambda spends                gathering records before invoking the function.(Optional) For Consumer group ID, enter the ID of a Kafka consumer group to join.(Optional) For Starting position, choose Latest to start                reading the stream from the latest record, Trim horizon to start at the                earliest available record, or At timestamp to specify a timestamp to start                reading from.(Optional) For VPC, choose the Amazon VPC for your Kafka cluster. Then, choose the                VPC subnets and VPC security groups.This setting is required if only users within your VPC access your brokers.(Optional) For Authentication, choose Add, and then do the                following:Choose the access or authentication protocol of the Kafka brokers in your cluster.If your Kafka broker uses SASL/PLAIN authentication, choose                        BASIC_AUTH.If your broker uses SASL/SCRAM authentication, choose one of the                        SASL_SCRAM protocols.If you're configuring mTLS authentication, choose the                        CLIENT_CERTIFICATE_TLS_AUTH protocol.For SASL/SCRAM or mTLS authentication, choose the Secrets Manager secret key that contains the                    credentials for your Kafka cluster.(Optional) For Encryption, choose the Secrets Manager secret containing the root CA                certificate that your Kafka brokers use for TLS encryption, if your Kafka brokers use certificates                signed by a private CA.This setting applies to TLS encryption for SASL/SCRAM or SASL/PLAIN, and to mTLS                authentication.To create the trigger in a disabled state for testing (recommended), clear Enable                trigger. Or, to enable the trigger immediately, select Enable                  trigger.",
                                            "  5 : To create the trigger, choose Add."
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding a self-managed Kafka cluster (AWS CLI)",
                                        "content": [
                                            "Use the following example AWS CLI commands to create and view a self-managed Apache Kafka trigger for your Lambda function.",
                                            {
                                                "sub_header": "Using SASL/SCRAM",
                                                "content": [
                                                    "If Kafka users access your Kafka brokers over the internet, specify the Secrets Manager secret that you created          for SASL/SCRAM authentication. The following example uses the create-event-source-mapping AWS CLI command to map a Lambda function named my-kafka-function to a Kafka topic named AWSKafkaTopic.",
                                                    "aws lambda create-event-source-mapping \\   --topics AWSKafkaTopic \\  --source-access-configuration Type=SASL_SCRAM_512_AUTH,URI=arn:aws:secretsmanager:us-east-1:111122223333:secret:MyBrokerSecretName \\  --function-name arn:aws:lambda:us-east-1:111122223333:function:my-kafka-function \\  --self-managed-event-source '{\"Endpoints\":{\"KAFKA_BOOTSTRAP_SERVERS\":[\"abc3.xyz.com:9092\", \"abc2.xyz.com:9092\"]}}'"
                                                ]
                                            },
                                            {
                                                "sub_header": "Using a VPC",
                                                "content": [
                                                    "If only Kafka users within your VPC access your Kafka brokers, you must specify your VPC, subnets, and VPC          security group. The following example uses the create-event-source-mapping AWS CLI command to map a Lambda function named my-kafka-function to a Kafka topic named AWSKafkaTopic.",
                                                    "aws lambda create-event-source-mapping \\   --topics AWSKafkaTopic \\  --source-access-configuration '[{\"Type\": \"VPC_SUBNET\", \"URI\": \"subnet:subnet-0011001100\"}, {\"Type\": \"VPC_SUBNET\", \"URI\": \"subnet:subnet-0022002200\"}, {\"Type\": \"VPC_SECURITY_GROUP\", \"URI\": \"security_group:sg-0123456789\"}]' \\  --function-name arn:aws:lambda:us-east-1:111122223333:function:my-kafka-function \\  --self-managed-event-source '{\"Endpoints\":{\"KAFKA_BOOTSTRAP_SERVERS\":[\"abc3.xyz.com:9092\", \"abc2.xyz.com:9092\"]}}'"
                                                ]
                                            },
                                            {
                                                "sub_header": "Viewing the status using the AWS CLI",
                                                "content": [
                                                    "The following example uses the get-event-source-mapping AWS CLI command to describe the status of the event source mapping that you created.",
                                                    "aws lambda get-event-source-mapping          --uuid dh38738e-992b-343a-1077-3478934hjkfd7"
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Self-managed Apache Kafka configuration parameters",
                                "content": [
                                    "All Lambda event source types share the same CreateEventSourceMapping and UpdateEventSourceMapping      API operations. However, only some of the parameters apply to Apache Kafka.",
                                    "ParameterRequiredDefaultNotesBatchSizeN100Maximum: 10,000DestinationConfigNN/ACapturing discarded batches for a self-managed Apache Kafka event sourceEnabledNTrueFilterCriteriaNN/AControl which events Lambda sends to your functionFunctionNameYN/AKMSKeyArnNN/AEncryption of filter criteriaMaximumBatchingWindowInSecondsN500 msBatching behaviorProvisionedPollersConfigNMinimumPollers: default value of 1 if not specifiedMaximumPollers: default value of 200 if not specifiedConfiguring provisioned modeSelfManagedEventSourceYN/AList of Kafka Brokers. Can set only on CreateSelfManagedKafkaEventSourceConfigNContains the ConsumerGroupId field which defaults to a unique value.Can set only on CreateSourceAccessConfigurationsNNo credentialsVPC information or authentication credentials for the cluster  For SASL_PLAIN, set to BASIC_AUTHStartingPositionYN/AAT_TIMESTAMP, TRIM_HORIZON, or LATESTCan set only on CreateStartingPositionTimestampNN/ARequired if StartingPosition is set to AT_TIMESTAMPTagsNN/AUsing tags on event source mappingsTopicsYN/ATopic nameCan set only on Create"
                                ]
                            },
                            {
                                "sub_header": "Using a Kafka cluster as an event source",
                                "content": [
                                    "When you add your Apache Kafka or Amazon MSK cluster as a trigger for your Lambda function, the cluster is used as an event source.",
                                    "Lambda reads event data from the Kafka topics that you specify as Topics in a      CreateEventSourceMapping request, based on the StartingPosition that you specify. After      successful processing, your Kafka topic is committed to your Kafka cluster.",
                                    "If you specify the StartingPosition as LATEST, Lambda starts reading from the latest      message in each partition belonging to the topic. Because there can be some delay after trigger configuration      before Lambda starts reading the messages, Lambda doesn't read any messages produced during this window.",
                                    "Lambda processes records from one or more Kafka topic partitions that you specify and sends a JSON payload to      your function. A single Lambda payload can contain messages from multiple partitions. When more records are available,       Lambda continues processing records in batches, based on the      BatchSize value that you specify in a CreateEventSourceMapping request, until your function      catches up with the topic.",
                                    "If your function returns an error for any of the messages in a batch, Lambda retries the whole batch of      messages until processing succeeds or the messages expire. You can send records that fail all retry attempts      to an on-failure destination for later processing.",
                                    "Note",
                                    "While Lambda functions typically have a maximum timeout limit of 15 minutes,      event source mappings for Amazon MSK, self-managed Apache Kafka, Amazon DocumentDB, and Amazon MQ for ActiveMQ and RabbitMQ only support functions with      maximum timeout limits of 14 minutes. This constraint ensures that the event source mapping can properly      handle function errors and retries."
                                ]
                            },
                            {
                                "sub_header": "Polling and stream starting positions",
                                "content": [
                                    "Be aware that stream polling during event source mapping creation and updates is eventually consistent.",
                                    "  1.During event source mapping creation, it may take several minutes to start polling events from the stream.",
                                    "  2.During event source mapping updates, it may take several minutes to stop and restart polling events from the stream.",
                                    "This behavior means that if you specify LATEST as the starting position for the stream, the event source mapping could     miss events during creation or updates. To ensure that no events are missed, specify the stream starting position as TRIM_HORIZON     or AT_TIMESTAMP."
                                ]
                            },
                            {
                                "sub_header": "Message throughput scaling behavior for self-managed Apache Kafka event source mappings",
                                "content": [
                                    "You can choose between two modes of message throughput scaling behavior for your Amazon MSK      event source mapping:",
                                    "  1.Default (on-demand) mode",
                                    "  2.Provisioned mode",
                                    {
                                        "sub_header": "Default (on-demand) mode",
                                        "content": [
                                            "When you initially create an self-managed Apache Kafka event source, Lambda allocates a default number of event        pollers to process all partitions in the Kafka topic. Lambda automatically scales up or down the        number of event pollers based on message load.",
                                            "In one-minute intervals, Lambda evaluates the consumer offset lag of all the partitions in the        topic. If the offset lag is too high, the partition is receiving messages faster than Lambda can        process them. If necessary, Lambda adds or removes event pollers from the topic. This autoscaling        process of adding or removing event pollers occurs within three minutes of evaluation.",
                                            "If your target Lambda function is throttled, Lambda reduces the number of event pollers. This        action reduces the workload on the function by reducing the number of messages that event        pollers can retrieve and send to the function.",
                                            "To monitor the throughput of your Kafka topic, you can view the Apache Kafka consumer metrics,        such as consumer_lag and consumer_offset."
                                        ]
                                    },
                                    {
                                        "sub_header": "Configuring provisioned mode",
                                        "content": [
                                            "For workloads where you need to fine-tune the throughput of your event source mapping,        you can use provisioned mode. In provisioned mode, you define minimum and maximum limits        for the amount of provisioned event pollers. These provisioned event pollers are dedicated        to your event source mapping, and can handle unexpected message spikes instantly when they        occur. We recommend that you use provisioned mode for Kafka workloads that have strict        performance requirements.",
                                            "In Lambda, an event poller is a compute unit capable of handling up to 5 MBps of throughput.    For reference, suppose your event source produces an average payload of 1MB, and the average function duration is 1 sec.    If the payload doesn’t undergo any transformation (such as filtering), a single poller can support 5 MBps throughput,    and 5 concurrent Lambda invocations. Using provisioned mode incurs additional costs. For pricing estimates,    see AWS Lambda pricing.",
                                            "In provisioned mode, the range of accepted values for the minimum number of event pollers                (MinimumPollers) is between 1 and 200, inclusive. The range of                accepted values for the maximum number of event pollers (MaximumPollers)                is between 1 and 2,000, inclusive. MaximumPollers must be greater than                or equal to MinimumPollers. In addition, to maintain ordered                processing within partitions, Lambda caps the MaximumPollers to the                number of partitions in the topic.",
                                            "For more details about choosing appropriate values for minimum and maximum event pollers,        see Best practices and considerations when using provisioned mode.",
                                            "You can configure provisioned mode for your self-managed Apache Kafka event source mapping using the console        or the Lambda API.",
                                            "To configure provisioned mode for an existing self-managed Apache Kafka event source mapping (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Choose the function with the self-managed Apache Kafka event source mapping you want to configure            provisioned mode for.",
                                            "  3 : Choose Configuration, then choose Triggers.",
                                            "  4 : Choose the self-managed Apache Kafka event source mapping that you want to configure provisioned mode for,            then choose Edit.",
                                            "  5 : Under Event source mapping configuration, choose             Configure provisioned mode.For Minimum event pollers, enter a value between 1 and 200.                                If you don't specify a value, Lambda chooses a default value of 1.For Maximum event pollers, enter a value between 1 and 2,000.                                This value must be greater than or equal to your value for Minimum event                                pollers. If you don't specify a value, Lambda chooses a default value of 200.",
                                            "  6 : Choose Save.",
                                            "You can configure provisioned mode programmatically using the ProvisionedPollerConfig object                in your                 EventSourceMappingConfiguration. For example, the following UpdateEventSourceMapping CLI                command configures a MinimumPollers value of 5, and a                MaximumPollers value of 100.",
                                            "aws lambda update-event-source-mapping \\    --uuid a1b2c3d4-5678-90ab-cdef-EXAMPLE11111 \\    --provisioned-poller-config '{\"MinimumPollers\": 5, \"MaximumPollers\": 100}'",
                                            "After configuring provisioned mode, you can observe the usage of event pollers for your workload by monitoring    the ProvisionedPollers metric. For more information, see Event source mapping metrics.",
                                            "To disable provisioned mode and return to default (on-demand) mode,                you can use the following UpdateEventSourceMapping CLI                command:",
                                            "aws lambda update-event-source-mapping \\    --uuid a1b2c3d4-5678-90ab-cdef-EXAMPLE11111 \\    --provisioned-poller-config '{}'"
                                        ]
                                    },
                                    {
                                        "sub_header": "Best practices and considerations when using provisioned mode",
                                        "content": [
                                            "The optimal configuration of minimum and maximum event pollers for your event source mapping                depends on your application's performance requirements. We recommend that you start with the                default minimum event pollers to baseline the performance profile. Adjust your configuration                based on observed message processing patterns and your desired performance profile.",
                                            "For workloads with spiky traffic and strict performance needs, increase the minimum event                pollers to handle sudden surges in messages. To determine the minimum event pollers required,                consider your workload's messages per second and average payload size, and use the throughput                capacity of a single event poller (up to 5 MBps) as a reference.",
                                            "To maintain ordered processing within a partition, Lambda limits the maximum event pollers                to the number of partitions in the topic. Additionally, the maximum event pollers your event                source mapping can scale to depends on the function's concurrency settings.",
                                            "When activating provisioned mode, update your network settings to remove AWS PrivateLink VPC                endpoints and associated permissions."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Amazon CloudWatch metrics",
                                "content": [
                                    "Lambda emits the OffsetLag metric while your function processes records. The value of this metric      is the difference in offset between the last record written to the Kafka event source topic and the last record that your function's       consumer group processed. You can use OffsetLag to estimate the latency between when a record is added and when      your consumer group processes it.",
                                    "An increasing trend in OffsetLag can indicate issues with pollers in your function's consumer group. For more information, see      Using CloudWatch metrics with Lambda."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for self-managed Apache Kafka event sources.",
                            "Topics",
                            {
                                "sub_header": "Self-managed Apache Kafka event filtering basics",
                                "content": [
                                    "Suppose a producer is writing messages to a topic in your self-managed Apache Kafka cluster, either in valid JSON format or as plain strings. An example record             would look like the following, with the message converted to a Base64 encoded string in the value field.",
                                    "{    \"mytopic-0\":[        {            \"topic\":\"mytopic\",            \"partition\":0,            \"offset\":15,            \"timestamp\":1545084650987,            \"timestampType\":\"CREATE_TIME\",            \"value\":\"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",            \"headers\":[]        }    ]}",
                                    "Suppose your Apache Kafka producer is writing messages to your topic in the following JSON format.",
                                    "{    \"device_ID\": \"AB1234\",    \"session\":{        \"start_time\": \"yyyy-mm-ddThh:mm:ss\",        \"duration\": 162    }}",
                                    "You can use the value key to filter records. Suppose you wanted to filter only those records where device_ID             begins with the letters AB. The FilterCriteria object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\": \\\"AB\\\" } ] } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"value\": {        \"device_ID\": [ { \"prefix\": \"AB\" } ]      }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }"
                                    },
                                    "With self-managed Apache Kafka, you can also filter records where the message is a plain string. Suppose you want to ignore those messages where the string is             \"error\". The FilterCriteria object would look as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"value\": [        {        \"anything-but\": [ \"error\" ]        }    ]}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }"
                                    },
                                    "Self-managed Apache Kafka messages must be UTF-8 encoded strings, either plain strings or in JSON format. That's because Lambda decodes Kafka byte arrays into UTF-8 before             applying filter criteria. If your messages use another encoding, such as UTF-16 or ASCII, or if the message format doesn't match the             FilterCriteria format, Lambda processes metadata filters only. The following table summarizes the specific behavior:",
                                    "Incoming message formatFilter pattern format for message propertiesResulting actionPlain stringPlain stringLambda filters based on your filter criteria.Plain stringNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Plain stringValid JSONLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONPlain stringLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONValid JSONLambda filters based on your filter criteria.Non-UTF-8 encoded stringJSON, plain string, or no patternLambda filters (on the other metadata properties only) based on your filter criteria."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "On-failure destinations",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka-on-failure.html",
                        "sections": [
                            "To retain records of failed event source mapping invocations, add a destination to your function's event source mapping. Each record sent to the destination is a JSON document containing metadata about the failed invocation. For Amazon S3 destinations, Lambda also sends the entire invocation record along with the metadata. You can configure any Amazon SNS topic, Amazon SQS queue, or S3 bucket as a destination.",
                            "With Amazon S3 destinations, you can use the Amazon S3 Event Notifications feature to receive notifications when objects are uploaded to your destination S3 bucket. You can also configure S3 Event Notifications to invoke another Lambda function to perform automated processing on failed batches.",
                            "Your execution role must have permissions for the destination:",
                            "  1.For SQS destinations: :  sqs:SendMessage",
                            "  2.For SNS destinations: :  sns:Publish",
                            "  3.For S3 bucket destinations: :   s3:PutObject and s3:ListBucket",
                            "You must deploy a VPC endpoint for your on-failure destination service inside your Apache Kafka cluster VPC.",
                            "Additionally, if you configured a KMS key on your destination, Lambda needs the following        permissions depending on the destination type:",
                            "  1.If you've enabled encryption with your own KMS key for an S3 destination,            kms:GenerateDataKey is required.            If the KMS key and S3 bucket destination are in a different account from your Lambda function            and execution role, configure the KMS key to trust the execution role to allow            kms:GenerateDataKey.",
                            "  2.If you've enabled encryption with your own KMS key for SQS destination,            kms:Decrypt and            kms:GenerateDataKey are            required. If the KMS key and SQS queue destination are in a different account from your            Lambda function and execution role, configure the KMS key to trust the execution role to            allow kms:Decrypt, kms:GenerateDataKey,            kms:DescribeKey, and            kms:ReEncrypt.",
                            "  3.If you've enabled encryption with your own KMS key for SNS destination,            kms:Decrypt and            kms:GenerateDataKey are            required. If the KMS key and SNS topic destination are in a different account from your            Lambda function and execution role, configure the KMS key to trust the execution role to            allow kms:Decrypt, kms:GenerateDataKey,            kms:DescribeKey, and            kms:ReEncrypt.",
                            {
                                "sub_header": "Configuring on-failure destinations for an self-managed Apache Kafka event source mapping",
                                "content": [
                                    "To configure an on-failure destination using the console, follow these steps:",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose a function.",
                                    "  3 : Under Function overview, choose Add destination.",
                                    "  4 : For Source, choose Event source mapping invocation.",
                                    "  5 : For Event source mapping, choose an event source that's configured              for this function.",
                                    "  6 : For Condition, select On failure. For event              source mapping invocations, this is the only accepted condition.",
                                    "  7 : For Destination type, choose the destination type that Lambda sends              invocation records to.",
                                    "  8 : For Destination, choose a resource.",
                                    "  9 : Choose Save.",
                                    "You can also configure an on-failure destination using the AWS CLI. For example, the following          create-event-source-mapping command adds an event source mapping with an SQS on-failure destination to          MyFunction:",
                                    "aws lambda create-event-source-mapping \\--function-name \"MyFunction\" \\--event-source-arn arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2 \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sqs:us-east-1:123456789012:dest-queue\"}}'",
                                    "The following update-event-source-mapping command adds an S3 on-failure destination to the event source associated with the input uuid:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:s3:::dest-bucket\"}}'",
                                    "To remove a destination, supply an empty string as the argument to the          destination-config parameter:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"\"}}'",
                                    {
                                        "sub_header": "Security best practices for Amazon S3 destinations",
                                        "content": [
                                            "Deleting an S3 bucket that's configured as a destination without removing the destination from your function's configuration can create a security risk. If another       user knows your destination bucket's name, they can recreate the bucket in their AWS account. Records of failed invocations will be sent to their bucket, potentially       exposing data from your function.",
                                            "Warning",
                                            "To ensure that invocation records from your function can't be sent to an S3 bucket in another AWS account, add a condition to your function's execution role         that limits s3:PutObject permissions to buckets in your account. ",
                                            "The following example shows an IAM policy that limits your function's s3:PutObject permissions to buckets in your account. This policy also gives Lambda        the s3:ListBucket permission it needs to use an S3 bucket as a destination.",
                                            "{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Sid\": \"S3BucketResourceAccountWrite\",            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\",                \"s3:ListBucket\"            ],            \"Resource\": \"arn:aws:s3:::*/*\",            \"Condition\": {                \"StringEquals\": {                    \"s3:ResourceAccount\": \"111122223333\"                }            }        }    ]}",
                                            "To add a permissions policy to your funcion's execution role using the AWS Management Console or AWS CLI, refer to the instructions in the following procedures:",
                                            "  1.Console : \nTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.\nSelect the Lambda function whose execution role you want to modify.\n\nIn the Configuration tab, select Permissions.\n\nIn the Execution role tab, select your function's Role name to open the role's IAM console page.\n\nAdd a permissions policy to the role by doing the following:\n\nIn the Permissions policies pane, choose Add permissions and select Create inline policy.\n\nIn Policy editor, select JSON.\n\nPaste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.\n\nUnder Policy details, enter a Policy name.\n\nChoose Create policy.\n\n\n",
                                            "  2.AWS CLI : put-role-policy",
                                            "ConsoleTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.Select the Lambda function whose execution role you want to modify.In the Configuration tab, select Permissions.In the Execution role tab, select your function's Role name to open the role's IAM console page.Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy.AWS CLITo add a permissions policy to a function's execution role (CLI)Create a JSON policy document with the required permissions and save it in a local directory.Use the IAM put-role-policy CLI command to add the permissions to your function's execution role. Run the following command from the                 directory you saved your JSON policy document in and replace the role name, policy name, and policy document with your own values.aws iam put-role-policy \\--role-name my_lambda_role \\--policy-name LambdaS3DestinationPolicy \\--policy-document file://my_policy.json",
                                            "anchor",
                                            "anchor",
                                            "To add a permissions policy to a function's execution role (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Select the Lambda function whose execution role you want to modify.",
                                            "  3 : In the Configuration tab, select Permissions.",
                                            "  4 : In the Execution role tab, select your function's Role name to open the role's IAM console page.",
                                            "  5 : Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy."
                                        ]
                                    },
                                    {
                                        "sub_header": "SNS and SQS example invocation record",
                                        "content": [
                                            "The following example shows what Lambda sends to an SNS topic or SQS queue destination for a          failed Kafka event source invocation. Each of the keys under recordsInfo contains          both the Kafka topic and partition, separated by a hyphen. For example, for the key          \"Topic-0\", Topic is the Kafka topic, and 0 is the          partition. For each topic and partition, you can use the offsets and timestamp data to find          the original invocation records.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\" | \"MaximumPayloadSizeExceeded\",        \"approximateInvokeCount\": 1    },    \"responseContext\": { // null if record is MaximumPayloadSizeExceeded        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KafkaBatchInfo\": {        \"batchSize\": 500,        \"eventSourceArn\": \"arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2\",        \"bootstrapServers\": \"...\",        \"payloadSize\": 2039086, // In bytes        \"recordsInfo\": {            \"Topic-0\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            },            \"Topic-1\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            }        }    }}"
                                        ]
                                    },
                                    {
                                        "sub_header": "S3 destination example invocation record",
                                        "content": [
                                            "For S3 destinations, Lambda sends the entire invocation record along with the metadata          to the destination. The following example shows that Lambda sends to an S3 bucket destination          for a failed Kafka event source invocation. In addition to all of the fields from the previous          example for SQS and SNS destinations, the payload field contains the original          invocation record as an escaped JSON string.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\" | \"MaximumPayloadSizeExceeded\",        \"approximateInvokeCount\": 1    },    \"responseContext\": { // null if record is MaximumPayloadSizeExceeded        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KafkaBatchInfo\": {        \"batchSize\": 500,        \"eventSourceArn\": \"arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2\",        \"bootstrapServers\": \"...\",        \"payloadSize\": 2039086, // In bytes        \"recordsInfo\": {            \"Topic-0\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            },            \"Topic-1\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            }        }    },    \"payload\": \"<Whole Event>\" // Only available in S3}",
                                            "Tip",
                                            "We recommend enabling S3 versioning on your destination bucket."
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Troubleshooting",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kafka-troubleshoot.html",
                        "sections": [
                            "The following topics provide troubleshooting advice for errors and issues that you might encounter when using    self-managed Apache Kafka with Lambda. If you find an issue that is not listed here, you can use the    Feedback button on this page to report it.",
                            "For more help with troubleshooting, visit the AWS Knowledge Center.",
                            {
                                "sub_header": "Authentication and authorization errors",
                                "content": [
                                    "If any of the permissions required to consume data from the Kafka cluster are missing, Lambda displays one of      the following error messages in the event source mapping under LastProcessingResult.",
                                    "Error messages",
                                    {
                                        "sub_header": "Cluster failed to authorize Lambda",
                                        "content": [
                                            "For SASL/SCRAM or mTLS, this error indicates that the provided user doesn't have all of the following        required Kafka access control list (ACL) permissions:",
                                            "  1.DescribeConfigs Cluster",
                                            "  2.Describe Group",
                                            "  3.Read Group",
                                            "  4.Describe Topic",
                                            "  5.Read Topic",
                                            "When you create Kafka ACLs with the required kafka-cluster permissions, specify the topic and        group as resources. The topic name must match the topic in the event source mapping. The group name must match        the event source mapping's UUID.",
                                            "After you add the required permissions to the execution role, it might take several minutes for the changes        to take effect."
                                        ]
                                    },
                                    {
                                        "sub_header": "SASL authentication failed",
                                        "content": [
                                            "For SASL/SCRAM or SASL/PLAIN, this error indicates that the provided sign-in credentials aren't        valid."
                                        ]
                                    },
                                    {
                                        "sub_header": "Server failed to authenticate Lambda",
                                        "content": [
                                            "This error indicates that the Kafka broker failed to authenticate Lambda. This can occur for any of the        following reasons:",
                                            "  1.You didn't provide a client certificate for mTLS authentication.",
                                            "  2.You provided a client certificate, but the Kafka brokers aren't configured to use mTLS authentication.",
                                            "  3.A client certificate isn't trusted by the Kafka brokers."
                                        ]
                                    },
                                    {
                                        "sub_header": "Lambda failed to authenticate server",
                                        "content": [
                                            "This error indicates that Lambda failed to authenticate the Kafka broker. This can occur for any of the        following reasons:",
                                            "  1.The Kafka brokers use self-signed certificates or a private CA, but didn't provide the server root CA          certificate.",
                                            "  2.The server root CA certificate doesn't match the root CA that signed the broker's certificate.",
                                            "  3.Hostname validation failed because the broker's certificate doesn't contain the broker's DNS name or IP address as          a subject alternative name."
                                        ]
                                    },
                                    {
                                        "sub_header": "Provided certificate or private key is invalid",
                                        "content": [
                                            "This error indicates that the Kafka consumer couldn't use the provided certificate or private key. Make sure        that the certificate and key use PEM format, and that the private key encryption uses a PBES1 algorithm."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Event source mapping errors",
                                "content": [
                                    "When you add your Apache Kafka cluster as an event source for your Lambda function, if your function encounters an error, your Kafka consumer stops processing records. Consumers of a topic partition are those that subscribe to, read, and process your records. Your other Kafka consumers can continue processing records, provided they don't encounter the same error.",
                                    "To determine the cause of a stopped consumer, check the StateTransitionReason field in the response of EventSourceMapping. The following list describes the event source errors that you can receive:",
                                    "  1.ESM_CONFIG_NOT_VALID : \nThe event source mapping configuration isn't valid.\n",
                                    "  2.EVENT_SOURCE_AUTHN_ERROR : \nLambda couldn't authenticate the event source.\n",
                                    "  3.EVENT_SOURCE_AUTHZ_ERROR : \nLambda doesn't have the required permissions to access the event source.\n",
                                    "  4.FUNCTION_CONFIG_NOT_VALID : \nThe function configuration isn't valid.\n",
                                    "ESM_CONFIG_NOT_VALIDThe event source mapping configuration isn't valid.EVENT_SOURCE_AUTHN_ERRORLambda couldn't authenticate the event source.EVENT_SOURCE_AUTHZ_ERRORLambda doesn't have the required permissions to access the event source.FUNCTION_CONFIG_NOT_VALIDThe function configuration isn't valid.",
                                    "Note",
                                    "If your Lambda event records exceed the allowed size limit of 6 MB, they can go        unprocessed."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "Note",
                    "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                    "Lambda supports Apache Kafka as an event source. Apache Kafka is a an    open-source event streaming platform that supports workloads such as data pipelines and streaming analytics.",
                    "You can use the AWS managed Kafka service Amazon Managed Streaming for Apache Kafka (Amazon MSK), or a self-managed Kafka cluster. For details    about using Lambda with Amazon MSK, see Using Lambda with Amazon MSK.",
                    "This topic describes how to use Lambda with a self-managed Kafka cluster. In AWS terminology, a self-managed    cluster includes non-AWS hosted Kafka clusters. For example, you can host your Kafka cluster with a cloud provider    such as Confluent Cloud.",
                    "Apache Kafka as an event source operates similarly to using Amazon Simple Queue Service (Amazon SQS) or Amazon Kinesis. Lambda internally polls for    new messages from the event source and then synchronously invokes the target Lambda function. Lambda reads the    messages in batches and provides these to your function as an event payload. The maximum batch size is configurable    (the default is 100 messages). For more information, see Batching behavior.",
                    "To optimize the throughput of your self-managed Apache Kafka event source mapping, configure provisioned mode. In provisioned    mode, you can define the minimum and maximum number of event pollers allocated to your event source mapping.    This can improve the ability of your event source mapping to handle unexpected message spikes. For more    information, see provisioned mode.",
                    "Warning",
                    "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                    "For Kafka-based event sources, Lambda supports processing control parameters, such as batching windows      and batch size. For more information, see Batching behavior.",
                    "For an example of how to use self-managed Kafka as an event source, see Using self-hosted Apache Kafka as an      event source for AWS Lambda on the AWS Compute Blog.",
                    "Topics",
                    {
                        "sub_header": "Example event",
                        "content": [
                            "Lambda sends the batch of messages in the event parameter when it invokes your Lambda function. The event payload    contains an array of messages. Each array item contains details of the Kafka topic and Kafka partition identifier,    together with a timestamp and a base64-encoded message.",
                            "{   \"eventSource\": \"SelfManagedKafka\",   \"bootstrapServers\":\"b-2.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092,b-1.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092\",   \"records\":{      \"mytopic-0\":[         {            \"topic\":\"mytopic\",            \"partition\":0,            \"offset\":15,            \"timestamp\":1545084650987,            \"timestampType\":\"CREATE_TIME\",            \"key\":\"abcDEFghiJKLmnoPQRstuVWXyz1234==\",            \"value\":\"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",            \"headers\":[               {                  \"headerKey\":[                     104,                     101,                     97,                     100,                     101,                     114,                     86,                     97,                     108,                     117,                     101                  ]               }            ]         }      ]   }}"
                        ]
                    }
                ]
            },
            {
                "title": "API Gateway",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html",
                "contents": [
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway-tutorial.html",
                        "sections": [
                            "In this tutorial, you create a REST API through which you invoke a Lambda function using an HTTP request.   Your Lambda function will perform create, read, update, and delete (CRUD) operations on a DynamoDB table.   This function is provided here for demonstration, but you will learn to configure an API Gateway REST API that can   invoke any Lambda function.",
                            "Using API Gateway provides users with a secure HTTP endpoint to invoke your Lambda function and can help manage   large volumes of calls to your function by throttling traffic and automatically validating and authorizing API   calls. API Gateway also provides flexible security controls using AWS Identity and Access Management (IAM) and Amazon Cognito. This is useful for use cases where   advance authorization is required for calls to your application.",
                            "To complete this tutorial, you will go through the following stages:",
                            "  1 : Create and configure a Lambda function in Python or Node.js to perform operations on a DynamoDB table.",
                            "  2 : Create a REST API in API Gateway to connect to your Lambda function.",
                            "  3 : Create a DynamoDB table and test it with your Lambda function in the console.",
                            "  4 : Deploy your API and test the full setup using curl in a terminal.",
                            "By completing these stages, you will learn how to use API Gateway to create an HTTP endpoint that can securely invoke   a Lambda function at any scale. You will also learn how to deploy your API, and how to test it in the console and by sending   an HTTP request using a terminal.",
                            "Sections",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "Install the AWS Command Line Interface",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          Install the AWS Command Line InterfaceIf you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          "
                                ]
                            },
                            {
                                "sub_header": "Create a permissions policy",
                                "content": [
                                    "Before you can create an execution role for your Lambda function, you first       need to create a permissions policy to give your function permission to access the required AWS resources. For this tutorial,       the policy allows Lambda to perform CRUD operations on a DynamoDB table and write to Amazon CloudWatch Logs.",
                                    "To create the policy",
                                    "  1 : Open the Policies page of the IAM console.",
                                    "  2 : Choose Create Policy.",
                                    " 3 : Choose the JSON tab, and then paste the following custom policy into the JSON          editor. ",
                                    {
                                        "code_example": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Stmt1428341300017\",\n      \"Action\": [\n        \"dynamodb:DeleteItem\",\n        \"dynamodb:GetItem\",\n        \"dynamodb:PutItem\",\n        \"dynamodb:Query\",\n        \"dynamodb:Scan\",\n        \"dynamodb:UpdateItem\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"\",\n      \"Resource\": \"*\",\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Effect\": \"Allow\"\n    }\n  ]\n}"
                                    },
                                    "  4 : Choose Next: Tags.",
                                    "  5 : Choose Next: Review.",
                                    "  6 : Under Review policy, for the policy Name, enter            lambda-apigateway-policy.",
                                    "  7 : Choose Create policy."
                                ]
                            },
                            {
                                "sub_header": "Create an execution role",
                                "content": [
                                    "An execution role is an AWS Identity and Access Management (IAM) role that grants a Lambda function permission to access AWS services and resources. To enable your function to perform operations on a DynamoDB table, you attach the permissions policy you created in the previous step.",
                                    "To create an execution role and attach your custom permissions policy",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : For the type of trusted entity, choose AWS service, then for the use case, choose Lambda.",
                                    "  4 : Choose Next.",
                                    "  5 : In the policy search box, enter lambda-apigateway-policy.",
                                    "  6 : In the search results, select the policy that you created (lambda-apigateway-policy), and          then choose Next.",
                                    "  7 : Under Role details, for the Role name, enter            lambda-apigateway-role, then choose Create role.",
                                    "Later in the tutorial, you need the Amazon Resource Name (ARN) of the role you just created. On the Roles     page of the IAM console, choose the name of your role (lambda-apigateway-role) and copy the Role ARN displayed     on the Summary page."
                                ]
                            },
                            {
                                "sub_header": "Create the function",
                                "content": [
                                    "The following code example receives an event input from API Gateway specifying an operation to perform on the DynamoDB table       you will create and some payload data. If the parameters the function receives are valid, it performs the requested operation on the table.",
                                    "  1.Node.js : region",
                                    "  2.Python 3 : import boto3\n\n# Define the DynamoDB table that Lambda will connect to\ntable_name = \"lambda-apigateway\"\n\n# Create the DynamoDB resource\ndynamo = boto3.resource('dynamodb').Table(table_name)\n\n# Define some functions to perform the CRUD operations\ndef create(payload):\n    return dynamo.put_item(Item=payload['Item'])\n\ndef read(payload):\n    return dynamo.get_item(Key=payload['Key'])\n\ndef update(payload):\n    return dynamo.update_item(**{k: payload[k] for k in ['Key', 'UpdateExpression', \n    'ExpressionAttributeNames', 'ExpressionAttributeValues'] if k in payload})\n\ndef delete(payload):\n    return dynamo.delete_item(Key=payload['Key'])\n\ndef echo(payload):\n    return payload\n\noperations = {\n    'create': create,\n    'read': read,\n    'update': update,\n    'delete': delete,\n    'echo': echo,\n}\n\ndef lambda_handler(event, context):\n    '''Provide an event that contains the following keys:\n      - operation: one of the operations in the operations dict below\n      - payload: a JSON object containing parameters to pass to the \n        operation being performed\n    '''\n    \n    operation = event['operation']\n    payload = event['payload']\n    \n    if operation in operations:\n        return operations[operation](payload)\n        \n    else:\n        raise ValueError(f'Unrecognized operation \"{operation}\"')",
                                    "Node.jsExample index.mjsNote the region setting. This must match the AWS Region where you deploy the function and create the DynamoDB table.import { DynamoDBDocumentClient, PutCommand, GetCommand,          UpdateCommand, DeleteCommand} from \"@aws-sdk/lib-dynamodb\";import { DynamoDBClient } from \"@aws-sdk/client-dynamodb\";const ddbClient = new DynamoDBClient({ region: \"us-east-2\" });const ddbDocClient = DynamoDBDocumentClient.from(ddbClient);// Define the name of the DDB table to perform the CRUD operations onconst tablename = \"lambda-apigateway\";/** * Provide an event that contains the following keys: * *   - operation: one of 'create,' 'read,' 'update,' 'delete,' or 'echo' *   - payload: a JSON object containing the parameters for the table item *     to perform the operation on */export const handler = async (event, context) => {        const operation = event.operation;        if (operation == 'echo'){          return(event.payload);     }         else {         event.payload.TableName = tablename;        let response;                switch (operation) {          case 'create':               response = await ddbDocClient.send(new PutCommand(event.payload));               break;          case 'read':               response = await ddbDocClient.send(new GetCommand(event.payload));               break;          case 'update':               response = ddbDocClient.send(new UpdateCommand(event.payload));               break;          case 'delete':               response = ddbDocClient.send(new DeleteCommand(event.payload));               break;          default:            response = 'Unknown operation: ${operation}';          }        console.log(response);        return response;    }};NoteIn this example, the name of the DynamoDB table is defined as a variable in your function code. In a real application,               best practice is to pass this parameter as an environment variable and to avoid hardcoding the table name. For more information see               Using AWS Lambda environment variables.To create the functionSave the code example as a file named index.mjs and, if necessary, edit the AWS region specified in the code.                 The region specified in the code must be the same as the region in which you create your DynamoDB table later in the tutorial.Create a deployment package using the following zip command.zip function.zip index.mjsCreate a Lambda function using the create-function AWS CLI command. For the                  role parameter, enter the execution role's Amazon Resource Name (ARN) that you copied                earlier.aws lambda create-function \\--function-name LambdaFunctionOverHttps \\--zip-file fileb://function.zip \\--handler index.handler \\--runtime nodejs22.x \\--role arn:aws:iam::123456789012:role/service-role/lambda-apigateway-rolePython 3Example LambdaFunctionOverHttps.pyimport boto3# Define the DynamoDB table that Lambda will connect totable_name = \"lambda-apigateway\"# Create the DynamoDB resourcedynamo = boto3.resource('dynamodb').Table(table_name)# Define some functions to perform the CRUD operationsdef create(payload):    return dynamo.put_item(Item=payload['Item'])def read(payload):    return dynamo.get_item(Key=payload['Key'])def update(payload):    return dynamo.update_item(**{k: payload[k] for k in ['Key', 'UpdateExpression',     'ExpressionAttributeNames', 'ExpressionAttributeValues'] if k in payload})def delete(payload):    return dynamo.delete_item(Key=payload['Key'])def echo(payload):    return payloadoperations = {    'create': create,    'read': read,    'update': update,    'delete': delete,    'echo': echo,}def lambda_handler(event, context):    '''Provide an event that contains the following keys:      - operation: one of the operations in the operations dict below      - payload: a JSON object containing parameters to pass to the         operation being performed    '''        operation = event['operation']    payload = event['payload']        if operation in operations:        return operations[operation](payload)            else:        raise ValueError(f'Unrecognized operation \"{operation}\"')NoteIn this example, the name of the DynamoDB table is defined as a variable in your function code. In a real application,               best practice is to pass this parameter as an environment variable and to avoid hardcoding the table name. For more information see               Using AWS Lambda environment variables.To create the functionSave the code example as a file named LambdaFunctionOverHttps.py.Create a deployment package using the following zip command.zip function.zip LambdaFunctionOverHttps.pyCreate a Lambda function using the create-function AWS CLI command. For the                  role parameter, enter the execution role's Amazon Resource Name (ARN) that you copied                earlier.aws lambda create-function \\--function-name LambdaFunctionOverHttps \\--zip-file fileb://function.zip \\--handler LambdaFunctionOverHttps.lambda_handler \\--runtime python3.12 \\--role arn:aws:iam::123456789012:role/service-role/lambda-apigateway-role",
                                    "anchor",
                                    "anchor",
                                    "Example index.mjs",
                                    "Note the region setting. This must match the AWS Region where you deploy the function and create the DynamoDB table.",
                                    {
                                        "code_example": "import { DynamoDBDocumentClient, PutCommand, GetCommand, \n         UpdateCommand, DeleteCommand} from \"@aws-sdk/lib-dynamodb\";\nimport { DynamoDBClient } from \"@aws-sdk/client-dynamodb\";\n\nconst ddbClient = new DynamoDBClient({ region: \"us-east-2\" });\nconst ddbDocClient = DynamoDBDocumentClient.from(ddbClient);\n\n// Define the name of the DDB table to perform the CRUD operations on\nconst tablename = \"lambda-apigateway\";\n\n/**\n * Provide an event that contains the following keys:\n *\n *   - operation: one of 'create,' 'read,' 'update,' 'delete,' or 'echo'\n *   - payload: a JSON object containing the parameters for the table item\n *     to perform the operation on\n */\nexport const handler = async (event, context) => {\n   \n     const operation = event.operation;\n   \n     if (operation == 'echo'){\n          return(event.payload);\n     }\n     \n    else { \n        event.payload.TableName = tablename;\n        let response;\n        \n        switch (operation) {\n          case 'create':\n               response = await ddbDocClient.send(new PutCommand(event.payload));\n               break;\n          case 'read':\n               response = await ddbDocClient.send(new GetCommand(event.payload));\n               break;\n          case 'update':\n               response = ddbDocClient.send(new UpdateCommand(event.payload));\n               break;\n          case 'delete':\n               response = ddbDocClient.send(new DeleteCommand(event.payload));\n               break;\n          default:\n            response = 'Unknown operation: ${operation}';\n          }\n        console.log(response);\n        return response;\n    }\n};"
                                    },
                                    "Note",
                                    "In this example, the name of the DynamoDB table is defined as a variable in your function code. In a real application,               best practice is to pass this parameter as an environment variable and to avoid hardcoding the table name. For more information see               Using AWS Lambda environment variables.",
                                    "To create the function",
                                    "  1 : Save the code example as a file named index.mjs and, if necessary, edit the AWS region specified in the code.                 The region specified in the code must be the same as the region in which you create your DynamoDB table later in the tutorial.",
                                    " 2 : Create a deployment package using the following zip command. ",
                                    {
                                        "code_example": "zip function.zip index.mjs"
                                    },
                                    " 3 : Create a Lambda function using the create-function AWS CLI command. For the                  role parameter, enter the execution role's Amazon Resource Name (ARN) that you copied                earlier. ",
                                    {
                                        "code_example": "aws lambda create-function \\\n--function-name LambdaFunctionOverHttps \\\n--zip-file fileb://function.zip \\\n--handler index.handler \\\n--runtime nodejs22.x \\\n--role arn:aws:iam::123456789012:role/service-role/lambda-apigateway-role"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Invoke the function using the AWS CLI",
                                "content": [
                                    "Before integrating your function with API Gateway, confirm that you have deployed the function successfully. Create       a test event containing the parameters your API Gateway API will send to Lambda and use the AWS CLI invoke command       to run your function.",
                                    "To invoke the Lambda function with the AWS CLI",
                                    " 1 : Save the following JSON as a file named input.txt. ",
                                    {
                                        "code_example": "{\n    \"operation\": \"echo\",\n    \"payload\": {\n        \"somekey1\": \"somevalue1\",\n        \"somekey2\": \"somevalue2\"\n    }\n}"
                                    },
                                    " 2 : Run the following invoke AWS CLI command. The cli-binary-format option is required if you're using AWS CLI version 2. To make this the default setting, run aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide for Version 2.You should see the following response:{    \"StatusCode\": 200,    \"ExecutedVersion\": \"LATEST\"}",
                                    {
                                        "code_example": "aws lambda invoke \\\n--function-name LambdaFunctionOverHttps \\\n--payload file://input.txt outputfile.txt \\\n--cli-binary-format raw-in-base64-out"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create a REST API using API Gateway",
                                "content": [
                                    "In this step, you create the API Gateway REST API you will use to invoke your Lambda function.",
                                    "To create the API",
                                    "  1 : Open the API Gateway console.",
                                    "  2 : Choose Create API.",
                                    "  3 : In the REST API box, choose Build.",
                                    "  4 : Under API details, leave New API selected, and for API Name, enter             DynamoDBOperations.",
                                    "  5 : Choose Create API."
                                ]
                            },
                            {
                                "sub_header": "Create a resource on your REST API",
                                "content": [
                                    "To add an HTTP method to your API, you first need to create a resource for that method to operate on. Here you create     the resource to manage your DynamoDB table.",
                                    "To create the resource",
                                    "  1 : In the API Gateway console, on the              Resources page for your API, choose Create Resource.",
                                    "  2 : In Resource details, for Resource name enter DynamoDBManager.",
                                    "  3 : Choose Create Resource."
                                ]
                            },
                            {
                                "sub_header": "Create an HTTP POST method",
                                "content": [
                                    "In this step, you create a method (POST) for your DynamoDBManager resource. You link     this POST method to your Lambda function so that when the method receives an HTTP request, API Gateway invokes     your Lambda function.",
                                    "Note",
                                    "      For the purpose of this tutorial, one HTTP method (POST) is used to invoke a single Lambda function which         carries out all of the operations on your DynamoDB table. In a real application, best practice is to use a different Lambda         function and HTTP method for each operation. For more information, see        The Lambda monolith        in Serverless Land.    ",
                                    "To create the POST method",
                                    "  1 : On the Resources page for your API, ensure that the /DynamoDBManager resource is highlighted.           Then, in the Methods pane, choose Create method.",
                                    "  2 : For Method type, choose POST.",
                                    "  3 : For Integration type, leave Lambda function selected.",
                                    "  4 : For Lambda function, choose the Amazon Resource Name (ARN) for your function (LambdaFunctionOverHttps).",
                                    "  5 : Choose Create method."
                                ]
                            },
                            {
                                "sub_header": "Create a DynamoDB table",
                                "content": [
                                    "Create an empty DynamoDB table that your Lambda function will perform CRUD operations on.",
                                    "To create the DynamoDB table",
                                    "  1 : Open the Tables page of the DynamoDB console.",
                                    "  2 : Choose Create table.",
                                    "  3 : Under Table details, do the following:For Table name, enter lambda-apigateway.For Partition key, enter id, and keep the data type set as                String.",
                                    "  4 : Under Table settings, keep the Default settings.",
                                    "  5 : Choose Create table."
                                ]
                            },
                            {
                                "sub_header": "Test the integration of API Gateway, Lambda, and DynamoDB",
                                "content": [
                                    "You're now ready to test the integration of your API Gateway API method with your Lambda function and your DynamoDB table. Using the       API Gateway console, you send requests directly to your POST method using the console's test function.       In this step, you first use a create operation to add a new item to your DynamoDB table, then you       use an update operation to modify the item.",
                                    "Test 1: To create a new item in your DynamoDB table",
                                    "  1 : In the API Gateway console, choose your API            (DynamoDBOperations).",
                                    "  2 : Choose the POST method under the DynamoDBManager resource.",
                                    "  3 : Choose the Test tab. You might need to choose the right arrow button to show the tab.",
                                    " 4 : Under Test method, leave Query strings and Headers empty.         For Request body, paste the following JSON: ",
                                    {
                                        "code_example": "{\n  \"operation\": \"create\",\n  \"payload\": {\n    \"Item\": {\n      \"id\": \"1234ABCD\",\n      \"number\": 5\n    }\n  }\n}"
                                    },
                                    "  5 : Choose Test.The results that are displayed when the test completes should show status 200. This status code indicates that the         create operation was successful. To confirm, check that your DynamoDB table now contains the new item.",
                                    "  6 : Open the Tables page of the DynamoDB console and         choose the lambda-apigateway table.",
                                    "  7 : Chose Explore table items. In the Items returned pane, you         should see one item with the id 1234ABCD and the number 5. Example:",
                                    "Test 2: To update the item in your DynamoDB table",
                                    "  1 : In the API Gateway console, return to your POST method's            Test tab.",
                                    " 2 : Under Test method, leave Query strings and Headers empty.           For Request body, paste the following JSON: ",
                                    {
                                        "code_example": "{\n    \"operation\": \"update\",\n    \"payload\": {\n        \"Key\": {\n            \"id\": \"1234ABCD\"\n        },\n        \"UpdateExpression\": \"SET #num = :newNum\",\n        \"ExpressionAttributeNames\": {\n            \"#num\": \"number\"\n        },\n        \"ExpressionAttributeValues\": {\n            \":newNum\": 10\n        }\n    }\n}"
                                    },
                                    "  3 : Choose Test.The results which are displayed when the test completes should show status 200. This status code indicates that         the update operation was successful. To confirm, check that the item in your DynamoDB table has been modified.",
                                    "  4 : Open the Tables page of the DynamoDB console and             choose the lambda-apigateway table.",
                                    "  5 : Chose Explore table items. In the Items returned pane, you         should see one item with the id 1234ABCD and the number 10."
                                ]
                            },
                            {
                                "sub_header": "Deploy the API",
                                "content": [
                                    "For a client to call the API, you must create a deployment and an associated stage. A stage represents a snapshot     of your API including its methods and integrations.",
                                    "To deploy the API",
                                    "  1 : Open the APIs page of the API Gateway console and choose the         DynamoDBOperations API.",
                                    "  2 : On the Resources page for your API choose Deploy API.",
                                    "  3 : For Stage, choose *New stage*, then for Stage name,         enter test.",
                                    "  4 : Choose Deploy.",
                                    "  5 : In the Stage details pane, copy the Invoke URL. You will use this in the           next step to invoke your function using an HTTP request."
                                ]
                            },
                            {
                                "sub_header": "Use curl to invoke your function using HTTP requests",
                                "content": [
                                    "You can now invoke your Lambda function by issuing an HTTP request to your API. In this step, you will create a     new item in your DynamoDB table and then perform read, update, and delete operations on that item.",
                                    "To create an item in your DynamoDB table using curl",
                                    " 1 : Run the following curl command using the invoke URL you copied in the previous step. When you use curl with the -d (data)         option, it automatically uses the HTTP POST method. If the operation was successful, you should see a response returned with an HTTP status code of 200.",
                                    {
                                        "code_example": "curl https://l8togsqxd8.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager \\\n-d '{\"operation\": \"create\", \"payload\": {\"Item\": {\"id\": \"5678EFGH\", \"number\": 15}}}'"
                                    },
                                    "  2 : You can also use the DynamoDB console to verify that the new item is in your table by doing the following:Open the Tables page of the DynamoDB console and choose               the lambda-apigateway table.Choose Explore table items. In the Items returned pane, you               should see an item with the id 5678EFGH and the number 15.",
                                    "To read the item in your DynamoDB table using curl",
                                    "  1.Run the following curl command to read the value of the item you just created. Use your own invoke URL.curl https://avos4dr2rk.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager -d \\'{\"operation\": \"read\", \"payload\": {\"Key\": {\"id\": \"5678EFGH\"}}}'You should see output like one of the following depending on whether you chose the Node.js or Python function code:Node.js{\"$metadata\":{\"httpStatusCode\":200,\"requestId\":\"7BP3G5Q0C0O1E50FBQI9NS099JVV4KQNSO5AEMVJF66Q9ASUAAJG\",\"attempts\":1,\"totalRetryDelay\":0},\"Item\":{\"id\":\"5678EFGH\",\"number\":15}}Python{\"Item\":{\"id\":\"5678EFGH\",\"number\":15},\"ResponseMetadata\":{\"RequestId\":\"QNDJICE52E86B82VETR6RKBE5BVV4KQNSO5AEMVJF66Q9ASUAAJG\",\"HTTPStatusCode\":200,\"HTTPHeaders\":{\"server\":\"Server\",\"date\":\"Wed, 31 Jul 2024 00:37:01 GMT\",\"content-type\":\"application/x-amz-json-1.0\",\"content-length\":\"52\",\"connection\":\"keep-alive\",\"x-amzn-requestid\":\"QNDJICE52E86B82VETR6RKBE5BVV4KQNSO5AEMVJF66Q9ASUAAJG\",\"x-amz-crc32\":\"2589610852\"},\"RetryAttempts\":0}}anchoranchorNode.jsPython{\"$metadata\":{\"httpStatusCode\":200,\"requestId\":\"7BP3G5Q0C0O1E50FBQI9NS099JVV4KQNSO5AEMVJF66Q9ASUAAJG\",\"attempts\":1,\"totalRetryDelay\":0},\"Item\":{\"id\":\"5678EFGH\",\"number\":15}}",
                                    {
                                        "code_example": "curl https://avos4dr2rk.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager -d \\\n'{\"operation\": \"read\", \"payload\": {\"Key\": {\"id\": \"5678EFGH\"}}}'"
                                    },
                                    "To update the item in your DynamoDB table using curl",
                                    " 1 : Run the following curl command to update the item you just created by changing the number value. Use your own invoke URL. ",
                                    {
                                        "code_example": "curl https://avos4dr2rk.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager \\\n-d '{\"operation\": \"update\", \"payload\": {\"Key\": {\"id\": \"5678EFGH\"}, \"UpdateExpression\": \"SET #num = :new_value\", \"ExpressionAttributeNames\": {\"#num\": \"number\"}, \"ExpressionAttributeValues\": {\":new_value\": 42}}}'"
                                    },
                                    " 2 : To confirm that the value of number for the item has been updated, run another read command: ",
                                    {
                                        "code_example": "curl https://avos4dr2rk.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager \\\n-d '{\"operation\": \"read\", \"payload\": {\"Key\": {\"id\": \"5678EFGH\"}}}'"
                                    },
                                    "To delete the item in your DynamoDB table using curl",
                                    " 1 : Run the following curl command to delete the item you just created. Use your own invoke URL. ",
                                    {
                                        "code_example": "curl https://l8togsqxd8.execute-api.us-east-2.amazonaws.com/test/DynamoDBManager \\\n-d '{\"operation\": \"delete\", \"payload\": {\"Key\": {\"id\": \"5678EFGH\"}}}'"
                                    },
                                    "  2 : Confirm that the delete operation was successful. In the Items returned pane of the DynamoDB console       Explore items page, verify that the item with id 5678EFGH is no longer in the table."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources (optional)",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the API",
                                    "  1 : Open the APIs page of the API Gateway console.",
                                    "  2 : Select the API you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Choose Delete.",
                                    "To delete the DynamoDB table",
                                    "  1 : Open the Tables page of the DynamoDB console.",
                                    "  2 : Select the table you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter delete in the text box.",
                                    "  5 : Choose Delete table."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Errors",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway-errors.html",
                        "sections": [
                            "API Gateway treats all invocation and function errors as internal errors. If the Lambda API rejects the invocation        request, API Gateway returns a 500 error code. If the function runs but returns an error, or returns a response in the        wrong format, API Gateway returns a 502. In both cases, the body of the response from API Gateway is {\"message\":            \"Internal server error\"}.",
                            "Note",
                            "API Gateway does not retry any Lambda invocations. If Lambda returns an error, API Gateway returns an error response to            the client.",
                            "The following example shows an X-Ray trace map for a request that resulted in a function error and a 502 from        API Gateway. The client receives the generic error message.",
                            "To customize the error response, you must catch errors in your code and format a response in the required        format.",
                            "Example index.mjs – Error            formatting",
                            {
                                "code_example": "var formatError = function(error){\n  var response = {\n    \"statusCode\": error.statusCode,\n    \"headers\": {\n      \"Content-Type\": \"text/plain\",\n      \"x-amzn-ErrorType\": error.code\n    },\n    \"isBase64Encoded\": false,\n    \"body\": error.code + \": \" + error.message\n  }\n  return response\n}"
                            },
                            "API Gateway converts this response into an HTTP error with a custom status code and body. In the trace map, the        function node is green because it handled the error."
                        ]
                    },
                    {
                        "title": "Select an HTTP invoke method for Lambda",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/apig-http-invoke-decision.html",
                        "sections": [
                            "Many common use cases for Lambda involve invoking your function using an HTTP request. For example, you might want to invoke a function     directly from a web browser, or to use a tool like curl or Postman.",
                            "The following sections explain what your choices are for invoking Lambda through HTTP and provide information to help you make the right decision for your particular use case.",
                            {
                                "sub_header": "What are your choices when selecting an HTTP invoke method?",
                                "content": [
                                    "Lambda offers two main methods to invoke a function using an HTTP request - function URLs and       API Gateway. The key differences between these two options are as follows:",
                                    "  1.Lambda function URLs :  provide a simple, direct HTTP endpoint for a Lambda function. They are optimized for         simplicity and cost-effectiveness and provide the fastest path to expose a Lambda function via HTTP.",
                                    "  2.API Gateway :  is a more advanced service for building fully-featured APIs.  is optimized for building and managing           productions APIs at scale and provides comprehensive tools for security, monitoring, and traffic management."
                                ]
                            },
                            {
                                "sub_header": "Recommendations if you already know your requirements",
                                "content": [
                                    "If you're already clear on your requirements, here are our basic recommendations:",
                                    "We recommend function URLs for simple applications or prototyping where       you only need basic authentication methods and request/response handling and where you want to keep costs and complexity to a minimum.",
                                    "API Gateway is a better choice for production applications at scale or for cases where you need more advanced features       like OpenAPI Description support, a choice of authentication options, custom domain names, or rich request/response       handling including throttling, caching, and request/response transformation."
                                ]
                            },
                            {
                                "sub_header": "What to consider when selecting a method to invoke your Lambda function",
                                "content": [
                                    "When selecting between function URLs and API Gateway, you need to consider the following factors:",
                                    "  1.Your authentication needs, such as whether you require OAuth or Amazon Cognito to authenticate users",
                                    "  2.Your scaling requirements and the complexity of the API you want to implement",
                                    "  3.Whether you need advanced features such as request validation and request/response formatting",
                                    "  4.Your monitoring requirements",
                                    "  5.Your cost goals",
                                    "By understanding these factors, you can select the option that best balances your security, complexity, and cost requirements.",
                                    "The following information summarizes the main differences between the two options.",
                                    "  1.Function URLs :  provide basic authentication options through AWS Identity and Access Management (IAM). You can configure your endpoints to be               either public (no authentication) or to require IAM authentication. With IAM authentication, you can use standard AWS credentials or IAM roles to               control access. While straightforward to set up, this approach provides limited options compared with other authenticaton methods.",
                                    "  2.API Gateway :  provides access to a more comprehensive range of authentication options. As well as IAM authentication,               you can use Lambda authorizers               (custom authentication logic), Amazon Cognito user pools, and OAuth2.0               flows. This flexibility allows you to implement complex authentication schemes, including third-party authentication providers, token-based authentication, and multi-factor               authentication.",
                                    "Authentication",
                                    "  1.Function URLs :  provide basic authentication options through AWS Identity and Access Management (IAM). You can configure your endpoints to be               either public (no authentication) or to require IAM authentication. With IAM authentication, you can use standard AWS credentials or IAM roles to               control access. While straightforward to set up, this approach provides limited options compared with other authenticaton methods.",
                                    "  2.API Gateway :  provides access to a more comprehensive range of authentication options. As well as IAM authentication,               you can use Lambda authorizers               (custom authentication logic), Amazon Cognito user pools, and OAuth2.0               flows. This flexibility allows you to implement complex authentication schemes, including third-party authentication providers, token-based authentication, and multi-factor               authentication.",
                                    "Function URLs provide basic authentication options through AWS Identity and Access Management (IAM). You can configure your endpoints to be               either public (no authentication) or to require IAM authentication. With IAM authentication, you can use standard AWS credentials or IAM roles to               control access. While straightforward to set up, this approach provides limited options compared with other authenticaton methods.API Gateway provides access to a more comprehensive range of authentication options. As well as IAM authentication,               you can use Lambda authorizers               (custom authentication logic), Amazon Cognito user pools, and OAuth2.0               flows. This flexibility allows you to implement complex authentication schemes, including third-party authentication providers, token-based authentication, and multi-factor               authentication.AuthenticationFunction URLs provide basic authentication options through AWS Identity and Access Management (IAM). You can configure your endpoints to be               either public (no authentication) or to require IAM authentication. With IAM authentication, you can use standard AWS credentials or IAM roles to               control access. While straightforward to set up, this approach provides limited options compared with other authenticaton methods.API Gateway provides access to a more comprehensive range of authentication options. As well as IAM authentication,               you can use Lambda authorizers               (custom authentication logic), Amazon Cognito user pools, and OAuth2.0               flows. This flexibility allows you to implement complex authentication schemes, including third-party authentication providers, token-based authentication, and multi-factor               authentication.",
                                    "  1.Function URLs :  provide basic HTTP request and response handling. They support standard HTTP methods and               include built-in cross-origin resource sharing (CORS) support. While they can handle JSON payloads and query parameters naturally, they don't offer request               transformation or validation capabilities. Response handling is similarly straightforward – the client receives the response from your Lambda function exactly as               Lambda returns it.",
                                    "  2.API Gateway :  provides sophisticated request and response handling capabilities. You can define request validators, transform               requests and responses using mapping templates, set up request/response headers, and implement response caching.  also supports binary payloads and custom domain               names and can modify responses before they reach the client. You can set up models for request/response validation and transformation using JSON Schema.",
                                    "Request/response handling",
                                    "  1.Function URLs :  provide basic HTTP request and response handling. They support standard HTTP methods and               include built-in cross-origin resource sharing (CORS) support. While they can handle JSON payloads and query parameters naturally, they don't offer request               transformation or validation capabilities. Response handling is similarly straightforward – the client receives the response from your Lambda function exactly as               Lambda returns it.",
                                    "  2.API Gateway :  provides sophisticated request and response handling capabilities. You can define request validators, transform               requests and responses using mapping templates, set up request/response headers, and implement response caching.  also supports binary payloads and custom domain               names and can modify responses before they reach the client. You can set up models for request/response validation and transformation using JSON Schema.",
                                    "Function URLs provide basic HTTP request and response handling. They support standard HTTP methods and               include built-in cross-origin resource sharing (CORS) support. While they can handle JSON payloads and query parameters naturally, they don't offer request               transformation or validation capabilities. Response handling is similarly straightforward – the client receives the response from your Lambda function exactly as               Lambda returns it.API Gateway provides sophisticated request and response handling capabilities. You can define request validators, transform               requests and responses using mapping templates, set up request/response headers, and implement response caching. API Gateway also supports binary payloads and custom domain               names and can modify responses before they reach the client. You can set up models for request/response validation and transformation using JSON Schema.Request/response handlingFunction URLs provide basic HTTP request and response handling. They support standard HTTP methods and               include built-in cross-origin resource sharing (CORS) support. While they can handle JSON payloads and query parameters naturally, they don't offer request               transformation or validation capabilities. Response handling is similarly straightforward – the client receives the response from your Lambda function exactly as               Lambda returns it.API Gateway provides sophisticated request and response handling capabilities. You can define request validators, transform               requests and responses using mapping templates, set up request/response headers, and implement response caching. API Gateway also supports binary payloads and custom domain               names and can modify responses before they reach the client. You can set up models for request/response validation and transformation using JSON Schema.",
                                    "  1.Function URLs :  scale directly with your Lambda function's concurrency limits and handle traffic spikes by scaling your function             up to its maximum configured concurrency limit. Once that limit is reached, Lambda responds to additional requests with HTTP 429 responses. There's no built-in queuing             mechanism, so handling scaling is entirely dependent on your Lambda function's configuration. By default, Lambda functions have a limit of 1,000 concurrent executions             per AWS Region.",
                                    "  2.API Gateway :  provides additional scaling capabilities on top of Lambda's own scaling. It includes built-in request queuing and throttling             controls, allowing you to manage traffic spikes more gracefully.  can handle up to 10,000 requests per second per region by default, with a burst capacity of             5,000 requests per second. It also provides tools to throttle requests at different levels (API, stage, or method) to protect your backend.",
                                    "Scaling",
                                    "  1.Function URLs :  scale directly with your Lambda function's concurrency limits and handle traffic spikes by scaling your function             up to its maximum configured concurrency limit. Once that limit is reached, Lambda responds to additional requests with HTTP 429 responses. There's no built-in queuing             mechanism, so handling scaling is entirely dependent on your Lambda function's configuration. By default, Lambda functions have a limit of 1,000 concurrent executions             per AWS Region.",
                                    "  2.API Gateway :  provides additional scaling capabilities on top of Lambda's own scaling. It includes built-in request queuing and throttling             controls, allowing you to manage traffic spikes more gracefully.  can handle up to 10,000 requests per second per region by default, with a burst capacity of             5,000 requests per second. It also provides tools to throttle requests at different levels (API, stage, or method) to protect your backend.",
                                    "Function URLs scale directly with your Lambda function's concurrency limits and handle traffic spikes by scaling your function             up to its maximum configured concurrency limit. Once that limit is reached, Lambda responds to additional requests with HTTP 429 responses. There's no built-in queuing             mechanism, so handling scaling is entirely dependent on your Lambda function's configuration. By default, Lambda functions have a limit of 1,000 concurrent executions             per AWS Region.API Gateway provides additional scaling capabilities on top of Lambda's own scaling. It includes built-in request queuing and throttling             controls, allowing you to manage traffic spikes more gracefully. API Gateway can handle up to 10,000 requests per second per region by default, with a burst capacity of             5,000 requests per second. It also provides tools to throttle requests at different levels (API, stage, or method) to protect your backend.ScalingFunction URLs scale directly with your Lambda function's concurrency limits and handle traffic spikes by scaling your function             up to its maximum configured concurrency limit. Once that limit is reached, Lambda responds to additional requests with HTTP 429 responses. There's no built-in queuing             mechanism, so handling scaling is entirely dependent on your Lambda function's configuration. By default, Lambda functions have a limit of 1,000 concurrent executions             per AWS Region.API Gateway provides additional scaling capabilities on top of Lambda's own scaling. It includes built-in request queuing and throttling             controls, allowing you to manage traffic spikes more gracefully. API Gateway can handle up to 10,000 requests per second per region by default, with a burst capacity of             5,000 requests per second. It also provides tools to throttle requests at different levels (API, stage, or method) to protect your backend.",
                                    "  1.Function URLs :  offer basic monitoring through Amazon CloudWatch metrics, including request count, latency, and error rates. You get               access to standard Lambda metrics and logs, which show the raw requests coming into your function. While this provides essential operational visibility, the metrics               are focused mainly on function execution.",
                                    "  2.API Gateway :  provides comprehensive monitoring capabilities including detailed metrics, logging, and tracing options. You can               monitor API calls, latency, error rates, and cache hit/miss rates through CloudWatch.  also integrates with AWS X-Ray for distributed tracing and provides               customizable logging formats.",
                                    "Monitoring",
                                    "  1.Function URLs :  offer basic monitoring through Amazon CloudWatch metrics, including request count, latency, and error rates. You get               access to standard Lambda metrics and logs, which show the raw requests coming into your function. While this provides essential operational visibility, the metrics               are focused mainly on function execution.",
                                    "  2.API Gateway :  provides comprehensive monitoring capabilities including detailed metrics, logging, and tracing options. You can               monitor API calls, latency, error rates, and cache hit/miss rates through CloudWatch.  also integrates with AWS X-Ray for distributed tracing and provides               customizable logging formats.",
                                    "Function URLs offer basic monitoring through Amazon CloudWatch metrics, including request count, latency, and error rates. You get               access to standard Lambda metrics and logs, which show the raw requests coming into your function. While this provides essential operational visibility, the metrics               are focused mainly on function execution.API Gateway provides comprehensive monitoring capabilities including detailed metrics, logging, and tracing options. You can               monitor API calls, latency, error rates, and cache hit/miss rates through CloudWatch. API Gateway also integrates with AWS X-Ray for distributed tracing and provides               customizable logging formats.MonitoringFunction URLs offer basic monitoring through Amazon CloudWatch metrics, including request count, latency, and error rates. You get               access to standard Lambda metrics and logs, which show the raw requests coming into your function. While this provides essential operational visibility, the metrics               are focused mainly on function execution.API Gateway provides comprehensive monitoring capabilities including detailed metrics, logging, and tracing options. You can               monitor API calls, latency, error rates, and cache hit/miss rates through CloudWatch. API Gateway also integrates with AWS X-Ray for distributed tracing and provides               customizable logging formats.",
                                    "  1.Function URLs :  follow the standard Lambda pricing model – you only pay for function invocations and compute time. There are               no additional charges for the URL endpoint itself. This makes it a cost-effective choice for simple APIs or low-traffic applications if you don't need the additional               features of API Gateway.",
                                    "  2.API Gateway :  offers a free tier that includes one million API calls               received for REST APIs and one million API calls received for HTTP APIs. After this,  charges for API calls, data transfer, and caching (if enabled). Refer to the                pricing page to understand the costs for your own use case.",
                                    "Cost",
                                    "  1.Function URLs :  follow the standard Lambda pricing model – you only pay for function invocations and compute time. There are               no additional charges for the URL endpoint itself. This makes it a cost-effective choice for simple APIs or low-traffic applications if you don't need the additional               features of API Gateway.",
                                    "  2.API Gateway :  offers a free tier that includes one million API calls               received for REST APIs and one million API calls received for HTTP APIs. After this,  charges for API calls, data transfer, and caching (if enabled). Refer to the                pricing page to understand the costs for your own use case.",
                                    "Function URLs follow the standard Lambda pricing model – you only pay for function invocations and compute time. There are               no additional charges for the URL endpoint itself. This makes it a cost-effective choice for simple APIs or low-traffic applications if you don't need the additional               features of API Gateway.API Gateway offers a free tier that includes one million API calls               received for REST APIs and one million API calls received for HTTP APIs. After this, API Gateway charges for API calls, data transfer, and caching (if enabled). Refer to the API Gateway               pricing page to understand the costs for your own use case.CostFunction URLs follow the standard Lambda pricing model – you only pay for function invocations and compute time. There are               no additional charges for the URL endpoint itself. This makes it a cost-effective choice for simple APIs or low-traffic applications if you don't need the additional               features of API Gateway.API Gateway offers a free tier that includes one million API calls               received for REST APIs and one million API calls received for HTTP APIs. After this, API Gateway charges for API calls, data transfer, and caching (if enabled). Refer to the API Gateway               pricing page to understand the costs for your own use case.",
                                    "  1.Function URLs :  are designed for simplicity and direct Lambda integration. They support both HTTP and HTTPS endpoints, offer               built-in CORS support, and provide dual-stack (IPv4 and IPv6) endpoints. While they lack advanced features, they excel in scenarios where you need a quick,               straightforward way to expose Lambda functions via HTTP.",
                                    "  2.API Gateway :  includes numerous additional features such as API versioning, stage management, API keys for usage plans, API documentation               through Swagger/OpenAPI, WebSocket APIs, private APIs within a VPC, and WAF integration for additional security. It also supports canary deployments, mock integrations               for testing, and integration with other AWS services beyond Lambda.",
                                    "Other features",
                                    "  1.Function URLs :  are designed for simplicity and direct Lambda integration. They support both HTTP and HTTPS endpoints, offer               built-in CORS support, and provide dual-stack (IPv4 and IPv6) endpoints. While they lack advanced features, they excel in scenarios where you need a quick,               straightforward way to expose Lambda functions via HTTP.",
                                    "  2.API Gateway :  includes numerous additional features such as API versioning, stage management, API keys for usage plans, API documentation               through Swagger/OpenAPI, WebSocket APIs, private APIs within a VPC, and WAF integration for additional security. It also supports canary deployments, mock integrations               for testing, and integration with other AWS services beyond Lambda.",
                                    "Function URLs are designed for simplicity and direct Lambda integration. They support both HTTP and HTTPS endpoints, offer               built-in CORS support, and provide dual-stack (IPv4 and IPv6) endpoints. While they lack advanced features, they excel in scenarios where you need a quick,               straightforward way to expose Lambda functions via HTTP.API Gateway includes numerous additional features such as API versioning, stage management, API keys for usage plans, API documentation               through Swagger/OpenAPI, WebSocket APIs, private APIs within a VPC, and WAF integration for additional security. It also supports canary deployments, mock integrations               for testing, and integration with other AWS services beyond Lambda.Other featuresFunction URLs are designed for simplicity and direct Lambda integration. They support both HTTP and HTTPS endpoints, offer               built-in CORS support, and provide dual-stack (IPv4 and IPv6) endpoints. While they lack advanced features, they excel in scenarios where you need a quick,               straightforward way to expose Lambda functions via HTTP.API Gateway includes numerous additional features such as API versioning, stage management, API keys for usage plans, API documentation               through Swagger/OpenAPI, WebSocket APIs, private APIs within a VPC, and WAF integration for additional security. It also supports canary deployments, mock integrations               for testing, and integration with other AWS services beyond Lambda."
                                ]
                            },
                            {
                                "sub_header": "Select a method to invoke your Lambda function",
                                "content": [
                                    "Now that you've read about the criteria for selecting between Lambda function URLs and API Gateway and the key differences between them, you can select the option     that best meets your needs and use the following resources to help you get started using it.",
                                    "  1.Function URLs : \n\nGet started with function URLs with the following resources\n\nFollow the tutorial Creating a Lambda function with a function URL\n\nLearn more about function URLs in the Creating and managing Lambda function URLs chapter of this guide\n\nTry the in-console guided tutorial Create a simple web app by doing the following:\n\n\nOpen the functions page of the Lambda console.\n\nOpen the help panel by choosing the icon in the top right corner of the screen.\n\n\n\n\nSelect Tutorials.\n\nIn Create a simple web app, choose Start tutorial.\n\n",
                                    "  2.API Gateway : \n\nGet started with Lambda and API Gateway with the following resources\n\nFollow the tutorial Using Lambda with API Gateway to create a REST API integrated with a backend \n              Lambda function.\n\nLearn more about the different kinds of API offered by API Gateway in the following sections of the Amazon API Gateway Developer Guide:\n\n\nAPI Gateway REST APIs\n\nAPI Gateway HTTP APIs\n\nAPI Gateway WebSocket APIs\n\n\nTry one or more of the examples in the Tutorials and workshops \n                section of the Amazon API Gateway Developer Guide.\n\n",
                                    "Function URLsGet started with function URLs with the following resourcesFollow the tutorial Creating a Lambda function with a function URLLearn more about function URLs in the Creating and managing Lambda function URLs chapter of this guideTry the in-console guided tutorial Create a simple web app by doing the following:Open the functions page of the Lambda console.Open the help panel by choosing the icon in the top right corner of the screen.Select Tutorials.In Create a simple web app, choose Start tutorial.API GatewayGet started with Lambda and API Gateway with the following resourcesFollow the tutorial Using Lambda with API Gateway to create a REST API integrated with a backend               Lambda function.Learn more about the different kinds of API offered by API Gateway in the following sections of the Amazon API Gateway Developer Guide:API Gateway REST APIsAPI Gateway HTTP APIsAPI Gateway WebSocket APIsTry one or more of the examples in the Tutorials and workshops                 section of the Amazon API Gateway Developer Guide.",
                                    "anchor",
                                    "anchor",
                                    "Get started with function URLs with the following resources",
                                    "  1.Follow the tutorial Creating a Lambda function with a function URL",
                                    "  2.Learn more about function URLs in the Creating and managing Lambda function URLs chapter of this guide",
                                    "  3.Create a simple web app : Try the in-console guided tutorial  by doing the following:",
                                    "  1 : Open the functions page of the Lambda console.",
                                    "  2 : Open the help panel by choosing the icon in the top right corner of the screen.",
                                    "  3 : Select Tutorials.",
                                    "  4 : In Create a simple web app, choose Start tutorial."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "You can create a web API with an HTTP endpoint for your Lambda function by using Amazon API Gateway. API Gateway provides tools    for creating and documenting web APIs that route HTTP requests to Lambda functions. You can secure access to your API    with authentication and authorization controls. Your APIs can serve traffic over the internet or can be accessible    only within your VPC.",
                    "Resources in your API define one or more methods, such as GET or POST. Methods have an integration that routes    requests to a Lambda function or another integration type. You can define each resource and method individually, or    use special resource and method types to match all requests that fit a pattern. A proxy      resource catches all paths beneath a resource. The ANY method catches all HTTP    methods.",
                    "Sections",
                    {
                        "sub_header": "Choosing an API type",
                        "content": [
                            "API Gateway supports three types of APIs that invoke Lambda functions:",
                            "  1.HTTP API: A lightweight, low-latency RESTful API.",
                            "  2.REST API: A customizable, feature-rich RESTful API.",
                            "  3.WebSocket API: A web API that maintains persistent connections          with clients for full-duplex communication.",
                            "HTTP APIs and REST APIs are both RESTful APIs that process HTTP requests and return responses. HTTP APIs are      newer and are built with the API Gateway version 2 API. The following features are new for HTTP APIs:",
                            "HTTP API features",
                            "  1.Automatic deployments :  – When you modify routes or integrations,          changes deploy automatically to stages that have automatic deployment enabled.",
                            "  2.Default stage :  – You can create a default stage          ($default) to serve requests at the root path of your API's URL. For named stages, you must          include the stage name at the beginning of the path.",
                            "  3.CORS configuration :  – You can configure your API to add CORS          headers to outgoing responses, instead of adding them manually in your function code.",
                            "REST APIs are the classic RESTful APIs that API Gateway has supported since launch. REST APIs currently have more      customization, integration, and management features.",
                            "REST API features",
                            "  1.Integration types :  – REST APIs support custom Lambda integrations.          With a custom integration, you can send just the body of the request to the function, or apply a transform          template to the request body before sending it to the function.",
                            "  2.Access control :  – REST APIs support more options for authentication          and authorization.",
                            "  3.Monitoring and tracing :  – REST APIs support AWS X-Ray tracing and          additional logging options.",
                            "For a detailed comparison, see Choose between HTTP APIs and REST APIs in the API Gateway Developer Guide.",
                            "WebSocket APIs also use the API Gateway version 2 API and support a similar feature set. Use a WebSocket API for      applications that benefit from a persistent connection between the client and API. WebSocket APIs provide      full-duplex communication, which means that both the client and the API can send messages continuously without      waiting for a response.",
                            "HTTP APIs support a simplified event format (version 2.0). For an example of an event from an HTTP      API, see Create AWS Lambda proxy integrations for HTTP APIs in API Gateway.",
                            "For more information, see Create AWS Lambda proxy integrations for HTTP APIs in API Gateway."
                        ]
                    },
                    {
                        "sub_header": "Adding an endpoint to your Lambda function",
                        "content": [
                            "To add a public endpoint to your Lambda function",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Choose a function.",
                            "  3 : Under Function overview, choose Add trigger.",
                            "  4 : Select API Gateway.",
                            "  5 : Choose Create an API or Use an existing API.New API: For API type, choose HTTP API. For more information, see Choosing an API type.Existing API: Select the API from the dropdown list or enter the API ID (for example, r3pmxmplak).",
                            "  6 : For Security, choose Open.",
                            "  7 : Choose Add."
                        ]
                    },
                    {
                        "sub_header": "Proxy integration",
                        "content": [
                            "API Gateway APIs are comprised of stages, resources, methods, and integrations. The stage and resource determine the      path of the endpoint:",
                            "API path format",
                            "  1./prod/ – The prod stage and root resource.",
                            "  2./prod/user – The prod stage and user resource.",
                            "  3./dev/{proxy+} – Any route in the dev stage.",
                            "  4./ – (HTTP APIs) The default stage and root resource.",
                            "A Lambda integration maps a path and HTTP method combination to a Lambda function. You can configure API Gateway to pass      the body of the HTTP request as-is (custom integration), or to encapsulate the request body in a document that      includes all of the request information including headers, resource, path, and method.",
                            "For more information, see Lambda proxy integrations in API Gateway."
                        ]
                    },
                    {
                        "sub_header": "Event format",
                        "content": [
                            "Amazon API Gateway invokes your function synchronously with an event that contains      a JSON representation of the HTTP request. For a custom integration, the event is the body of the request. For a      proxy integration, the event has a defined structure. For an example of a proxy event from an API Gateway REST      API, see Input format of a Lambda function for proxy integration in the API Gateway Developer Guide."
                        ]
                    },
                    {
                        "sub_header": "Response format",
                        "content": [
                            "API Gateway waits for a response from your function and relays the result to the caller. For a custom integration, you      define an integration response and a method response to convert the output from the function to an HTTP response.      For a proxy integration, the function must respond with a representation of the response in a specific      format.",
                            "The following example shows a response object from a Node.js function. The response object represents a      successful HTTP response that contains a JSON document.",
                            "Example index.mjs – Proxy integration response object (Node.js)",
                            {
                                "code_example": "var response = {\n      \"statusCode\": 200,\n      \"headers\": {\n        \"Content-Type\": \"application/json\"\n      },\n      \"isBase64Encoded\": false,\n      \"multiValueHeaders\": { \n        \"X-Custom-Header\": [\"My value\", \"My other value\"],\n      },\n      \"body\": \"{\\n  \\\"TotalCodeSize\\\": 104330022,\\n  \\\"FunctionCount\\\": 26\\n}\"\n    }"
                            },
                            "The Lambda runtime serializes the response object into JSON and sends it to the API. The API parses the response      and uses it to create an HTTP response, which it then sends to the client that made the original request.",
                            "Example HTTP response",
                            {
                                "code_example": "< HTTP/1.1 200 OK\n  < Content-Type: application/json\n  < Content-Length: 55\n  < Connection: keep-alive\n  < x-amzn-RequestId: 32998fea-xmpl-4268-8c72-16138d629356\n  < X-Custom-Header: My value\n  < X-Custom-Header: My other value\n  < X-Amzn-Trace-Id: Root=1-5e6aa925-ccecxmplbae116148e52f036\n  <\n  {\n    \"TotalCodeSize\": 104330022,\n    \"FunctionCount\": 26\n  }"
                            }
                        ]
                    },
                    {
                        "sub_header": "Permissions",
                        "content": [
                            "Amazon API Gateway gets permission to invoke your function from the function's resource-based policy. You can grant invoke permission to an      entire API, or grant limited access to a stage, resource, or method.",
                            "When you add an API to your function by using the Lambda console, using the API Gateway console, or in an AWS SAM      template, the function's resource-based policy is updated automatically. The following is an example function policy.",
                            "Example function policy",
                            {
                                "code_example": "{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"default\",\n  \"Statement\": [\n    {\n      \"Sid\": \"nodejs-apig-functiongetEndpointPermissionProd-BWDBXMPLXE2F\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"apigateway.amazonaws.com\"\n      },\n      \"Action\": \"lambda:InvokeFunction\",\n      \"Resource\": \"arn:aws:lambda:us-east-2:111122223333:function:nodejs-apig-function-1G3MXMPLXVXYI\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:SourceAccount\": \"111122223333\"\n        },\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"arn:aws:execute-api:us-east-2:111122223333:ktyvxmpls1/*/GET/\"\n        }\n      }\n    }\n  ]\n}"
                            },
                            "You can manage function policy permissions manually with the following API operations:",
                            "  1.AddPermission",
                            "  2.RemovePermission",
                            "  3.GetPolicy",
                            "To grant invocation permission to an existing API, use the add-permission command. Example:",
                            "aws lambda add-permission \\  --function-name my-function \\  --statement-id apigateway-get --action lambda:InvokeFunction \\  --principal apigateway.amazonaws.com \\  --source-arn \"arn:aws:execute-api:us-east-2:123456789012:mnh1xmpli7/default/GET/\"",
                            "You should see the following output:",
                            "{    \"Statement\": \"{\\\"Sid\\\":\\\"apigateway-test-2\\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"apigateway.amazonaws.com\\\"},\\\"Action\\\":\\\"lambda:InvokeFunction\\\",\\\"Resource\\\":\\\"arn:aws:lambda:us-east-2:123456789012:function:my-function\\\",\\\"Condition\\\":{\\\"ArnLike\\\":{\\\"AWS:SourceArn\\\":\\\"arn:aws:execute-api:us-east-2:123456789012:mnh1xmpli7/default/GET\\\"}}}\"}",
                            "Note",
                            "If your function and API are in different AWS Regions, the Region identifier in the source ARN must match the        Region of the function, not the Region of the API. When API Gateway invokes a function, it uses a resource ARN that is        based on the ARN of the API, but modified to match the function's Region.",
                            "The source ARN in this example grants permission to an integration on the GET method of the root resource in      the default stage of an API, with ID mnh1xmpli7. You can use an asterisk in the source ARN to grant      permissions to multiple stages, methods, or resources.",
                            "Resource patterns",
                            "  1.mnh1xmpli7/*/GET/* – GET method on all resources in all stages.",
                            "  2.mnh1xmpli7/prod/ANY/user – ANY method on the user resource in the            prod stage.",
                            "  3.mnh1xmpli7/*/*/* – Any method on all resources in all stages.",
                            "For details on viewing the policy and removing statements, see Working with resource-based IAM policies in Lambda."
                        ]
                    },
                    {
                        "sub_header": "Sample application",
                        "content": [
                            "The API Gateway with Node.js sample app includes a function with an AWS SAM      template that creates a REST API that has AWS X-Ray tracing enabled. It also includes scripts for deploying,      invoking the function, testing the API, and cleanup."
                        ]
                    }
                ]
            },
            {
                "title": "Infrastructure Composer",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-appcomposer.html",
                "sections": [
                    "AWS Infrastructure Composer is a visual builder for desiging modern applications on AWS. You design your application architecture by dragging, grouping, and   connecting AWS services in a visual canvas. Infrastructure Composer creates infrastructure as code (IaC) templates from your design that you can deploy using     AWS SAM or     AWS CloudFormation.",
                    {
                        "sub_header": "Exporting a Lambda function to Infrastructure Composer",
                        "content": [
                            "You can get started using Infrastructure Composer by creating a new project based on the configuration of an existing Lambda function using the Lambda console.      To export your function's configuration and code to Infrastructure Composer to create a new project, do the following:",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Select the function you want to use as a basis for your Infrastructure Composer project.",
                            "  3 : In the Function overview pane, choose Export to Infrastructure Composer.To export your function's configuration and code to Infrastructure Composer, Lambda creates an Amazon S3 bucket in your account to temporarily store this data.",
                            "  4 : In the dialog box, choose Confirm and create project to accept the default name for this bucket and export your function's          configuration and code to Infrastructure Composer.",
                            "  5 : (Optional) To choose another name for the Amazon S3 bucket that Lambda creates, enter a new name and choose Confirm and create project.          Amazon S3 bucket names must be globally unique and follow the bucket naming rules.",
                            "  6 : To save your project and function files in Infrastructure Composer, activate local sync mode.",
                            "Note",
                            "If you've used the Export to Application Composer feature before and created an Amazon S3 bucket using the default name,        Lambda can re-use this bucket if it still exists. Accept the default bucket name in the dialog box to re-use the existing bucket.",
                            {
                                "sub_header": "Amazon S3 transfer bucket configuration",
                                "content": [
                                    "The Amazon S3 bucket that Lambda creates to transfer your function's configuration automatically encrypts objects using the AES 256 encryption        standard. Lambda also configures the bucket to use the bucket owner condition        to ensure that only your AWS account is able to add objects to the bucket.",
                                    "Lambda configures the bucket to automatically delete objects 10 days after they are uploaded. However, Lambda doesn't        automaticaly delete the bucket itself. To delete the bucket from your AWS account, follow the instructions in Deleting a bucket.        The default bucket name uses the prefix lambdasam, a 10-digit alphanumeric string, and the AWS Region you created your function in:",
                                    "lambdasam-06f22da95b-us-east-1",
                                    "To avoid additional charges being added to your AWS account, we recommend that you delete the Amazon S3 bucket as soon as you have finished exporting        your function to Infrastructure Composer.",
                                    "Standard Amazon S3 pricing applies."
                                ]
                            },
                            {
                                "sub_header": "Required permissions",
                                "content": [
                                    "To use the Lambda integration with Infrastructure Composer feature, you need certain permissions to download an AWS SAM template and to write your      function's configuration to Amazon S3.",
                                    "To download an AWS SAM template, you must have permission to use the following API actions:",
                                    "  1.GetPolicy",
                                    "  2.iam:GetPolicyVersion",
                                    "  3.iam:GetRole",
                                    "  4.iam:GetRolePolicy",
                                    "  5.iam:ListAttachedRolePolicies",
                                    "  6.iam:ListRolePolicies",
                                    "  7.iam:ListRoles",
                                    "You can grant permission to use all of these actions by adding the AWSLambda_ReadOnlyAccess        AWS managed policy to your IAM user role.",
                                    "For Lambda to write your function's configuration to Amazon S3, you must have permission to use the following API actions:",
                                    "  1.S3:PutObject",
                                    "  2.S3:CreateBucket",
                                    "  3.S3:PutBucketEncryption",
                                    "  4.S3:PutBucketLifecycleConfiguration",
                                    "If you are unable to export your function's configuration to Infrastructure Composer, check that your account has the required permissions for these        operations. If you have the required permissions, but still cannot export your function's configuration, check for any        resource-based policies that might limit access to Amazon S3."
                                ]
                            }
                        ]
                    },
                    {
                        "sub_header": "Other resources",
                        "content": [
                            "For a more detailed tutorial on how to design a serverless application in Infrastructure Composer based on an existing Lambda function, see       Using Lambda with infrastructure as code (IaC).",
                            "To use Infrastructure Composer and AWS SAM to design and deploy a complete serverless application using Lambda, you can also       follow the AWS Infrastructure Composer tutorial in the       AWS Serverless Patterns Workshop."
                        ]
                    }
                ]
            },
            {
                "title": "CloudFormation",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-cloudformation.html",
                "sections": [
                    "In an AWS CloudFormation template, you can specify a Lambda function as the target of a custom resource. Use custom    resources to process parameters, retrieve configuration values, or call other AWS services during stack lifecycle    events.",
                    "The following example invokes a function that's defined elsewhere in the template.",
                    "Example  – Custom resource definition",
                    {
                        "code_example": "Resources:\n  primerinvoke:\n    Type: AWS::CloudFormation::CustomResource\n    Version: \"1.0\"\n    Properties:\n      ServiceToken: !GetAtt primer.Arn\n      FunctionName: !Ref randomerror"
                    },
                    "The service token is the Amazon Resource Name (ARN) of the function that AWS CloudFormation invokes when you create, update,    or delete the stack. You can also include additional properties like FunctionName, which AWS CloudFormation passes    to your function as is.",
                    "AWS CloudFormation invokes your Lambda function asynchronously with an event that    includes a callback URL.",
                    "Example  – AWS CloudFormation message event",
                    {
                        "code_example": "{\n    \"RequestType\": \"Create\",\n    \"ServiceToken\": \"arn:aws:lambda:us-east-1:123456789012:function:lambda-error-processor-primer-14ROR2T3JKU66\",\n    \"ResponseURL\": \"https://cloudformation-custom-resource-response-useast1.s3-us-east-1.amazonaws.com/arn%3Aaws%3Acloudformation%3Aus-east-1%3A123456789012%3Astack/lambda-error-processor/1134083a-2608-1e91-9897-022501a2c456%7Cprimerinvoke%7C5d478078-13e9-baf0-464a-7ef285ecc786?AWSAccessKeyId=AKIAIOSFODNN7EXAMPLE&Expires=1555451971&Signature=28UijZePE5I4dvukKQqM%2F9Rf1o4%3D\",\n    \"StackId\": \"arn:aws:cloudformation:us-east-1:123456789012:stack/lambda-error-processor/1134083a-2608-1e91-9897-022501a2c456\",\n    \"RequestId\": \"5d478078-13e9-baf0-464a-7ef285ecc786\",\n    \"LogicalResourceId\": \"primerinvoke\",\n    \"ResourceType\": \"AWS::CloudFormation::CustomResource\",\n    \"ResourceProperties\": {\n        \"ServiceToken\": \"arn:aws:lambda:us-east-1:123456789012:function:lambda-error-processor-primer-14ROR2T3JKU66\",\n        \"FunctionName\": \"lambda-error-processor-randomerror-ZWUC391MQAJK\"\n    }\n}"
                    },
                    "The function is responsible for returning a response to the callback URL that indicates success or failure. For    the full response syntax, see Custom resource response      objects.",
                    "Example  – AWS CloudFormation custom resource response",
                    {
                        "code_example": "{\n    \"Status\": \"SUCCESS\",\n    \"PhysicalResourceId\": \"2019/04/18/[$LATEST]b3d1bfc65f19ec610654e4d9b9de47a0\",\n    \"StackId\": \"arn:aws:cloudformation:us-east-1:123456789012:stack/lambda-error-processor/1134083a-2608-1e91-9897-022501a2c456\",\n    \"RequestId\": \"5d478078-13e9-baf0-464a-7ef285ecc786\",\n    \"LogicalResourceId\": \"primerinvoke\"\n}"
                    },
                    "AWS CloudFormation provides a library called cfn-response that handles sending the response. If you define your    function within a template, you can require the library by name. AWS CloudFormation then adds the library to the deployment    package that it creates for the function.",
                    "If your function that a Custom Resource uses has an Elastic Network Interface attached to it,     add the following resources to the VPC policy where region is the Region the function is in without the dashes. For example,     us-east-1 is useast1. This will allow the Custom Resource to respond to the callback URL that sends a signal back to the AWS CloudFormation stack.",
                    "arn:aws:s3:::cloudformation-custom-resource-response-region\",\"arn:aws:s3:::cloudformation-custom-resource-response-region/*\",",
                    "The following example function invokes a second function. If the call succeeds, the function sends a success    response to AWS CloudFormation, and the stack update continues. The template uses the AWS::Serverless::Function resource type provided by    AWS Serverless Application Model.",
                    "Example  – Custom resource function",
                    {
                        "code_example": "Transform: 'AWS::Serverless-2016-10-31'\nResources:\n  primer:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: index.handler\n      Runtime: nodejs16.x\n      InlineCode: |\n        var aws = require('aws-sdk');\n        var response = require('cfn-response');\n        exports.handler = function(event, context) {\n            // For Delete requests, immediately send a SUCCESS response.\n            if (event.RequestType == \"Delete\") {\n                response.send(event, context, \"SUCCESS\");\n                return;\n            }\n            var responseStatus = \"FAILED\";\n            var responseData = {};\n            var functionName = event.ResourceProperties.FunctionName\n            var lambda = new aws.Lambda();\n            lambda.invoke({ FunctionName: functionName }, function(err, invokeResult) {\n                if (err) {\n                    responseData = {Error: \"Invoke call failed\"};\n                    console.log(responseData.Error + \":\\n\", err);\n                }\n                else responseStatus = \"SUCCESS\";\n                response.send(event, context, responseStatus, responseData);\n            });\n        };\n      Description: Invoke a function to create a log stream.\n      MemorySize: 128\n      Timeout: 8\n      Role: !GetAtt role.Arn\n      Tracing: Active"
                    },
                    "If the function that the custom resource invokes isn't defined in a template, you can get the source code for      cfn-response from cfn-response module in the AWS CloudFormation User Guide.",
                    "For more information about custom resources, see Custom      resources in the AWS CloudFormation User Guide."
                ]
            },
            {
                "title": "Amazon DocumentDB",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-documentdb.html",
                "contents": [
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-documentdb-tutorial.html",
                        "sections": [
                            "    In this tutorial, you create a basic Lambda function that consumes events from an Amazon DocumentDB (with MongoDB compatibility) change stream.    To complete this tutorial, you will go through the following stages:  ",
                            "  1.Set up your Amazon DocumentDB cluster, connect to it, and activate change streams on it.",
                            "  2.Create your Lambda function, and configure your Amazon DocumentDB cluster as an event source for your function.",
                            "  3.Test the end-to-end setup by inserting items into your Amazon DocumentDB database.",
                            "Topics",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "Install the AWS Command Line Interface",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          Install the AWS Command Line InterfaceIf you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          "
                                ]
                            },
                            {
                                "sub_header": "Create the AWS Cloud9 environment",
                                "content": [
                                    "      Before creating the Lambda function, you need to create and configure your Amazon DocumentDB cluster. The steps to set up      your cluster in this tutorial is based on the procedure in      Get Started with Amazon DocumentDB.    ",
                                    "Note",
                                    "If you already have an Amazon DocumentDB cluster set up, ensure that you activate change streams and      create the necessary interface VPC endpoints. Then, you can skip directly to the      function creation steps.",
                                    "      First, create an AWS Cloud9 environment. You’ll use this environment throughout this tutorial to connect to and query your Amazon DocumentDB cluster.    ",
                                    "To create an AWS Cloud9 environment",
                                    "  1 : Open the AWS Cloud9 console and choose          Create environment.",
                                    "  2 : Create an environment with the following configuration:Under Details:Name: DocumentDBCloud9EnvironmentEnvironment type: New EC2 instanceUnder New EC2 instance:Instance type: t2.micro (1 GiB RAM + 1 vCPU)Platform: Amazon Linux 2Timeout: 30 minutesUnder Network settings:Connection: AWS Systems Manager (SSM)Expand the VPC settingsdropdown.Amazon Virtual Private Cloud (VPC):Choose your                  default VPC.Subnet: No preferenceKeep all other default settings.",
                                    "  3 : Choose Create. Provisioning your new AWS Cloud9 environment can take several minutes."
                                ]
                            },
                            {
                                "sub_header": "Create the Amazon EC2 security group",
                                "content": [
                                    "      Next, create an Amazon EC2 security group      with rules that allow traffic between your Amazon DocumentDB cluster and your AWS Cloud9 environment.    ",
                                    "To create an EC2 security group",
                                    "  1 : Open the EC2 console. Under          Network and Security, choose Security groups.",
                                    "  2 : Choose Create security group.",
                                    "  3 : Create a security group with the following configuration:Under Basic details:Security group name: DocDBTutorialDescription: Security group for traffic between AWS Cloud9 and Amazon DocumentDB.VPC: Choose your default VPC.Under Inbound rules, choose Add rule.              Create a rule with the following configuration:Type: Custom TCPPort range: 27017Source: CustomIn the search box next to Source, choose the security group for the AWS Cloud9 environment                  you created in the previous step. To see a list of available security groups, enter cloud9 in the search box.                  Choose the security group with the name aws-cloud9-<environment_name>.Keep all other default settings.",
                                    "  4 : Choose Create security group."
                                ]
                            },
                            {
                                "sub_header": "Create the Amazon DocumentDB cluster",
                                "content": [
                                    "      In this step, you’ll create an Amazon DocumentDB cluster using the security group from the previous step.    ",
                                    "To create an Amazon DocumentDB cluster",
                                    "  1 : Open the Amazon DocumentDB console.          Under Clusters, choose Create.",
                                    "  2 : Create a cluster with the following configuration:For Cluster type, choose Instance Based Cluster.Under Configuration:Engine version: 5.0.0Instance class: db.t3.medium (free trial eligible)Number of instances: 1Under Authentication:Enter the Usernameand Passwordneeded                  to connect to your cluster (same credentials as you used to create the secret in the previous step). In                  Confirm password, confirm your password.Toggle on Show advanced settings.Under Network settings:Virtual Private Cloud (VPC): Choose your                  default VPC.Subnet group: defaultVPC security groups: In addition to default (VPC),                  choose the DocDBTutorial (VPC) security group you created in the previous step.Keep all other default settings.",
                                    "  3 : Choose Create cluster. Provisioning your Amazon DocumentDB cluster can take several minutes."
                                ]
                            },
                            {
                                "sub_header": "Create the secret in Secrets Manager",
                                "content": [
                                    "      To access your Amazon DocumentDB cluster manually, you must provide username and password credentials. For Lambda to access your cluster,      you must provide a Secrets Manager secret that contains these same access credentials when setting up your event source mapping.      In this step, you’ll create this secret.    ",
                                    "To create the secret in Secrets Manager",
                                    "  1 : Open the Secrets Manager console and choose          Store a new secret.",
                                    "  2 : For Choose secret type, choose the following options:Under Basic details:Secret type: Credentials for your Amazon DocumentDB databaseUnder Credentials, enter the username and password you’ll use to access your Amazon DocumentDB cluster.Database: Choose your Amazon DocumentDB cluster.Choose Next.",
                                    "  3 : For Configure secret, choose the following options:Secret name– DocumentDBSecretChoose Next.",
                                    "  4 : Choose Next.",
                                    "  5 : Choose Store.",
                                    "  6 : Refresh the console to verify that you successfully stored the DocumentDBSecret secret.",
                                    "      Note down the Secret ARNof your secret. You’ll need it in a later step.    "
                                ]
                            },
                            {
                                "sub_header": "Install the mongo shell",
                                "content": [
                                    "      In this step, you’ll install the mongo shell in your AWS Cloud9 environment. The mongo shell is a command-line utility      that you use to connect to and query your Amazon DocumentDB cluster.    ",
                                    "To install the mongo shell on your AWS Cloud9 environment",
                                    "  1 : Open the AWS Cloud9 console. Next to the          DocumentDBCloud9Environment environment you created earlier, click on the Open          link under the AWS Cloud9 IDE column.",
                                    " 2 : In the terminal window, create the MongoDB repository file with the following command: ",
                                    {
                                        "code_example": "echo -e \"[mongodb-org-5.0] \\nname=MongoDB Repository\\nbaseurl=https://repo.mongodb.org/yum/amazon/2/mongodb-org/5.0/x86_64/\\ngpgcheck=1 \\nenabled=1 \\ngpgkey=https://www.mongodb.org/static/pgp/server-5.0.asc\" | sudo tee /etc/yum.repos.d/mongodb-org-5.0.repo"
                                    },
                                    " 3 : Then, install the mongo shell with the following command: ",
                                    {
                                        "code_example": "sudo yum install -y mongodb-org-shell"
                                    },
                                    " 4 : To encrypt data in transit, download the public key for Amazon DocumentDB.          The following command downloads a file named global-bundle.pem: ",
                                    {
                                        "code_example": "wget https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Connect to the Amazon DocumentDB cluster",
                                "content": [
                                    "      You’re now ready to connect to your Amazon DocumentDB cluster using the mongo shell.    ",
                                    "To connect to your Amazon DocumentDB cluster",
                                    "  1 : Open the Amazon DocumentDB console. Under          Clusters, choose your cluster by choosing its cluster identifier.",
                                    "  2 : In the Connectivity & securitytab, under          Connect to this cluster with the mongo shell,          choose Copy.",
                                    "  3 : In your AWS Cloud9 environment, paste this command into the terminal. Replace <insertYourPassword>          with the correct password.",
                                    "After entering this command, if the command prompt becomes rs0:PRIMARY>, then you’re connected to your Amazon DocumentDB cluster."
                                ]
                            },
                            {
                                "sub_header": "Activate change streams",
                                "content": [
                                    "For this tutorial, you’ll track changes to the products collection of the docdbdemo database      in your Amazon DocumentDB cluster. You do this by activating change streams. First, create the docdbdemo database and test it by inserting a record.",
                                    "To create a new database within your cluster",
                                    "  1 : In your AWS Cloud9 environment, ensure that you’re still connected to your Amazon DocumentDB cluster.",
                                    " 2 : In the terminal window, use the following command to create a new database called docdbdemo: ",
                                    {
                                        "code_example": "use docdbdemo"
                                    },
                                    " 3 : Then, use the following command to insert a record into docdbdemo: You should see output that looks like this:WriteResult({ \"nInserted\" : 1 })",
                                    {
                                        "code_example": "db.products.insert({\"hello\":\"world\"})"
                                    },
                                    " 4 : Use the following command to list all databases: Ensure that your output contains the docdbdemo database:docdbdemo  0.000GB",
                                    {
                                        "code_example": "show dbs"
                                    },
                                    "      Next, activate change streams on the products collection of the docdbdemo database using the following command:    ",
                                    "db.adminCommand({modifyChangeStreams: 1,    database: \"docdbdemo\",    collection: \"products\",     enable: true});",
                                    "      You should see output that looks like this:    ",
                                    "{ \"ok\" : 1, \"operationTime\" : Timestamp(1680126165, 1) }"
                                ]
                            },
                            {
                                "sub_header": "Create interface VPC endpoints",
                                "content": [
                                    "      Next, create interface VPC endpoints      to ensure that Lambda and Secrets Manager (used later to store our cluster access credentials) can connect to your default VPC.     ",
                                    "To create interface VPC endpoints",
                                    "  1 : Open the VPC console. In the left menu, under Virtual private cloud,          choose Endpoints.",
                                    "  2 : Choose Create endpoint. Create an endpoint with the following configuration:For Name tag, enter lambda-default-vpc.For Service category, choose AWS services.For Services, enter lambda in the search box. Choose the service with format com.amazonaws.<region>.lambda.For VPC, choose your default VPC.For Subnets, check the boxes next to each availability zone. Choose the correct subnet ID for each availability zone.For IP address type, select IPv4.For Security groups, choose the default VPC security group (Group name of default), and the security group you created earlier (Group name of DocDBTutorial).Keep all other default settings.Choose Create endpoint.",
                                    "  3 : Again, choose Create endpoint. Create an endpoint with the following configuration:For Name tag, enter secretsmanager-default-vpc.For Service category, choose AWS services.For Services, enter secretsmanager in the search box. Choose the service with format com.amazonaws.<region>.secretsmanager.For VPC, choose your default VPC.For Subnets, check the boxes next to each availability zone. Choose the correct subnet ID for each availability zone.For IP address type, select IPv4.For Security groups, choose the default VPC security group (Group name of default), and the security group you created earlier (Group name of DocDBTutorial).Keep all other default settings.Choose Create endpoint.",
                                    "      This completes the cluster setup portion of this tutorial.    "
                                ]
                            },
                            {
                                "sub_header": "Create the execution role",
                                "content": [
                                    "      In the next set of steps, you’ll create your Lambda function. First, you need to create the execution role that gives      your function permission to access your cluster. You do this by creating an IAM policy first, then attaching this      policy to an IAM role.    ",
                                    "To create IAM policy",
                                    "  1 : Open the Policies page in the IAM console          and choose Create policy.",
                                    " 2 : Choose the JSONtab. In the following policy, replace the Secrets Manager resource ARN          in the final line of the statement with your secret ARN from earlier, and copy the policy into the editor. ",
                                    {
                                        "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"LambdaESMNetworkingAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:CreateNetworkInterface\",\n                \"ec2:DescribeNetworkInterfaces\",\n                \"ec2:DescribeVpcs\",\n                \"ec2:DeleteNetworkInterface\",\n                \"ec2:DescribeSubnets\",\n                \"ec2:DescribeSecurityGroups\",\n                \"kms:Decrypt\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Sid\": \"LambdaDocDBESMAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"rds:DescribeDBClusters\",\n                \"rds:DescribeDBClusterParameters\",\n                \"rds:DescribeDBSubnetGroups\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Sid\": \"LambdaDocDBESMGetSecretValueAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"secretsmanager:GetSecretValue\"\n            ],\n            \"Resource\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:DocumentDBSecret\"\n        }\n    ]\n}"
                                    },
                                    "  3 : Choose Next: Tags, then choose Next: Review.",
                                    "  4 : For Name, enter AWSDocumentDBLambdaPolicy.",
                                    "  5 : Choose Create policy.",
                                    "To create the IAM role",
                                    "  1 : Open the Roles page in the IAM console and choose          Create role.",
                                    "  2 : For Select trusted entity, choose the following options:Trusted entity type– AWS serviceUse case– LambdaChoose Next.",
                                    "  3 : For Add permissions, choose the AWSDocumentDBLambdaPolicy policy you just created,          as well as the AWSLambdaBasicExecutionRole to give your function permissions to write to Amazon CloudWatch Logs.",
                                    "  4 : Choose Next.",
                                    "  5 : For Role name, enter AWSDocumentDBLambdaExecutionRole.",
                                    "  6 : Choose Create role."
                                ]
                            },
                            {
                                "sub_header": "Create the Lambda function",
                                "content": [
                                    "      The following example code receives an Amazon DocumentDB event input and processes the message that it contains.    ",
                                    "  1..NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                                    "  2.AWS SDK for .NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                                    "  3.Go : \npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Event struct {\n\tEvents []Record `json:\"events\"`\n}\n\ntype Record struct {\n\tEvent struct {\n\t\tOperationType string `json:\"operationType\"`\n\t\tNS            struct {\n\t\t\tDB   string `json:\"db\"`\n\t\t\tColl string `json:\"coll\"`\n\t\t} `json:\"ns\"`\n\t\tFullDocument interface{} `json:\"fullDocument\"`\n\t} `json:\"event\"`\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\nfunc handler(ctx context.Context, event Event) (string, error) {\n\tfmt.Println(\"Loading function\")\n\tfor _, record := range event.Events {\n\t\tlogDocumentDBEvent(record)\n\t}\n\n\treturn \"OK\", nil\n}\n\nfunc logDocumentDBEvent(record Record) {\n\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\n\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\n\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\n\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\n\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))\n}\n\n",
                                    "  4.SDK for Go V2 : \npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Event struct {\n\tEvents []Record `json:\"events\"`\n}\n\ntype Record struct {\n\tEvent struct {\n\t\tOperationType string `json:\"operationType\"`\n\t\tNS            struct {\n\t\t\tDB   string `json:\"db\"`\n\t\t\tColl string `json:\"coll\"`\n\t\t} `json:\"ns\"`\n\t\tFullDocument interface{} `json:\"fullDocument\"`\n\t} `json:\"event\"`\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\nfunc handler(ctx context.Context, event Event) (string, error) {\n\tfmt.Println(\"Loading function\")\n\tfor _, record := range event.Events {\n\t\tlogDocumentDBEvent(record)\n\t}\n\n\treturn \"OK\", nil\n}\n\nfunc logDocumentDBEvent(record Record) {\n\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\n\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\n\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\n\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\n\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))\n}\n\n",
                                    "  5.JavaScript : console.log('Loading function');\nexports.handler = async (event, context) => {\n    event.events.forEach(record => {\n        logDocumentDBEvent(record);\n    });\n    return 'OK';\n};\n\nconst logDocumentDBEvent = (record) => {\n    console.log('Operation type: ' + record.event.operationType);\n    console.log('db: ' + record.event.ns.db);\n    console.log('collection: ' + record.event.ns.coll);\n    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));\n};\n\n\n",
                                    "  6.SDK for JavaScript (v3) : console.log('Loading function');\nexports.handler = async (event, context) => {\n    event.events.forEach(record => {\n        logDocumentDBEvent(record);\n    });\n    return 'OK';\n};\n\nconst logDocumentDBEvent = (record) => {\n    console.log('Operation type: ' + record.event.operationType);\n    console.log('db: ' + record.event.ns.db);\n    console.log('collection: ' + record.event.ns.coll);\n    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));\n};\n\n\n",
                                    "  7.PHP : <?php\n\nrequire __DIR__.'/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler;\n\nclass DocumentDBEventHandler implements Handler\n{\n    public function handle($event, Context $context): string\n    {\n\n        $events = $event['events'] ?? [];\n        foreach ($events as $record) {\n            $this->logDocumentDBEvent($record['event']);\n        }\n        return 'OK';\n    }\n\n    private function logDocumentDBEvent($event): void\n    {\n        // Extract information from the event record\n\n        $operationType = $event['operationType'] ?? 'Unknown';\n        $db = $event['ns']['db'] ?? 'Unknown';\n        $collection = $event['ns']['coll'] ?? 'Unknown';\n        $fullDocument = $event['fullDocument'] ?? [];\n\n        // Log the event details\n\n        echo \"Operation type: $operationType\\n\";\n        echo \"Database: $db\\n\";\n        echo \"Collection: $collection\\n\";\n        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";\n    }\n}\nreturn new DocumentDBEventHandler();\n",
                                    "  8.SDK for PHP : <?php\n\nrequire __DIR__.'/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler;\n\nclass DocumentDBEventHandler implements Handler\n{\n    public function handle($event, Context $context): string\n    {\n\n        $events = $event['events'] ?? [];\n        foreach ($events as $record) {\n            $this->logDocumentDBEvent($record['event']);\n        }\n        return 'OK';\n    }\n\n    private function logDocumentDBEvent($event): void\n    {\n        // Extract information from the event record\n\n        $operationType = $event['operationType'] ?? 'Unknown';\n        $db = $event['ns']['db'] ?? 'Unknown';\n        $collection = $event['ns']['coll'] ?? 'Unknown';\n        $fullDocument = $event['fullDocument'] ?? [];\n\n        // Log the event details\n\n        echo \"Operation type: $operationType\\n\";\n        echo \"Database: $db\\n\";\n        echo \"Collection: $collection\\n\";\n        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";\n    }\n}\nreturn new DocumentDBEventHandler();\n",
                                    "  9.Python : import json\n\ndef lambda_handler(event, context):\n    for record in event.get('events', []):\n        log_document_db_event(record)\n    return 'OK'\n\ndef log_document_db_event(record):\n    event_data = record.get('event', {})\n    operation_type = event_data.get('operationType', 'Unknown')\n    db = event_data.get('ns', {}).get('db', 'Unknown')\n    collection = event_data.get('ns', {}).get('coll', 'Unknown')\n    full_document = event_data.get('fullDocument', {})\n\n    print(f\"Operation type: {operation_type}\")\n    print(f\"db: {db}\")\n    print(f\"collection: {collection}\")\n    print(\"Full document:\", json.dumps(full_document, indent=2))\n",
                                    "  10.SDK for Python (Boto3) : import json\n\ndef lambda_handler(event, context):\n    for record in event.get('events', []):\n        log_document_db_event(record)\n    return 'OK'\n\ndef log_document_db_event(record):\n    event_data = record.get('event', {})\n    operation_type = event_data.get('operationType', 'Unknown')\n    db = event_data.get('ns', {}).get('db', 'Unknown')\n    collection = event_data.get('ns', {}).get('coll', 'Unknown')\n    full_document = event_data.get('fullDocument', {})\n\n    print(f\"Operation type: {operation_type}\")\n    print(f\"db: {db}\")\n    print(f\"collection: {collection}\")\n    print(\"Full document:\", json.dumps(full_document, indent=2))\n",
                                    "  11.Ruby : require 'json'\n\ndef lambda_handler(event:, context:)\n  event['events'].each do |record|\n    log_document_db_event(record)\n  end\n  'OK'\nend\n\ndef log_document_db_event(record)\n  event_data = record['event'] || {}\n  operation_type = event_data['operationType'] || 'Unknown'\n  db = event_data.dig('ns', 'db') || 'Unknown'\n  collection = event_data.dig('ns', 'coll') || 'Unknown'\n  full_document = event_data['fullDocument'] || {}\n\n  puts \"Operation type: #{operation_type}\"\n  puts \"db: #{db}\"\n  puts \"collection: #{collection}\"\n  puts \"Full document: #{JSON.pretty_generate(full_document)}\"\nend\n",
                                    "  12.SDK for Ruby : require 'json'\n\ndef lambda_handler(event:, context:)\n  event['events'].each do |record|\n    log_document_db_event(record)\n  end\n  'OK'\nend\n\ndef log_document_db_event(record)\n  event_data = record['event'] || {}\n  operation_type = event_data['operationType'] || 'Unknown'\n  db = event_data.dig('ns', 'db') || 'Unknown'\n  collection = event_data.dig('ns', 'coll') || 'Unknown'\n  full_document = event_data['fullDocument'] || {}\n\n  puts \"Operation type: #{operation_type}\"\n  puts \"db: #{db}\"\n  puts \"collection: #{collection}\"\n  puts \"Full document: #{JSON.pretty_generate(full_document)}\"\nend\n",
                                    "  13.Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {\n    \n    tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);\n    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);\n  \n    let records = &event.payload.events;\n   \n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_document_db_event(record);\n    }\n\n    tracing::info!(\"Document db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{\n    tracing::info!(\"Change Event: {:?}\", record.event);\n    \n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                                    "  14.SDK for Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {\n    \n    tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);\n    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);\n  \n    let records = &event.payload.events;\n   \n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_document_db_event(record);\n    }\n\n    tracing::info!(\"Document db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{\n    tracing::info!(\"Change Event: {:?}\", record.event);\n    \n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using .NET.using Amazon.Lambda.Core;using System.Text.Json;using System;using System.Collections.Generic;using System.Text.Json.Serialization;//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaDocDb;public class Function{         /// <summary>    /// Lambda function entry point to process Amazon DocumentDB events.    /// </summary>    /// <param name=\"event\">The Amazon DocumentDB event.</param>    /// <param name=\"context\">The Lambda context object.</param>    /// <returns>A string to indicate successful processing.</returns>    public string FunctionHandler(Event evnt, ILambdaContext context)    {                foreach (var record in evnt.Events)        {            ProcessDocumentDBEvent(record, context);        }        return \"OK\";    }     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)    {                var eventData = record.Event;        var operationType = eventData.OperationType;        var databaseName = eventData.Ns.Db;        var collectionName = eventData.Ns.Coll;        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });        context.Logger.LogLine($\"Operation type: {operationType}\");        context.Logger.LogLine($\"Database: {databaseName}\");        context.Logger.LogLine($\"Collection: {collectionName}\");        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");    }    public class Event    {        [JsonPropertyName(\"eventSourceArn\")]        public string EventSourceArn { get; set; }        [JsonPropertyName(\"events\")]        public List<DocumentDBEventRecord> Events { get; set; }        [JsonPropertyName(\"eventSource\")]        public string EventSource { get; set; }    }    public class DocumentDBEventRecord    {        [JsonPropertyName(\"event\")]        public EventData Event { get; set; }    }    public class EventData    {        [JsonPropertyName(\"_id\")]        public IdData Id { get; set; }        [JsonPropertyName(\"clusterTime\")]        public ClusterTime ClusterTime { get; set; }        [JsonPropertyName(\"documentKey\")]        public DocumentKey DocumentKey { get; set; }        [JsonPropertyName(\"fullDocument\")]        public Dictionary<string, object> FullDocument { get; set; }        [JsonPropertyName(\"ns\")]        public Namespace Ns { get; set; }        [JsonPropertyName(\"operationType\")]        public string OperationType { get; set; }    }    public class IdData    {        [JsonPropertyName(\"_data\")]        public string Data { get; set; }    }    public class ClusterTime    {        [JsonPropertyName(\"$timestamp\")]        public Timestamp Timestamp { get; set; }    }    public class Timestamp    {        [JsonPropertyName(\"t\")]        public long T { get; set; }        [JsonPropertyName(\"i\")]        public int I { get; set; }    }    public class DocumentKey    {        [JsonPropertyName(\"_id\")]        public Id Id { get; set; }    }    public class Id    {        [JsonPropertyName(\"$oid\")]        public string Oid { get; set; }    }    public class Namespace    {        [JsonPropertyName(\"db\")]        public string Db { get; set; }        [JsonPropertyName(\"coll\")]        public string Coll { get; set; }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Go.package mainimport (\t\"context\"\t\"encoding/json\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/lambda\")type Event struct {\tEvents []Record `json:\"events\"`}type Record struct {\tEvent struct {\t\tOperationType string `json:\"operationType\"`\t\tNS            struct {\t\t\tDB   string `json:\"db\"`\t\t\tColl string `json:\"coll\"`\t\t} `json:\"ns\"`\t\tFullDocument interface{} `json:\"fullDocument\"`\t} `json:\"event\"`}func main() {\tlambda.Start(handler)}func handler(ctx context.Context, event Event) (string, error) {\tfmt.Println(\"Loading function\")\tfor _, record := range event.Events {\t\tlogDocumentDBEvent(record)\t}\treturn \"OK\", nil}func logDocumentDBEvent(record Record) {\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using JavaScript.console.log('Loading function');exports.handler = async (event, context) => {    event.events.forEach(record => {        logDocumentDBEvent(record);    });    return 'OK';};const logDocumentDBEvent = (record) => {    console.log('Operation type: ' + record.event.operationType);    console.log('db: ' + record.event.ns.db);    console.log('collection: ' + record.event.ns.coll);    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));};Consuming a Amazon DocumentDB event with Lambda using TypeScriptimport { DocumentDBEventRecord, DocumentDBEventSubscriptionContext } from 'aws-lambda';console.log('Loading function');export const handler = async (  event: DocumentDBEventSubscriptionContext,  context: any): Promise<string> => {  event.events.forEach((record: DocumentDBEventRecord) => {    logDocumentDBEvent(record);  });  return 'OK';};const logDocumentDBEvent = (record: DocumentDBEventRecord): void => {  console.log('Operation type: ' + record.event.operationType);  console.log('db: ' + record.event.ns.db);  console.log('collection: ' + record.event.ns.coll);  console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using PHP.<?phprequire __DIR__.'/vendor/autoload.php';use Bref\\Context\\Context;use Bref\\Event\\Handler;class DocumentDBEventHandler implements Handler{    public function handle($event, Context $context): string    {        $events = $event['events'] ?? [];        foreach ($events as $record) {            $this->logDocumentDBEvent($record['event']);        }        return 'OK';    }    private function logDocumentDBEvent($event): void    {        // Extract information from the event record        $operationType = $event['operationType'] ?? 'Unknown';        $db = $event['ns']['db'] ?? 'Unknown';        $collection = $event['ns']['coll'] ?? 'Unknown';        $fullDocument = $event['fullDocument'] ?? [];        // Log the event details        echo \"Operation type: $operationType\\n\";        echo \"Database: $db\\n\";        echo \"Collection: $collection\\n\";        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";    }}return new DocumentDBEventHandler();PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Python.import jsondef lambda_handler(event, context):    for record in event.get('events', []):        log_document_db_event(record)    return 'OK'def log_document_db_event(record):    event_data = record.get('event', {})    operation_type = event_data.get('operationType', 'Unknown')    db = event_data.get('ns', {}).get('db', 'Unknown')    collection = event_data.get('ns', {}).get('coll', 'Unknown')    full_document = event_data.get('fullDocument', {})    print(f\"Operation type: {operation_type}\")    print(f\"db: {db}\")    print(f\"collection: {collection}\")    print(\"Full document:\", json.dumps(full_document, indent=2))RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Ruby.require 'json'def lambda_handler(event:, context:)  event['events'].each do |record|    log_document_db_event(record)  end  'OK'enddef log_document_db_event(record)  event_data = record['event'] || {}  operation_type = event_data['operationType'] || 'Unknown'  db = event_data.dig('ns', 'db') || 'Unknown'  collection = event_data.dig('ns', 'coll') || 'Unknown'  full_document = event_data['fullDocument'] || {}  puts \"Operation type: #{operation_type}\"  puts \"db: #{db}\"  puts \"collection: #{collection}\"  puts \"Full document: #{JSON.pretty_generate(full_document)}\"endRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Rust.use lambda_runtime::{service_fn, tracing, Error, LambdaEvent};use aws_lambda_events::{    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},   };// Built with the following dependencies://lambda_runtime = \"0.11.1\"//serde_json = \"1.0\"//tokio = { version = \"1\", features = [\"macros\"] }//tracing = { version = \"0.1\", features = [\"log\"] }//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }//aws_lambda_events = \"0.15.0\"async fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {        tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);      let records = &event.payload.events;       if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    for record in records{        log_document_db_event(record);    }    tracing::info!(\"Document db records processed\");    // Prepare the response    Ok(())}fn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{    tracing::info!(\"Change Event: {:?}\", record.event);        Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()    .with_max_level(tracing::Level::INFO)    .with_target(false)    .without_time()    .init();    let func = service_fn(function_handler);    lambda_runtime::run(func).await?;    Ok(())    }",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using .NET.using Amazon.Lambda.Core;using System.Text.Json;using System;using System.Collections.Generic;using System.Text.Json.Serialization;//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaDocDb;public class Function{         /// <summary>    /// Lambda function entry point to process Amazon DocumentDB events.    /// </summary>    /// <param name=\"event\">The Amazon DocumentDB event.</param>    /// <param name=\"context\">The Lambda context object.</param>    /// <returns>A string to indicate successful processing.</returns>    public string FunctionHandler(Event evnt, ILambdaContext context)    {                foreach (var record in evnt.Events)        {            ProcessDocumentDBEvent(record, context);        }        return \"OK\";    }     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)    {                var eventData = record.Event;        var operationType = eventData.OperationType;        var databaseName = eventData.Ns.Db;        var collectionName = eventData.Ns.Coll;        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });        context.Logger.LogLine($\"Operation type: {operationType}\");        context.Logger.LogLine($\"Database: {databaseName}\");        context.Logger.LogLine($\"Collection: {collectionName}\");        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");    }    public class Event    {        [JsonPropertyName(\"eventSourceArn\")]        public string EventSourceArn { get; set; }        [JsonPropertyName(\"events\")]        public List<DocumentDBEventRecord> Events { get; set; }        [JsonPropertyName(\"eventSource\")]        public string EventSource { get; set; }    }    public class DocumentDBEventRecord    {        [JsonPropertyName(\"event\")]        public EventData Event { get; set; }    }    public class EventData    {        [JsonPropertyName(\"_id\")]        public IdData Id { get; set; }        [JsonPropertyName(\"clusterTime\")]        public ClusterTime ClusterTime { get; set; }        [JsonPropertyName(\"documentKey\")]        public DocumentKey DocumentKey { get; set; }        [JsonPropertyName(\"fullDocument\")]        public Dictionary<string, object> FullDocument { get; set; }        [JsonPropertyName(\"ns\")]        public Namespace Ns { get; set; }        [JsonPropertyName(\"operationType\")]        public string OperationType { get; set; }    }    public class IdData    {        [JsonPropertyName(\"_data\")]        public string Data { get; set; }    }    public class ClusterTime    {        [JsonPropertyName(\"$timestamp\")]        public Timestamp Timestamp { get; set; }    }    public class Timestamp    {        [JsonPropertyName(\"t\")]        public long T { get; set; }        [JsonPropertyName(\"i\")]        public int I { get; set; }    }    public class DocumentKey    {        [JsonPropertyName(\"_id\")]        public Id Id { get; set; }    }    public class Id    {        [JsonPropertyName(\"$oid\")]        public string Oid { get; set; }    }    public class Namespace    {        [JsonPropertyName(\"db\")]        public string Db { get; set; }        [JsonPropertyName(\"coll\")]        public string Coll { get; set; }    }}",
                                    "To create the Lambda function",
                                    "  1 : Copy the sample code into a file named index.js.",
                                    " 2 : Create a deployment package with the following command. ",
                                    {
                                        "code_example": "zip function.zip index.js"
                                    },
                                    " 3 : Use the following CLI command to create the function. Replace us-east-1 with the AWS Region,          and 123456789012 with your account ID. ",
                                    {
                                        "code_example": "aws lambda create-function \\\n  --function-name ProcessDocumentDBRecords \\\n  --zip-file fileb://function.zip --handler index.handler --runtime nodejs22.x \\\n  --region us-east-1 \\\n  --role arn:aws:iam::123456789012:role/AWSDocumentDBLambdaExecutionRole"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create the Lambda event source mapping",
                                "content": [
                                    "      Create the event source mapping that associates your Amazon DocumentDB change stream with your Lambda function.      After you create this event source mapping, AWS Lambda immediately starts polling the stream.    ",
                                    "To create the event source mapping",
                                    "  1 : Open the Functions page in the Lambda console.",
                                    "  2 : Choose the ProcessDocumentDBRecords function you created earlier.",
                                    "  3 : Choose the Configurationtab, then choose Triggersin the left menu.",
                                    "  4 : Choose Add trigger.",
                                    "  5 : Under Trigger configuration, for the source, select Amazon DocumentDB.",
                                    "  6 : Create the event source mapping with the following configuration:Amazon DocumentDB cluster– Choose the cluster you created earlier.Database name– docdbdemoCollection name– productsBatch size– 1Starting position– LatestAuthentication– BASIC_AUTHSecrets Manager key– Choose the DocumentDBSecret you just created.Batch window– 1Full document configuration– UpdateLookup",
                                    "  7 : Choose Add. Creating your event source mapping can take a few minutes."
                                ]
                            },
                            {
                                "sub_header": "Test your function - manual invoke",
                                "content": [
                                    "      To test that you created your function and event source mapping correctly, invoke your function using the invoke command.      To do this, first copy the following event JSON into a file called input.txt:    ",
                                    "{  \"eventSourceArn\": \"arn:aws:rds:us-east-1:123456789012:cluster:canaryclusterb2a659a2-qo5tcmqkcl03\",  \"events\": [    {      \"event\": {        \"_id\": {          \"_data\": \"0163eeb6e7000000090100000009000041e1\"        },        \"clusterTime\": {          \"$timestamp\": {            \"t\": 1676588775,            \"i\": 9          }        },        \"documentKey\": {          \"_id\": {            \"$oid\": \"63eeb6e7d418cd98afb1c1d7\"          }        },        \"fullDocument\": {          \"_id\": {            \"$oid\": \"63eeb6e7d418cd98afb1c1d7\"          },          \"anyField\": \"sampleValue\"        },        \"ns\": {          \"db\": \"docdbdemo\",          \"coll\": \"products\"        },        \"operationType\": \"insert\"      }    }  ],  \"eventSource\": \"aws:docdb\"}",
                                    "      Then, use the following command to invoke your function with this event:    ",
                                    "aws lambda invoke \\  --function-name ProcessDocumentDBRecords \\  --cli-binary-format raw-in-base64-out \\  --region us-east-1 \\  --payload file://input.txt out.txt",
                                    "      You should see a response that looks like the following:    ",
                                    "{   \"StatusCode\": 200,   \"ExecutedVersion\": \"$LATEST\"}",
                                    "      You can verify that your function successfully processed the event by checking CloudWatch Logs.    ",
                                    "To verify manual invocation via CloudWatch Logs",
                                    "  1 : Open the Functions page in the Lambda console.",
                                    "  2 : Choose the Monitor tab, then choose View CloudWatch logs.          This takes you to the specific log group associated with your function in the CloudWatch console.",
                                    "  3 : Choose the most recent log stream. Within the log messages, you should see the event JSON."
                                ]
                            },
                            {
                                "sub_header": "Test your function - insert a record",
                                "content": [
                                    "      Test your end-to-end setup by interacting directly with your Amazon DocumentDB database. In the next set of steps,      you’ll insert a record, update it, then delete it.    ",
                                    "To insert a record",
                                    "  1 : Reconnect to your Amazon DocumentDB cluster in your AWS Cloud9 environment.",
                                    " 2 : Use this command to ensure that you’re currently using the docdbdemo database: ",
                                    {
                                        "code_example": "use docdbdemo"
                                    },
                                    " 3 : Insert a record into the products collection of the docdbdemo database: ",
                                    {
                                        "code_example": "db.products.insert({\"name\":\"Pencil\", \"price\": 1.00})"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Test your function - update a record",
                                "content": [
                                    "      Next, update the record you just inserted with the following command:    ",
                                    "db.products.update(    { \"name\": \"Pencil\" },    { $set: { \"price\": 0.50 }})",
                                    "      Verify that your function successfully processed this event by checking CloudWatch Logs.    "
                                ]
                            },
                            {
                                "sub_header": "Test your function - delete a record",
                                "content": [
                                    "Finally, delete the record you just updated with the following command:",
                                    "db.products.remove( { \"name\": \"Pencil\" } )",
                                    "Verify that your function successfully processed this event by checking CloudWatch Logs."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "      You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS      resources that you're no longer using, you prevent unnecessary charges to your AWS account.    ",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the VPC endpoints",
                                    "  1 : Open the VPC console. In the left menu, under Virtual private cloud,      choose Endpoints.",
                                    "  2 : Select the endpoints you created.",
                                    "  3 : Choose Actions, Delete VPC endpoints.",
                                    "  4 : Enter delete in the text input field.",
                                    "  5 : Choose Delete.",
                                    "To delete the Amazon DocumentDB cluster",
                                    "  1 : Open the Amazon DocumentDB console.",
                                    "  2 : Choose the Amazon DocumentDB cluster you created for this tutorial, and disable deletion protection.",
                                    "  3 : In the main Clusters page, choose your Amazon DocumentDB cluster again.",
                                    "  4 : Choose Actions, Delete.",
                                    "  5 : For Create final cluster snapshot, select No.",
                                    "  6 : Enter delete in the text input field.",
                                    "  7 : Choose Delete.",
                                    "To delete the secret in Secrets Manager",
                                    "  1 : Open the Secrets Manager console.",
                                    "  2 : Choose the secret you created for this tutorial.",
                                    "  3 : Choose Actions, Delete secret.",
                                    "  4 : Choose Schedule deletion.",
                                    "To delete the Amazon EC2 security group",
                                    "  1 : Open the EC2 console. Under      Network and Security, choose Security groups.",
                                    "  2 : Select the security group you created for this tutorial.",
                                    "  3 : Choose Actions, Delete security groups.",
                                    "  4 : Choose Delete.",
                                    "To delete the AWS Cloud9 environment",
                                    "  1 : Open the AWS Cloud9 console.",
                                    "  2 : Select the environment you created for this tutorial.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter delete in the text input field.",
                                    "  5 : Choose Delete."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "You can use a Lambda function to process events in an Amazon DocumentDB (with MongoDB compatibility) change stream by configuring an    Amazon DocumentDB cluster as an event source. Then, you can automate event-driven workloads by invoking your Lambda function    each time that data changes with your Amazon DocumentDB cluster.",
                    "Note",
                    "Lambda supports version 4.0 and 5.0 of Amazon DocumentDB only. Lambda doesn't support version 3.6.",
                    "Also, for event source mappings, Lambda supports instance-based clusters and      regional clusters only. Lambda doesn't support              elastic clusters or              global clusters. This limitation doesn't apply when using Lambda as a client to connect to Amazon DocumentDB. Lambda can connect to     all cluster types to perform CRUD operations.",
                    "Lambda processes events from Amazon DocumentDB change streams sequentially in the order in which they arrive.    Because of this, your function can handle only one concurrent invocation from Amazon DocumentDB at a time.    To monitor your function, you can track its concurrency metrics.",
                    "Warning",
                    "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                    "Topics",
                    {
                        "sub_header": "Example Amazon DocumentDB event",
                        "content": [
                            "{    \"eventSourceArn\": \"arn:aws:rds:us-east-1:123456789012:cluster:canaryclusterb2a659a2-qo5tcmqkcl03\",    \"events\": [        {            \"event\": {                \"_id\": {                    \"_data\": \"0163eeb6e7000000090100000009000041e1\"                },                \"clusterTime\": {                    \"$timestamp\": {                        \"t\": 1676588775,                        \"i\": 9                    }                },                \"documentKey\": {                    \"_id\": {                        \"$oid\": \"63eeb6e7d418cd98afb1c1d7\"                    }                },                \"fullDocument\": {                    \"_id\": {                        \"$oid\": \"63eeb6e7d418cd98afb1c1d7\"                    },                    \"anyField\": \"sampleValue\"                },                \"ns\": {                    \"db\": \"test_database\",                    \"coll\": \"test_collection\"                },                \"operationType\": \"insert\"            }        }    ],    \"eventSource\": \"aws:docdb\"}",
                            "For more information about the events in this example and their shapes, see Change Events on the MongoDB      Documentation website."
                        ]
                    },
                    {
                        "sub_header": "Prerequisites and permissions",
                        "content": [
                            "Before you can use Amazon DocumentDB as an event source for your Lambda function, note the following prerequisites. You      must:",
                            "  1.Have an existing Amazon DocumentDB cluster in the same AWS account and AWS Region as your\n            function. :  If you don't have an existing cluster, you can create one by following the steps in            Get Started with              Amazon DocumentDB in the Amazon DocumentDB Developer Guide. Alternatively, the first set of steps in            Tutorial: Using AWS Lambda with Amazon DocumentDB Streams guide you            through creating an Amazon DocumentDB cluster with all the necessary prerequisites.",
                            "  2.Allow Lambda to access the Amazon Virtual Private Cloud (Amazon VPC) resources associated with your Amazon DocumentDB\n            cluster. :  For more information, see Configure network security.",
                            "  3.Enable TLS on your Amazon DocumentDB cluster. :  This is the default setting. If you          disable TLS, then Lambda cannot communicate with your cluster.",
                            "  4.Activate change streams on your Amazon DocumentDB cluster. :  For more information,          see Using Change            Streams with Amazon DocumentDB in the Amazon DocumentDB Developer Guide.",
                            "  5.Provide Lambda with credentials to access your Amazon DocumentDB cluster. :  When          setting up the event source, provide the AWS Secrets Manager key that contains the authentication          details (username and password) required to access your cluster. To provide this key during setup, do either          of the following:If you're using the Lambda console for setup, then provide the key in the Secrets manager                key field.If you're using the AWS Command Line Interface (AWS CLI) for setup, then provide this key in the                source-access-configurations option. You can include this option with either the create-event-source-mapping command or the update-event-source-mapping command. For example:aws lambda create-event-source-mapping \\    ...    --source-access-configurations  '[{\"Type\":\"BASIC_AUTH\",\"URI\":\"arn:aws:secretsmanager:us-west-2:123456789012:secret:DocDBSecret-AbC4E6\"}]' \\    ...",
                            {
                                "code_example": "aws lambda create-event-source-mapping \\\n    ...\n    --source-access-configurations  '[{\"Type\":\"BASIC_AUTH\",\"URI\":\"arn:aws:secretsmanager:us-west-2:123456789012:secret:DocDBSecret-AbC4E6\"}]' \\\n    ..."
                            },
                            "  6.Secrets manager\n                key : If you're using the Lambda console for setup, then provide the key in the  field.",
                            "  7.If you're using the AWS Command Line Interface (AWS CLI) for setup, then provide this key in the                source-access-configurations option. You can include this option with either the create-event-source-mapping command or the update-event-source-mapping command. For example:aws lambda create-event-source-mapping \\    ...    --source-access-configurations  '[{\"Type\":\"BASIC_AUTH\",\"URI\":\"arn:aws:secretsmanager:us-west-2:123456789012:secret:DocDBSecret-AbC4E6\"}]' \\    ...",
                            {
                                "code_example": "aws lambda create-event-source-mapping \\\n    ...\n    --source-access-configurations  '[{\"Type\":\"BASIC_AUTH\",\"URI\":\"arn:aws:secretsmanager:us-west-2:123456789012:secret:DocDBSecret-AbC4E6\"}]' \\\n    ..."
                            },
                            "  8.Grant Lambda permissions to manage resources related to your Amazon DocumentDB\n            stream. :  Manually add the following permissions to your function's execution role:rds:DescribeDBClustersrds:DescribeDBClusterParametersrds:DescribeDBSubnetGroupsec2:CreateNetworkInterfaceec2:DescribeNetworkInterfacesec2:DescribeVpcsec2:DeleteNetworkInterfaceec2:DescribeSubnetsec2:DescribeSecurityGroupskms:Decryptsecretsmanager:GetSecretValue",
                            "  9.rds:DescribeDBClusters",
                            "  10.rds:DescribeDBClusterParameters",
                            "  11.rds:DescribeDBSubnetGroups",
                            "  12.ec2:CreateNetworkInterface",
                            "  13.ec2:DescribeNetworkInterfaces",
                            "  14.ec2:DescribeVpcs",
                            "  15.ec2:DeleteNetworkInterface",
                            "  16.ec2:DescribeSubnets",
                            "  17.ec2:DescribeSecurityGroups",
                            "  18.kms:Decrypt",
                            "  19.secretsmanager:GetSecretValue",
                            "  20.Keep the size of Amazon DocumentDB change stream events that you send to Lambda under 6\n            MB. :  Lambda supports payload sizes of up to 6 MB. If your change stream tries to send Lambda an          event larger than 6 MB, then Lambda drops the message and emits the OversizedRecordCount metric.          Lambda emits all metrics on a best-effort basis.",
                            "Note",
                            "While Lambda functions typically have a maximum timeout limit of 15 minutes,      event source mappings for Amazon MSK, self-managed Apache Kafka, Amazon DocumentDB, and Amazon MQ for ActiveMQ and RabbitMQ only support functions with      maximum timeout limits of 14 minutes. This constraint ensures that the event source mapping can properly      handle function errors and retries."
                        ]
                    },
                    {
                        "sub_header": "Configure network security",
                        "content": [
                            "To give Lambda full access to Amazon DocumentDB through your event source mapping, either your cluster must use a public endpoint             (public IP address), or you must provide access to the Amazon VPC you created the cluster in.",
                            "When you use Amazon DocumentDB with Lambda, create AWS PrivateLink VPC endpoints that provide your function            access to the resources in your Amazon VPC.",
                            "Note",
                            "AWS PrivateLink VPC endpoints are required for functions with event source mappings that use the default (on-demand) mode                for event pollers. If your event source mapping uses                 provisioned mode, you don't need to configure AWS PrivateLink VPC endpoints.",
                            "Create an endpoint to provide access to the following resources:",
                            "  1.                    Lambda — Create an endpoint for the Lambda service principal.                ",
                            "  2.                    AWS STS — Create an endpoint for the AWS STS in order for a service principal to assume a role on your behalf.                ",
                            "  3.                    Secrets Manager — If your cluster uses Secrets Manager to store credentials, create an endpoint for Secrets Manager.                ",
                            "Alternatively, configure a NAT gateway on each public subnet in the Amazon VPC. For more information,             see Enable internet access for VPC-connected Lambda functions.",
                            "When you create an event source mapping for Amazon DocumentDB, Lambda checks whether Elastic Network Interfaces (ENIs)             are already present for the subnets and security groups configured for your Amazon VPC. If Lambda finds existing ENIs, it             attempts to re-use them. Otherwise, Lambda creates new ENIs to connect to the event source and invoke your function.",
                            "Note",
                            "Lambda functions always run inside VPCs owned by the Lambda service. Your function's VPC configuration                does not affect the event source mapping. Only the networking configuration of the event source's determines                 how Lambda connects to your event source.",
                            "Configure the security groups for the Amazon VPC containing your cluster. By default,            Amazon DocumentDB uses the following ports: 27017.",
                            "  1.Inbound rules – Allow all traffic on the default cluster port for the security group associated with your event source.",
                            "  2.Outbound rules – Allow all traffic on port 443 for all destinations. Allow all traffic on the default cluster port                    for the security group associated with your event source.",
                            "  3.Amazon VPC endpoint inbound rules — If you are using an Amazon VPC endpoint, the security group associated with your Amazon VPC endpoint must allow inbound traffic                    on port 443 from the cluster security group.",
                            "If your cluster uses authentication, you can also restrict the endpoint policy for the Secrets Manager endpoint.             To call the Secrets Manager API, Lambda uses your function role, not the Lambda service principal.",
                            "Example VPC endpoint policy — Secrets Manager endpoint",
                            {
                                "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"secretsmanager:GetSecretValue\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"AWS\": [\n                      \"arn:aws::iam::123456789012:role/my-role\"\n                  ]\n              },\n              \"Resource\": \"arn:aws::secretsmanager:us-west-2:123456789012:secret:my-secret\"\n          }\n      ]\n  }"
                            },
                            "When you use Amazon VPC endpoints, AWS routes your API calls to invoke your function using the endpoint's Elastic Network Interface (ENI).            The Lambda service principal needs to call lambda:InvokeFunction on any roles and functions that use those ENIs.",
                            "By default, Amazon VPC endpoints have open IAM policies that allow broad access to resources. Best practice is to restrict these            policies to perform the needed actions using that endpoint. To ensure that your event source mapping is able to invoke your Lambda            function, the VPC endpoint policy must allow the Lambda service principal to call sts:AssumeRole and            lambda:InvokeFunction. Restricting your VPC endpoint policies to allow only API calls originating within your organization            prevents the event source mapping from functioning properly, so \"Resource\": \"*\" is required in these policies.",
                            "The following example VPC endpoint policies show how to grant the required access to the Lambda service principal for the            AWS STS and Lambda endpoints.",
                            "Example VPC Endpoint policy — AWS STS endpoint",
                            {
                                "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"sts:AssumeRole\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n    }"
                            },
                            "Example VPC Endpoint policy — Lambda endpoint",
                            {
                                "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"lambda:InvokeFunction\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n  }"
                            }
                        ]
                    },
                    {
                        "sub_header": "Creating an Amazon DocumentDB event source mapping (console)",
                        "content": [
                            "For a Lambda function to read from an Amazon DocumentDB cluster's change stream, create an event source mapping. This section describes how to do this from      the Lambda console. For AWS SDK and AWS CLI instructions, see Creating an Amazon DocumentDB event source mapping (SDK or CLI).",
                            "To create an Amazon DocumentDB event source mapping (console)",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Choose the name of a function.",
                            "  3 : Under Function overview, choose Add          trigger.",
                            "  4 : Under Trigger configuration, in the dropdown list, choose          DocumentDB.",
                            "  5 : Configure the required options, and then choose Add.",
                            "Lambda supports the following options for Amazon DocumentDB event sources:",
                            "  1.DocumentDB cluster :  – Select an Amazon .",
                            "  2.Activate trigger :  – Choose whether you want to activate the trigger          immediately. If you select this check box, then your function immediately starts receiving traffic from the          specified Amazon DocumentDB change stream upon creation of the event source mapping. We recommend that you clear the          check box to create the event source mapping in a deactivated state for testing. After creation, you can          activate the event source mapping at any time.",
                            "  3.Database name :  – Enter the name of a database within the cluster to          consume.",
                            "  4.Collection name : (Optional)  – Enter the name of a collection within the          database to consume. If you don't specify a collection, then Lambda listens to all events from each collection          in the database.",
                            "  5.Batch size :  – Set the maximum number of messages to retrieve in a single batch,          up to 10,000. The default batch size is 100.",
                            "  6.Starting position :  – Choose the position in the stream to start reading records          from.Latest – Process only new records that are added to the stream. Your              function starts processing records only after Lambda finishes creating your event source. This means that              some records may be dropped until your event source is created successfully.Trim horizon – Process all records in the stream. Lambda uses the log              retention duration of your cluster to determine where to start reading events from. Specifically, Lambda              starts reading from current_time - log_retention_duration. Your change stream must already be              active before this timestamp for Lambda to read all events properly.At timestamp – Process records starting from a specific time. Your change              stream must already be active before the specified timestamp for Lambda to read all events properly.",
                            "  7.Latest :  – Process only new records that are added to the stream. Your              function starts processing records only after Lambda finishes creating your event source. This means that              some records may be dropped until your event source is created successfully.",
                            "  8.Trim horizon :  – Process all records in the stream. Lambda uses the log              retention duration of your cluster to determine where to start reading events from. Specifically, Lambda              starts reading from current_time - log_retention_duration. Your change stream must already be              active before this timestamp for Lambda to read all events properly.",
                            "  9.At timestamp :  – Process records starting from a specific time. Your change              stream must already be active before the specified timestamp for Lambda to read all events properly.",
                            "  10.Authentication :  – Choose the authentication method for accessing the brokers in          your cluster.BASIC_AUTH – With basic authentication, you must provide the Secrets Manager key              that contains the credentials to access your cluster.",
                            "  11.BASIC_AUTH :  – With basic authentication, you must provide the Secrets Manager key              that contains the credentials to access your cluster.",
                            "  12.Secrets Manager key :  – Choose the  that contains the authentication details          (username and password) required to access your Amazon DocumentDB cluster.",
                            "  13.Batch window : (Optional)  – Set the maximum amount of time in seconds to gather          records before invoking your function, up to 300.",
                            "  14.Full document configuration : (Optional)  – For document update operations,          choose what you want to send to the stream. The default value is Default, which means that for          each change stream event, Amazon DocumentDB sends only a delta describing the changes made. For more information about          this field, see FullDocument in the MongoDB Javadoc API documentation.Default – Lambda sends only a partial document describing the changes              made.UpdateLookup – Lambda sends a delta describing the changes, along with a              copy of the entire document.",
                            "  15.Default :  – Lambda sends only a partial document describing the changes              made.",
                            "  16.UpdateLookup :  – Lambda sends a delta describing the changes, along with a              copy of the entire document."
                        ]
                    },
                    {
                        "sub_header": "Creating an Amazon DocumentDB event source mapping (SDK or CLI)",
                        "content": [
                            "To create or manage an Amazon DocumentDB event source mapping with an AWS SDK, you can use the following API      operations:",
                            "  1.CreateEventSourceMapping",
                            "  2.ListEventSourceMappings",
                            "  3.GetEventSourceMapping",
                            "  4.UpdateEventSourceMapping",
                            "  5.DeleteEventSourceMapping",
                            "To create the event source mapping with the AWS CLI, use the create-event-source-mapping command. The following example uses this command to map a      function named my-function to an Amazon DocumentDB change stream. The event source is specified by an Amazon      Resource Name (ARN), with a batch size of 500, starting from the timestamp in Unix time. The command also      specifies the Secrets Manager key that Lambda uses to connect to Amazon DocumentDB. Additionally, it includes        document-db-event-source-config parameters that specify the database and the collection to read      from.",
                            "aws lambda create-event-source-mapping --function-name my-function \\    --event-source-arn arn:aws:rds:us-west-2:123456789012:cluster:privatecluster7de2-epzcyvu4pjoy    --batch-size 500 \\    --starting-position AT_TIMESTAMP \\    --starting-position-timestamp 1541139109 \\    --source-access-configurations '[{\"Type\":\"BASIC_AUTH\",\"URI\":\"arn:aws:secretsmanager:us-east-1:123456789012:secret:DocDBSecret-BAtjxi\"}]' \\    --document-db-event-source-config '{\"DatabaseName\":\"test_database\", \"CollectionName\": \"test_collection\"}' \\",
                            "You should see output that looks like this:",
                            "{    \"UUID\": \"2b733gdc-8ac3-cdf5-af3a-1827b3b11284\",    \"BatchSize\": 500,    \"DocumentDBEventSourceConfig\": {        \"CollectionName\": \"test_collection\",        \"DatabaseName\": \"test_database\",        \"FullDocument\": \"Default\"    },    \"MaximumBatchingWindowInSeconds\": 0,    \"EventSourceArn\": \"arn:aws:rds:us-west-2:123456789012:cluster:privatecluster7de2-epzcyvu4pjoy\",    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"LastModified\": 1541348195.412,    \"LastProcessingResult\": \"No records processed\",    \"State\": \"Creating\",    \"StateTransitionReason\": \"User action\"}",
                            "After creation, you can use the update-event-source-mapping command to update the settings for your Amazon DocumentDB event      source. The following example updates the batch size to 1,000 and the batch window to 10 seconds. For this      command, you need the UUID of your event source mapping, which you can retrieve using the        list-event-source-mapping command or the Lambda console.",
                            "aws lambda update-event-source-mapping --function-name my-function \\    --uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\    --batch-size 1000 \\    --batch-window 10",
                            "You should see this output that looks like this:",
                            "{    \"UUID\": \"2b733gdc-8ac3-cdf5-af3a-1827b3b11284\",    \"BatchSize\": 500,    \"DocumentDBEventSourceConfig\": {        \"CollectionName\": \"test_collection\",        \"DatabaseName\": \"test_database\",        \"FullDocument\": \"Default\"    },    \"MaximumBatchingWindowInSeconds\": 0,    \"EventSourceArn\": \"arn:aws:rds:us-west-2:123456789012:cluster:privatecluster7de2-epzcyvu4pjoy\",    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"LastModified\": 1541359182.919,    \"LastProcessingResult\": \"OK\",    \"State\": \"Updating\",    \"StateTransitionReason\": \"User action\"}",
                            "Lambda updates settings asynchronously, so you may not see these changes in the output until the process      completes. To view the current settings of your event source mapping, use the get-event-source-mapping command.",
                            "aws lambda get-event-source-mapping --uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b",
                            "You should see this output that looks like this:",
                            "{    \"UUID\": \"2b733gdc-8ac3-cdf5-af3a-1827b3b11284\",    \"DocumentDBEventSourceConfig\": {        \"CollectionName\": \"test_collection\",        \"DatabaseName\": \"test_database\",        \"FullDocument\": \"Default\"    },    \"BatchSize\": 1000,    \"MaximumBatchingWindowInSeconds\": 10,    \"EventSourceArn\": \"arn:aws:rds:us-west-2:123456789012:cluster:privatecluster7de2-epzcyvu4pjoy\",    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"LastModified\": 1541359182.919,    \"LastProcessingResult\": \"OK\",    \"State\": \"Enabled\",    \"StateTransitionReason\": \"User action\"}",
                            "To delete your Amazon DocumentDB event source mapping, use the delete-event-source-mapping command.",
                            "aws lambda delete-event-source-mapping \\    --uuid 2b733gdc-8ac3-cdf5-af3a-1827b3b11284"
                        ]
                    },
                    {
                        "sub_header": "Polling and stream starting positions",
                        "content": [
                            "Be aware that stream polling during event source mapping creation and updates is eventually consistent.",
                            "  1.During event source mapping creation, it may take several minutes to start polling events from the stream.",
                            "  2.During event source mapping updates, it may take several minutes to stop and restart polling events from the stream.",
                            "This behavior means that if you specify LATEST as the starting position for the stream, the event source mapping could     miss events during creation or updates. To ensure that no events are missed, specify the stream starting position as TRIM_HORIZON     or AT_TIMESTAMP."
                        ]
                    },
                    {
                        "sub_header": "Monitoring your Amazon DocumentDB event source",
                        "content": [
                            "To help you monitor your Amazon DocumentDB event source, Lambda emits the IteratorAge metric when your      function finishes processing a batch of records. Iterator age is the difference between the      timestamp of the most recent event and the current timestamp. Essentially, the IteratorAge metric      indicates how old the last processed record in the batch is. If your function is currently processing new events,      then you can use the iterator age to estimate the latency between when a record is added and when your function      processes it. An increasing trend in IteratorAge can indicate issues with your function.      For more information, see Using CloudWatch metrics with Lambda.",
                            "Amazon DocumentDB change streams aren't optimized to handle large time gaps between events. If your Amazon DocumentDB event source doesn't      receive any events for an extended period of time, Lambda may disable the event source mapping. The length of      this time period can vary from a few weeks to a few months depending on cluster size and other workloads.",
                            "Lambda supports payloads of up to 6 MB. However, Amazon DocumentDB change stream events can be up to 16 MB in size. If      your change stream tries to send Lambda a change stream event larger than 6 MB, then Lambda drops the message and      emits the OversizedRecordCount metric. Lambda emits all metrics on a best-effort basis."
                        ]
                    }
                ]
            },
            {
                "title": "DynamoDB",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html",
                "contents": [
                    {
                        "title": "Create mapping",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-dynamodb-eventsourcemapping.html",
                        "sections": [
                            "Create an event source mapping to tell Lambda to send records from your stream to a Lambda function. You can        create multiple event source mappings to process the same data with multiple Lambda functions, or to process items        from multiple streams with a single function.",
                            "To configure your function to read from DynamoDB Streams, attach the AWSLambdaDynamoDBExecutionRole AWS managed policy to your execution role and then create a DynamoDB        trigger.",
                            "To add permissions and create a trigger",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Choose the name of a function.",
                            "  3 : Choose the Configuration tab, and then choose Permissions.",
                            "  4 : Under Role name, choose the link to your execution role. This link opens the role in the IAM console.",
                            "  5 : Choose Add permissions, and then choose Attach policies.",
                            "  6 : In the search field, enter AWSLambdaDynamoDBExecutionRole. Add this policy to your execution role. This is an AWS managed policy that contains the permissions your function needs to read from the DynamoDB stream. For more information about this policy, see AWSLambdaDynamoDBExecutionRole in the AWS Managed Policy Reference.",
                            "  7 : Go back to your function in the Lambda console. Under Function overview, choose Add trigger.",
                            "  8 : Choose a trigger type.",
                            "  9 : Configure the required options, and then choose Add.",
                            "Lambda supports the following options for DynamoDB event sources:",
                            "Event source options",
                            "  1.DynamoDB table :  – The  to read records from.",
                            "  2.Batch size :  – The number of records to send to the function in each batch, up                to 10,000. Lambda passes all of the records in the batch to the function in a single call, as long as the total                size of the events doesn't exceed the payload limit for                synchronous invocation (6 MB).",
                            "  3.Batch window :  – Specify the maximum amount of time to gather records before          invoking the function, in seconds.",
                            "  4.Starting position :  – Process only new records, or all existing records.Latest – Process new records that are added to the stream.Trim horizon – Process all records in the stream.After processing any existing records, the function is caught up and continues to process new                records.",
                            "  5.Latest :  – Process new records that are added to the stream.",
                            "  6.Trim horizon :  – Process all records in the stream.",
                            "  7.On-failure destination :  – A standard SQS queue or standard SNS topic  for records that can't be processed. When Lambda discards a batch of records that's too old or has exhausted  all retries, Lambda sends details about the batch to the queue or topic.",
                            "  8.Retry attempts :  – The maximum number of times that  Lambda retries when the function returns an error. This doesn't apply to service errors or throttles where the  batch didn't reach the function.",
                            "  9.Maximum age of record :  – The maximum age of a record that  Lambda sends to your function.",
                            "  10.Split batch on error :  – When the function returns an error,  split the batch into two before retrying. Your original batch size setting remains unchanged.",
                            "  11.Concurrent batches per shard :  – Concurrently process multiple batches from the same shard.",
                            "  12.Enabled :  – Set to true to enable the event source mapping. Set to false to stop                processing records. Lambda keeps track of the last record processed and resumes processing from that point when                the mapping is reenabled.",
                            "Note",
                            "You are not charged for GetRecords API calls invoked by Lambda as part of DynamoDB triggers.",
                            "To manage the event source configuration later, choose the trigger in the designer."
                        ]
                    },
                    {
                        "title": "Batch item failures",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-ddb-batchfailurereporting.html",
                        "sections": [
                            "When consuming and processing streaming data from an event source, by default Lambda checkpoints to the highest    sequence number of a batch only when the batch is a complete success. Lambda treats all other results as a complete    failure and retries processing the batch up to the retry limit. To allow for partial successes while processing    batches from a stream, turn on ReportBatchItemFailures. Allowing partial successes can help to reduce    the number of retries on a record, though it doesn’t entirely prevent the possibility of retries in a successful record.",
                            "To turn on ReportBatchItemFailures, include the enum value    ReportBatchItemFailures in the FunctionResponseTypes list. This list indicates    which response types are enabled for your function. You can configure this list when you create or update an event source mapping.",
                            {
                                "sub_header": "Report syntax",
                                "content": [
                                    "When configuring reporting on batch item failures, the StreamsEventResponse class is returned with a      list of batch item failures. You can use a StreamsEventResponse object to return the sequence number      of the first failed record in the batch. You can also create your own custom class using the correct response      syntax. The following JSON structure shows the required response syntax:",
                                    "{   \"batchItemFailures\": [         {            \"itemIdentifier\": \"<SequenceNumber>\"        }    ]}",
                                    "Note",
                                    "If the batchItemFailures array contains multiple items, Lambda uses the record with the lowest      sequence number as the checkpoint. Lambda then retries all records starting from that checkpoint."
                                ]
                            },
                            {
                                "sub_header": "Success and failure conditions",
                                "content": [
                                    "Lambda treats a batch as a complete success if you return any of the following:",
                                    "  1.An empty batchItemFailure list",
                                    "  2.A null batchItemFailure list",
                                    "  3.An empty EventResponse",
                                    "  4.A null EventResponse",
                                    "Lambda treats a batch as a complete failure if you return any of the following:",
                                    "  1.An empty string itemIdentifier",
                                    "  2.A null itemIdentifier",
                                    "  3.An itemIdentifier with a bad key name",
                                    "Lambda retries failures based on your retry strategy."
                                ]
                            },
                            {
                                "sub_header": "Bisecting a batch",
                                "content": [
                                    "If your invocation fails and BisectBatchOnFunctionError is turned on, the batch is bisected      regardless of your ReportBatchItemFailures setting.",
                                    "When a partial batch success response is received and both BisectBatchOnFunctionError and        ReportBatchItemFailures are turned on, the batch is bisected at the returned sequence number and      Lambda retries only the remaining records.",
                                    "Here are some examples of function code that return the list of failed message IDs in the batch:",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype BatchItemFailure struct {\n\tItemIdentifier string `json:\"ItemIdentifier\"`\n}\n\ntype BatchResult struct {\n\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`\n}\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\n\tvar batchItemFailures []BatchItemFailure\n\tcurRecordSequenceNumber := \"\"\n\n\tfor _, record := range event.Records {\n\t\t// Process your record\n\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\n\t}\n\n\tif curRecordSequenceNumber != \"\" {\n\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\n\t}\n\t\n\tbatchResult := BatchResult{\n\t\tBatchItemFailures: batchItemFailures,\n\t}\n\n\treturn &batchResult, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype BatchItemFailure struct {\n\tItemIdentifier string `json:\"ItemIdentifier\"`\n}\n\ntype BatchResult struct {\n\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`\n}\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\n\tvar batchItemFailures []BatchItemFailure\n\tcurRecordSequenceNumber := \"\"\n\n\tfor _, record := range event.Records {\n\t\t// Process your record\n\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\n\t}\n\n\tif curRecordSequenceNumber != \"\" {\n\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\n\t}\n\t\n\tbatchResult := BatchResult{\n\t\tBatchItemFailures: batchItemFailures,\n\t}\n\n\treturn &batchResult, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                                    "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {\n\n    @Override\n    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {\n          try {\n                //Process your record\n                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();\n                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();\n                \n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse();   \n    }\n}\n\n",
                                    "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {\n\n    @Override\n    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {\n          try {\n                //Process your record\n                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();\n                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();\n                \n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse();   \n    }\n}\n\n",
                                    "  7.JavaScript : export const handler = async (event) => {\n  const records = event.Records;\n  let curRecordSequenceNumber = \"\";\n\n  for (const record of records) {\n    try {\n      // Process your record\n      curRecordSequenceNumber = record.dynamodb.SequenceNumber;\n    } catch (e) {\n      // Return failed record's sequence number\n      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };\n    }\n  }\n\n  return { batchItemFailures: [] };\n};\n\n",
                                    "  8.SDK for JavaScript (v3) : export const handler = async (event) => {\n  const records = event.Records;\n  let curRecordSequenceNumber = \"\";\n\n  for (const record of records) {\n    try {\n      // Process your record\n      curRecordSequenceNumber = record.dynamodb.SequenceNumber;\n    } catch (e) {\n      // Return failed record's sequence number\n      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };\n    }\n  }\n\n  return { batchItemFailures: [] };\n};\n\n",
                                    "  9.PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $dynamoDbEvent = new DynamoDbEvent($event);\n        $this->logger->info(\"Processing records\");\n\n        $records = $dynamoDbEvent->getRecords();\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  10.SDK for PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $dynamoDbEvent = new DynamoDbEvent($event);\n        $this->logger->info(\"Processing records\");\n\n        $records = $dynamoDbEvent->getRecords();\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                                    "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                                    "  13.Ruby : def lambda_handler(event:, context:)\n    records = event[\"Records\"]\n    cur_record_sequence_number = \"\"\n  \n    records.each do |record|\n      begin\n        # Process your record\n        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]\n      rescue StandardError => e\n        # Return failed record's sequence number\n        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}\n      end\n    end\n  \n    {\"batchItemFailures\" => []}\n  end\n",
                                    "  14.SDK for Ruby : def lambda_handler(event:, context:)\n    records = event[\"Records\"]\n    cur_record_sequence_number = \"\"\n  \n    records.each do |record|\n      begin\n        # Process your record\n        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]\n      rescue StandardError => e\n        # Return failed record's sequence number\n        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}\n      end\n    end\n  \n    {\"batchItemFailures\" => []}\n  end\n",
                                    "  15.Rust : use aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord, StreamRecord},\n    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n/// Process the stream record\nfn process_record(record: &EventRecord) -> Result<(), Error> {\n    let stream_record: &StreamRecord = &record.change;\n\n    // process your stream record here...\n    tracing::info!(\"Data: {:?}\", stream_record);\n\n    Ok(())\n}\n\n/// Main Lambda handler here...\nasync fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {\n    let mut response = DynamoDbEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    let records = &event.payload.records;\n\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in records {\n        tracing::info!(\"EventId: {}\", record.event_id);\n\n        // Couldn't find a sequence number\n        if record.change.sequence_number.is_none() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: Some(\"\".to_string()),\n            });\n            return Ok(response);\n        }\n\n        // Process your record here...\n        if process_record(record).is_err() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: record.change.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\"Successfully processed {} record(s)\", records.len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n",
                                    "  16.SDK for Rust : use aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord, StreamRecord},\n    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n/// Process the stream record\nfn process_record(record: &EventRecord) -> Result<(), Error> {\n    let stream_record: &StreamRecord = &record.change;\n\n    // process your stream record here...\n    tracing::info!(\"Data: {:?}\", stream_record);\n\n    Ok(())\n}\n\n/// Main Lambda handler here...\nasync fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {\n    let mut response = DynamoDbEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    let records = &event.payload.records;\n\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in records {\n        tracing::info!(\"EventId: {}\", record.event_id);\n\n        // Couldn't find a sequence number\n        if record.change.sequence_number.is_none() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: Some(\"\".to_string()),\n            });\n            return Ok(response);\n        }\n\n        // Process your record here...\n        if process_record(record).is_err() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: record.change.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\"Successfully processed {} record(s)\", records.len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();        foreach (var record in dynamoEvent.Records)        {            try            {                var sequenceNumber = record.Dynamodb.SequenceNumber;                context.Logger.LogInformation(sequenceNumber);            }            catch (Exception ex)            {                context.Logger.LogError(ex.Message);                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });            }        }        if (batchItemFailures.Count > 0)        {            streamsEventResponse.BatchItemFailures = batchItemFailures;        }        context.Logger.LogInformation(\"Stream processing complete.\");        return streamsEventResponse;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")type BatchItemFailure struct {\tItemIdentifier string `json:\"ItemIdentifier\"`}type BatchResult struct {\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`}func HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\tvar batchItemFailures []BatchItemFailure\tcurRecordSequenceNumber := \"\"\tfor _, record := range event.Records {\t\t// Process your record\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\t}\tif curRecordSequenceNumber != \"\" {\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\t}\t\tbatchResult := BatchResult{\t\tBatchItemFailures: batchItemFailures,\t}\treturn &batchResult, nil}func main() {\tlambda.Start(HandleRequest)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent;import com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;import com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;import java.io.Serializable;import java.util.ArrayList;import java.util.List;public class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {    @Override    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();        String curRecordSequenceNumber = \"\";        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {          try {                //Process your record                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();                            } catch (Exception e) {                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));                return new StreamsEventResponse(batchItemFailures);            }        }              return new StreamsEventResponse();       }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using JavaScript.export const handler = async (event) => {  const records = event.Records;  let curRecordSequenceNumber = \"\";  for (const record of records) {    try {      // Process your record      curRecordSequenceNumber = record.dynamodb.SequenceNumber;    } catch (e) {      // Return failed record's sequence number      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };    }  }  return { batchItemFailures: [] };};Reporting DynamoDB batch item failures with Lambda using TypeScript.import {  DynamoDBBatchResponse,  DynamoDBBatchItemFailure,  DynamoDBStreamEvent,} from \"aws-lambda\";export const handler = async (  event: DynamoDBStreamEvent): Promise<DynamoDBBatchResponse> => {  const batchItemFailures: DynamoDBBatchItemFailure[] = [];  let curRecordSequenceNumber;  for (const record of event.Records) {    curRecordSequenceNumber = record.dynamodb?.SequenceNumber;    if (curRecordSequenceNumber) {      batchItemFailures.push({        itemIdentifier: curRecordSequenceNumber,      });    }  }  return { batchItemFailures: batchItemFailures };};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using PHP.<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\DynamoDb\\DynamoDbEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): array    {        $dynamoDbEvent = new DynamoDbEvent($event);        $this->logger->info(\"Processing records\");        $records = $dynamoDbEvent->getRecords();        $failedRecords = [];        foreach ($records as $record) {            try {                $data = $record->getData();                $this->logger->info(json_encode($data));                // TODO: Do interesting work based on the new data            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $failedRecords[] = $record->getSequenceNumber();            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");        // change format for the response        $failures = array_map(            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],            $failedRecords        );        return [            'batchItemFailures' => $failures        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def handler(event, context):    records = event.get(\"Records\")    curRecordSequenceNumber = \"\"        for record in records:        try:            # Process your record            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]        except Exception as e:            # Return failed record's sequence number            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}    return {\"batchItemFailures\":[]}RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Ruby.def lambda_handler(event:, context:)    records = event[\"Records\"]    cur_record_sequence_number = \"\"      records.each do |record|      begin        # Process your record        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]      rescue StandardError => e        # Return failed record's sequence number        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}      end    end      {\"batchItemFailures\" => []}  endRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Rust.use aws_lambda_events::{    event::dynamodb::{Event, EventRecord, StreamRecord},    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};/// Process the stream recordfn process_record(record: &EventRecord) -> Result<(), Error> {    let stream_record: &StreamRecord = &record.change;    // process your stream record here...    tracing::info!(\"Data: {:?}\", stream_record);    Ok(())}/// Main Lambda handler here...async fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {    let mut response = DynamoDbEventResponse {        batch_item_failures: vec![],    };    let records = &event.payload.records;    if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(response);    }    for record in records {        tracing::info!(\"EventId: {}\", record.event_id);        // Couldn't find a sequence number        if record.change.sequence_number.is_none() {            response.batch_item_failures.push(DynamoDbBatchItemFailure {                item_identifier: Some(\"\".to_string()),            });            return Ok(response);        }        // Process your record here...        if process_record(record).is_err() {            response.batch_item_failures.push(DynamoDbBatchItemFailure {                item_identifier: record.change.sequence_number.clone(),            });            /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */            return Ok(response);        }    }    tracing::info!(\"Successfully processed {} record(s)\", records.len());    Ok(response)}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();        foreach (var record in dynamoEvent.Records)        {            try            {                var sequenceNumber = record.Dynamodb.SequenceNumber;                context.Logger.LogInformation(sequenceNumber);            }            catch (Exception ex)            {                context.Logger.LogError(ex.Message);                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });            }        }        if (batchItemFailures.Count > 0)        {            streamsEventResponse.BatchItemFailures = batchItemFailures;        }        context.Logger.LogInformation(\"Stream processing complete.\");        return streamsEventResponse;    }}"
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Error handling",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-dynamodb-errors.html",
                        "sections": [
                            "Error handling for DynamoDB event source mappings depends on whether the error occurs before the function is invoked or during function invocation:",
                            "  1.Before invocation: :  If a Lambda event source mapping is unable to invoke the function due to throttling or other issues, it retries until the records expire or exceed the maximum age configured on the event source mapping (MaximumRecordAgeInSeconds).",
                            "  2.During invocation: :  If the function is invoked but returns an error, Lambda retries until the records expire, exceed the maximum age (MaximumRecordAgeInSeconds), or reach the configured retry quota (MaximumRetryAttempts). For function errors, you can also configure BisectBatchOnFunctionError, which splits a failed batch into two smaller batches, isolating bad records and avoiding timeouts. Splitting batches doesn't consume the retry quota.",
                            "If the error handling measures fail, Lambda discards the records and continues processing  batches from the stream. With the default settings, this means that a bad record can block processing on the affected  shard for up to one day. To avoid this, configure your function's event source mapping with a reasonable  number of retries and a maximum record age that fits your use case.",
                            {
                                "sub_header": "Configuring destinations for failed invocations",
                                "content": [
                                    "To retain records of failed event source mapping invocations, add a destination to your function's event source mapping. Each record sent to the destination is a JSON document containing metadata about the failed invocation. For Amazon S3 destinations, Lambda also sends the entire invocation record along with the metadata. You can configure any Amazon SNS topic, Amazon SQS queue, or S3 bucket as a destination.",
                                    "With Amazon S3 destinations, you can use the Amazon S3 Event Notifications feature to receive notifications when objects are uploaded to your destination S3 bucket. You can also configure S3 Event Notifications to invoke another Lambda function to perform automated processing on failed batches.",
                                    "Your execution role must have permissions for the destination:",
                                    "  1.For SQS destinations: :  sqs:SendMessage",
                                    "  2.For SNS destinations: :  sns:Publish",
                                    "  3.For S3 bucket destinations: :   s3:PutObject and s3:ListBucket",
                                    "If you've enabled encryption with your own KMS key for an S3 destination, your function's execution role must also have permission to call             kms:GenerateDataKey.            If the KMS key and S3 bucket destination are in a different account from your Lambda function            and execution role, configure the KMS key to trust the execution role to allow            kms:GenerateDataKey.",
                                    "To configure an on-failure destination using the console, follow these steps:",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose a function.",
                                    "  3 : Under Function overview, choose Add destination.",
                                    "  4 : For Source, choose Event source mapping invocation.",
                                    "  5 : For Event source mapping, choose an event source that's configured              for this function.",
                                    "  6 : For Condition, select On failure. For event              source mapping invocations, this is the only accepted condition.",
                                    "  7 : For Destination type, choose the destination type that Lambda sends              invocation records to.",
                                    "  8 : For Destination, choose a resource.",
                                    "  9 : Choose Save.",
                                    "You can also configure an on-failure destination using the AWS Command Line Interface (AWS CLI). For example, the following          create-event-source-mapping command adds an event source mapping with an SQS on-failure destination to          MyFunction:",
                                    "aws lambda create-event-source-mapping \\--function-name \"MyFunction\" \\--event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table/stream/2024-06-10T19:26:16.525 \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sqs:us-east-1:123456789012:dest-queue\"}}'",
                                    "The following update-event-source-mapping command updates an event source mapping to send failed invocation records to an SNS destination after two retry attempts, or if the records are more than an hour old.",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--maximum-retry-attempts 2 \\--maximum-record-age-in-seconds 3600 \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sns:us-east-1:123456789012:dest-topic\"}}'",
                                    "Updated settings are applied asynchronously and aren't reflected in the output until the process completes. Use    the get-event-source-mapping command to view the current status.",
                                    "To remove a destination, supply an empty string as the argument to the          destination-config parameter:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"\"}}'",
                                    {
                                        "sub_header": "Security best practices for Amazon S3 destinations",
                                        "content": [
                                            "Deleting an S3 bucket that's configured as a destination without removing the destination from your function's configuration can create a security risk. If another       user knows your destination bucket's name, they can recreate the bucket in their AWS account. Records of failed invocations will be sent to their bucket, potentially       exposing data from your function.",
                                            "Warning",
                                            "To ensure that invocation records from your function can't be sent to an S3 bucket in another AWS account, add a condition to your function's execution role         that limits s3:PutObject permissions to buckets in your account. ",
                                            "The following example shows an IAM policy that limits your function's s3:PutObject permissions to buckets in your account. This policy also gives Lambda        the s3:ListBucket permission it needs to use an S3 bucket as a destination.",
                                            "{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Sid\": \"S3BucketResourceAccountWrite\",            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\",                \"s3:ListBucket\"            ],            \"Resource\": \"arn:aws:s3:::*/*\",            \"Condition\": {                \"StringEquals\": {                    \"s3:ResourceAccount\": \"111122223333\"                }            }        }    ]}",
                                            "To add a permissions policy to your funcion's execution role using the AWS Management Console or AWS CLI, refer to the instructions in the following procedures:",
                                            "  1.Console : \nTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.\nSelect the Lambda function whose execution role you want to modify.\n\nIn the Configuration tab, select Permissions.\n\nIn the Execution role tab, select your function's Role name to open the role's IAM console page.\n\nAdd a permissions policy to the role by doing the following:\n\nIn the Permissions policies pane, choose Add permissions and select Create inline policy.\n\nIn Policy editor, select JSON.\n\nPaste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.\n\nUnder Policy details, enter a Policy name.\n\nChoose Create policy.\n\n\n",
                                            "  2.AWS CLI : put-role-policy",
                                            "ConsoleTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.Select the Lambda function whose execution role you want to modify.In the Configuration tab, select Permissions.In the Execution role tab, select your function's Role name to open the role's IAM console page.Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy.AWS CLITo add a permissions policy to a function's execution role (CLI)Create a JSON policy document with the required permissions and save it in a local directory.Use the IAM put-role-policy CLI command to add the permissions to your function's execution role. Run the following command from the                 directory you saved your JSON policy document in and replace the role name, policy name, and policy document with your own values.aws iam put-role-policy \\--role-name my_lambda_role \\--policy-name LambdaS3DestinationPolicy \\--policy-document file://my_policy.json",
                                            "anchor",
                                            "anchor",
                                            "To add a permissions policy to a function's execution role (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Select the Lambda function whose execution role you want to modify.",
                                            "  3 : In the Configuration tab, select Permissions.",
                                            "  4 : In the Execution role tab, select your function's Role name to open the role's IAM console page.",
                                            "  5 : Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy."
                                        ]
                                    },
                                    {
                                        "sub_header": "Example Amazon SNS and Amazon SQS invocation record",
                                        "content": [
                                            "The following example shows an invocation record Lambda sends to an SQS or SNS destination for a DynamoDB stream.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\",        \"approximateInvokeCount\": 1    },    \"responseContext\": {        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:13:49.717Z\",    \"DDBStreamBatchInfo\": {        \"shardId\": \"shardId-00000001573689847184-864758bb\",        \"startSequenceNumber\": \"800000000003126276362\",        \"endSequenceNumber\": \"800000000003126276362\",        \"approximateArrivalOfFirstRecord\": \"2019-11-14T00:13:19Z\",        \"approximateArrivalOfLastRecord\": \"2019-11-14T00:13:19Z\",        \"batchSize\": 1,        \"streamArn\": \"arn:aws:dynamodb:us-east-2:123456789012:table/mytable/stream/2019-11-14T00:04:06.388\"    }}",
                                            "You can use this information to retrieve the affected records from the stream for  troubleshooting. The actual records aren't included, so you must process this record and retrieve them from the  stream before they expire and are lost."
                                        ]
                                    },
                                    {
                                        "sub_header": "Example Amazon S3 invocation record",
                                        "content": [
                                            "The following example shows an invocation record Lambda sends to an S3 bucket for a DynamoDB stream. In addition to all of the fields from the previous example for SQS and SNS destinations, the payload field       contains the original invocation record as an escaped JSON string.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\",        \"approximateInvokeCount\": 1    },    \"responseContext\": {        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:13:49.717Z\",    \"DDBStreamBatchInfo\": {        \"shardId\": \"shardId-00000001573689847184-864758bb\",        \"startSequenceNumber\": \"800000000003126276362\",        \"endSequenceNumber\": \"800000000003126276362\",        \"approximateArrivalOfFirstRecord\": \"2019-11-14T00:13:19Z\",        \"approximateArrivalOfLastRecord\": \"2019-11-14T00:13:19Z\",        \"batchSize\": 1,        \"streamArn\": \"arn:aws:dynamodb:us-east-2:123456789012:table/mytable/stream/2019-11-14T00:04:06.388\"    },    \"payload\": \"<Whole Event>\" // Only available in S3}",
                                            "The S3 object containing the invocation record uses the following naming convention:",
                                            "aws/lambda/<ESM-UUID>/<shardID>/YYYY/MM/DD/YYYY-MM-DDTHH.MM.SS-<Random UUID>"
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Stateful processing",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-ddb-windows.html",
                        "sections": [
                            "Lambda functions can run continuous stream processing applications. A stream represents unbounded data that flows    continuously through your application. To analyze information from this continuously updating input, you can bound    the included records using a window defined in terms of time.",
                            "Tumbling windows are distinct time windows that open and close at regular intervals. By default, Lambda invocations    are stateless—you cannot use them for processing data across multiple continuous invocations without an external database.    However, with tumbling windows, you can maintain your state across invocations. This state contains the aggregate result    of the messages previously processed for the current window. Your state can be a maximum of 1 MB per shard. If it exceeds    that size, Lambda terminates the window early.",
                            "Each record in a stream belongs to a specific window. Lambda will process each record at least once, but doesn't guarantee that each record will be processed only once. In rare cases, such as error handling, some records might be processed more than once. Records are always processed in order the first time. If records are processed more than once, they might be processed out of order.",
                            {
                                "sub_header": "Aggregation and processing",
                                "content": [
                                    "Your user managed function is invoked both for aggregation and for processing the final results of that      aggregation. Lambda aggregates all records received in the window. You can receive these records in multiple      batches, each as a separate invocation. Each invocation receives a state. Thus, when using tumbling windows,      your Lambda function response must contain a state property. If the response does not contain a      state property, Lambda considers this a failed invocation. To satisfy this condition, your function      can return a TimeWindowEventResponse object, which has the following JSON shape:",
                                    "Example TimeWindowEventResponse values",
                                    {
                                        "code_example": "{\n    \"state\": {\n        \"1\": 282,\n        \"2\": 715\n    },\n    \"batchItemFailures\": []\n}"
                                    },
                                    "Note",
                                    "For Java functions, we recommend using a Map<String, String> to represent the state.",
                                    "At the end of the window, the flag isFinalInvokeForWindow is set to true to indicate      that this is the final state and that it’s ready for processing. After processing, the window completes and your      final invocation completes, and then the state is dropped.",
                                    "At the end of your window, Lambda uses final processing for actions on the aggregation results. Your final      processing is synchronously invoked. After successful invocation, your function checkpoints the sequence number      and stream processing continues. If invocation is unsuccessful, your Lambda function suspends further processing      until a successful invocation.",
                                    "Example  DynamodbTimeWindowEvent",
                                    {
                                        "code_example": "\n{\n   \"Records\":[\n      {\n         \"eventID\":\"1\",\n         \"eventName\":\"INSERT\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"NewImage\":{\n               \"Message\":{\n                  \"S\":\"New item!\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"111\",\n            \"SizeBytes\":26,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      },\n      {\n         \"eventID\":\"2\",\n         \"eventName\":\"MODIFY\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"NewImage\":{\n               \"Message\":{\n                  \"S\":\"This item has changed\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"OldImage\":{\n               \"Message\":{\n                  \"S\":\"New item!\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"222\",\n            \"SizeBytes\":59,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      },\n      {\n         \"eventID\":\"3\",\n         \"eventName\":\"REMOVE\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"OldImage\":{\n               \"Message\":{\n                  \"S\":\"This item has changed\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"333\",\n            \"SizeBytes\":38,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      }\n   ],\n    \"window\": {\n        \"start\": \"2020-07-30T17:00:00Z\",\n        \"end\": \"2020-07-30T17:05:00Z\"\n    },\n    \"state\": {\n        \"1\": \"state1\"\n    },\n    \"shardId\": \"shard123456789\",\n    \"eventSourceARN\": \"stream-ARN\",\n    \"isFinalInvokeForWindow\": false,\n    \"isWindowTerminatedEarly\": false\n}\n"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Configuration",
                                "content": [
                                    "You can configure tumbling windows when you create or update an event source mapping. To configure a tumbling window, specify the window in seconds (TumblingWindowInSeconds). The following        example AWS Command Line Interface (AWS CLI) command creates a streaming event source mapping that has a tumbling window of 120        seconds. The Lambda function defined for aggregation and processing is named        tumbling-window-example-function.",
                                    "aws lambda create-event-source-mapping \\--event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table/stream/2024-06-10T19:26:16.525 \\--function-name tumbling-window-example-function \\--starting-position TRIM_HORIZON \\--tumbling-window-in-seconds 120",
                                    "Lambda determines tumbling window boundaries based on the time when records were inserted into the stream. All      records have an approximate timestamp available that Lambda uses in boundary determinations.",
                                    "Tumbling window aggregations do not support resharding. When the shard ends, Lambda considers the window      closed, and the child shards start their own window in a fresh state.",
                                    "Tumbling windows fully support the existing retry policies maxRetryAttempts and        maxRecordAge.",
                                    "Example  Handler.py – Aggregation and processing",
                                    "The following Python function demonstrates how to aggregate and then process your final state:",
                                    {
                                        "code_example": "def lambda_handler(event, context):\n    print('Incoming event: ', event)\n    print('Incoming state: ', event['state'])\n\n#Check if this is the end of the window to either aggregate or process.\n    if event['isFinalInvokeForWindow']:\n        # logic to handle final state of the window\n        print('Destination invoke')\n    else:\n        print('Aggregate invoke')\n\n#Check for early terminations\n    if event['isWindowTerminatedEarly']:\n        print('Window terminated early')\n\n    #Aggregation logic\n    state = event['state']\n    for record in event['Records']:\n        state[record['dynamodb']['NewImage']['Id']] = state.get(record['dynamodb']['NewImage']['Id'], 0) + 1\n\n    print('Returning state: ', state)\n    return {'state': state}"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Parameters",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-ddb-params.html",
                        "sections": [
                            "All Lambda event source types share the same CreateEventSourceMapping and UpdateEventSourceMapping      API operations. However, only some of the parameters apply to DynamoDB Streams.",
                            "ParameterRequiredDefaultNotesBatchSizeN100Maximum: 10,000BisectBatchOnFunctionErrorNfalsenoneDestinationConfigNN/AStandard Amazon SQS queue or standard Amazon SNS topic destination for discarded recordsEnabledNtruenoneEventSourceArnYN/AARN of the data stream or a stream consumerFilterCriteriaNN/AControl which events Lambda sends to your functionFunctionNameYN/AnoneFunctionResponseTypesNN/ATo let your function report specific failures in a batch, include the value                ReportBatchItemFailures in FunctionResponseTypes. For more information, see                Configuring partial batch response with DynamoDB and Lambda.MaximumBatchingWindowInSecondsN0noneMaximumRecordAgeInSecondsN-1-1 means infinite: failed records are retried until the record expires. The data retention limit for DynamoDB Streams is 24 hours.Minimum: -1Maximum: 604,800MaximumRetryAttemptsN-1-1 means infinite: failed records are retried until the record expiresMinimum: 0Maximum: 10,000ParallelizationFactorN1Maximum: 10StartingPositionYN/ATRIM_HORIZON or LATESTTumblingWindowInSecondsNN/AMinimum: 0Maximum: 900"
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-ddb-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for DynamoDB event sources.",
                            "Topics",
                            {
                                "sub_header": "DynamoDB event",
                                "content": [
                                    "Suppose you have a DynamoDB table with the primary key CustomerName and attributes AccountManager and       PaymentTerms. The following shows an example record from your DynamoDB table’s stream.",
                                    "{      \"eventID\": \"1\",      \"eventVersion\": \"1.0\",      \"dynamodb\": {          \"ApproximateCreationDateTime\": \"1678831218.0\",          \"Keys\": {              \"CustomerName\": {                  \"S\": \"AnyCompany Industries\"              },              \"NewImage\": {                  \"AccountManager\": {                      \"S\": \"Pat Candella\"                  },                  \"PaymentTerms\": {                      \"S\": \"60 days\"                  },                  \"CustomerName\": {                      \"S\": \"AnyCompany Industries\"                  }              },              \"SequenceNumber\": \"111\",              \"SizeBytes\": 26,              \"StreamViewType\": \"NEW_IMAGE\"          }      }  }",
                                    "To filter based on the key and attribute values in your DynamoDB table, use the dynamodb key in the record.       The following sections provide examples for different filter types.",
                                    {
                                        "sub_header": "Filtering with table keys",
                                        "content": [
                                            "Suppose you want your function to process only those records where the primary key CustomerName is “AnyCompany Industries.” The       FilterCriteria object would be as follows.",
                                            "{     \"Filters\": [          {              \"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"Keys\\\" : { \\\"CustomerName\\\" : { \\\"S\\\" : [ \\\"AnyCompany Industries\\\" ] } } } }\"          }      ] }",
                                            "For added clarity, here is the value of the filter's Pattern expanded in plain JSON. ",
                                            "{     \"dynamodb\": {          \"Keys\": {              \"CustomerName\": {                  \"S\": [ \"AnyCompany Industries\" ]                  }              }          } }",
                                            "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                            "  1.Console : { \"dynamodb\" : { \"Keys\" : { \"CustomerName\" : { \"S\" : [ \"AnyCompany Industries\" ] } } } }",
                                            "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"Keys\\\" : { \\\"CustomerName\\\" : { \\\"S\\\" : [ \\\"AnyCompany Industries\\\" ] } } } }\"}]}'",
                                            "  3.AWS SAM : FilterCriteria:\n   Filters:\n     - Pattern: '{ \"dynamodb\" : { \"Keys\" : { \"CustomerName\" : { \"S\" : [ \"AnyCompany Industries\" ] } } } }'",
                                            "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.{ \"dynamodb\" : { \"Keys\" : { \"CustomerName\" : { \"S\" : [ \"AnyCompany Industries\" ] } } } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following            command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"Keys\\\" : { \\\"CustomerName\\\" : { \\\"S\\\" : [ \\\"AnyCompany Industries\\\" ] } } } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"Keys\\\" : { \\\"CustomerName\\\" : { \\\"S\\\" : [ \\\"AnyCompany Industries\\\" ] } } } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:   Filters:     - Pattern: '{ \"dynamodb\" : { \"Keys\" : { \"CustomerName\" : { \"S\" : [ \"AnyCompany Industries\" ] } } } }'",
                                            "anchor",
                                            "anchor",
                                            "anchor",
                                            "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.",
                                            {
                                                "code_example": "{ \"dynamodb\" : { \"Keys\" : { \"CustomerName\" : { \"S\" : [ \"AnyCompany Industries\" ] } } } }"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Filtering with table attributes",
                                "content": [
                                    "With DynamoDB, you can also use the NewImage and OldImage keys to filter for attribute values. Suppose you want       to filter records where the AccountManager attribute in the latest table image is “Pat Candella” or \"Shirley Rodriguez.\" The       FilterCriteria object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\", \\\"Shirley Rodriguez\\\" ] } } } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"dynamodb\": {        \"NewImage\": {            \"AccountManager\": {                \"S\": [ \"Pat Candella\", \"Shirley Rodriguez\" ]            }        }    }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\", \"Shirley Rodriguez\" ] } } } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\", \\\"Shirley Rodriguez\\\" ] } } } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\", \"Shirley Rodriguez\" ] } } } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\", \"Shirley Rodriguez\" ] } } } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following            command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\", \\\"Shirley Rodriguez\\\" ] } } } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\", \\\"Shirley Rodriguez\\\" ] } } } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\", \"Shirley Rodriguez\" ] } } } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\", \"Shirley Rodriguez\" ] } } } }"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Filtering with Boolean expressions",
                                "content": [
                                    "You can also create filters using Boolean AND expressions. These expressions can include both your table's key and attribute parameters.     Suppose you want to filter records where the NewImage value of AccountManager is \"Pat Candella\" and the     OldImage value is \"Terry Whitlock\". The FilterCriteria object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\" ] } } } , \\\"dynamodb\\\" : { \\\"OldImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Terry Whitlock\\\" ] } } } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{     \"dynamodb\" : {         \"NewImage\" : {             \"AccountManager\" : {                 \"S\" : [                     \"Pat Candella\"                 ]             }         }     },     \"dynamodb\": {         \"OldImage\": {             \"AccountManager\": {                 \"S\": [                     \"Terry Whitlock\"                 ]             }         }     } }",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\" ] } } } , \"dynamodb\" : { \"OldImage\" : { \"AccountManager\" : { \"S\" : [ \"Terry Whitlock\" ] } } } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\" ] } } } , \\\"dynamodb\\\" : { \\\"OldImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Terry Whitlock\\\" ] } } } } \"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\" ] } } } , \"dynamodb\" : { \"OldImage\" : { \"AccountManager\" : { \"S\" : [ \"Terry Whitlock\" ] } } } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\" ] } } } , \"dynamodb\" : { \"OldImage\" : { \"AccountManager\" : { \"S\" : [ \"Terry Whitlock\" ] } } } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following            command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:dynamodb:us-east-2:123456789012:table/my-table \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\" ] } } } , \\\"dynamodb\\\" : { \\\"OldImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Terry Whitlock\\\" ] } } } } \"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"dynamodb\\\" : { \\\"NewImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Pat Candella\\\" ] } } } , \\\"dynamodb\\\" : { \\\"OldImage\\\" : { \\\"AccountManager\\\" : { \\\"S\\\" : [ \\\"Terry Whitlock\\\" ] } } } } \"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\" ] } } } , \"dynamodb\" : { \"OldImage\" : { \"AccountManager\" : { \"S\" : [ \"Terry Whitlock\" ] } } } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following             string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"dynamodb\" : { \"NewImage\" : { \"AccountManager\" : { \"S\" : [ \"Pat Candella\" ] } } } , \"dynamodb\" : { \"OldImage\" : { \"AccountManager\" : { \"S\" : [ \"Terry Whitlock\" ] } } } }"
                                    },
                                    "Note",
                                    "DynamoDB event filtering doesn’t support the use of numeric operators (numeric equals and numeric range). Even if items in your         table are stored as numbers, these parameters are converted to strings in the JSON record object."
                                ]
                            },
                            {
                                "sub_header": "Using the Exists operator",
                                "content": [
                                    "Because of the way that JSON event objects from DynamoDB are structured, using the Exists operator requires special care.       The Exists operator only works on leaf nodes in the event JSON, so if your filter pattern uses Exists to test for an intermediate       node, it won't work. Consider the following DynamoDB table item:",
                                    "{  \"UserID\": {\"S\": \"12345\"},  \"Name\": {\"S\": \"John Doe\"},  \"Organizations\": {\"L\": [      {\"S\":\"Sales\"},      {\"S\":\"Marketing\"},      {\"S\":\"Support\"}    ]  }}",
                                    "You might want to create a filter pattern like the following that would test for events containing \"Organizations\":",
                                    "{ \"dynamodb\" : { \"NewImage\" : { \"Organizations\" : [ { \"exists\": true } ] } } }",
                                    "However, this filter pattern would never return a match because \"Organizations\" is not a leaf node. The following         example shows how to properly use the Exists operator to construct the desired filter pattern:",
                                    "{ \"dynamodb\" : { \"NewImage\" : {\"Organizations\": {\"L\": {\"S\": [ {\"exists\": true } ] } } } } }"
                                ]
                            },
                            {
                                "sub_header": "JSON format for DynamoDB filtering",
                                "content": [
                                    "To properly filter events from DynamoDB sources, both the data field and your filter criteria for the data field (dynamodb)       must be in valid JSON format. If either field isn't in a valid JSON format, Lambda drops the message or throws an exception. The following       table summarizes the specific behavior: ",
                                    "Incoming data formatFilter pattern format for data propertiesResulting actionValid JSONValid JSONLambda filters based on your filter criteria.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONNon-JSONLambda throws an exception at the time of the event source mapping creation or update. The filter pattern                for data properties must be in a valid JSON format.Non-JSONValid JSONLambda drops the record.Non-JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Non-JSONNon-JSONLambda throws an exception at the time of the event source mapping creation or update. The filter pattern                for data properties must be in a valid JSON format."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-ddb-example.html",
                        "sections": [
                            " In this tutorial, you create a Lambda function to consume events from an Amazon DynamoDB stream.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "This tutorial assumes that you have some knowledge of basic Lambda operations and the Lambda console. If you      haven't already, follow the instructions in Create a Lambda function with the console to create your first Lambda function.",
                                    "To complete the following steps, you need the AWS CLI version 2. Commands and the expected output are listed in separate blocks:",
                                    "aws --version",
                                    "You should see the following output:",
                                    "aws-cli/2.13.27 Python/3.11.6 Linux/4.14.328-248.540.amzn2.x86_64 exe/x86_64.amzn.2",
                                    "For long commands, an escape character (\\) is used to split a command over multiple lines.",
                                    "On Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.     To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.     Example CLI commands in this guide use Linux formatting. Commands which include inline JSON documents must be reformatted if you are using the Windows CLI.    "
                                ]
                            },
                            {
                                "sub_header": "Create the execution role",
                                "content": [
                                    "Create the execution role that gives your function      permission to access AWS resources.",
                                    "To create an execution role",
                                    "  1 : Open the roles page in the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : Create a role with the following properties.Trusted entity – Lambda.Permissions – AWSLambdaDynamoDBExecutionRole.Role name – lambda-dynamodb-role.",
                                    "The AWSLambdaDynamoDBExecutionRole has the permissions that the function needs to read      items from DynamoDB and write logs to CloudWatch Logs."
                                ]
                            },
                            {
                                "sub_header": "Create the function",
                                "content": [
                                    "Create a Lambda function that processes your DynamoDB events. The function code writes some of      the incoming event data to CloudWatch Logs.",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"fmt\"\n)\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\n\tif len(event.Records) == 0 {\n\t\treturn nil, fmt.Errorf(\"received empty event\")\n\t}\n\n\tfor _, record := range event.Records {\n\t \tLogDynamoDBRecord(record)\n\t}\n\n\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\n\treturn &message, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\nfunc LogDynamoDBRecord(record events.DynamoDBEventRecord){\n\tfmt.Println(record.EventID)\n\tfmt.Println(record.EventName)\n\tfmt.Printf(\"%+v\\n\", record.Change)\n}\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"fmt\"\n)\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\n\tif len(event.Records) == 0 {\n\t\treturn nil, fmt.Errorf(\"received empty event\")\n\t}\n\n\tfor _, record := range event.Records {\n\t \tLogDynamoDBRecord(record)\n\t}\n\n\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\n\treturn &message, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\nfunc LogDynamoDBRecord(record events.DynamoDBEventRecord){\n\tfmt.Println(record.EventID)\n\tfmt.Println(record.EventName)\n\tfmt.Printf(\"%+v\\n\", record.Change)\n}\n",
                                    "  5.Java : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;\nimport com.google.gson.Gson;\nimport com.google.gson.GsonBuilder;\n\npublic class example implements RequestHandler<DynamodbEvent, Void> {\n\n    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();\n\n    @Override\n    public Void handleRequest(DynamodbEvent event, Context context) {\n        System.out.println(GSON.toJson(event));\n        event.getRecords().forEach(this::logDynamoDBRecord);\n        return null;\n    }\n\n    private void logDynamoDBRecord(DynamodbStreamRecord record) {\n        System.out.println(record.getEventID());\n        System.out.println(record.getEventName());\n        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));\n    }\n}\n",
                                    "  6.SDK for Java 2.x : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;\nimport com.google.gson.Gson;\nimport com.google.gson.GsonBuilder;\n\npublic class example implements RequestHandler<DynamodbEvent, Void> {\n\n    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();\n\n    @Override\n    public Void handleRequest(DynamodbEvent event, Context context) {\n        System.out.println(GSON.toJson(event));\n        event.getRecords().forEach(this::logDynamoDBRecord);\n        return null;\n    }\n\n    private void logDynamoDBRecord(DynamodbStreamRecord record) {\n        System.out.println(record.getEventID());\n        System.out.println(record.getEventName());\n        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));\n    }\n}\n",
                                    "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n    console.log(JSON.stringify(event, null, 2));\n    event.Records.forEach(record => {\n        logDynamoDBRecord(record);\n    });\n};\n\nconst logDynamoDBRecord = (record) => {\n    console.log(record.eventID);\n    console.log(record.eventName);\n    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);\n};\n\n",
                                    "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n    console.log(JSON.stringify(event, null, 2));\n    event.Records.forEach(record => {\n        logDynamoDBRecord(record);\n    });\n};\n\nconst logDynamoDBRecord = (record) => {\n    console.log(record.eventID);\n    console.log(record.eventName);\n    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);\n};\n\n",
                                    "  9.PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\DynamoDb\\DynamoDbHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends DynamoDbHandler\n{\n    private StderrLogger $logger;\n\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing DynamoDb table items\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            $eventName = $record->getEventName();\n            $keys = $record->getKeys();\n            $old = $record->getOldImage();\n            $new = $record->getNewImage();\n            \n            $this->logger->info(\"Event Name:\".$eventName.\"\\n\");\n            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");\n            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");\n            $this->logger->info(\"New Image:\". json_encode($new));\n            \n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords items\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                                    "  10.SDK for PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\DynamoDb\\DynamoDbHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends DynamoDbHandler\n{\n    private StderrLogger $logger;\n\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing DynamoDb table items\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            $eventName = $record->getEventName();\n            $keys = $record->getKeys();\n            $old = $record->getOldImage();\n            $new = $record->getNewImage();\n            \n            $this->logger->info(\"Event Name:\".$eventName.\"\\n\");\n            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");\n            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");\n            $this->logger->info(\"New Image:\". json_encode($new));\n            \n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords items\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                                    "  11.Python : \nimport json\n\ndef lambda_handler(event, context):\n    print(json.dumps(event, indent=2))\n\n    for record in event['Records']:\n        log_dynamodb_record(record)\n\ndef log_dynamodb_record(record):\n    print(record['eventID'])\n    print(record['eventName'])\n    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")\n\n",
                                    "  12.SDK for Python (Boto3) : \nimport json\n\ndef lambda_handler(event, context):\n    print(json.dumps(event, indent=2))\n\n    for record in event['Records']:\n        log_dynamodb_record(record)\n\ndef log_dynamodb_record(record):\n    print(record['eventID'])\n    print(record['eventName'])\n    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")\n\n",
                                    "  13.Ruby : \ndef lambda_handler(event:, context:)\n    return 'received empty event' if event['Records'].empty?\n  \n    event['Records'].each do |record|\n      log_dynamodb_record(record)\n    end\n  \n    \"Records processed: #{event['Records'].length}\"\n  end\n  \n  def log_dynamodb_record(record)\n    puts record['eventID']\n    puts record['eventName']\n    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"\n  end\n  \n",
                                    "  14.SDK for Ruby : \ndef lambda_handler(event:, context:)\n    return 'received empty event' if event['Records'].empty?\n  \n    event['Records'].each do |record|\n      log_dynamodb_record(record)\n    end\n  \n    \"Records processed: #{event['Records'].length}\"\n  end\n  \n  def log_dynamodb_record(record)\n    puts record['eventID']\n    puts record['eventName']\n    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"\n  end\n  \n",
                                    "  15.Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {\n    \n    let records = &event.payload.records;\n    tracing::info!(\"event payload: {:?}\",records);\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_dynamo_dbrecord(record);\n    }\n\n    tracing::info!(\"Dynamo db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{\n    tracing::info!(\"EventId: {}\", record.event_id);\n    tracing::info!(\"EventName: {}\", record.event_name);\n    tracing::info!(\"DynamoDB Record: {:?}\", record.change );\n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                                    "  16.SDK for Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {\n    \n    let records = &event.payload.records;\n    tracing::info!(\"event payload: {:?}\",records);\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_dynamo_dbrecord(record);\n    }\n\n    tracing::info!(\"Dynamo db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{\n    tracing::info!(\"EventId: {}\", record.event_id);\n    tracing::info!(\"EventName: {}\", record.event_name);\n    tracing::info!(\"DynamoDB Record: {:?}\", record.change );\n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        foreach (var record in dynamoEvent.Records)        {            context.Logger.LogInformation($\"Event ID: {record.EventID}\");            context.Logger.LogInformation($\"Event Name: {record.EventName}\");            context.Logger.LogInformation(JsonSerializer.Serialize(record));        }        context.Logger.LogInformation(\"Stream processing complete.\");    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-lambda-go/events\"\t\"fmt\")func HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\tif len(event.Records) == 0 {\t\treturn nil, fmt.Errorf(\"received empty event\")\t}\tfor _, record := range event.Records {\t \tLogDynamoDBRecord(record)\t}\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\treturn &message, nil}func main() {\tlambda.Start(HandleRequest)}func LogDynamoDBRecord(record events.DynamoDBEventRecord){\tfmt.Println(record.EventID)\tfmt.Println(record.EventName)\tfmt.Printf(\"%+v\\n\", record.Change)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;import com.google.gson.Gson;import com.google.gson.GsonBuilder;public class example implements RequestHandler<DynamodbEvent, Void> {    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();    @Override    public Void handleRequest(DynamodbEvent event, Context context) {        System.out.println(GSON.toJson(event));        event.getRecords().forEach(this::logDynamoDBRecord);        return null;    }    private void logDynamoDBRecord(DynamodbStreamRecord record) {        System.out.println(record.getEventID());        System.out.println(record.getEventName());        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {    console.log(JSON.stringify(event, null, 2));    event.Records.forEach(record => {        logDynamoDBRecord(record);    });};const logDynamoDBRecord = (record) => {    console.log(record.eventID);    console.log(record.eventName);    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);};Consuming a DynamoDB event with Lambda using TypeScript.export const handler = async (event, context) => {    console.log(JSON.stringify(event, null, 2));    event.Records.forEach(record => {        logDynamoDBRecord(record);    });}const logDynamoDBRecord = (record) => {    console.log(record.eventID);    console.log(record.eventName);    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using PHP.<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\DynamoDb\\DynamoDbEvent;use Bref\\Event\\DynamoDb\\DynamoDbHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends DynamoDbHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void    {        $this->logger->info(\"Processing DynamoDb table items\");        $records = $event->getRecords();        foreach ($records as $record) {            $eventName = $record->getEventName();            $keys = $record->getKeys();            $old = $record->getOldImage();            $new = $record->getNewImage();                        $this->logger->info(\"Event Name:\".$eventName.\"\\n\");            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");            $this->logger->info(\"New Image:\". json_encode($new));                        // TODO: Do interesting work based on the new data            // Any exception thrown will be logged and the invocation will be marked as failed        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords items\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Python.import jsondef lambda_handler(event, context):    print(json.dumps(event, indent=2))    for record in event['Records']:        log_dynamodb_record(record)def log_dynamodb_record(record):    print(record['eventID'])    print(record['eventName'])    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Ruby.def lambda_handler(event:, context:)    return 'received empty event' if event['Records'].empty?      event['Records'].each do |record|      log_dynamodb_record(record)    end      \"Records processed: #{event['Records'].length}\"  end    def log_dynamodb_record(record)    puts record['eventID']    puts record['eventName']    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"  end  RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Rust.use lambda_runtime::{service_fn, tracing, Error, LambdaEvent};use aws_lambda_events::{    event::dynamodb::{Event, EventRecord},   };// Built with the following dependencies://lambda_runtime = \"0.11.1\"//serde_json = \"1.0\"//tokio = { version = \"1\", features = [\"macros\"] }//tracing = { version = \"0.1\", features = [\"log\"] }//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }//aws_lambda_events = \"0.15.0\"async fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {        let records = &event.payload.records;    tracing::info!(\"event payload: {:?}\",records);    if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    for record in records{        log_dynamo_dbrecord(record);    }    tracing::info!(\"Dynamo db records processed\");    // Prepare the response    Ok(())}fn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{    tracing::info!(\"EventId: {}\", record.event_id);    tracing::info!(\"EventName: {}\", record.event_name);    tracing::info!(\"DynamoDB Record: {:?}\", record.change );    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()    .with_max_level(tracing::Level::INFO)    .with_target(false)    .without_time()    .init();    let func = service_fn(function_handler);    lambda_runtime::run(func).await?;    Ok(())    }",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        foreach (var record in dynamoEvent.Records)        {            context.Logger.LogInformation($\"Event ID: {record.EventID}\");            context.Logger.LogInformation($\"Event Name: {record.EventName}\");            context.Logger.LogInformation(JsonSerializer.Serialize(record));        }        context.Logger.LogInformation(\"Stream processing complete.\");    }}",
                                    "To create the function",
                                    "  1 : Copy the sample code into a file named example.js.",
                                    " 2 : Create a deployment package. ",
                                    {
                                        "code_example": "zip function.zip example.js"
                                    },
                                    " 3 : Create a Lambda function with the create-function command. ",
                                    {
                                        "code_example": "aws lambda create-function --function-name ProcessDynamoDBRecords \\\n    --zip-file fileb://function.zip --handler example.handler --runtime nodejs18.x \\\n    --role arn:aws:iam::111122223333:role/lambda-dynamodb-role"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Test the Lambda function",
                                "content": [
                                    "In this step, you invoke your Lambda function manually using the invoke AWS Lambda CLI command and      the following sample DynamoDB event. Copy the following into a file named input.txt.",
                                    "Example input.txt",
                                    {
                                        "code_example": "{\n   \"Records\":[\n      {\n         \"eventID\":\"1\",\n         \"eventName\":\"INSERT\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"NewImage\":{\n               \"Message\":{\n                  \"S\":\"New item!\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"111\",\n            \"SizeBytes\":26,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      },\n      {\n         \"eventID\":\"2\",\n         \"eventName\":\"MODIFY\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"NewImage\":{\n               \"Message\":{\n                  \"S\":\"This item has changed\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"OldImage\":{\n               \"Message\":{\n                  \"S\":\"New item!\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"222\",\n            \"SizeBytes\":59,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      },\n      {\n         \"eventID\":\"3\",\n         \"eventName\":\"REMOVE\",\n         \"eventVersion\":\"1.0\",\n         \"eventSource\":\"aws:dynamodb\",\n         \"awsRegion\":\"us-east-1\",\n         \"dynamodb\":{\n            \"Keys\":{\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"OldImage\":{\n               \"Message\":{\n                  \"S\":\"This item has changed\"\n               },\n               \"Id\":{\n                  \"N\":\"101\"\n               }\n            },\n            \"SequenceNumber\":\"333\",\n            \"SizeBytes\":38,\n            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n         },\n         \"eventSourceARN\":\"stream-ARN\"\n      }\n   ]\n}"
                                    },
                                    "Run the following invoke command. ",
                                    "aws lambda invoke --function-name ProcessDynamoDBRecords \\    --cli-binary-format raw-in-base64-out \\    --payload file://input.txt outputfile.txt",
                                    "The cli-binary-format option is required if you're using AWS CLI version 2. To make this the default setting, run aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide for Version 2.",
                                    "The function returns the string message in the response body. ",
                                    "Verify the output in the outputfile.txt file."
                                ]
                            },
                            {
                                "sub_header": "Create a DynamoDB table with a stream enabled",
                                "content": [
                                    "Create an Amazon DynamoDB table with a stream enabled.",
                                    "To create a DynamoDB table",
                                    "  1 : Open the DynamoDB console.",
                                    "  2 : Choose Create table.",
                                    "  3 : Create a table with the following settings.Table name – lambda-dynamodb-streamPrimary key – id (string)",
                                    "  4 : Choose Create.",
                                    "To enable streams",
                                    "  1 : Open the DynamoDB console.",
                                    "  2 : Choose Tables.",
                                    "  3 : Choose the lambda-dynamodb-stream table.",
                                    "  4 : Under Exports and streams, choose DynamoDB stream details.",
                                    "  5 : Choose Turn on.",
                                    "  6 : For View type, choose Key attributes only.",
                                    "  7 : Choose Turn on stream.",
                                    "Write down the stream ARN. You need this in the next step when you associate the stream with your Lambda      function. For more information on enabling streams, see Capturing table        activity with DynamoDB Streams."
                                ]
                            },
                            {
                                "sub_header": "Add an event source in AWS Lambda",
                                "content": [
                                    "Create an event source mapping in AWS Lambda. This event source mapping associates the DynamoDB stream with      your Lambda function. After you create this event source mapping, AWS Lambda starts polling the stream.",
                                    "Run the following AWS CLI create-event-source-mapping command. After the command runs, note      down the UUID. You'll need this UUID to refer to the event source mapping in any commands, for example, when      deleting the event source mapping.",
                                    "aws lambda create-event-source-mapping --function-name ProcessDynamoDBRecords \\    --batch-size 100 --starting-position LATEST --event-source DynamoDB-stream-arn",
                                    " This creates a mapping between the specified DynamoDB stream and the Lambda function. You can associate a DynamoDB      stream with multiple Lambda functions, and associate the same Lambda function with multiple streams. However, the      Lambda functions will share the read throughput for the stream they share. ",
                                    "You can get the list of event source mappings by running the following command.",
                                    "aws lambda list-event-source-mappings",
                                    "The list returns all of the event source mappings you created, and for each mapping it shows the        LastProcessingResult, among other things. This field is used to provide an informative message if      there are any problems. Values such as No records processed (indicates that AWS Lambda has not started      polling or that there are no records in the stream) and OK (indicates AWS Lambda successfully read      records from the stream and invoked your Lambda function) indicate that there are no issues. If there are issues,      you receive an error message.",
                                    "If you have a lot of event source mappings, use the function name parameter to narrow down the results.",
                                    "aws lambda list-event-source-mappings --function-name ProcessDynamoDBRecords"
                                ]
                            },
                            {
                                "sub_header": "Test the setup",
                                "content": [
                                    "Test the end-to-end experience. As you perform table updates, DynamoDB writes event records to the stream. As      AWS Lambda polls the stream, it detects new records in the stream and invokes your Lambda function on your behalf      by passing events to the function. ",
                                    "  1 : In the DynamoDB console, add, update, and delete items to the table. DynamoDB writes records of these actions to          the stream.",
                                    "  2 : AWS Lambda polls the stream and when it detects updates to the stream, it invokes your Lambda function by          passing in the event data it finds in the stream.",
                                    "  3 : Your function runs and creates logs in Amazon CloudWatch. You can verify the logs reported in the Amazon CloudWatch          console."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the DynamoDB table",
                                    "  1 : Open the Tables page of the DynamoDB console.",
                                    "  2 : Select the table you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter delete in the text box.",
                                    "  5 : Choose Delete table."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "Note",
                    "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                    "You can use an AWS Lambda function to process records in an Amazon DynamoDB      stream. With DynamoDB Streams, you can trigger a Lambda function to perform additional work each time a DynamoDB table is    updated.",
                    "Topics",
                    {
                        "sub_header": "Polling and batching streams",
                        "content": [
                            "Lambda polls shards in your DynamoDB stream for records at a base rate of 4 times per second. When records are      available, Lambda invokes your function and waits for the result. If processing succeeds, Lambda resumes polling until      it receives more records.",
                            "By default, Lambda invokes your function as soon as records are available. If the batch      that Lambda reads from the event source has only one record in it, Lambda sends only one record to the function. To avoid invoking the function      with a small number of records, you can tell the event source to buffer records for up to 5 minutes by configuring a        batching window. Before invoking the function, Lambda continues to read records from the event source      until it has gathered a full batch, the batching window expires, or the batch reaches the payload limit of 6 MB. For more information,      see Batching behavior.",
                            "Warning",
                            "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                            "Lambda doesn't wait for any configured extensions to complete      before sending the next batch for processing. In other words, your extensions may continue to run as Lambda      processes the next batch of records. This can cause throttling issues if you breach any of your account's       concurrency settings or limits. To detect whether this is a      potential issue, monitor your functions and check whether you're seeing higher      concurrency metrics than expected for your event      source mapping. Due to short times in between invokes, Lambda may briefly report higher concurrency usage      than the number of shards. This can be true even for Lambda functions without extensions.",
                            "Configure the       ParallelizationFactor setting to process one shard of a DynamoDB stream with more than one Lambda invocation simultaneously.       You can specify the number of concurrent batches that Lambda polls from a shard via a parallelization factor from 1      (default) to 10. For example, when you set ParallelizationFactor to 2, you can have 200 concurrent      Lambda invocations at maximum to process 100 DynamoDB stream shards (though in practice, you may see different values      for the ConcurrentExecutions metric). This helps scale up the processing throughput when the data volume      is volatile and the IteratorAge is high. When you increase the number of concurrent batches per shard,      Lambda still ensures in-order processing at the item (partition and sort key) level."
                        ]
                    },
                    {
                        "sub_header": "Polling and stream starting positions",
                        "content": [
                            "Be aware that stream polling during event source mapping creation and updates is eventually consistent.",
                            "  1.During event source mapping creation, it may take several minutes to start polling events from the stream.",
                            "  2.During event source mapping updates, it may take several minutes to stop and restart polling events from the stream.",
                            "This behavior means that if you specify LATEST as the starting position for the stream, the event source mapping could     miss events during creation or updates. To ensure that no events are missed, specify the stream starting position as TRIM_HORIZON."
                        ]
                    },
                    {
                        "sub_header": "Simultaneous readers of a shard in DynamoDB Streams",
                        "content": [
                            "For single-Region tables that are not global tables, you can design for up to two Lambda functions to read from the same DynamoDB Streams shard at the same time. Exceeding this limit can result in request throttling.      For global tables, we recommend you limit the number of simultaneous functions to one to avoid request throttling."
                        ]
                    },
                    {
                        "sub_header": "Example event",
                        "content": [
                            {
                                "code_example": "{\n  \"Records\": [\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"New item!\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"111\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"arn:aws:dynamodb:us-east-2:123456789012:table/my-table/stream/2024-06-10T19:26:16.525\",\n      \"eventSource\": \"aws:dynamodb\"\n    },\n    {\n      \"eventID\": \"2\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"OldImage\": {\n          \"Message\": {\n            \"S\": \"New item!\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"SequenceNumber\": \"222\",\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"SizeBytes\": 59,\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"This item has changed\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"MODIFY\",\n      \"eventSourceARN\": \"arn:aws:dynamodb:us-east-2:123456789012:table/my-table/stream/2024-06-10T19:26:16.525\",\n      \"eventSource\": \"aws:dynamodb\"\n    }\n  ]}"
                            }
                        ]
                    }
                ]
            },
            {
                "title": "EC2",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-ec2.html",
                "sections": [
                    "You can use AWS Lambda to process lifecycle events from Amazon Elastic Compute Cloud and manage Amazon EC2 resources. Amazon EC2 sends events    to Amazon EventBridge (CloudWatch Events) for    lifecycle events    such as when an instance changes state, when an Amazon Elastic Block Store volume snapshot completes, or when a spot instance    is scheduled to be terminated. You configure EventBridge (CloudWatch Events) to forward those events to a Lambda function for processing.",
                    "EventBridge (CloudWatch Events) invokes your Lambda function asynchronously with the event document from Amazon EC2.",
                    "Example instance lifecycle event",
                    {
                        "code_example": "{\n    \"version\": \"0\",\n    \"id\": \"b6ba298a-7732-2226-xmpl-976312c1a050\",\n    \"detail-type\": \"EC2 Instance State-change Notification\",\n    \"source\": \"aws.ec2\",\n    \"account\": \"111122223333\",\n    \"time\": \"2019-10-02T17:59:30Z\",\n    \"region\": \"us-east-1\",\n    \"resources\": [\n        \"arn:aws:ec2:us-east-1:111122223333:instance/i-0c314xmplcd5b8173\"\n    ],\n    \"detail\": {\n        \"instance-id\": \"i-0c314xmplcd5b8173\",\n        \"state\": \"running\"\n    }\n}\n"
                    },
                    "For details on configuring events, see Invoke a Lambda function on a schedule. For an example function that processes Amazon EBS snapshot notifications, see    EventBridge Scheduler for Amazon EBS.",
                    "You can also use the AWS SDK to manage instances and other resources with the Amazon EC2 API.         ",
                    {
                        "sub_header": "Granting permissions to EventBridge (CloudWatch Events)",
                        "content": [
                            "To process lifecycle events from Amazon EC2, EventBridge (CloudWatch Events) needs permission to invoke your function. This permission comes      from the function's resource-based policy. If you use the      EventBridge (CloudWatch Events) console to configure an event trigger, the console updates the resource-based policy on your behalf.      Otherwise, add a statement like the following:",
                            "Example resource-based policy statement for Amazon EC2 lifecycle notifications",
                            {
                                "code_example": "{\n  \"Sid\": \"ec2-events\",\n  \"Effect\": \"Allow\",\n  \"Principal\": {\n    \"Service\": \"events.amazonaws.com\"\n  },\n  \"Action\": \"lambda:InvokeFunction\",\n  \"Resource\": \"arn:aws:lambda:us-east-1:12456789012:function:my-function\",\n  \"Condition\": {\n    \"ArnLike\": {\n      \"AWS:SourceArn\": \"arn:aws:events:us-east-1:12456789012:rule/*\"\n    }\n  }\n}"
                            },
                            "To add a statement, use the add-permission AWS CLI command.",
                            "aws lambda add-permission --action lambda:InvokeFunction --statement-id ec2-events \\--principal events.amazonaws.com --function-name my-function --source-arn 'arn:aws:events:us-east-1:12456789012:rule/*'",
                            "If your function uses the AWS SDK to manage Amazon EC2 resources, add Amazon EC2 permissions to the function's execution role."
                        ]
                    }
                ]
            },
            {
                "title": "Elastic Load Balancing (Application Load Balancer)",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-alb.html",
                "sections": [
                    "You can use a Lambda function to process requests from an Application Load Balancer. Elastic Load Balancing supports Lambda functions as a target for    an Application Load Balancer. Use load balancer rules to route HTTP requests to a function, based on path or header values. Process the    request and return an HTTP response from your Lambda function.",
                    "Elastic Load Balancing invokes your Lambda function synchronously with an event that contains the request body and    metadata.",
                    "Example Application Load Balancer request event",
                    {
                        "code_example": "{\n    \"requestContext\": {\n        \"elb\": {\n            \"targetGroupArn\": \"arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/lambda-279XGJDqGZ5rsrHC2Fjr/49e9d65c45c6791a\"\n        }\n    },\n    \"httpMethod\": \"GET\",\n    \"path\": \"/lambda\",\n    \"queryStringParameters\": {\n        \"query\": \"1234ABCD\"\n    },\n    \"headers\": {\n        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n        \"accept-encoding\": \"gzip\",\n        \"accept-language\": \"en-US,en;q=0.9\",\n        \"connection\": \"keep-alive\",\n        \"host\": \"lambda-alb-123578498.us-east-1.elb.amazonaws.com\",\n        \"upgrade-insecure-requests\": \"1\",\n        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\",\n        \"x-amzn-trace-id\": \"Root=1-5c536348-3d683b8b04734faae651f476\",\n        \"x-forwarded-for\": \"72.12.164.125\",\n        \"x-forwarded-port\": \"80\",\n        \"x-forwarded-proto\": \"http\",\n        \"x-imforwards\": \"20\"\n    },\n    \"body\": \"\",\n    \"isBase64Encoded\": False\n}"
                    },
                    "Your function processes the event and returns a response document to the load balancer in JSON. Elastic Load Balancing converts    the document to an HTTP success or error response and returns it to the user.",
                    "Example response document format",
                    {
                        "code_example": "{\n    \"statusCode\": 200,\n    \"statusDescription\": \"200 OK\",\n    \"isBase64Encoded\": False,\n    \"headers\": {\n        \"Content-Type\": \"text/html\"\n    },\n    \"body\": \"<h1>Hello from Lambda!</h1>\"\n}"
                    },
                    "To configure an Application Load Balancer as a function trigger, grant Elastic Load Balancing permission to run the function, create a target    group that routes requests to the function, and add a rule to the load balancer that sends requests to the target    group.",
                    "Use the add-permission command to add a permission statement to your function's resource-based    policy.",
                    "aws lambda add-permission --function-name alb-function \\--statement-id load-balancer --action \"lambda:InvokeFunction\" \\--principal elasticloadbalancing.amazonaws.com",
                    "You should see the following output:",
                    "{    \"Statement\": \"{\\\"Sid\\\":\\\"load-balancer\\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"elasticloadbalancing.amazonaws.com\\\"},\\\"Action\\\":\\\"lambda:InvokeFunction\\\",\\\"Resource\\\":\\\"arn:aws:lambda:us-west-2:123456789012:function:alb-function\\\"}\"}",
                    "For instructions on configuring the Application Load Balancer listener and target group, see Lambda functions as a target in the      User Guide for Application Load Balancers."
                ]
            },
            {
                "title": "Invoke using an EventBridge Scheduler",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-eventbridge-scheduler.html",
                "sections": [
                    "Amazon EventBridge Scheduler is a serverless scheduler that allows you to create, run, and manage tasks    from one central, managed service. With EventBridge Scheduler, you can create schedules using cron and rate expressions for recurring patterns, or configure one-time invocations. You can set    up flexible time windows for delivery, define retry limits, and set the maximum retention time for unprocessed events.",
                    "When you set up EventBridge Scheduler with Lambda, EventBridge Scheduler invokes your Lambda function asynchronously.      This page explains how to use EventBridge Scheduler to invoke a Lambda function on a schedule.",
                    {
                        "sub_header": "Set up the execution role",
                        "content": [
                            " When you create a new schedule, EventBridge Scheduler must have permission to invoke its target API operation on your behalf. You grant these permissions to EventBridge Scheduler        using an execution role. The permission policy you attach to your schedule's execution role defines the required permissions.        These permissions depend on the target API you want EventBridge Scheduler to invoke.",
                            "        When you use the EventBridge Scheduler console to create a schedule, as in the following procedure, EventBridge Scheduler automatically sets up an execution role based on your selected target.        If you want to create a schedule using one of the EventBridge Scheduler SDKs, the AWS CLI, or AWS CloudFormation, you must have an existing execution role that grants the permissions        EventBridge Scheduler requires to invoke a target. For more information about manually setting up an execution role for your schedule, see Setting up an execution role        in the EventBridge Scheduler User Guide.    "
                        ]
                    },
                    {
                        "sub_header": "Create a schedule",
                        "content": [
                            "To create a schedule by using the console",
                            "  1 : Open the Amazon EventBridge Scheduler console at https://console.aws.amazon.com/scheduler/home.",
                            "  2 :                         On the Schedules page, choose Create schedule.                    ",
                            "  3 :                         On the Specify schedule detail page, in the Schedule name and description section, do the following:                    For Schedule name, enter a name for your                                schedule. For example, MyTestSchedule. (Optional) For Description, enter a                                description for your schedule. For example, My first                                    schedule.For Schedule group, choose a schedule group from                                the dropdown list. If you don't have a group, choose                                    default. To create a schedule group, choose                                    create your own schedule. You use schedule groups to add tags to groups of schedules. ",
                            "  4 : Choose your schedule options.OccurrenceDo this...One-time scheduleA one-time schedule invokes a target only once                                                    at the date and time that you specify. For Date and time, do the                                                    following:Enter a valid date in                                                            YYYY/MM/DD format.Enter a timestamp in 24-hour                                                            hh:mm format.For Timezone, choose                                                            the timezone.Recurring scheduleA recurring schedule invokes a target at a                                                    rate that you specify using a                                                    cron expression or rate                                                    expression. For Schedule type, do                                                            one of the following:To use a cron expression to define the                                                                    schedule, choose Cron-based                                                                        schedule and enter the cron                                                                    expression.To use a rate expression to define the                                                                    schedule, choose Rate-based                                                                        schedule and enter the rate                                                                    expression.For more information about cron and rate                                                                    expressions, see Schedule types on EventBridge Scheduler in the Amazon EventBridge Scheduler User Guide.                                                                For Flexible time                                                            window, choose Off                                                            to turn off the option, or choose one of the                                                            pre-defined time windows.                                                            For example, if you choose 15                                                                minutes and you set a recurring                                                            schedule to invoke its target once every hour, the                                                            schedule runs within 15 minutes after the start of                                                            every hour. ",
                            "  5 : (Optional) If you chose Recurring schedule in the previous step,                        in the Timeframe section, do the following: For Timezone,                                choose a timezone. For Start date and time, enter a valid date in                                    YYYY/MM/DD format, and then specify a timestamp in                                24-hour hh:mm format. For End date and time, enter a valid date in                                    YYYY/MM/DD format, and then specify a timestamp in                                24-hour hh:mm format. ",
                            "  6 : Choose Next. ",
                            "  7 : On the Select target page, choose the AWS API operation that EventBridge Scheduler invokes: Choose AWS Lambda Invoke.In the Invoke section, select a function or choose Create new Lambda function.(Optional) Enter a JSON payload. If you don't enter a payload, EventBridge Scheduler uses an empty event to invoke the function.",
                            "  8 : Choose Next. ",
                            "  9 : On the Settings page, do the following: To turn on the schedule, under Schedule                                state, toggle Enable schedule. To configure a retry policy for your schedule, under                                Retry policy and dead-letter queue (DLQ),                                do the following:Toggle Retry.For Maximum age of event,                                        enter the maximum hour(s) and                                        min(s) that EventBridge Scheduler must keep an                                        unprocessed event.The maximum time is 24 hours.For Maximum retries, enter the                                        maximum number of times EventBridge Scheduler retries the schedule if the                                        target returns an error.   The maximum value is 185 retries. With retry policies, if a schedule fails to invoke its target,                                EventBridge Scheduler re-runs the schedule. If configured, you must set the maximum                                retention time and retries for the schedule.Choose where EventBridge Scheduler stores undelivered events. Dead-letter queue (DLQ)                                                optionDo this...Don't storeChoose None.Store the event in the same AWS account where                                                you're creating the scheduleChoose Select an Amazon SQS queue in                                                      my AWS account as a DLQ.Choose the Amazon Resource Name (ARN) of                                                      the Amazon SQS queue. Store the event in a different AWS account from                                                where you're creating the scheduleChoose Specify an Amazon SQS queue in                                                      other AWS accounts as a DLQ.Enter the Amazon Resource Name (ARN) of                                                      the Amazon SQS queue. To use a customer managed key to encrypt your target input, under                                    Encryption, choose Customize                                    encryption settings (advanced). If you choose this option, enter an existing KMS key ARN or choose                                    Create an AWS KMS key to navigate to the                                AWS KMS console. For more information about how EventBridge Scheduler encrypts your data                                at rest, see Encryption at                                    rest in the Amazon EventBridge Scheduler User                                    Guide. To have EventBridge Scheduler create a new execution role for you, choose                                Create new role for this schedule.                                Then, enter a name for Role name. If you choose                                this option, EventBridge Scheduler attaches the required permissions necessary for                                your templated target to the role.",
                            "  10 : Choose Next. ",
                            "  11 :  In the Review and create schedule page, review the                        details of your schedule. In each section, choose Edit to                        go back to that step and edit its details. ",
                            "  12 : Choose Create schedule. You can view a list of your new and existing schedules on the                        Schedules page. Under the                        Status column, verify that your new schedule is                        Enabled. ",
                            "To confirm that EventBridge Scheduler invoked the function, check the function's Amazon CloudWatch logs."
                        ]
                    },
                    {
                        "sub_header": "Related resources",
                        "content": [
                            "        For more information about EventBridge Scheduler, see the following:    ",
                            "  1.EventBridge Scheduler User Guide",
                            "  2.EventBridge Scheduler API Reference",
                            "  3.EventBridge Scheduler Pricing"
                        ]
                    }
                ]
            },
            {
                "title": "IoT",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-iot.html",
                "sections": [
                    "AWS IoT provides secure communication between internet-connected devices (such as sensors) and the AWS Cloud.    This makes it possible for you to collect, store, and analyze telemetry data from multiple devices.",
                    "You can create AWS IoT rules for your devices to interact with AWS services. The AWS IoT Rules Engine provides a SQL-based language to select data    from message payloads and send the data to other services, such as Amazon S3, Amazon DynamoDB, and AWS Lambda. You define a rule    to invoke a Lambda function when you want to invoke another AWS service or a third-party service. ",
                    "When an incoming IoT message triggers the rule, AWS IoT invokes your Lambda function asynchronously and passes data from the IoT message to the function. ",
                    "The following example shows a moisture reading from a greenhouse sensor. The row and pos values identify the location of the sensor. This example    event is based on the greenhouse type in the AWS IoT Rules tutorials. ",
                    "Example AWS IoT message event",
                    {
                        "code_example": "\n{\n    \"row\" : \"10\",\n    \"pos\" : \"23\",\n    \"moisture\" : \"75\"\n}"
                    },
                    "For asynchronous invocation, Lambda queues the message and retries  if your function returns an error. Configure your function with a destination to retain  events that your function could not process.",
                    "You need to grant permission for the AWS IoT service to invoke your Lambda function. Use the      add-permission command to add a permission statement to your function's resource-based policy.",
                    "aws lambda add-permission --function-name my-function \\--statement-id iot-events --action \"lambda:InvokeFunction\" --principal iot.amazonaws.com",
                    "You should see the following output:",
                    "{    \"Statement\": \"{\\\"Sid\\\":\\\"iot-events\\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"iot.amazonaws.com\\\"},\\\"Action\\\":\\\"lambda:InvokeFunction\\\",\\\"Resource\\\":\\\"arn:aws:lambda:us-east-1:123456789012:function:my-function\\\"}\"} ",
                    "For more information about how to use Lambda with AWS IoT, see Creating an AWS Lambda rule.  "
                ]
            },
            {
                "title": "Kinesis Data Streams",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html",
                "contents": [
                    {
                        "title": "Create mapping",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-kinesis-create.html",
                        "sections": [
                            "To process Amazon Kinesis Data Streams records with Lambda, create a consumer for your stream and then create a Lambda event source mapping.",
                            {
                                "sub_header": "Configuring your data stream and function",
                                "content": [
                                    "Your Lambda function is a consumer application for your data stream. It processes one batch of records at a      time from each shard. You can map a Lambda function to a shared-throughput consumer (standard iterator), or to a dedicated-throughput consumer with enhanced fan-out.",
                                    "  1.Standard iterator: :  Lambda polls each shard in your Kinesis stream for records at a base rate of once per          second. When more records are available, Lambda keeps processing batches until the function catches up with the          stream. The event source mapping shares read throughput with other consumers of the shard.",
                                    "  2.Enhanced fan-out: :  To minimize latency and maximize read throughput, create a data stream consumer with enhanced fan-out. Enhanced fan-out consumers get a dedicated connection to each shard that doesn't impact other applications reading from the stream. Stream consumers use HTTP/2 to reduce latency by pushing records to Lambda over a long-lived          connection and by compressing request headers. You can create a stream consumer with the Kinesis RegisterStreamConsumer API.",
                                    "aws kinesis register-stream-consumer \\--consumer-name con1 \\--stream-arn arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream",
                                    "You should see the following output:",
                                    "{    \"Consumer\": {        \"ConsumerName\": \"con1\",        \"ConsumerARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream/consumer/con1:1540591608\",        \"ConsumerStatus\": \"CREATING\",        \"ConsumerCreationTimestamp\": 1540591608.0    }}",
                                    "To increase the speed at which your function processes records, add shards to your data stream. Lambda      processes records in each shard in order. It stops processing additional records in a shard if your function      returns an error. With more shards, there are more batches being processed at once, which lowers the impact of      errors on concurrency.",
                                    "If your function can't scale up to handle the total number of concurrent batches, request a quota increase or reserve concurrency for your function."
                                ]
                            },
                            {
                                "sub_header": "Create an event source mapping to invoke a Lambda function",
                                "content": [
                                    "To invoke your Lambda function with records from your data stream, create an event source mapping.       You can create multiple event source mappings to process the same data with multiple Lambda functions, or to process items       from multiple data streams with a single function. When processing items from multiple streams, each batch contains records       from only a single shard or stream.",
                                    "You can configure event source mappings to process records from a stream in a different AWS account.       To learn more, see Creating a cross-account event source mapping.",
                                    "Before you create an event source mapping, you need to give your Lambda function permission to read from a Kinesis data stream.       Lambda needs the following permissions to manage resources related to your Kinesis data stream:",
                                    "  1.kinesis:DescribeStream",
                                    "  2.kinesis:DescribeStreamSummary",
                                    "  3.kinesis:GetRecords",
                                    "  4.kinesis:GetShardIterator",
                                    "  5.kinesis:ListShards",
                                    "  6.kinesis:ListStreams",
                                    "  7.kinesis:SubscribeToShard",
                                    "The AWS managed policy AWSLambdaKinesisExecutionRole       includes these permissions. Add this managed policy to your function as described in the following procedure.",
                                    "  1.AWS Management Console : AWSLambdaKinesisExecutionRole",
                                    "  2.AWS CLI : AWSLambdaKinesisExecutionRole",
                                    "  3.AWS SAM : Policies",
                                    "AWS Management ConsoleTo add Kinesis permissions to your functionOpen the Functions page of the Lambda console           and select your function.In the Configuration tab, select Permissions.In the Execution role pane, under Role name, choose the link to           your function’s execution role. This link opens the page for that role in the IAM console.In the Permissions policies pane, choose Add permissions, then           select Attach policies.In the search field, enter AWSLambdaKinesisExecutionRole.Select the checkbox next to the policy and choose Add permission.AWS CLITo add Kinesis permissions to your functionRun the following CLI command to add the AWSLambdaKinesisExecutionRole policy to your function’s execution role:aws iam attach-role-policy \\--role-name MyFunctionRole \\--policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaKinesisExecutionRoleAWS SAMTo add Kinesis permissions to your functionIn your function’s definition, add the Policies property as shown in the following example:Resources:  MyFunction:    Type: AWS::Serverless::Function    Properties:      CodeUri: ./my-function/      Handler: index.handler      Runtime: nodejs22.x      Policies:        - AWSLambdaKinesisExecutionRole",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add Kinesis permissions to your function",
                                    "  1 : Open the Functions page of the Lambda console           and select your function.",
                                    "  2 : In the Configuration tab, select Permissions.",
                                    "  3 : In the Execution role pane, under Role name, choose the link to           your function’s execution role. This link opens the page for that role in the IAM console.",
                                    "  4 : In the Permissions policies pane, choose Add permissions, then           select Attach policies.",
                                    "  5 : In the search field, enter AWSLambdaKinesisExecutionRole.",
                                    "  6 : Select the checkbox next to the policy and choose Add permission.",
                                    "After configuring the required permissions, create the event source mapping.",
                                    "  1.AWS Management Console : \nTo create the Kinesis event source mapping\nOpen the Functions page of the Lambda console \n                and select your function.\n\nIn the Function overview pane, choose Add trigger.\n\nUnder Trigger configuration, for the source, select Kinesis.\n\nSelect the Kinesis stream you want to create the event source mapping for and, optionally, a consumer of your stream.\n\n(Optional) edit the Batch size, Starting position, and Batch window \n                for your event source mapping.\n\nChoose Add.\n\nWhen creating your event source mapping from the console, your IAM role must have the\n            kinesis:ListStreams and\n            kinesis:ListStreamConsumers permissions.\n",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n--function-name MyFunction \\\n--event-source-arn arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream \\\n--starting-position LATEST \\\n--batch-size 100",
                                    "  3.AWS SAM : KinesisEvent",
                                    "AWS Management ConsoleTo create the Kinesis event source mappingOpen the Functions page of the Lambda console                 and select your function.In the Function overview pane, choose Add trigger.Under Trigger configuration, for the source, select Kinesis.Select the Kinesis stream you want to create the event source mapping for and, optionally, a consumer of your stream.(Optional) edit the Batch size, Starting position, and Batch window                 for your event source mapping.Choose Add.When creating your event source mapping from the console, your IAM role must have the            kinesis:ListStreams and            kinesis:ListStreamConsumers permissions.AWS CLITo create the Kinesis event source mappingRun the following CLI command to create a Kinesis event source mapping. Choose your own batch size and starting                 position according to your use case.aws lambda create-event-source-mapping \\--function-name MyFunction \\--event-source-arn arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream \\--starting-position LATEST \\--batch-size 100To specify a batching window, add the --maximum-batching-window-in-seconds option. For more information about using this and other parameters, see create-event-source-mapping             in the AWS CLI Command Reference.AWS SAMTo create the Kinesis event source mappingIn your function’s definition, add the KinesisEvent property as shown in the following example:Resources:  MyFunction:    Type: AWS::Serverless::Function    Properties:      CodeUri: ./my-function/      Handler: index.handler      Runtime: nodejs22.x      Policies:        - AWSLambdaKinesisExecutionRole      Events:        KinesisEvent:          Type: Kinesis          Properties:            Stream: !GetAtt MyKinesisStream.Arn            StartingPosition: LATEST            BatchSize: 100  MyKinesisStream:    Type: AWS::Kinesis::Stream    Properties:      ShardCount: 1To learn more about creating an event source mapping for Kinesis Data Streams in AWS SAM, see Kinesis             in the AWS Serverless Application Model Developer Guide.",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To create the Kinesis event source mapping",
                                    "  1 : Open the Functions page of the Lambda console                 and select your function.",
                                    "  2 : In the Function overview pane, choose Add trigger.",
                                    "  3 : Under Trigger configuration, for the source, select Kinesis.",
                                    "  4 : Select the Kinesis stream you want to create the event source mapping for and, optionally, a consumer of your stream.",
                                    "  5 : (Optional) edit the Batch size, Starting position, and Batch window                 for your event source mapping.",
                                    "  6 : Choose Add.",
                                    "When creating your event source mapping from the console, your IAM role must have the            kinesis:ListStreams and            kinesis:ListStreamConsumers permissions."
                                ]
                            },
                            {
                                "sub_header": "Polling and stream starting position",
                                "content": [
                                    "Be aware that stream polling during event source mapping creation and updates is eventually consistent.",
                                    "  1.During event source mapping creation, it may take several minutes to start polling events from the stream.",
                                    "  2.During event source mapping updates, it may take several minutes to stop and restart polling events from the stream.",
                                    "This behavior means that if you specify LATEST as the starting position for the stream, the event source mapping could     miss events during creation or updates. To ensure that no events are missed, specify the stream starting position as TRIM_HORIZON     or AT_TIMESTAMP."
                                ]
                            },
                            {
                                "sub_header": "Creating a cross-account event source mapping",
                                "content": [
                                    "Amazon Kinesis Data Streams supports resource-based policies.       Because of this, you can process data ingested into a stream in one AWS account with a Lambda function in another account.",
                                    "To create an event source mapping for your Lambda function using a Kinesis stream in a different AWS account, you must       configure the stream using a resource-based policy to give your Lambda function permission to read items. To learn how to       configure your stream to allow cross-account access, see Sharing access with cross-account AWS Lambda functions       in the Amazon Kinesis Streams Developer guide.",
                                    "Once you’ve configured your stream with a resource-based policy that gives your Lambda function the required       permissions, create the event source mapping using any of the methods described in the previous section.",
                                    "If you choose to create your event source mapping using the Lambda console, paste the ARN of your stream directly       into the input field. If you want to specify a consumer for your stream, pasting the ARN of the       consumer automatically populates the stream field."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Batch item failures",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-kinesis-batchfailurereporting.html",
                        "sections": [
                            "When consuming and processing streaming data from an event source, by default Lambda checkpoints to the highest    sequence number of a batch only when the batch is a complete success. Lambda treats all other results as a complete    failure and retries processing the batch up to the retry limit. To allow for partial successes while processing    batches from a stream, turn on ReportBatchItemFailures. Allowing partial successes can help to reduce    the number of retries on a record, though it doesn’t entirely prevent the possibility of retries in a successful record.",
                            "To turn on ReportBatchItemFailures, include the enum value    ReportBatchItemFailures in the FunctionResponseTypes list. This list indicates    which response types are enabled for your function. You can configure this list when you create or update an event source mapping.",
                            {
                                "sub_header": "Report syntax",
                                "content": [
                                    "When configuring reporting on batch item failures, the StreamsEventResponse class is returned with a      list of batch item failures. You can use a StreamsEventResponse object to return the sequence number      of the first failed record in the batch. You can also create your own custom class using the correct response      syntax. The following JSON structure shows the required response syntax:",
                                    "{   \"batchItemFailures\": [         {            \"itemIdentifier\": \"<SequenceNumber>\"        }    ]}",
                                    "Note",
                                    "If the batchItemFailures array contains multiple items, Lambda uses the record with the lowest      sequence number as the checkpoint. Lambda then retries all records starting from that checkpoint."
                                ]
                            },
                            {
                                "sub_header": "Success and failure conditions",
                                "content": [
                                    "Lambda treats a batch as a complete success if you return any of the following:",
                                    "  1.An empty batchItemFailure list",
                                    "  2.A null batchItemFailure list",
                                    "  3.An empty EventResponse",
                                    "  4.A null EventResponse",
                                    "Lambda treats a batch as a complete failure if you return any of the following:",
                                    "  1.An empty string itemIdentifier",
                                    "  2.A null itemIdentifier",
                                    "  3.An itemIdentifier with a bad key name",
                                    "Lambda retries failures based on your retry strategy."
                                ]
                            },
                            {
                                "sub_header": "Bisecting a batch",
                                "content": [
                                    "If your invocation fails and BisectBatchOnFunctionError is turned on, the batch is bisected      regardless of your ReportBatchItemFailures setting.",
                                    "When a partial batch success response is received and both BisectBatchOnFunctionError and        ReportBatchItemFailures are turned on, the batch is bisected at the returned sequence number and      Lambda retries only the remaining records.",
                                    "Here are some examples of function code that return the list of failed message IDs in the batch:",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tcurRecordSequenceNumber := \"\"\n\n\t\t// Process your record\n\t\tif /* Your record processing condition here */ {\n\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\n\t\t}\n\n\t\t// Add a condition to check if the record processing failed\n\t\tif curRecordSequenceNumber != \"\" {\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\n\t\t}\n\t}\n\n\tkinesisBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn kinesisBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tcurRecordSequenceNumber := \"\"\n\n\t\t// Process your record\n\t\tif /* Your record processing condition here */ {\n\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\n\t\t}\n\n\t\t// Add a condition to check if the record processing failed\n\t\tif curRecordSequenceNumber != \"\" {\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\n\t\t}\n\t}\n\n\tkinesisBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn kinesisBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {\n\n    @Override\n    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {\n            try {\n                //Process your record\n                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();\n                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();\n\n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse(batchItemFailures);   \n    }\n}\n\n",
                                    "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {\n\n    @Override\n    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {\n            try {\n                //Process your record\n                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();\n                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();\n\n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse(batchItemFailures);   \n    }\n}\n\n",
                                    "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n      return {\n        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],\n      };\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n  return { batchItemFailures: [] };\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                                    "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n      return {\n        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],\n      };\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n  return { batchItemFailures: [] };\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                                    "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $kinesisEvent = new KinesisEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kinesisEvent->getRecords();\n\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $kinesisEvent = new KinesisEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kinesisEvent->getRecords();\n\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                                    "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                                    "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  batch_item_failures = []\n\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue StandardError => err\n      puts \"An error occurred #{err}\"\n      # Since we are working with streams, we can return the failed item immediately.\n      # Lambda will immediately begin to retry processing from this failed item onwards.\n      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }\n    end\n  end\n\n  puts \"Successfully processed #{event['Records'].length} records.\"\n  { batchItemFailures: batch_item_failures }\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('utf-8')\n  # Placeholder for actual async work\n  sleep(1)\n  data\nend\n",
                                    "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  batch_item_failures = []\n\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue StandardError => err\n      puts \"An error occurred #{err}\"\n      # Since we are working with streams, we can return the failed item immediately.\n      # Lambda will immediately begin to retry processing from this failed item onwards.\n      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }\n    end\n  end\n\n  puts \"Successfully processed #{event['Records'].length} records.\"\n  { batchItemFailures: batch_item_failures }\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('utf-8')\n  # Placeholder for actual async work\n  sleep(1)\n  data\nend\n",
                                    "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::kinesis::KinesisEvent,\n    kinesis::KinesisEventRecord,\n    streams::{KinesisBatchItemFailure, KinesisEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {\n    let mut response = KinesisEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in &event.payload.records {\n        tracing::info!(\n            \"EventId: {}\",\n            record.event_id.as_deref().unwrap_or_default()\n        );\n\n        let record_processing_result = process_record(record);\n\n        if record_processing_result.is_err() {\n            response.batch_item_failures.push(KinesisBatchItemFailure {\n                item_identifier: record.kinesis.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(response)\n}\n\nfn process_record(record: &KinesisEventRecord) -> Result<(), Error> {\n    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());\n\n    if let Some(err) = record_data.err() {\n        tracing::error!(\"Error: {}\", err);\n        return Err(Error::from(err));\n    }\n\n    let record_data = record_data.unwrap_or_default();\n\n    // do something interesting with the data\n    tracing::info!(\"Data: {}\", record_data);\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::kinesis::KinesisEvent,\n    kinesis::KinesisEventRecord,\n    streams::{KinesisBatchItemFailure, KinesisEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {\n    let mut response = KinesisEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in &event.payload.records {\n        tracing::info!(\n            \"EventId: {}\",\n            record.event_id.as_deref().unwrap_or_default()\n        );\n\n        let record_processing_result = process_record(record);\n\n        if record_processing_result.is_err() {\n            response.batch_item_failures.push(KinesisBatchItemFailure {\n                item_identifier: record.kinesis.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(response)\n}\n\nfn process_record(record: &KinesisEventRecord) -> Result<(), Error> {\n    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());\n\n    if let Some(err) = record_data.err() {\n        tracing::error!(\"Error: {}\", err);\n        return Err(Error::from(err));\n    }\n\n    let record_data = record_data.unwrap_or_default();\n\n    // do something interesting with the data\n    tracing::info!(\"Data: {}\", record_data);\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using System.Text.Json.Serialization;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegration;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return new StreamsEventResponse();        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                return new StreamsEventResponse                {                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>                    {                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }                    }                };            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");        return new StreamsEventResponse();    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}public class StreamsEventResponse{    [JsonPropertyName(\"batchItemFailures\")]    public IList<BatchItemFailure> BatchItemFailures { get; set; }    public class BatchItemFailure    {        [JsonPropertyName(\"itemIdentifier\")]        public string ItemIdentifier { get; set; }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\tbatchItemFailures := []map[string]interface{}{}\tfor _, record := range kinesisEvent.Records {\t\tcurRecordSequenceNumber := \"\"\t\t// Process your record\t\tif /* Your record processing condition here */ {\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\t\t}\t\t// Add a condition to check if the record processing failed\t\tif curRecordSequenceNumber != \"\" {\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\t\t}\t}\tkinesisBatchResponse := map[string]interface{}{\t\t\"batchItemFailures\": batchItemFailures,\t}\treturn kinesisBatchResponse, nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KinesisEvent;import com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;import java.io.Serializable;import java.util.ArrayList;import java.util.List;public class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {    @Override    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();        String curRecordSequenceNumber = \"\";        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {            try {                //Process your record                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();            } catch (Exception e) {                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));                return new StreamsEventResponse(batchItemFailures);            }        }              return new StreamsEventResponse(batchItemFailures);       }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Javascript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    try {      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      console.log(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      console.error(`An error occurred ${err}`);      /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */      return {        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],      };    }  }  console.log(`Successfully processed ${event.Records.length} records.`);  return { batchItemFailures: [] };};async function getRecordDataAsync(payload) {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}Reporting Kinesis batch item failures with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import {  KinesisStreamEvent,  Context,  KinesisStreamHandler,  KinesisStreamRecordPayload,  KinesisStreamBatchResponse,} from \"aws-lambda\";import { Buffer } from \"buffer\";import { Logger } from \"@aws-lambda-powertools/logger\";const logger = new Logger({  logLevel: \"INFO\",  serviceName: \"kinesis-stream-handler-sample\",});export const functionHandler: KinesisStreamHandler = async (  event: KinesisStreamEvent,  context: Context): Promise<KinesisStreamBatchResponse> => {  for (const record of event.Records) {    try {      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      logger.info(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      logger.error(`An error occurred ${err}`);      /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */      return {        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],      };    }  }  logger.info(`Successfully processed ${event.Records.length} records.`);  return { batchItemFailures: [] };};async function getRecordDataAsync(  payload: KinesisStreamRecordPayload): Promise<string> {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kinesis\\KinesisEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): array    {        $kinesisEvent = new KinesisEvent($event);        $this->logger->info(\"Processing records\");        $records = $kinesisEvent->getRecords();        $failedRecords = [];        foreach ($records as $record) {            try {                $data = $record->getData();                $this->logger->info(json_encode($data));                // TODO: Do interesting work based on the new data            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $failedRecords[] = $record->getSequenceNumber();            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");        // change format for the response        $failures = array_map(            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],            $failedRecords        );        return [            'batchItemFailures' => $failures        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def handler(event, context):    records = event.get(\"Records\")    curRecordSequenceNumber = \"\"        for record in records:        try:            # Process your record            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]        except Exception as e:            # Return failed record's sequence number            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}    return {\"batchItemFailures\":[]}RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'aws-sdk'def lambda_handler(event:, context:)  batch_item_failures = []  event['Records'].each do |record|    begin      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"      record_data = get_record_data_async(record['kinesis'])      puts \"Record Data: #{record_data}\"      # TODO: Do interesting work based on the new data    rescue StandardError => err      puts \"An error occurred #{err}\"      # Since we are working with streams, we can return the failed item immediately.      # Lambda will immediately begin to retry processing from this failed item onwards.      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }    end  end  puts \"Successfully processed #{event['Records'].length} records.\"  { batchItemFailures: batch_item_failures }enddef get_record_data_async(payload)  data = Base64.decode64(payload['data']).force_encoding('utf-8')  # Placeholder for actual async work  sleep(1)  dataendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::{    event::kinesis::KinesisEvent,    kinesis::KinesisEventRecord,    streams::{KinesisBatchItemFailure, KinesisEventResponse},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {    let mut response = KinesisEventResponse {        batch_item_failures: vec![],    };    if event.payload.records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(response);    }    for record in &event.payload.records {        tracing::info!(            \"EventId: {}\",            record.event_id.as_deref().unwrap_or_default()        );        let record_processing_result = process_record(record);        if record_processing_result.is_err() {            response.batch_item_failures.push(KinesisBatchItemFailure {                item_identifier: record.kinesis.sequence_number.clone(),            });            /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */            return Ok(response);        }    }    tracing::info!(        \"Successfully processed {} records\",        event.payload.records.len()    );    Ok(response)}fn process_record(record: &KinesisEventRecord) -> Result<(), Error> {    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());    if let Some(err) = record_data.err() {        tracing::error!(\"Error: {}\", err);        return Err(Error::from(err));    }    let record_data = record_data.unwrap_or_default();    // do something interesting with the data    tracing::info!(\"Data: {}\", record_data);    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using System.Text.Json.Serialization;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegration;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return new StreamsEventResponse();        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                return new StreamsEventResponse                {                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>                    {                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }                    }                };            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");        return new StreamsEventResponse();    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}public class StreamsEventResponse{    [JsonPropertyName(\"batchItemFailures\")]    public IList<BatchItemFailure> BatchItemFailures { get; set; }    public class BatchItemFailure    {        [JsonPropertyName(\"itemIdentifier\")]        public string ItemIdentifier { get; set; }    }}"
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Error handling",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/kinesis-on-failure-destination.html",
                        "sections": [
                            "Error handling for Kinesis event source mappings depends on whether the error occurs before the function is invoked or during function invocation:",
                            "  1.Before invocation: :  If a Lambda event source mapping is unable to invoke the function due to throttling or other issues, it retries until the records expire or exceed the maximum age configured on the event source mapping (MaximumRecordAgeInSeconds).",
                            "  2.During invocation: :  If the function is invoked but returns an error, Lambda retries until the records expire, exceed the maximum age (MaximumRecordAgeInSeconds), or reach the configured retry quota (MaximumRetryAttempts). For function errors, you can also configure BisectBatchOnFunctionError, which splits a failed batch into two smaller batches, isolating bad records and avoiding timeouts. Splitting batches doesn't consume the retry quota.",
                            "If the error handling measures fail, Lambda discards the records and continues processing  batches from the stream. With the default settings, this means that a bad record can block processing on the affected  shard for up to one week. To avoid this, configure your function's event source mapping with a reasonable  number of retries and a maximum record age that fits your use case.",
                            {
                                "sub_header": "Configuring destinations for failed invocations",
                                "content": [
                                    "To retain records of failed event source mapping invocations, add a destination to your function's event source mapping. Each record sent to the destination is a JSON document containing metadata about the failed invocation. For Amazon S3 destinations, Lambda also sends the entire invocation record along with the metadata. You can configure any Amazon SNS topic, Amazon SQS queue, or S3 bucket as a destination.",
                                    "With Amazon S3 destinations, you can use the Amazon S3 Event Notifications feature to receive notifications when objects are uploaded to your destination S3 bucket. You can also configure S3 Event Notifications to invoke another Lambda function to perform automated processing on failed batches.",
                                    "Your execution role must have permissions for the destination:",
                                    "  1.For SQS destinations: :  sqs:SendMessage",
                                    "  2.For SNS destinations: :  sns:Publish",
                                    "  3.For S3 bucket destinations: :   s3:PutObject and s3:ListBucket",
                                    "If you've enabled encryption with your own KMS key for an S3 destination, your function's execution role must also have permission to call             kms:GenerateDataKey.            If the KMS key and S3 bucket destination are in a different account from your Lambda function            and execution role, configure the KMS key to trust the execution role to allow            kms:GenerateDataKey.",
                                    "To configure an on-failure destination using the console, follow these steps:",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose a function.",
                                    "  3 : Under Function overview, choose Add destination.",
                                    "  4 : For Source, choose Event source mapping invocation.",
                                    "  5 : For Event source mapping, choose an event source that's configured              for this function.",
                                    "  6 : For Condition, select On failure. For event              source mapping invocations, this is the only accepted condition.",
                                    "  7 : For Destination type, choose the destination type that Lambda sends              invocation records to.",
                                    "  8 : For Destination, choose a resource.",
                                    "  9 : Choose Save.",
                                    "You can also configure an on-failure destination using the AWS Command Line Interface (AWS CLI). For example, the following          create-event-source-mapping command adds an event source mapping with an SQS on-failure destination to          MyFunction:",
                                    "aws lambda create-event-source-mapping \\--function-name \"MyFunction\" \\--event-source-arn arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sqs:us-east-1:123456789012:dest-queue\"}}'",
                                    "The following update-event-source-mapping command updates an event source mapping to send failed invocation records to an SNS destination after two retry attempts, or if the records are more than an hour old.",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--maximum-retry-attempts 2 \\--maximum-record-age-in-seconds 3600 \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sns:us-east-1:123456789012:dest-topic\"}}'",
                                    "Updated settings are applied asynchronously and aren't reflected in the output until the process completes. Use    the get-event-source-mapping command to view the current status.",
                                    "To remove a destination, supply an empty string as the argument to the          destination-config parameter:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"\"}}'",
                                    {
                                        "sub_header": "Security best practices for Amazon S3 destinations",
                                        "content": [
                                            "Deleting an S3 bucket that's configured as a destination without removing the destination from your function's configuration can create a security risk. If another       user knows your destination bucket's name, they can recreate the bucket in their AWS account. Records of failed invocations will be sent to their bucket, potentially       exposing data from your function.",
                                            "Warning",
                                            "To ensure that invocation records from your function can't be sent to an S3 bucket in another AWS account, add a condition to your function's execution role         that limits s3:PutObject permissions to buckets in your account. ",
                                            "The following example shows an IAM policy that limits your function's s3:PutObject permissions to buckets in your account. This policy also gives Lambda        the s3:ListBucket permission it needs to use an S3 bucket as a destination.",
                                            "{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Sid\": \"S3BucketResourceAccountWrite\",            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\",                \"s3:ListBucket\"            ],            \"Resource\": \"arn:aws:s3:::*/*\",            \"Condition\": {                \"StringEquals\": {                    \"s3:ResourceAccount\": \"111122223333\"                }            }        }    ]}",
                                            "To add a permissions policy to your funcion's execution role using the AWS Management Console or AWS CLI, refer to the instructions in the following procedures:",
                                            "  1.Console : \nTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.\nSelect the Lambda function whose execution role you want to modify.\n\nIn the Configuration tab, select Permissions.\n\nIn the Execution role tab, select your function's Role name to open the role's IAM console page.\n\nAdd a permissions policy to the role by doing the following:\n\nIn the Permissions policies pane, choose Add permissions and select Create inline policy.\n\nIn Policy editor, select JSON.\n\nPaste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.\n\nUnder Policy details, enter a Policy name.\n\nChoose Create policy.\n\n\n",
                                            "  2.AWS CLI : put-role-policy",
                                            "ConsoleTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.Select the Lambda function whose execution role you want to modify.In the Configuration tab, select Permissions.In the Execution role tab, select your function's Role name to open the role's IAM console page.Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy.AWS CLITo add a permissions policy to a function's execution role (CLI)Create a JSON policy document with the required permissions and save it in a local directory.Use the IAM put-role-policy CLI command to add the permissions to your function's execution role. Run the following command from the                 directory you saved your JSON policy document in and replace the role name, policy name, and policy document with your own values.aws iam put-role-policy \\--role-name my_lambda_role \\--policy-name LambdaS3DestinationPolicy \\--policy-document file://my_policy.json",
                                            "anchor",
                                            "anchor",
                                            "To add a permissions policy to a function's execution role (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Select the Lambda function whose execution role you want to modify.",
                                            "  3 : In the Configuration tab, select Permissions.",
                                            "  4 : In the Execution role tab, select your function's Role name to open the role's IAM console page.",
                                            "  5 : Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy."
                                        ]
                                    },
                                    {
                                        "sub_header": "Example Amazon SNS and Amazon SQS invocation record",
                                        "content": [
                                            "The following example shows what Lambda sends to an SQS queue or SNS topic for a failed Kinesis      event source invocation. Because Lambda sends only the metadata for these destination types, use the      streamArn, shardId, startSequenceNumber, and      endSequenceNumber fields to obtain the full original record. All of the fields shown in the       KinesisBatchInfo property will always be present.",
                                            "{    \"requestContext\": {        \"requestId\": \"c9b8fa9f-5a7f-xmpl-af9c-0c604cde93a5\",        \"functionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\",        \"approximateInvokeCount\": 1    },    \"responseContext\": {        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KinesisBatchInfo\": {        \"shardId\": \"shardId-000000000001\",        \"startSequenceNumber\": \"49601189658422359378836298521827638475320189012309704722\",        \"endSequenceNumber\": \"49601189658422359378836298522902373528957594348623495186\",        \"approximateArrivalOfFirstRecord\": \"2019-11-14T00:38:04.835Z\",        \"approximateArrivalOfLastRecord\": \"2019-11-14T00:38:05.580Z\",        \"batchSize\": 500,        \"streamArn\": \"arn:aws:kinesis:us-east-2:123456789012:stream/mystream\"    }}",
                                            "You can use this information to retrieve the affected records from the stream for  troubleshooting. The actual records aren't included, so you must process this record and retrieve them from the  stream before they expire and are lost."
                                        ]
                                    },
                                    {
                                        "sub_header": "Example Amazon S3 invocation record",
                                        "content": [
                                            "The following example shows what Lambda sends to an Amazon S3 bucket for a failed Kinesis      event source invocation. In addition to all of the fields from the previous example for SQS and SNS destinations, the payload field       contains the original invocation record as an escaped JSON string.",
                                            "{    \"requestContext\": {        \"requestId\": \"c9b8fa9f-5a7f-xmpl-af9c-0c604cde93a5\",        \"functionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\",        \"approximateInvokeCount\": 1    },    \"responseContext\": {        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KinesisBatchInfo\": {        \"shardId\": \"shardId-000000000001\",        \"startSequenceNumber\": \"49601189658422359378836298521827638475320189012309704722\",        \"endSequenceNumber\": \"49601189658422359378836298522902373528957594348623495186\",        \"approximateArrivalOfFirstRecord\": \"2019-11-14T00:38:04.835Z\",        \"approximateArrivalOfLastRecord\": \"2019-11-14T00:38:05.580Z\",        \"batchSize\": 500,        \"streamArn\": \"arn:aws:kinesis:us-east-2:123456789012:stream/mystream\"    },    \"payload\": \"<Whole Event>\" // Only available in S3}",
                                            "The S3 object containing the invocation record uses the following naming convention:",
                                            "aws/lambda/<ESM-UUID>/<shardID>/YYYY/MM/DD/YYYY-MM-DDTHH.MM.SS-<Random UUID>"
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Stateful processing",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-kinesis-windows.html",
                        "sections": [
                            "Lambda functions can run continuous stream processing applications. A stream represents unbounded data that flows    continuously through your application. To analyze information from this continuously updating input, you can bound    the included records using a window defined in terms of time.",
                            "Tumbling windows are distinct time windows that open and close at regular intervals. By default, Lambda invocations    are stateless—you cannot use them for processing data across multiple continuous invocations without an external database.    However, with tumbling windows, you can maintain your state across invocations. This state contains the aggregate result    of the messages previously processed for the current window. Your state can be a maximum of 1 MB per shard. If it exceeds    that size, Lambda terminates the window early.",
                            "Each record in a stream belongs to a specific window. Lambda will process each record at least once, but doesn't guarantee that each record will be processed only once. In rare cases, such as error handling, some records might be processed more than once. Records are always processed in order the first time. If records are processed more than once, they might be processed out of order.",
                            {
                                "sub_header": "Aggregation and processing",
                                "content": [
                                    "Your user managed function is invoked both for aggregation and for processing the final results of that      aggregation. Lambda aggregates all records received in the window. You can receive these records in multiple      batches, each as a separate invocation. Each invocation receives a state. Thus, when using tumbling windows,      your Lambda function response must contain a state property. If the response does not contain a      state property, Lambda considers this a failed invocation. To satisfy this condition, your function      can return a TimeWindowEventResponse object, which has the following JSON shape:",
                                    "Example TimeWindowEventResponse values",
                                    {
                                        "code_example": "{\n    \"state\": {\n        \"1\": 282,\n        \"2\": 715\n    },\n    \"batchItemFailures\": []\n}"
                                    },
                                    "Note",
                                    "For Java functions, we recommend using a Map<String, String> to represent the state.",
                                    "At the end of the window, the flag isFinalInvokeForWindow is set to true to indicate      that this is the final state and that it’s ready for processing. After processing, the window completes and your      final invocation completes, and then the state is dropped.",
                                    "At the end of your window, Lambda uses final processing for actions on the aggregation results. Your final      processing is synchronously invoked. After successful invocation, your function checkpoints the sequence number      and stream processing continues. If invocation is unsuccessful, your Lambda function suspends further processing      until a successful invocation.",
                                    "Example  KinesisTimeWindowEvent",
                                    {
                                        "code_example": "\n{\n    \"Records\": [\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"1\",\n                \"sequenceNumber\": \"49590338271490256608559692538361571095921575989136588898\",\n                \"data\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n                \"approximateArrivalTimestamp\": 1607497475.000\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000006:49590338271490256608559692538361571095921575989136588898\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-kinesis-role\",\n            \"awsRegion\": \"us-east-1\",\n            \"eventSourceARN\": \"arn:aws:kinesis:us-east-1:123456789012:stream/lambda-stream\"\n        }\n    ],\n    \"window\": {\n        \"start\": \"2020-12-09T07:04:00Z\",\n        \"end\": \"2020-12-09T07:06:00Z\"\n    },\n    \"state\": {\n        \"1\": 282,\n        \"2\": 715\n    },\n    \"shardId\": \"shardId-000000000006\",\n    \"eventSourceARN\": \"arn:aws:kinesis:us-east-1:123456789012:stream/lambda-stream\",\n    \"isFinalInvokeForWindow\": false,\n    \"isWindowTerminatedEarly\": false\n}\n"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Configuration",
                                "content": [
                                    "You can configure tumbling windows when you create or update an event source mapping. To configure a tumbling window, specify the window in seconds (TumblingWindowInSeconds). The following            example AWS Command Line Interface (AWS CLI) command creates a streaming event source mapping that has a tumbling window of 120            seconds. The Lambda function defined for aggregation and processing is named            tumbling-window-example-function.",
                                    "aws lambda create-event-source-mapping \\--event-source-arn arn:aws:kinesis:us-east-1:123456789012:stream/lambda-stream \\--function-name tumbling-window-example-function \\--starting-position TRIM_HORIZON \\--tumbling-window-in-seconds 120",
                                    "Lambda determines tumbling window boundaries based on the time when records were inserted into the stream. All            records have an approximate timestamp available that Lambda uses in boundary determinations.",
                                    "Tumbling window aggregations do not support resharding. When a shard ends, Lambda considers the current window to be closed, and any child shards will start their own window in a fresh state. When no new records are being added to the current window, Lambda waits for up to 2 minutes before assuming that the window is over. This helps ensure that the function reads all records in the current window, even if the records are added intermittently.",
                                    "Tumbling windows fully support the existing retry policies maxRetryAttempts and            maxRecordAge.",
                                    "Example  Handler.py – Aggregation and processing",
                                    "The following Python function demonstrates how to aggregate and then process your final state:",
                                    {
                                        "code_example": "def lambda_handler(event, context):\n    print('Incoming event: ', event)\n    print('Incoming state: ', event['state'])\n\n#Check if this is the end of the window to either aggregate or process.\n    if event['isFinalInvokeForWindow']:\n        # logic to handle final state of the window\n        print('Destination invoke')\n    else:\n        print('Aggregate invoke')\n\n#Check for early terminations\n    if event['isWindowTerminatedEarly']:\n        print('Window terminated early')\n\n    #Aggregation logic\n    state = event['state']\n    for record in event['Records']:\n        state[record['kinesis']['partitionKey']] = state.get(record['kinesis']['partitionKey'], 0) + 1\n\n    print('Returning state: ', state)\n    return {'state': state}"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Parameters",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-kinesis-parameters.html",
                        "sections": [
                            "All Lambda event source mappings share the same CreateEventSourceMapping and UpdateEventSourceMapping        API operations. However, only some of the parameters apply to Kinesis.",
                            "ParameterRequiredDefaultNotesBatchSizeN100Maximum: 10,000BisectBatchOnFunctionErrorNfalse noneDestinationConfigNN/AAmazon SQS queue or Amazon SNS topic destination for discarded records. For more information, see Configuring destinations for failed invocations.EnabledNtrue noneEventSourceArnYN/AARN of the data stream or a stream consumerFunctionNameYN/A noneFunctionResponseTypesN N/ATo let your function report specific failures in a batch, include the value                            ReportBatchItemFailures in FunctionResponseTypes. For more information, see                            Configuring partial batch response with Kinesis Data Streams and Lambda.MaximumBatchingWindowInSecondsN0 noneMaximumRecordAgeInSecondsN-1-1 means infinite: Lambda doesn't discard records (Kinesis Data Streams data retention settings still apply)Minimum: -1Maximum: 604,800MaximumRetryAttemptsN-1-1 means infinite: failed records are retried until the record expiresMinimum: -1Maximum: 10,000ParallelizationFactorN1Maximum: 10StartingPositionY N/AAT_TIMESTAMP, TRIM_HORIZON, or LATESTStartingPositionTimestampN N/AOnly valid if StartingPosition is set to AT_TIMESTAMP. The time from which to start reading, in Unix time secondsTumblingWindowInSecondsN N/AMinimum: 0Maximum: 900"
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for Kinesis event sources.",
                            "Topics",
                            {
                                "sub_header": "Kinesis event filtering basics",
                                "content": [
                                    "Suppose a producer is putting JSON formatted data into your Kinesis data stream. An example record would look like the following, with the             JSON data converted to a Base64 encoded string in the data field.",
                                    "{    \"kinesis\": {        \"kinesisSchemaVersion\": \"1.0\",        \"partitionKey\": \"1\",        \"sequenceNumber\": \"49590338271490256608559692538361571095921575989136588898\",        \"data\": \"eyJSZWNvcmROdW1iZXIiOiAiMDAwMSIsICJUaW1lU3RhbXAiOiAieXl5eS1tbS1kZFRoaDptbTpzcyIsICJSZXF1ZXN0Q29kZSI6ICJBQUFBIn0=\",        \"approximateArrivalTimestamp\": 1545084650.987        },    \"eventSource\": \"aws:kinesis\",    \"eventVersion\": \"1.0\",    \"eventID\": \"shardId-000000000006:49590338271490256608559692538361571095921575989136588898\",    \"eventName\": \"aws:kinesis:record\",    \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",    \"awsRegion\": \"us-east-2\",    \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"}",
                                    "As long as the data the producer puts into the stream is valid JSON, you can use event filtering to filter records using the data             key. Suppose a producer is putting records into your Kinesis stream in the following JSON format.",
                                    "{    \"record\": 12345,    \"order\": {        \"type\": \"buy\",        \"stock\": \"ANYCO\",        \"quantity\": 1000        }}",
                                    "To filter only those records where the order type is “buy,” the FilterCriteria object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"data\\\" : { \\\"order\\\" : { \\\"type\\\" : [ \\\"buy\\\" ] } } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON. ",
                                    "{    \"data\": {        \"order\": {            \"type\": [ \"buy\" ]            }      }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"data\" : { \"order\" : { \"type\" : [ \"buy\" ] } } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:kinesis:us-east-2:123456789012:stream/my-stream \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"order\\\" : { \\\"type\\\" : [ \\\"buy\\\" ] } } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"data\" : { \"order\" : { \"type\" : [ \"buy\" ] } } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"data\" : { \"order\" : { \"type\" : [ \"buy\" ] } } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:kinesis:us-east-2:123456789012:stream/my-stream \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"order\\\" : { \\\"type\\\" : [ \\\"buy\\\" ] } } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"order\\\" : { \\\"type\\\" : [ \\\"buy\\\" ] } } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"data\" : { \"order\" : { \"type\" : [ \"buy\" ] } } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"data\" : { \"order\" : { \"type\" : [ \"buy\" ] } } }"
                                    },
                                    "To properly filter events from Kinesis sources, both the data field and your filter criteria for the data field must be in valid JSON format.             If either field isn't in a valid JSON format, Lambda drops the message or throws an exception. The following table summarizes the specific behavior: ",
                                    "Incoming data formatFilter pattern format for data propertiesResulting actionValid JSONValid JSONLambda filters based on your filter criteria.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONNon-JSONLambda throws an exception at the time of the event source mapping creation or update. The filter pattern                                for data properties must be in a valid JSON format.Non-JSONValid JSONLambda drops the record.Non-JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Non-JSONNon-JSONLambda throws an exception at the time of the event source mapping creation or update. The filter pattern                                for data properties must be in a valid JSON format."
                                ]
                            },
                            {
                                "sub_header": "Filtering Kinesis aggregated records",
                                "content": [
                                    "With Kinesis, you can aggregate multiple records into a single Kinesis Data Streams record to increase your data throughput. Lambda can only apply             filter criteria to aggregated records when you use Kinesis enhanced fan-out.             Filtering aggregated records with standard Kinesis isn't supported. When using enhanced fan-out, you configure a Kinesis dedicated-throughput consumer             to act as the trigger for your Lambda function. Lambda then filters the aggregated records and passes only those records that meet your filter criteria.",
                                    "To learn more about Kinesis record aggregation, refer to the Aggregation             section on the Kinesis Producer Library (KPL) Key Concepts page. To Learn more about using Lambda with Kinesis enhanced fan-out, see             Increasing real-time stream processing performance with Amazon Kinesis Data Streams enhanced fan-out and AWS Lambda             on the AWS compute blog."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis-example.html",
                        "sections": [
                            "In this tutorial, you create a Lambda function to consume events from a Amazon Kinesis data stream. ",
                            "  1 : Custom app writes records to the stream.",
                            "  2 : AWS Lambda polls the stream and, when it detects new records in the stream, invokes your Lambda        function.",
                            "  3 : AWS Lambda runs the Lambda function by assuming the execution role you specified at the time you created        the Lambda function.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "This tutorial assumes that you have some knowledge of basic Lambda operations and the Lambda console. If you      haven't already, follow the instructions in Create a Lambda function with the console to create your first Lambda function.",
                                    "To complete the following steps, you need the AWS CLI version 2. Commands and the expected output are listed in separate blocks:",
                                    "aws --version",
                                    "You should see the following output:",
                                    "aws-cli/2.13.27 Python/3.11.6 Linux/4.14.328-248.540.amzn2.x86_64 exe/x86_64.amzn.2",
                                    "For long commands, an escape character (\\) is used to split a command over multiple lines.",
                                    "On Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.     To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.     Example CLI commands in this guide use Linux formatting. Commands which include inline JSON documents must be reformatted if you are using the Windows CLI.    "
                                ]
                            },
                            {
                                "sub_header": "Create the execution role",
                                "content": [
                                    "Create the execution role that gives your function      permission to access AWS resources.",
                                    "To create an execution role",
                                    "  1 : Open the roles page in the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : Create a role with the following properties.Trusted entity – AWS Lambda.Permissions – AWSLambdaKinesisExecutionRole.Role name – lambda-kinesis-role.",
                                    "The AWSLambdaKinesisExecutionRole policy has the permissions that the function needs to      read items from Kinesis and write logs to CloudWatch Logs."
                                ]
                            },
                            {
                                "sub_header": "Create the function",
                                "content": [
                                    "Create a Lambda function that processes your Kinesis messages. The function code logs the event ID      and event data of the Kinesis record to CloudWatch Logs.",
                                    "This tutorial uses the Node.js 18.x runtime, but we've also provided example code in other runtime      languages. You can select the tab in the following box to see code for the runtime you're interested in.      The JavaScript code you'll use in this step is in the first example shown in the      JavaScript tab.",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\n\tif len(kinesisEvent.Records) == 0 {\n\t\tlog.Printf(\"empty Kinesis event received\")\n\t\treturn nil\n\t}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\n\t\trecordDataBytes := record.Kinesis.Data\n\t\trecordDataText := string(recordDataBytes)\n\t\tlog.Printf(\"record data: %v\", recordDataText)\n\t\t// TODO: Do interesting work based on the new data\n\t}\n\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\n\tif len(kinesisEvent.Records) == 0 {\n\t\tlog.Printf(\"empty Kinesis event received\")\n\t\treturn nil\n\t}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\n\t\trecordDataBytes := record.Kinesis.Data\n\t\trecordDataText := string(recordDataBytes)\n\t\tlog.Printf(\"record data: %v\", recordDataText)\n\t\t// TODO: Do interesting work based on the new data\n\t}\n\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\n\npublic class Handler implements RequestHandler<KinesisEvent, Void> {\n    @Override\n    public Void handleRequest(final KinesisEvent event, final Context context) {\n        LambdaLogger logger = context.getLogger();\n        if (event.getRecords().isEmpty()) {\n            logger.log(\"Empty Kinesis Event received\");\n            return null;\n        }\n        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {\n            try {\n                logger.log(\"Processed Event with EventId: \"+record.getEventID());\n                String data = new String(record.getKinesis().getData().array());\n                logger.log(\"Data:\"+ data);\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex) {\n                logger.log(\"An error occurred:\"+ex.getMessage());\n                throw ex;\n            }\n        }\n        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");\n        return null;\n    }\n\n}\n\n",
                                    "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\n\npublic class Handler implements RequestHandler<KinesisEvent, Void> {\n    @Override\n    public Void handleRequest(final KinesisEvent event, final Context context) {\n        LambdaLogger logger = context.getLogger();\n        if (event.getRecords().isEmpty()) {\n            logger.log(\"Empty Kinesis Event received\");\n            return null;\n        }\n        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {\n            try {\n                logger.log(\"Processed Event with EventId: \"+record.getEventID());\n                String data = new String(record.getKinesis().getData().array());\n                logger.log(\"Data:\"+ data);\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex) {\n                logger.log(\"An error occurred:\"+ex.getMessage());\n                throw ex;\n            }\n        }\n        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");\n        return null;\n    }\n\n}\n\n",
                                    "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      throw err;\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                                    "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      throw err;\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                                    "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Kinesis\\KinesisHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends KinesisHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleKinesis(KinesisEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing records\");\n        $records = $event->getRecords();\n        foreach ($records as $record) {\n            $data = $record->getData();\n            $this->logger->info(json_encode($data));\n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Kinesis\\KinesisHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends KinesisHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleKinesis(KinesisEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing records\");\n        $records = $event->getRecords();\n        foreach ($records as $record) {\n            $data = $record->getData();\n            $this->logger->info(json_encode($data));\n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport base64\ndef lambda_handler(event, context):\n\n    for record in event['Records']:\n        try:\n            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")\n            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')\n            print(f\"Record Data: {record_data}\")\n            # TODO: Do interesting work based on the new data\n        except Exception as e:\n            print(f\"An error occurred {e}\")\n            raise e\n    print(f\"Successfully processed {len(event['Records'])} records.\")\n\n",
                                    "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport base64\ndef lambda_handler(event, context):\n\n    for record in event['Records']:\n        try:\n            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")\n            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')\n            print(f\"Record Data: {record_data}\")\n            # TODO: Do interesting work based on the new data\n        except Exception as e:\n            print(f\"An error occurred {e}\")\n            raise e\n    print(f\"Successfully processed {len(event['Records'])} records.\")\n\n",
                                    "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue => err\n      $stderr.puts \"An error occurred #{err}\"\n      raise err\n    end\n  end\n  puts \"Successfully processed #{event['Records'].length} records.\"\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('UTF-8')\n  # Placeholder for actual async work\n  # You can use Ruby's asynchronous programming tools like async/await or fibers here.\n  return data\nend\n",
                                    "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue => err\n      $stderr.puts \"An error occurred #{err}\"\n      raise err\n    end\n  end\n  puts \"Successfully processed #{event['Records'].length} records.\"\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('UTF-8')\n  # Placeholder for actual async work\n  # You can use Ruby's asynchronous programming tools like async/await or fibers here.\n  return data\nend\n",
                                    "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::kinesis::KinesisEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    event.payload.records.iter().for_each(|record| {\n        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());\n\n        let record_data = std::str::from_utf8(&record.kinesis.data);\n\n        match record_data {\n            Ok(data) => {\n                // log the record data\n                tracing::info!(\"Data: {}\", data);\n            }\n            Err(e) => {\n                tracing::error!(\"Error: {}\", e);\n            }\n        }\n    });\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::kinesis::KinesisEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    event.payload.records.iter().for_each(|record| {\n        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());\n\n        let record_data = std::str::from_utf8(&record.kinesis.data);\n\n        match record_data {\n            Ok(data) => {\n                // log the record data\n                tracing::info!(\"Data: {}\", data);\n            }\n            Err(e) => {\n                tracing::error!(\"Error: {}\", e);\n            }\n        }\n    });\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegrationSampleCode;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return;        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                throw;            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"log\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\tif len(kinesisEvent.Records) == 0 {\t\tlog.Printf(\"empty Kinesis event received\")\t\treturn nil\t}\tfor _, record := range kinesisEvent.Records {\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\t\trecordDataBytes := record.Kinesis.Data\t\trecordDataText := string(recordDataBytes)\t\tlog.Printf(\"record data: %v\", recordDataText)\t\t// TODO: Do interesting work based on the new data\t}\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.LambdaLogger;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KinesisEvent;public class Handler implements RequestHandler<KinesisEvent, Void> {    @Override    public Void handleRequest(final KinesisEvent event, final Context context) {        LambdaLogger logger = context.getLogger();        if (event.getRecords().isEmpty()) {            logger.log(\"Empty Kinesis Event received\");            return null;        }        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {            try {                logger.log(\"Processed Event with EventId: \"+record.getEventID());                String data = new String(record.getKinesis().getData().array());                logger.log(\"Data:\"+ data);                // TODO: Do interesting work based on the new data            }            catch (Exception ex) {                logger.log(\"An error occurred:\"+ex.getMessage());                throw ex;            }        }        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");        return null;    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    try {      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      console.log(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      console.error(`An error occurred ${err}`);      throw err;    }  }  console.log(`Successfully processed ${event.Records.length} records.`);};async function getRecordDataAsync(payload) {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}Consuming a Kinesis event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import {  KinesisStreamEvent,  Context,  KinesisStreamHandler,  KinesisStreamRecordPayload,} from \"aws-lambda\";import { Buffer } from \"buffer\";import { Logger } from \"@aws-lambda-powertools/logger\";const logger = new Logger({  logLevel: \"INFO\",  serviceName: \"kinesis-stream-handler-sample\",});export const functionHandler: KinesisStreamHandler = async (  event: KinesisStreamEvent,  context: Context): Promise<void> => {  for (const record of event.Records) {    try {      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      logger.info(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      logger.error(`An error occurred ${err}`);      throw err;    }    logger.info(`Successfully processed ${event.Records.length} records.`);  }};async function getRecordDataAsync(  payload: KinesisStreamRecordPayload): Promise<string> {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kinesis\\KinesisEvent;use Bref\\Event\\Kinesis\\KinesisHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends KinesisHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleKinesis(KinesisEvent $event, Context $context): void    {        $this->logger->info(\"Processing records\");        $records = $event->getRecords();        foreach ($records as $record) {            $data = $record->getData();            $this->logger->info(json_encode($data));            // TODO: Do interesting work based on the new data            // Any exception thrown will be logged and the invocation will be marked as failed        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0import base64def lambda_handler(event, context):    for record in event['Records']:        try:            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')            print(f\"Record Data: {record_data}\")            # TODO: Do interesting work based on the new data        except Exception as e:            print(f\"An error occurred {e}\")            raise e    print(f\"Successfully processed {len(event['Records'])} records.\")RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'aws-sdk'def lambda_handler(event:, context:)  event['Records'].each do |record|    begin      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"      record_data = get_record_data_async(record['kinesis'])      puts \"Record Data: #{record_data}\"      # TODO: Do interesting work based on the new data    rescue => err      $stderr.puts \"An error occurred #{err}\"      raise err    end  end  puts \"Successfully processed #{event['Records'].length} records.\"enddef get_record_data_async(payload)  data = Base64.decode64(payload['data']).force_encoding('UTF-8')  # Placeholder for actual async work  # You can use Ruby's asynchronous programming tools like async/await or fibers here.  return dataendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::kinesis::KinesisEvent;use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {    if event.payload.records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    event.payload.records.iter().for_each(|record| {        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());        let record_data = std::str::from_utf8(&record.kinesis.data);        match record_data {            Ok(data) => {                // log the record data                tracing::info!(\"Data: {}\", data);            }            Err(e) => {                tracing::error!(\"Error: {}\", e);            }        }    });    tracing::info!(        \"Successfully processed {} records\",        event.payload.records.len()    );    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegrationSampleCode;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return;        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                throw;            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}",
                                    "To create the function",
                                    " 1 : Create a directory for the project, and then switch to that directory. ",
                                    {
                                        "code_example": "mkdir kinesis-tutorial\ncd kinesis-tutorial"
                                    },
                                    "  2 : Copy the sample JavaScript code into a new file named index.js.",
                                    " 3 : Create a deployment package. ",
                                    {
                                        "code_example": "zip function.zip index.js"
                                    },
                                    " 4 : Create a Lambda function with the create-function command. ",
                                    {
                                        "code_example": "aws lambda create-function --function-name ProcessKinesisRecords \\\n--zip-file fileb://function.zip --handler index.handler --runtime nodejs18.x \\\n--role arn:aws:iam::111122223333:role/lambda-kinesis-role"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Test the\n        Lambda function",
                                "content": [
                                    "Invoke your Lambda function manually using the invoke AWS Lambda CLI command and a sample Kinesis      event.",
                                    "To test the Lambda function",
                                    " 1 : Copy the following JSON into a file and save it as input.txt.  ",
                                    {
                                        "code_example": "{\n    \"Records\": [\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"1\",\n                \"sequenceNumber\": \"49590338271490256608559692538361571095921575989136588898\",\n                \"data\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n                \"approximateArrivalTimestamp\": 1545084650.987\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000006:49590338271490256608559692538361571095921575989136588898\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::111122223333:role/lambda-kinesis-role\",\n            \"awsRegion\": \"us-east-2\",\n            \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:111122223333:stream/lambda-stream\"\n        }\n    ]\n}"
                                    },
                                    " 2 : Use the invoke command to send the event to the function. The cli-binary-format option is required if you're using AWS CLI version 2. To make this the default setting, run aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide for Version 2.The response is saved to out.txt.",
                                    {
                                        "code_example": "aws lambda invoke --function-name ProcessKinesisRecords \\\n--cli-binary-format raw-in-base64-out \\\n--payload file://input.txt outputfile.txt"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create a Kinesis stream",
                                "content": [
                                    "Use the create-stream  command to create a stream.",
                                    "aws kinesis create-stream --stream-name lambda-stream --shard-count 1",
                                    "Run the following describe-stream command to get the stream ARN.",
                                    "aws kinesis describe-stream --stream-name lambda-stream",
                                    "You should see the following output:",
                                    "{    \"StreamDescription\": {        \"Shards\": [            {                \"ShardId\": \"shardId-000000000000\",                \"HashKeyRange\": {                    \"StartingHashKey\": \"0\",                    \"EndingHashKey\": \"340282366920746074317682119384634633455\"                },                \"SequenceNumberRange\": {                    \"StartingSequenceNumber\": \"49591073947768692513481539594623130411957558361251844610\"                }            }        ],        \"StreamARN\": \"arn:aws:kinesis:us-east-1:111122223333:stream/lambda-stream\",        \"StreamName\": \"lambda-stream\",        \"StreamStatus\": \"ACTIVE\",        \"RetentionPeriodHours\": 24,        \"EnhancedMonitoring\": [            {                \"ShardLevelMetrics\": []            }        ],        \"EncryptionType\": \"NONE\",        \"KeyId\": null,        \"StreamCreationTimestamp\": 1544828156.0    }}",
                                    "You use the stream ARN in the next step to associate the stream with your Lambda function."
                                ]
                            },
                            {
                                "sub_header": "Add an event source in\n        AWS Lambda",
                                "content": [
                                    "Run the following AWS CLI add-event-source command.",
                                    "aws lambda create-event-source-mapping --function-name ProcessKinesisRecords \\--event-source  arn:aws:kinesis:us-east-1:111122223333:stream/lambda-stream \\--batch-size 100 --starting-position LATEST",
                                    "Note the mapping ID for later use. You can get a list of event source mappings by running the        list-event-source-mappings command.",
                                    "aws lambda list-event-source-mappings --function-name ProcessKinesisRecords \\--event-source arn:aws:kinesis:us-east-1:111122223333:stream/lambda-stream",
                                    "In the response, you can verify the status value is enabled. Event source mappings can be      disabled to pause polling temporarily without losing any records."
                                ]
                            },
                            {
                                "sub_header": "Test the setup",
                                "content": [
                                    "To test the event source mapping, add event records to your Kinesis stream. The --data value is a      string that the CLI encodes to base64 prior to sending it to Kinesis. You can run the same command more than once to      add multiple records to the stream.",
                                    "aws kinesis put-record --stream-name lambda-stream --partition-key 1 \\--data \"Hello, this is a test.\"",
                                    "Lambda uses the execution role to read records from the stream. Then it invokes your Lambda function, passing in      batches of records. The function decodes data from each record and logs it, sending the output to CloudWatch Logs. View the      logs in the CloudWatch console."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the Kinesis stream",
                                    "  1 : Sign in to the AWS Management Console and open the Kinesis console at         https://console.aws.amazon.com/kinesis.",
                                    "  2 : Select the stream you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Enter delete in the text input field.",
                                    "  5 : Choose Delete."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "You can use a Lambda function to process records in an Amazon Kinesis data stream. You can map a Lambda function to a Kinesis Data Streams shared-throughput consumer (standard iterator), or to a    dedicated-throughput consumer with enhanced fan-out. For standard iterators, Lambda polls each shard in your Kinesis stream for records using HTTP protocol. The event source mapping shares read throughput with other consumers of the shard.",
                    " For details about Kinesis data streams, see Reading Data from      Amazon Kinesis Data Streams.",
                    "Note",
                    "Kinesis charges for each shard and, for enhanced fan-out, data read from the stream. For pricing details, see      Amazon Kinesis pricing.",
                    "Topics",
                    {
                        "sub_header": " Polling and batching streams",
                        "content": [
                            "Lambda reads records from the data stream and invokes your function synchronously with an event that contains stream records. Lambda reads records in batches and invokes your    function to process records from the batch. Each batch contains records from a single shard/data stream.",
                            "For standard Kinesis data streams, Lambda polls shards in your stream for records at a rate of once per second for each shard.       For Kinesis enhanced fan-out,     Lambda uses an HTTP/2 connection to listen for records being pushed from Kinesis. When records are available, Lambda invokes your     function and waits for the result.",
                            "By default, Lambda invokes your function as soon as records are available. If the batch      that Lambda reads from the event source has only one record in it, Lambda sends only one record to the function. To avoid invoking the function      with a small number of records, you can tell the event source to buffer records for up to 5 minutes by configuring a        batching window. Before invoking the function, Lambda continues to read records from the event source      until it has gathered a full batch, the batching window expires, or the batch reaches the payload limit of 6 MB. For more information,      see Batching behavior.",
                            "Warning",
                            "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                            "Lambda doesn't wait for any configured extensions to complete      before sending the next batch for processing. In other words, your extensions may continue to run as Lambda      processes the next batch of records. This can cause throttling issues if you breach any of your account's       concurrency settings or limits. To detect whether this is a      potential issue, monitor your functions and check whether you're seeing higher      concurrency metrics than expected for your event      source mapping. Due to short times in between invokes, Lambda may briefly report higher concurrency usage      than the number of shards. This can be true even for Lambda functions without extensions.",
                            "Configure the ParallelizationFactor setting to process one shard of a Kinesis data stream with more than one Lambda invocation simultaneously.       You can specify the number of concurrent batches that Lambda polls from a shard via a parallelization factor from 1 (default) to 10. For example, when you set ParallelizationFactor       to 2, you can have 200 concurrent Lambda invocations at maximum to process 100 Kinesis data shards (though in practice, you may see different values for the ConcurrentExecutions metric).      This helps scale up the processing throughput when the data volume is volatile and       the IteratorAge is high. When you increase the number of concurrent batches per shard, Lambda still ensures in-order processing at the partition-key level.",
                            "You can also use ParallelizationFactor with Kinesis aggregation. The behavior of the event source mapping      depends on whether you're using enhanced fan-out:",
                            "  1.Without enhanced fan-out : : All of the events inside an aggregated event must have the same          partition key. The partition key must also match that of the aggregated event. If the events inside the aggregated event have          different partition keys, Lambda cannot guarantee in-order processing of the events by partition key.",
                            "  2.With enhanced fan-out : : First, Lambda decodes the aggregated event into its individual events.          The aggregated event can have a different partition key than events it contains. However, events that don't correspond to          the partition key are dropped and lost.          Lambda doesn't process these events, and doesn't send them to a configured failure destination."
                        ]
                    },
                    {
                        "sub_header": " Example event",
                        "content": [
                            {
                                "code_example": "{\n    \"Records\": [\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"1\",\n                \"sequenceNumber\": \"49590338271490256608559692538361571095921575989136588898\",\n                \"data\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n                \"approximateArrivalTimestamp\": 1545084650.987\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000006:49590338271490256608559692538361571095921575989136588898\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n            \"awsRegion\": \"us-east-2\",\n            \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n        },\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"1\",\n                \"sequenceNumber\": \"49590338271490256608559692540925702759324208523137515618\",\n                \"data\": \"VGhpcyBpcyBvbmx5IGEgdGVzdC4=\",\n                \"approximateArrivalTimestamp\": 1545084711.166\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000006:49590338271490256608559692540925702759324208523137515618\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n            \"awsRegion\": \"us-east-2\",\n            \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n        }\n    ]\n}"
                            }
                        ]
                    }
                ]
            },
            {
                "title": "MQ",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-mq.html",
                "contents": [
                    {
                        "title": "Configure event source",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/process-mq-messages-with-lambda.html",
                        "sections": [
                            "Topics",
                            {
                                "sub_header": "Configure network security",
                                "content": [
                                    "To give Lambda full access to Amazon MQ through your event source mapping, either your broker must use a public endpoint             (public IP address), or you must provide access to the Amazon VPC you created the broker in.",
                                    "When you use Amazon MQ with Lambda, create AWS PrivateLink VPC endpoints that provide your function            access to the resources in your Amazon VPC.",
                                    "Note",
                                    "AWS PrivateLink VPC endpoints are required for functions with event source mappings that use the default (on-demand) mode                for event pollers. If your event source mapping uses                 provisioned mode, you don't need to configure AWS PrivateLink VPC endpoints.",
                                    "Create an endpoint to provide access to the following resources:",
                                    "  1.                    Lambda — Create an endpoint for the Lambda service principal.                ",
                                    "  2.                    AWS STS — Create an endpoint for the AWS STS in order for a service principal to assume a role on your behalf.                ",
                                    "  3.                    Secrets Manager — If your broker uses Secrets Manager to store credentials, create an endpoint for Secrets Manager.                ",
                                    "Alternatively, configure a NAT gateway on each public subnet in the Amazon VPC. For more information,             see Enable internet access for VPC-connected Lambda functions.",
                                    "When you create an event source mapping for Amazon MQ, Lambda checks whether Elastic Network Interfaces (ENIs)             are already present for the subnets and security groups configured for your Amazon VPC. If Lambda finds existing ENIs, it             attempts to re-use them. Otherwise, Lambda creates new ENIs to connect to the event source and invoke your function.",
                                    "Note",
                                    "Lambda functions always run inside VPCs owned by the Lambda service. Your function's VPC configuration                does not affect the event source mapping. Only the networking configuration of the event source's determines                 how Lambda connects to your event source.",
                                    "Configure the security groups for the Amazon VPC containing your broker. By default,            Amazon MQ uses the following ports: 61617 (Amazon MQ for ActiveMQ), and 5671 (Amazon MQ for RabbitMQ).",
                                    "  1.Inbound rules – Allow all traffic on the default broker port for the security group associated with your event source.",
                                    "  2.Outbound rules – Allow all traffic on port 443 for all destinations. Allow all traffic on the default broker port                    for the security group associated with your event source.",
                                    "  3.Amazon VPC endpoint inbound rules — If you are using an Amazon VPC endpoint, the security group associated with your Amazon VPC endpoint must allow inbound traffic                    on port 443 from the broker security group.",
                                    "If your broker uses authentication, you can also restrict the endpoint policy for the Secrets Manager endpoint.             To call the Secrets Manager API, Lambda uses your function role, not the Lambda service principal.",
                                    "Example VPC endpoint policy — Secrets Manager endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"secretsmanager:GetSecretValue\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"AWS\": [\n                      \"arn:aws::iam::123456789012:role/my-role\"\n                  ]\n              },\n              \"Resource\": \"arn:aws::secretsmanager:us-west-2:123456789012:secret:my-secret\"\n          }\n      ]\n  }"
                                    },
                                    "When you use Amazon VPC endpoints, AWS routes your API calls to invoke your function using the endpoint's Elastic Network Interface (ENI).            The Lambda service principal needs to call lambda:InvokeFunction on any roles and functions that use those ENIs.",
                                    "By default, Amazon VPC endpoints have open IAM policies that allow broad access to resources. Best practice is to restrict these            policies to perform the needed actions using that endpoint. To ensure that your event source mapping is able to invoke your Lambda            function, the VPC endpoint policy must allow the Lambda service principal to call sts:AssumeRole and            lambda:InvokeFunction. Restricting your VPC endpoint policies to allow only API calls originating within your organization            prevents the event source mapping from functioning properly, so \"Resource\": \"*\" is required in these policies.",
                                    "The following example VPC endpoint policies show how to grant the required access to the Lambda service principal for the            AWS STS and Lambda endpoints.",
                                    "Example VPC Endpoint policy — AWS STS endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"sts:AssumeRole\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n    }"
                                    },
                                    "Example VPC Endpoint policy — Lambda endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"lambda:InvokeFunction\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n  }"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create the event source mapping",
                                "content": [
                                    "Create        an event source mapping to tell Lambda to        send records from an Amazon MQ broker to a Lambda function. You can create multiple event source mappings to process        the same data with multiple functions, or to process items from multiple sources with a single function.",
                                    "To configure your function to read from Amazon MQ, add the required permissions and create an          MQ trigger in the Lambda console.",
                                    "To read records from an Amazon MQ broker, your Lambda function needs the following permissions. You grant Lambda permission to interact with your Amazon MQ broker        and its underlying resouces by adding permission statements to your function execution role:",
                                    "  1.mq:DescribeBroker",
                                    "  2.secretsmanager:GetSecretValue",
                                    "  3.ec2:CreateNetworkInterface",
                                    "  4.ec2:DeleteNetworkInterface",
                                    "  5.ec2:DescribeNetworkInterfaces",
                                    "  6.ec2:DescribeSecurityGroups",
                                    "  7.ec2:DescribeSubnets",
                                    "  8.ec2:DescribeVpcs",
                                    "  9.logs:CreateLogGroup",
                                    "  10.logs:CreateLogStream",
                                    "  11.logs:PutLogEvents",
                                    "Note",
                                    "When using an encrypted customer managed key, add the kms:Decrypt permission as well.",
                                    "To add permissions and create a trigger",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose the name of a function.",
                                    "  3 : Choose the Configuration tab, and then choose Permissions.",
                                    "  4 : Under Role name, choose the link to your execution role. This link opens the role in the IAM console.",
                                    "  5 : Choose Add permissions, and then choose Create inline policy.",
                                    " 6 : In the Policy editor, choose JSON. Enter the following policy. Your function needs these permissions to read from an Amazon MQ broker. NoteWhen using an encrypted customer managed key, you must also add the kms:Decrypt permission.",
                                    {
                                        "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n          \"mq:DescribeBroker\",\n          \"secretsmanager:GetSecretValue\",\n          \"ec2:CreateNetworkInterface\",\n          \"ec2:DeleteNetworkInterface\",\n          \"ec2:DescribeNetworkInterfaces\", \n          \"ec2:DescribeSecurityGroups\",\n          \"ec2:DescribeSubnets\",\n          \"ec2:DescribeVpcs\",\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\", \n          \"logs:PutLogEvents\"\t\t\n        ],\n        \"Resource\": \"*\"\n      }\n    ]\n  }"
                                    },
                                    "  7 : Choose Next. Enter a policy name and then choose Create policy.",
                                    "  8 : Go back to your function in the Lambda console. Under Function overview, choose Add trigger.",
                                    "  9 : Choose the MQ trigger type.",
                                    "  10 : Configure the required options, and then choose Add.",
                                    "Lambda supports the following options for Amazon MQ event sources:",
                                    "  1.MQ broker :  – Select an Amazon .",
                                    "  2.Batch size :  – Set the maximum number of messages to retrieve in a single            batch.",
                                    "  3.Queue name :  – Enter the Amazon MQ queue to consume.",
                                    "  4.Source access configuration :  – Enter virtual host information and the Secrets Manager            secret that stores your broker credentials.",
                                    "  5.Enable trigger :  – Disable the trigger to stop processing records.",
                                    "To enable or disable the trigger (or delete it), choose the MQ trigger in the designer. To reconfigure the trigger, use the event source mapping API        operations."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Parameters",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-mq-params.html",
                        "sections": [
                            "All Lambda event source types share the same CreateEventSourceMapping and UpdateEventSourceMapping        API operations. However, only some of the parameters apply to Amazon MQ and RabbitMQ.",
                            "ParameterRequiredDefaultNotesBatchSizeN100Maximum: 10,000EnabledNtruenoneFunctionNameYN/A noneFilterCriteriaNN/A Control which events Lambda sends to your functionMaximumBatchingWindowInSecondsN500 msBatching behaviorQueuesNN/AThe name of the Amazon MQ broker destination queue to consume.SourceAccessConfigurationsNN/A For ActiveMQ, BASIC_AUTH credentials. For RabbitMQ, can contain both BASIC_AUTH credentials and VIRTUAL_HOST information."
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-mq-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for Amazon MQ event sources.",
                            "Topics",
                            {
                                "sub_header": "Amazon MQ event filtering basics",
                                "content": [
                                    "Suppose your Amazon MQ message queue contains messages either in valid JSON format or as plain strings. An example record would look like the             following, with the data converted to a Base64 encoded string in the data field.",
                                    "  1.ActiveMQ : { \n    \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\", \n    \"messageType\": \"jms/text-message\",\n    \"deliveryMode\": 1,\n    \"replyTo\": null,\n    \"type\": null,\n    \"expiration\": \"60000\",\n    \"priority\": 1,\n    \"correlationId\": \"myJMSCoID\",\n    \"redelivered\": false,\n    \"destination\": { \n      \"physicalName\": \"testQueue\" \n    },\n    \"data\":\"QUJDOkFBQUE=\",\n    \"timestamp\": 1598827811958,\n    \"brokerInTime\": 1598827811958, \n    \"brokerOutTime\": 1598827811959, \n    \"properties\": {\n      \"index\": \"1\",\n      \"doAlarm\": \"false\",\n      \"myCustomProperty\": \"value\"\n    }\n}",
                                    "  2.RabbitMQ : {\n    \"basicProperties\": {\n        \"contentType\": \"text/plain\",\n        \"contentEncoding\": null,\n        \"headers\": {\n            \"header1\": {\n                \"bytes\": [\n                  118,\n                  97,\n                  108,\n                  117,\n                  101,\n                  49\n                ]\n            },\n            \"header2\": {\n                \"bytes\": [\n                  118,\n                  97,\n                  108,\n                  117,\n                  101,\n                  50\n                ]\n            },\n            \"numberInHeader\": 10\n        },\n        \"deliveryMode\": 1,\n        \"priority\": 34,\n        \"correlationId\": null,\n        \"replyTo\": null,\n        \"expiration\": \"60000\",\n        \"messageId\": null,\n        \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",\n        \"type\": null,\n        \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",\n        \"appId\": null,\n        \"clusterId\": null,\n        \"bodySize\": 80\n        },\n    \"redelivered\": false,\n    \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"\n}",
                                    "ActiveMQ{     \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",     \"messageType\": \"jms/text-message\",    \"deliveryMode\": 1,    \"replyTo\": null,    \"type\": null,    \"expiration\": \"60000\",    \"priority\": 1,    \"correlationId\": \"myJMSCoID\",    \"redelivered\": false,    \"destination\": {       \"physicalName\": \"testQueue\"     },    \"data\":\"QUJDOkFBQUE=\",    \"timestamp\": 1598827811958,    \"brokerInTime\": 1598827811958,     \"brokerOutTime\": 1598827811959,     \"properties\": {      \"index\": \"1\",      \"doAlarm\": \"false\",      \"myCustomProperty\": \"value\"    }}RabbitMQ{    \"basicProperties\": {        \"contentType\": \"text/plain\",        \"contentEncoding\": null,        \"headers\": {            \"header1\": {                \"bytes\": [                  118,                  97,                  108,                  117,                  101,                  49                ]            },            \"header2\": {                \"bytes\": [                  118,                  97,                  108,                  117,                  101,                  50                ]            },            \"numberInHeader\": 10        },        \"deliveryMode\": 1,        \"priority\": 34,        \"correlationId\": null,        \"replyTo\": null,        \"expiration\": \"60000\",        \"messageId\": null,        \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",        \"type\": null,        \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",        \"appId\": null,        \"clusterId\": null,        \"bodySize\": 80        },    \"redelivered\": false,    \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"}",
                                    "anchor",
                                    "anchor",
                                    {
                                        "code_example": "{ \n    \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\", \n    \"messageType\": \"jms/text-message\",\n    \"deliveryMode\": 1,\n    \"replyTo\": null,\n    \"type\": null,\n    \"expiration\": \"60000\",\n    \"priority\": 1,\n    \"correlationId\": \"myJMSCoID\",\n    \"redelivered\": false,\n    \"destination\": { \n      \"physicalName\": \"testQueue\" \n    },\n    \"data\":\"QUJDOkFBQUE=\",\n    \"timestamp\": 1598827811958,\n    \"brokerInTime\": 1598827811958, \n    \"brokerOutTime\": 1598827811959, \n    \"properties\": {\n      \"index\": \"1\",\n      \"doAlarm\": \"false\",\n      \"myCustomProperty\": \"value\"\n    }\n}"
                                    },
                                    "For both Active MQ and Rabbit MQ brokers, you can use event filtering to filter records using the data key. Suppose your             Amazon MQ queue contains messages in the following JSON format.",
                                    "{    \"timeout\": 0,    \"IPAddress\": \"203.0.113.254\"}",
                                    "To filter only those records where the timeout field is greater than 0, the FilterCriteria object would be             as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"data\\\" : { \\\"timeout\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 0] } } ] } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"data\": {        \"timeout\": [ { \"numeric\": [ \">\", 0 ] } ]        }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"data\" : { \"timeout\" : [ { \"numeric\": [ \">\", 0 ] } ] } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:mq:us-east-2:123456789012:broker:my-broker:b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"timeout\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 0 ] } ] } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"data\" : { \"timeout\" : [ { \"numeric\": [ \">\", 0 ] } ] } }'",
                                    "Consoleto add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"data\" : { \"timeout\" : [ { \"numeric\": [ \">\", 0 ] } ] } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:mq:us-east-2:123456789012:broker:my-broker:b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"timeout\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 0 ] } ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"timeout\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 0 ] } ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : { \\\"timeout\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 0 ] } ] } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"data\" : { \"timeout\" : [ { \"numeric\": [ \">\", 0 ] } ] } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "to add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"data\" : { \"timeout\" : [ { \"numeric\": [ \">\", 0 ] } ] } }"
                                    },
                                    "With Amazon MQ, you can also filter records where the message is a plain string. Suppose you want to process only records where the             message begins with \"Result: \". The FilterCriteria object would look as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"data\\\" : [ { \\\"prefix\\\": \\\"Result: \\\" } ] }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"data\": [        {        \"prefix\": \"Result: \"        }    ]}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"data\" : [ { \"prefix\": \"Result: \" } ] }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:mq:us-east-2:123456789012:broker:my-broker:b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : [ { \\\"prefix\\\": \\\"Result: \\\" } ] }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"data\" : [ { \"prefix\": \"Result \" } ] }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"data\" : [ { \"prefix\": \"Result: \" } ] }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:mq:us-east-2:123456789012:broker:my-broker:b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : [ { \\\"prefix\\\": \\\"Result: \\\" } ] }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"data\\\" : [ { \\\"prefix\\\": \\\"Result: \\\" } ] }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"data\" : [ { \"prefix\": \"Result \" } ] }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"data\" : [ { \"prefix\": \"Result: \" } ] }"
                                    },
                                    "Amazon MQ messages must be UTF-8 encoded strings, either plain strings or in JSON format. That's because Lambda decodes Amazon MQ byte arrays into UTF-8 before             applying filter criteria. If your messages use another encoding, such as UTF-16 or ASCII, or if the message format doesn't match the             FilterCriteria format, Lambda processes metadata filters only. The following table summarizes the specific behavior:",
                                    "Incoming message formatFilter pattern format for message propertiesResulting actionPlain stringPlain stringLambda filters based on your filter criteria.Plain stringNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Plain stringValid JSONLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONPlain stringLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONValid JSONLambda filters based on your filter criteria.Non-UTF-8 encoded stringJSON, plain string, or no patternLambda filters (on the other metadata properties only) based on your filter criteria."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Troubleshoot",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-mq-errors.html",
                        "sections": [
                            "When a Lambda function encounters an unrecoverable error, your Amazon MQ consumer stops processing records. Any        other consumers can continue processing, provided that they do not encounter the same error. To determine the        potential cause of a stopped consumer, check the StateTransitionReason field in the return details of        your EventSourceMapping for one of the following codes:",
                            "  1.ESM_CONFIG_NOT_VALID : \nThe event source mapping configuration is not valid.\n",
                            "  2.EVENT_SOURCE_AUTHN_ERROR : \nLambda failed to authenticate the event source.\n",
                            "  3.EVENT_SOURCE_AUTHZ_ERROR : \nLambda does not have the required permissions to access the event source.\n",
                            "  4.FUNCTION_CONFIG_NOT_VALID : \nThe function's configuration is not valid.\n",
                            "ESM_CONFIG_NOT_VALIDThe event source mapping configuration is not valid.EVENT_SOURCE_AUTHN_ERRORLambda failed to authenticate the event source.EVENT_SOURCE_AUTHZ_ERRORLambda does not have the required permissions to access the event source.FUNCTION_CONFIG_NOT_VALIDThe function's configuration is not valid.",
                            "Records also go unprocessed if Lambda drops        them due to their size. The size limit for Lambda records is 6 MB. To        redeliver messages upon function error, you can use a dead-letter queue (DLQ). For more information, see Message Redelivery and            DLQ Handling on the Apache ActiveMQ website and Reliability Guide on the RabbitMQ        website.",
                            "Note",
                            "Lambda does not support custom redelivery policies. Instead, Lambda uses a policy with the default values from the Redelivery Policy page on the Apache ActiveMQ website, with maximumRedeliveries set to 6."
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "Note",
                    "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                    "Amazon MQ is a managed message broker service for Apache ActiveMQ    and RabbitMQ. A message broker enables software    applications and components to communicate using various programming languages, operating systems, and formal    messaging protocols through either topic or queue event destinations.",
                    "Amazon MQ can also manage Amazon Elastic Compute Cloud (Amazon EC2) instances on your behalf by installing ActiveMQ or RabbitMQ brokers and by providing    different network topologies and other infrastructure needs.",
                    "You can use a Lambda function to process records from your Amazon MQ message broker. Lambda invokes your function    through an event source mapping, a Lambda resource that reads    messages from your broker and invokes the function synchronously.",
                    "Warning",
                    "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                    "The Amazon MQ event source mapping has the following configuration restrictions:",
                    "  1.Concurrency – Lambda functions that use an Amazon MQ event source mapping have a default maximum concurrency       setting. For ActiveMQ, the Lambda service limits the number of concurrent execution environments to five per Amazon MQ      event source mapping. For RabbitMQ, the number of concurrent execution environments is limited to 1 per Amazon MQ      event source mapping. Even if you change your function's reserved or provisioned concurrency settings, the Lambda       service won't make more execution environments available. To request an increase in the default maximum concurrency      for a single Amazon MQ event source mapping, contact AWS Support with the event source mapping UUID, as well as the region.      Because increases are applied at the specific event source mapping level, not the account or region level,      you need to manually request a scaling increase for each event source mapping.",
                    "  2.Cross account – Lambda does not support cross-account processing. You cannot use Lambda to process records        from an Amazon MQ message broker that is in a different AWS account.",
                    "  3.Authentication – For ActiveMQ, only the ActiveMQ SimpleAuthenticationPlugin is        supported. For RabbitMQ, only the PLAIN authentication mechanism is supported. Users must use AWS Secrets Manager to manage their credentials.        For more information about ActiveMQ authentication, see Integrating ActiveMQ brokers          with LDAP in the Amazon MQ Developer Guide.",
                    "  4.Quotas in Amazon MQ : Connection quota – Brokers have a maximum number of allowed connections per wire-level protocol. This        quota is based on the broker instance type. For more information, see the Brokers        section of  in the          Amazon MQ Developer Guide.",
                    "  5.Connectivity – You can create brokers in a public or private virtual private cloud (VPC). For private VPCs, your Lambda function needs access to the VPC to receive messages. For more information, see Configure network security later in this        section.",
                    "  6.Event destinations – Only queue destinations are supported. However, you can use a virtual topic,        which behaves  as a topic internally while interacting with Lambda as a queue. For more information, see Virtual Destinations        on the Apache ActiveMQ website, and Virtual Hosts        on the RabbitMQ website.",
                    "  7.Network topology – For ActiveMQ, only one single-instance or standby broker is supported per event source mapping.        For RabbitMQ, only one single-instance broker or cluster deployment is supported per event source mapping.        Single-instance brokers require a failover endpoint. For more information about these broker deployment modes, see        Active MQ Broker Architecture and        Rabbit MQ Broker Architecturein the Amazon MQ Developer Guide.",
                    "  8.Protocols – Supported protocols depend on the type of Amazon MQ integration.For ActiveMQ integrations, Lambda consumes messages using the OpenWire/Java Message Service (JMS) protocol. No other protocols are supported for consuming messages. Within the JMS protocol, only TextMessage and BytesMessage are supported. Lambda also supports JMS custom properties. For more information about the OpenWire protocol, see              OpenWire on the Apache ActiveMQ website.For RabbitMQ integrations, Lambda consumes messages using the AMQP 0-9-1 protocol. No other protocols are supported            for consuming messages. For more information about RabbitMQ's implementation of the AMQP 0-9-1 protocol, see              AMQP 0-9-1 Complete Reference              Guide on the RabbitMQ website.",
                    "  9.For ActiveMQ integrations, Lambda consumes messages using the OpenWire/Java Message Service (JMS) protocol. No other protocols are supported for consuming messages. Within the JMS protocol, only TextMessage and BytesMessage are supported. Lambda also supports JMS custom properties. For more information about the OpenWire protocol, see              OpenWire on the Apache ActiveMQ website.",
                    "  10.For RabbitMQ integrations, Lambda consumes messages using the AMQP 0-9-1 protocol. No other protocols are supported            for consuming messages. For more information about RabbitMQ's implementation of the AMQP 0-9-1 protocol, see              AMQP 0-9-1 Complete Reference              Guide on the RabbitMQ website.",
                    "Lambda automatically supports the latest versions of ActiveMQ and RabbitMQ that Amazon MQ supports. For the latest    supported versions, see Amazon MQ release notes in the      Amazon MQ Developer Guide.",
                    "Note",
                    "By default, Amazon MQ has a weekly maintenance window for brokers. During that      window of time, brokers are unavailable. For brokers without standby, Lambda cannot process any messages during that window.",
                    "Topics",
                    {
                        "sub_header": "Understanding the Lambda consumer group for Amazon MQ",
                        "content": [
                            "To interact with Amazon MQ, Lambda creates a consumer group which can read from your Amazon MQ brokers. The consumer      group is created with the same ID as the event source mapping UUID.",
                            "For Amazon MQ event sources, Lambda batches records together and sends them to your function in a single payload.      To control behavior, you can configure the batching window and batch size. Lambda pulls messages until it processes      the payload size maximum of 6 MB, the batching window expires, or the number of records reaches the full batch      size. For more information, see Batching behavior.",
                            "The consumer group retrieves the messages as a BLOB of bytes, base64-encodes them into a single JSON payload, and then invokes your function. If your function returns an error for any of the messages in a batch, Lambda retries the      whole batch of messages until processing succeeds or the messages expire.",
                            "Note",
                            "While Lambda functions typically have a maximum timeout limit of 15 minutes,      event source mappings for Amazon MSK, self-managed Apache Kafka, Amazon DocumentDB, and Amazon MQ for ActiveMQ and RabbitMQ only support functions with      maximum timeout limits of 14 minutes. This constraint ensures that the event source mapping can properly      handle function errors and retries.",
                            "You can monitor a given function's concurrency usage using the ConcurrentExecutions metric in      Amazon CloudWatch. For more information about concurrency, see Configuring reserved concurrency for a function.",
                            "Example Amazon MQ record events",
                            "  1.ActiveMQ : {\n   \"eventSource\": \"aws:mq\",\n   \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",\n   \"messages\": [\n      { \n        \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\", \n        \"messageType\": \"jms/text-message\",\n        \"deliveryMode\": 1,\n        \"replyTo\": null,\n        \"type\": null,\n        \"expiration\": \"60000\",\n        \"priority\": 1,\n        \"correlationId\": \"myJMSCoID\",\n        \"redelivered\": false,\n        \"destination\": { \n          \"physicalName\": \"testQueue\" \n        },\n        \"data\":\"QUJDOkFBQUE=\",\n        \"timestamp\": 1598827811958,\n        \"brokerInTime\": 1598827811958, \n        \"brokerOutTime\": 1598827811959, \n        \"properties\": {\n          \"index\": \"1\",\n          \"doAlarm\": \"false\",\n          \"myCustomProperty\": \"value\"\n        }\n      },\n      { \n        \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",\n        \"messageType\": \"jms/bytes-message\",\n        \"deliveryMode\": 1,\n        \"replyTo\": null,\n        \"type\": null,\n        \"expiration\": \"60000\",\n        \"priority\": 2,\n        \"correlationId\": \"myJMSCoID1\",\n        \"redelivered\": false,\n        \"destination\": { \n          \"physicalName\": \"testQueue\" \n        },\n        \"data\":\"LQaGQ82S48k=\",\n        \"timestamp\": 1598827811958,\n        \"brokerInTime\": 1598827811958, \n        \"brokerOutTime\": 1598827811959, \n        \"properties\": {\n          \"index\": \"1\",\n          \"doAlarm\": \"false\",\n          \"myCustomProperty\": \"value\"\n        }\n      }\n   ]\n}",
                            "  2.RabbitMQ : \n{\n  \"eventSource\": \"aws:rmq\",\n  \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:pizzaBroker:b-9bcfa592-423a-4942-879d-eb284b418fc8\",\n  \"rmqMessagesByQueue\": {\n    \"pizzaQueue::/\": [\n      {\n        \"basicProperties\": {\n          \"contentType\": \"text/plain\",\n          \"contentEncoding\": null,\n          \"headers\": {\n            \"header1\": {\n              \"bytes\": [\n                118,\n                97,\n                108,\n                117,\n                101,\n                49\n              ]\n            },\n            \"header2\": {\n              \"bytes\": [\n                118,\n                97,\n                108,\n                117,\n                101,\n                50\n              ]\n            },\n            \"numberInHeader\": 10\n          },\n          \"deliveryMode\": 1,\n          \"priority\": 34,\n          \"correlationId\": null,\n          \"replyTo\": null,\n          \"expiration\": \"60000\",\n          \"messageId\": null,\n          \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",\n          \"type\": null,\n          \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",\n          \"appId\": null,\n          \"clusterId\": null,\n          \"bodySize\": 80\n        },\n        \"redelivered\": false,\n        \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"\n      }\n    ]\n  }\n}",
                            "ActiveMQ{   \"eventSource\": \"aws:mq\",   \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",   \"messages\": [      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",         \"messageType\": \"jms/text-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 1,        \"correlationId\": \"myJMSCoID\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"QUJDOkFBQUE=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      },      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",        \"messageType\": \"jms/bytes-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 2,        \"correlationId\": \"myJMSCoID1\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"LQaGQ82S48k=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      }   ]}RabbitMQ{  \"eventSource\": \"aws:rmq\",  \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:pizzaBroker:b-9bcfa592-423a-4942-879d-eb284b418fc8\",  \"rmqMessagesByQueue\": {    \"pizzaQueue::/\": [      {        \"basicProperties\": {          \"contentType\": \"text/plain\",          \"contentEncoding\": null,          \"headers\": {            \"header1\": {              \"bytes\": [                118,                97,                108,                117,                101,                49              ]            },            \"header2\": {              \"bytes\": [                118,                97,                108,                117,                101,                50              ]            },            \"numberInHeader\": 10          },          \"deliveryMode\": 1,          \"priority\": 34,          \"correlationId\": null,          \"replyTo\": null,          \"expiration\": \"60000\",          \"messageId\": null,          \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",          \"type\": null,          \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",          \"appId\": null,          \"clusterId\": null,          \"bodySize\": 80        },        \"redelivered\": false,        \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"      }    ]  }}",
                            "anchor",
                            "anchor",
                            {
                                "code_example": "{\n   \"eventSource\": \"aws:mq\",\n   \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",\n   \"messages\": [\n      { \n        \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\", \n        \"messageType\": \"jms/text-message\",\n        \"deliveryMode\": 1,\n        \"replyTo\": null,\n        \"type\": null,\n        \"expiration\": \"60000\",\n        \"priority\": 1,\n        \"correlationId\": \"myJMSCoID\",\n        \"redelivered\": false,\n        \"destination\": { \n          \"physicalName\": \"testQueue\" \n        },\n        \"data\":\"QUJDOkFBQUE=\",\n        \"timestamp\": 1598827811958,\n        \"brokerInTime\": 1598827811958, \n        \"brokerOutTime\": 1598827811959, \n        \"properties\": {\n          \"index\": \"1\",\n          \"doAlarm\": \"false\",\n          \"myCustomProperty\": \"value\"\n        }\n      },\n      { \n        \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",\n        \"messageType\": \"jms/bytes-message\",\n        \"deliveryMode\": 1,\n        \"replyTo\": null,\n        \"type\": null,\n        \"expiration\": \"60000\",\n        \"priority\": 2,\n        \"correlationId\": \"myJMSCoID1\",\n        \"redelivered\": false,\n        \"destination\": { \n          \"physicalName\": \"testQueue\" \n        },\n        \"data\":\"LQaGQ82S48k=\",\n        \"timestamp\": 1598827811958,\n        \"brokerInTime\": 1598827811958, \n        \"brokerOutTime\": 1598827811959, \n        \"properties\": {\n          \"index\": \"1\",\n          \"doAlarm\": \"false\",\n          \"myCustomProperty\": \"value\"\n        }\n      }\n   ]\n}"
                            },
                            "ActiveMQ{   \"eventSource\": \"aws:mq\",   \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",   \"messages\": [      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",         \"messageType\": \"jms/text-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 1,        \"correlationId\": \"myJMSCoID\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"QUJDOkFBQUE=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      },      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",        \"messageType\": \"jms/bytes-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 2,        \"correlationId\": \"myJMSCoID1\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"LQaGQ82S48k=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      }   ]}RabbitMQ{  \"eventSource\": \"aws:rmq\",  \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:pizzaBroker:b-9bcfa592-423a-4942-879d-eb284b418fc8\",  \"rmqMessagesByQueue\": {    \"pizzaQueue::/\": [      {        \"basicProperties\": {          \"contentType\": \"text/plain\",          \"contentEncoding\": null,          \"headers\": {            \"header1\": {              \"bytes\": [                118,                97,                108,                117,                101,                49              ]            },            \"header2\": {              \"bytes\": [                118,                97,                108,                117,                101,                50              ]            },            \"numberInHeader\": 10          },          \"deliveryMode\": 1,          \"priority\": 34,          \"correlationId\": null,          \"replyTo\": null,          \"expiration\": \"60000\",          \"messageId\": null,          \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",          \"type\": null,          \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",          \"appId\": null,          \"clusterId\": null,          \"bodySize\": 80        },        \"redelivered\": false,        \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"      }    ]  }}anchoranchorActiveMQRabbitMQ{   \"eventSource\": \"aws:mq\",   \"eventSourceArn\": \"arn:aws:mq:us-east-2:111122223333:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",   \"messages\": [      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",         \"messageType\": \"jms/text-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 1,        \"correlationId\": \"myJMSCoID\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"QUJDOkFBQUE=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      },      {         \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-east-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",        \"messageType\": \"jms/bytes-message\",        \"deliveryMode\": 1,        \"replyTo\": null,        \"type\": null,        \"expiration\": \"60000\",        \"priority\": 2,        \"correlationId\": \"myJMSCoID1\",        \"redelivered\": false,        \"destination\": {           \"physicalName\": \"testQueue\"         },        \"data\":\"LQaGQ82S48k=\",        \"timestamp\": 1598827811958,        \"brokerInTime\": 1598827811958,         \"brokerOutTime\": 1598827811959,         \"properties\": {          \"index\": \"1\",          \"doAlarm\": \"false\",          \"myCustomProperty\": \"value\"        }      }   ]}",
                            "Note",
                            "In the RabbitMQ example, pizzaQueue is the name of the RabbitMQ queue, and / is the          name of the virtual host. When receiving messages, the event source lists messages under          pizzaQueue::/."
                        ]
                    }
                ]
            },
            {
                "title": "MSK",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html",
                "contents": [
                    {
                        "title": "Configure event source",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-msk-configure.html",
                        "sections": [
                            "Before you create an event source mapping for your Amazon MSK cluster, you need to ensure that        your cluster and the VPC it resides in are correctly configured. You also need to make sure        that your Lambda function's execution role has         the necessary IAM permissions.",
                            "Follow the instructions in the following sections to configure your Amazon MSK cluster, VPC, and Lambda        function. To learn how to create the event source mapping, see        Adding Amazon MSK as an event source.",
                            "Topics",
                            {
                                "sub_header": "MSK cluster authentication",
                                "content": [
                                    "Lambda needs permission to access the Amazon MSK cluster, retrieve records, and perform other tasks. Amazon MSK supports      several options for controlling client access to the MSK cluster.",
                                    "Cluster access options",
                                    {
                                        "sub_header": "Unauthenticated access",
                                        "content": [
                                            "If no clients access the cluster over the internet, you can use unauthenticated access."
                                        ]
                                    },
                                    {
                                        "sub_header": "SASL/SCRAM authentication",
                                        "content": [
                                            "Amazon MSK supports Simple Authentication and Security Layer/Salted Challenge Response Authentication Mechanism        (SASL/SCRAM) authentication with Transport Layer Security (TLS) encryption. For Lambda to connect to the cluster,        you store the authentication credentials (user name and password) in an AWS Secrets Manager secret.",
                                            "For more information about using Secrets Manager, see User name and password authentication with AWS Secrets Manager        in the Amazon Managed Streaming for Apache Kafka Developer Guide.",
                                            "Amazon MSK doesn't support SASL/PLAIN authentication."
                                        ]
                                    },
                                    {
                                        "sub_header": "IAM role-based authentication",
                                        "content": [
                                            "You can use IAM to authenticate the identity of clients that connect to the MSK cluster. If IAM auth is        active on your MSK cluster, and you don't provide a secret for auth, Lambda automatically defaults to using IAM auth.        To create and deploy user or role-based policies, use the IAM console or API. For more information, see IAM access control in        the Amazon Managed Streaming for Apache Kafka Developer Guide.",
                                            "To allow Lambda to connect to the MSK cluster, read records, and perform other required actions, add the        following permissions to your function's execution role.",
                                            "{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"kafka-cluster:Connect\",                \"kafka-cluster:DescribeGroup\",                \"kafka-cluster:AlterGroup\",                \"kafka-cluster:DescribeTopic\",                \"kafka-cluster:ReadData\",                \"kafka-cluster:DescribeClusterDynamicConfiguration\"            ],            \"Resource\": [                \"arn:aws:kafka:region:account-id:cluster/cluster-name/cluster-uuid\",                \"arn:aws:kafka:region:account-id:topic/cluster-name/cluster-uuid/topic-name\",                \"arn:aws:kafka:region:account-id:group/cluster-name/cluster-uuid/consumer-group-id\"            ]        }    ]}       ",
                                            "You can scope these permissions to a specific cluster, topic, and group. For more information, see the          Amazon MSK Kafka          actions in the Amazon Managed Streaming for Apache Kafka Developer Guide."
                                        ]
                                    },
                                    {
                                        "sub_header": "Mutual TLS authentication",
                                        "content": [
                                            "Mutual TLS (mTLS) provides two-way authentication between the client and server. The client sends a        certificate to the server for the server to verify the client, and the server sends a certificate to the client        for the client to verify the server. ",
                                            "For Amazon MSK, Lambda acts as the client. You configure a client certificate (as a secret in Secrets Manager) to        authenticate Lambda with the brokers in your MSK cluster. The client certificate must be signed by a CA in the        server's trust store. The MSK cluster sends a server certificate to Lambda to authenticate the brokers with        Lambda. The server certificate must be signed by a certificate authority (CA) that's in the AWS trust store. ",
                                            "For instructions on how to generate a client certificate, see         Introducing mutual TLS authentication for Amazon MSK as an event source.",
                                            "Amazon MSK doesn't support self-signed server certificates, because all brokers in Amazon MSK use public certificates signed by          Amazon Trust Services CAs, which Lambda trusts by        default.",
                                            "For more information about mTLS for Amazon MSK, see Mutual TLS Authentication in the          Amazon Managed Streaming for Apache Kafka Developer Guide."
                                        ]
                                    },
                                    {
                                        "sub_header": "Configuring the mTLS secret",
                                        "content": [
                                            "The CLIENT_CERTIFICATE_TLS_AUTH secret requires a certificate field and a private key field. For an        encrypted private key, the secret requires a private key password. Both the certificate and private key must be        in PEM format.",
                                            "Note",
                                            "Lambda supports the PBES1 (but not          PBES2) private key encryption algorithms.",
                                            "The certificate field must contain a list of certificates, beginning with the client certificate, followed        by any intermediate certificates, and ending with the root certificate. Each certificate must start on a new        line with the following structure:",
                                            "-----BEGIN CERTIFICATE-----          <certificate contents>-----END CERTIFICATE-----      ",
                                            "Secrets Manager supports secrets up to 65,536 bytes, which is enough space for long certificate chains.",
                                            "The private key must be in PKCS #8        format, with the following structure:",
                                            "-----BEGIN PRIVATE KEY-----           <private key contents>-----END PRIVATE KEY-----            ",
                                            "For an encrypted private key, use the following structure:",
                                            "-----BEGIN ENCRYPTED PRIVATE KEY-----            <private key contents>-----END ENCRYPTED PRIVATE KEY-----           ",
                                            "The following example shows the contents of a secret for mTLS authentication using an encrypted private key.        For an encrypted private key, you include the private key password in the secret.",
                                            "{ \"privateKeyPassword\": \"testpassword\", \"certificate\": \"-----BEGIN CERTIFICATE-----MIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw...j0Lh4/+1HfgyE2KlmII36dg4IMzNjAFEBZiCRoPimO40s1cRqtFHXoal0QQbIlxkcmUuiAii9R0=-----END CERTIFICATE----------BEGIN CERTIFICATE-----MIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb...rQoiowbbk5wXCheYSANQIfTZ6weQTgiCHCCbuuMKNVS95FkXm0vqVD/YpXKwA/noc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==-----END CERTIFICATE-----\", \"privateKey\": \"-----BEGIN ENCRYPTED PRIVATE KEY-----MIIFKzBVBgkqhkiG9w0BBQ0wSDAnBgkqhkiG9w0BBQwwGgQUiAFcK5hT/X7Kjmgp...QrSekqF+kWzmB6nAfSzgO9IaoAaytLvNgGTckWeUkWn/V0Ck+LdGUXzAC4RxZnoQzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==-----END ENCRYPTED PRIVATE KEY-----\"} "
                                        ]
                                    },
                                    {
                                        "sub_header": "How Lambda chooses a bootstrap broker",
                                        "content": [
                                            "Lambda chooses a         bootstrap broker based on the authentication methods available on your cluster, and whether you provide a secret        for authentication. If you provide a secret for mTLS or SASL/SCRAM, Lambda automatically chooses that auth method.        If you don't provide a secret, Lambda selects the strongest auth method that's active on your cluster. The following is        the order of priority in which Lambda selects a broker, from strongest to weakest auth:",
                                            "  1.mTLS (secret provided for mTLS)",
                                            "  2.SASL/SCRAM (secret provided for SASL/SCRAM)",
                                            "  3.SASL IAM (no secret provided, and IAM auth active)",
                                            "  4.Unauthenticated TLS (no secret provided, and IAM auth not active)",
                                            "  5.Plaintext (no secret provided, and both IAM auth and unauthenticated TLS are not active)",
                                            "Note",
                                            "If Lambda can't connect to the most secure broker type, Lambda doesn't attempt to connect to a different (weaker)        broker type. If you want Lambda to choose a weaker broker type, deactivate all stronger auth methods on your cluster."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Managing API access and permissions",
                                "content": [
                                    "In addition to accessing the Amazon MSK cluster, your function needs permissions to perform various Amazon MSK API      actions. You add these permissions to the function's execution role. If your users need access to any of the Amazon MSK      API actions, add the required permissions to the identity policy for the user or role.",
                                    "You can add each of the following permissions to your execution role manually. Alternatively, you can attach the      AWS managed policy AWSLambdaMSKExecutionRole to your execution role. The      AWSLambdaMSKExecutionRole policy contains all required API actions and VPC permissions listed below.",
                                    {
                                        "sub_header": "Required Lambda function execution role permissions",
                                        "content": [
                                            "To create and store logs in a log group in Amazon CloudWatch Logs, your Lambda function must have the following        permissions in its execution role:",
                                            "  1.logs:CreateLogGroup",
                                            "  2.logs:CreateLogStream",
                                            "  3.logs:PutLogEvents",
                                            "For Lambda to access your Amazon MSK cluster on your behalf, your Lambda function must have the following        permissions in its execution role:",
                                            "  1.kafka:DescribeCluster",
                                            "  2.kafka:DescribeClusterV2",
                                            "  3.kafka:GetBootstrapBrokers",
                                            "  4.kafka:DescribeVpcConnection: Only required for cross-account event source mappings.",
                                            "  5.kafka:ListVpcConnections: Not required in execution role, but required for an IAM principal that is creating a cross-account event source mapping.",
                                            "You only need to add one of either kafka:DescribeCluster or kafka:DescribeClusterV2. For provisioned MSK        clusters, either permission works. For serverless MSK clusters, you must use kafka:DescribeClusterV2.",
                                            "Note",
                                            "Lambda eventually plans to remove the kafka:DescribeCluster permission from the        associated AWSLambdaMSKExecutionRole managed policy. If you use this policy, you should        migrate any applications using kafka:DescribeCluster to use        kafka:DescribeClusterV2 instead."
                                        ]
                                    },
                                    {
                                        "sub_header": "VPC permissions",
                                        "content": [
                                            "If only users within a VPC can access your Amazon MSK cluster, your Lambda function must have permission to        access your Amazon VPC resources. These resources include your VPC, subnets, security groups, and network        interfaces. To access these resources, your function's execution role must have the following        permissions. These permissions are included in the AWSLambdaMSKExecutionRole AWS managed policy.",
                                            "  1.ec2:CreateNetworkInterface",
                                            "  2.ec2:DescribeNetworkInterfaces",
                                            "  3.ec2:DescribeVpcs",
                                            "  4.ec2:DeleteNetworkInterface",
                                            "  5.ec2:DescribeSubnets",
                                            "  6.ec2:DescribeSecurityGroups"
                                        ]
                                    },
                                    {
                                        "sub_header": "Optional Lambda function permissions",
                                        "content": [
                                            "Your Lambda function might also need permissions to:",
                                            "  1.Access your SCRAM secret, if using SASL/SCRAM authentication.",
                                            "  2.Describe your Secrets Manager secret.",
                                            "  3.Access your AWS Key Management Service (AWS KMS) customer managed key.",
                                            "  4.Send records of failed invocations to a destination.",
                                            {
                                                "sub_header": "Secrets Manager and AWS KMS permissions",
                                                "content": [
                                                    "Depending on the type of access control that you're configuring for your Amazon MSK brokers, your Lambda          function might need permission to access your SCRAM secret (if using SASL/SCRAM authentication), or Secrets Manager          secret to decrypt your AWS KMS customer managed key. To access these resources, your function's execution role must have          the following permissions:",
                                                    "  1.              kafka:ListScramSecrets",
                                                    "  2.secretsmanager:GetSecretValue",
                                                    "  3.kms:Decrypt"
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding permissions to your execution role",
                                        "content": [
                                            "Follow these steps to add the AWS managed policy AWSLambdaMSKExecutionRole to your execution role using the IAM console.",
                                            "To add an AWS managed policy",
                                            "  1 : Open the Policies page of the IAM            console.",
                                            "  2 : In the search box, enter the policy name (AWSLambdaMSKExecutionRole).",
                                            "  3 : Select the policy from the list, and then choose Policy actions, Attach.",
                                            "  4 : On the Attach policy page, select your execution role from the list, and then            choose Attach policy."
                                        ]
                                    },
                                    {
                                        "sub_header": "Granting users access with an IAM policy",
                                        "content": [
                                            "By default, users and roles don't have permission to perform Amazon MSK API operations. To grant access to        users in your organization or account, you can add or update an identity-based policy. For more information, see          Amazon MSK          Identity-Based Policy Examples in the Amazon Managed Streaming for Apache Kafka Developer Guide."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Authentication and authorization errors",
                                "content": [
                                    "If any of the permissions required to consume data from the Amazon MSK cluster are missing, Lambda displays one of      the following error messages in the event source mapping under LastProcessingResult.",
                                    "Error messages",
                                    {
                                        "sub_header": "Cluster failed to authorize Lambda",
                                        "content": [
                                            "For SASL/SCRAM or mTLS, this error indicates that the provided user doesn't have all of the following        required Kafka access control list (ACL) permissions:",
                                            "  1.DescribeConfigs Cluster",
                                            "  2.Describe Group",
                                            "  3.Read Group",
                                            "  4.Describe Topic",
                                            "  5.Read Topic",
                                            "For IAM access control, your function's execution role is missing one or more of the permissions required        to access the group or topic. Review the list of required permissions in IAM role-based authentication.",
                                            "When you create either Kafka ACLs or an IAM policy with the required Kafka cluster permissions, specify        the topic and group as resources. The topic name must match the topic in the event source mapping. The group        name must match the event source mapping's UUID.",
                                            "After you add the required permissions to the execution role, it might take several minutes for the changes        to take effect."
                                        ]
                                    },
                                    {
                                        "sub_header": "SASL authentication failed",
                                        "content": [
                                            "For SASL/SCRAM, this error indicates that the provided user name and password aren't valid.",
                                            "For IAM access control, the execution role is missing the kafka-cluster:Connect permission        for the MSK cluster. Add this permission to the role and specify the cluster's Amazon Resource Name (ARN) as a        resource.",
                                            "You might see this error occurring intermittently. The cluster rejects connections after the number of TCP        connections exceeds the Amazon MSK service          quota. Lambda backs off and retries until a connection is successful. After Lambda connects to the        cluster and polls for records, the last processing result changes to OK."
                                        ]
                                    },
                                    {
                                        "sub_header": "Server failed to authenticate Lambda",
                                        "content": [
                                            "This error indicates that the Amazon MSK Kafka brokers failed to authenticate with Lambda. This can occur for        any of the following reasons:",
                                            "  1.You didn't provide a client certificate for mTLS authentication.",
                                            "  2.You provided a client certificate, but the brokers aren't configured to use mTLS.",
                                            "  3.A client certificate isn't trusted by the brokers."
                                        ]
                                    },
                                    {
                                        "sub_header": "Provided certificate or private key is invalid",
                                        "content": [
                                            "This error indicates that the Amazon MSK consumer couldn't use the provided certificate or private key. Make        sure that the certificate and key use PEM format, and that the private key encryption uses a PBES1        algorithm."
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Configure network security",
                                "content": [
                                    "To give Lambda full access to Amazon MSK through your event source mapping, either your cluster must use a public endpoint             (public IP address), or you must provide access to the Amazon VPC you created the cluster in.",
                                    "When you use Amazon MSK with Lambda, create AWS PrivateLink VPC endpoints that provide your function            access to the resources in your Amazon VPC.",
                                    "Note",
                                    "AWS PrivateLink VPC endpoints are required for functions with event source mappings that use the default (on-demand) mode                for event pollers. If your event source mapping uses                 provisioned mode, you don't need to configure AWS PrivateLink VPC endpoints.",
                                    "Create an endpoint to provide access to the following resources:",
                                    "  1.                    Lambda — Create an endpoint for the Lambda service principal.                ",
                                    "  2.                    AWS STS — Create an endpoint for the AWS STS in order for a service principal to assume a role on your behalf.                ",
                                    "  3.                    Secrets Manager — If your cluster uses Secrets Manager to store credentials, create an endpoint for Secrets Manager.                ",
                                    "Alternatively, configure a NAT gateway on each public subnet in the Amazon VPC. For more information,             see Enable internet access for VPC-connected Lambda functions.",
                                    "When you create an event source mapping for Amazon MSK, Lambda checks whether Elastic Network Interfaces (ENIs)             are already present for the subnets and security groups configured for your Amazon VPC. If Lambda finds existing ENIs, it             attempts to re-use them. Otherwise, Lambda creates new ENIs to connect to the event source and invoke your function.",
                                    "Note",
                                    "Lambda functions always run inside VPCs owned by the Lambda service. Your function's VPC configuration                does not affect the event source mapping. Only the networking configuration of the event source's determines                 how Lambda connects to your event source.",
                                    "Configure the security groups for the Amazon VPC containing your cluster. By default,            Amazon MSK uses the following ports: 9092 for plaintext, 9094 for TLS, 9096 for SASL, 9098 for IAM.",
                                    "  1.Inbound rules – Allow all traffic on the default cluster port for the security group associated with your event source.",
                                    "  2.Outbound rules – Allow all traffic on port 443 for all destinations. Allow all traffic on the default cluster port                    for the security group associated with your event source.",
                                    "  3.Amazon VPC endpoint inbound rules — If you are using an Amazon VPC endpoint, the security group associated with your Amazon VPC endpoint must allow inbound traffic                    on port 443 from the cluster security group.",
                                    "If your cluster uses authentication, you can also restrict the endpoint policy for the Secrets Manager endpoint.             To call the Secrets Manager API, Lambda uses your function role, not the Lambda service principal.",
                                    "Example VPC endpoint policy — Secrets Manager endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"secretsmanager:GetSecretValue\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"AWS\": [\n                      \"arn:aws::iam::123456789012:role/my-role\"\n                  ]\n              },\n              \"Resource\": \"arn:aws::secretsmanager:us-west-2:123456789012:secret:my-secret\"\n          }\n      ]\n  }"
                                    },
                                    "When you use Amazon VPC endpoints, AWS routes your API calls to invoke your function using the endpoint's Elastic Network Interface (ENI).            The Lambda service principal needs to call lambda:InvokeFunction on any roles and functions that use those ENIs.",
                                    "By default, Amazon VPC endpoints have open IAM policies that allow broad access to resources. Best practice is to restrict these            policies to perform the needed actions using that endpoint. To ensure that your event source mapping is able to invoke your Lambda            function, the VPC endpoint policy must allow the Lambda service principal to call sts:AssumeRole and            lambda:InvokeFunction. Restricting your VPC endpoint policies to allow only API calls originating within your organization            prevents the event source mapping from functioning properly, so \"Resource\": \"*\" is required in these policies.",
                                    "The following example VPC endpoint policies show how to grant the required access to the Lambda service principal for the            AWS STS and Lambda endpoints.",
                                    "Example VPC Endpoint policy — AWS STS endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"sts:AssumeRole\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n    }"
                                    },
                                    "Example VPC Endpoint policy — Lambda endpoint",
                                    {
                                        "code_example": "{\n      \"Statement\": [\n          {\n              \"Action\": \"lambda:InvokeFunction\",\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                  \"Service\": [\n                      \"lambda.amazonaws.com\"\n                  ]\n              },\n              \"Resource\": \"*\"\n          }\n      ]\n  }"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Process messages",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-msk-process.html",
                        "sections": [
                            "Note",
                            "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                            "Topics",
                            {
                                "sub_header": "Adding Amazon MSK as an event source",
                                "content": [
                                    "To create an event source mapping, add Amazon MSK as a Lambda            function trigger using the Lambda console, an AWS SDK, or the AWS Command Line Interface (AWS CLI). Note that when you add Amazon MSK            as a trigger, Lambda assumes the VPC settings of the Amazon MSK cluster, not the Lambda function's VPC settings.",
                                    "This section describes how to create an event source mapping using the Lambda console and the AWS CLI.",
                                    {
                                        "sub_header": "Prerequisites",
                                        "content": [
                                            "  1.An  Amazon MSK cluster and a Kafka topic. For more information, see Getting Started Using Amazon MSK in the                        Amazon Managed Streaming for Apache Kafka Developer Guide.",
                                            "  2.An execution role with permission to access the AWS resources that your MSK cluster uses."
                                        ]
                                    },
                                    {
                                        "sub_header": "Customizable consumer group ID",
                                        "content": [
                                            "When setting up Kafka as an event source, you can specify a consumer group ID. This consumer group ID is an    existing identifier for the Kafka consumer group that you want your Lambda function to join. You can use this feature to seamlessly migrate any    ongoing Kafka record processing setups from other consumers to Lambda.",
                                            "If you specify a consumer group ID and there are other active pollers within that consumer group, Kafka distributes messages across      all consumers. In other words, Lambda doesn't receive all message for the Kafka topic. If you want Lambda to handle all messages in the      topic, turn off any other pollers in that consumer group.",
                                            "Additionally, if you specify a consumer group ID, and Kafka finds a valid existing consumer group with the same ID, Lambda ignores the      StartingPosition parameter for your event source mapping. Instead, Lambda begins processing records according to the committed      offset of the consumer group. If you specify a consumer group ID, and Kafka cannot find an existing consumer group, then Lambda configures your      event source with the specified StartingPosition.",
                                            "The consumer group ID that you specify must be unique among all your Kafka event sources. After creating a Kafka event source mapping      with the consumer group ID specified, you cannot update this value."
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding an Amazon MSK trigger (console)",
                                        "content": [
                                            "Follow these steps to add your Amazon MSK cluster and a Kafka topic as a trigger for your Lambda function.",
                                            "To add an Amazon MSK trigger to your Lambda function (console)",
                                            "  1 : Open the Functions page of the Lambda                        console.",
                                            "  2 : Choose the name of your Lambda function.",
                                            "  3 : Under Function overview, choose Add trigger.",
                                            "  4 : Under Trigger configuration, do the following:Choose the MSK trigger type.For MSK cluster, select your cluster.For Batch size, enter the maximum number of messages to receive in a single                                batch.For Batch window, enter the maximum amount of seconds that Lambda spends                                gathering records before invoking the function.For Topic name, enter the name of a Kafka topic.(Optional) For Consumer group ID, enter the ID of a Kafka consumer group to join.(Optional) For Starting position, choose Latest to start                                reading the stream from the latest record, Trim horizon to start at the                                earliest available record, or At timestamp to specify a timestamp to start                                reading from.(Optional) For Authentication, choose the secret key for authenticating with                                the brokers in your MSK cluster.To create the trigger in a disabled state for testing (recommended), clear Enable                                trigger. Or, to enable the trigger immediately, select Enable                                    trigger.",
                                            "  5 : To create the trigger, choose Add."
                                        ]
                                    },
                                    {
                                        "sub_header": "Adding an Amazon MSK trigger (AWS CLI)",
                                        "content": [
                                            "Use the following example AWS CLI commands to create and view an Amazon MSK trigger for your Lambda function.",
                                            {
                                                "sub_header": "Creating a trigger using the AWS CLI",
                                                "content": [
                                                    "Example — Create event source mapping for cluster that uses IAM authentication",
                                                    "The following example uses the create-event-source-mapping AWS CLI command to map a Lambda function named my-kafka-function to a Kafka topic named AWSKafkaTopic. The topic's starting position is set to LATEST.                        When the cluster uses IAM role-based authentication,                        you don't need a SourceAccessConfiguration object. Example:",
                                                    {
                                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:cluster/my-cluster/fc2f5bdf-fd1b-45ad-85dd-15b4a5a6247e-2 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function"
                                                    },
                                                    "Example — Create event source mapping for cluster that uses SASL/SCRAM authentication",
                                                    "If the cluster uses SASL/SCRAM authentication,                        you must include a SourceAccessConfiguration object that specifies SASL_SCRAM_512_AUTH and a Secrets Manager secret ARN.",
                                                    {
                                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:cluster/my-cluster/fc2f5bdf-fd1b-45ad-85dd-15b4a5a6247e-2 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function\n  --source-access-configurations '[{\"Type\": \"SASL_SCRAM_512_AUTH\",\"URI\": \"arn:aws:secretsmanager:us-east-1:111122223333:secret:my-secret\"}]'"
                                                    },
                                                    "Example — Create event source mapping for cluster that uses mTLS authentication",
                                                    "If the cluster uses mTLS authentication,                        you must include a SourceAccessConfiguration object that specifies CLIENT_CERTIFICATE_TLS_AUTH and a Secrets Manager secret ARN.",
                                                    {
                                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:cluster/my-cluster/fc2f5bdf-fd1b-45ad-85dd-15b4a5a6247e-2 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function\n  --source-access-configurations '[{\"Type\": \"CLIENT_CERTIFICATE_TLS_AUTH\",\"URI\": \"arn:aws:secretsmanager:us-east-1:111122223333:secret:my-secret\"}]'"
                                                    },
                                                    "For more information, see the CreateEventSourceMapping API reference documentation."
                                                ]
                                            },
                                            {
                                                "sub_header": "Viewing the status using the AWS CLI",
                                                "content": [
                                                    "The following example uses the get-event-source-mapping AWS CLI command to describe the status of the event source mapping that you created.",
                                                    "aws lambda get-event-source-mapping \\  --uuid 6d9bce8e-836b-442c-8070-74e77903c815"
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Amazon MSK configuration parameters",
                                "content": [
                                    "All Lambda event source types share the same CreateEventSourceMapping and UpdateEventSourceMapping            API operations. However, only some of the parameters apply to Amazon MSK.",
                                    "ParameterRequiredDefaultNotesAmazonManagedKafkaEventSourceConfigNContains the ConsumerGroupId field, which defaults to a unique value.Can set only on CreateBatchSizeN100Maximum: 10,000DestinationConfigNN/ACapturing discarded batches for an Amazon MSK event sourceEnabledNTrueEventSourceArnYN/ACan set only on CreateFilterCriteriaNN/AControl which events Lambda sends to your functionFunctionNameYN/AKMSKeyArnNN/AEncryption of filter criteriaMaximumBatchingWindowInSecondsN500 msBatching behaviorProvisionedPollersConfigNMinimumPollers: default value of 1 if not specifiedMaximumPollers: default value of 200 if not specifiedConfiguring provisioned modeSourceAccessConfigurationsNNo credentialsSASL/SCRAM or CLIENT_CERTIFICATE_TLS_AUTH (MutualTLS) authentication credentials for your event sourceStartingPositionYN/AAT_TIMESTAMP, TRIM_HORIZON, or LATESTCan set only on CreateStartingPositionTimestampNN/ARequired if StartingPosition is set to AT_TIMESTAMPTagsNN/AUsing tags on event source mappingsTopicsYN/AKafka topic nameCan set only on Create"
                                ]
                            },
                            {
                                "sub_header": "Creating cross-account event source mappings",
                                "content": [
                                    "You can use multi-VPC private connectivity to connect a Lambda function to a provisioned MSK cluster in a different AWS account. Multi-VPC connectivity uses AWS PrivateLink, which keeps all traffic within the AWS network.",
                                    "Note",
                                    "You can't create cross-account event source mappings for serverless MSK clusters.",
                                    "To create a cross-account event source mapping, you must first configure multi-VPC connectivity for the MSK cluster. When you create the event source mapping, use the managed VPC connection ARN instead of the cluster ARN, as shown in the following examples. The CreateEventSourceMapping operation also differs depending on which authentication type the MSK cluster uses.",
                                    "Example — Create cross-account event source mapping for cluster that uses IAM authentication",
                                    "When the cluster uses IAM role-based authentication,                you don't need a SourceAccessConfiguration object. Example:",
                                    {
                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:vpc-connection/444455556666/my-cluster-name/51jn98b4-0a61-46cc-b0a6-61g9a3d797d5-7 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function"
                                    },
                                    "Example — Create cross-account event source mapping for cluster that uses SASL/SCRAM authentication",
                                    "If the cluster uses SASL/SCRAM authentication,                you must include a SourceAccessConfiguration object that specifies SASL_SCRAM_512_AUTH and a Secrets Manager secret ARN.",
                                    "There are two ways to use secrets for cross-account Amazon MSK event source mappings with SASL/SCRAM authentication:",
                                    "  1.Create a secret in the Lambda function account and sync it with the cluster secret. Create a rotation to keep the two secrets in sync. This option allows you to control the secret from the function account.",
                                    "  2.Use the secret that's associated with the MSK cluster. This secret must allow cross-account access to the Lambda function account. For more information, see Permissions to AWS Secrets Manager secrets for users in a different account.",
                                    {
                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:vpc-connection/444455556666/my-cluster-name/51jn98b4-0a61-46cc-b0a6-61g9a3d797d5-7 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function \\\n  --source-access-configurations '[{\"Type\": \"SASL_SCRAM_512_AUTH\",\"URI\": \"arn:aws:secretsmanager:us-east-1:444455556666:secret:my-secret\"}]'"
                                    },
                                    "Example — Create cross-account event source mapping for cluster that uses mTLS authentication",
                                    "If the cluster uses mTLS authentication,                you must include a SourceAccessConfiguration object that specifies CLIENT_CERTIFICATE_TLS_AUTH                and a Secrets Manager secret ARN. The secret can be stored in the cluster account or the Lambda function account.",
                                    {
                                        "code_example": "aws lambda create-event-source-mapping \\\n  --event-source-arn arn:aws:kafka:us-east-1:111122223333:vpc-connection/444455556666/my-cluster-name/51jn98b4-0a61-46cc-b0a6-61g9a3d797d5-7 \\\n  --topics AWSKafkaTopic \\\n  --starting-position LATEST \\\n  --function-name my-kafka-function \\\n  --source-access-configurations '[{\"Type\": \"CLIENT_CERTIFICATE_TLS_AUTH\",\"URI\": \"arn:aws:secretsmanager:us-east-1:444455556666:secret:my-secret\"}]'"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Using an Amazon MSK cluster as an event source",
                                "content": [
                                    "When you add your Apache Kafka or Amazon MSK cluster as a trigger for your Lambda function, the cluster is used as an event source.",
                                    "Lambda reads event data from the Kafka topics that you specify as Topics in a            CreateEventSourceMapping request, based on the StartingPosition that you specify. After            successful processing, your Kafka topic is committed to your Kafka cluster.",
                                    "If you specify the StartingPosition as LATEST, Lambda starts reading from the latest            message in each partition belonging to the topic. Because there can be some delay after trigger configuration            before Lambda starts reading the messages, Lambda doesn't read any messages produced during this window.",
                                    "Lambda reads messages sequentially for each Kafka topic partition. A single Lambda payload can contain            messages from multiple partitions. When more records are available, Lambda continues processing records            in batches, based on the BatchSize value that you specify in a CreateEventSourceMapping            request, until your function catches up with the topic.",
                                    "After Lambda processes each batch, it commits the offsets of the messages in that batch. If your            function returns an error for any of the messages in a batch, Lambda retries the whole batch of messages            until processing succeeds or the messages expire. You can send records that fail all retry attempts to            an on-failure destination for later processing.",
                                    "Note",
                                    "While Lambda functions typically have a maximum timeout limit of 15 minutes,      event source mappings for Amazon MSK, self-managed Apache Kafka, Amazon DocumentDB, and Amazon MQ for ActiveMQ and RabbitMQ only support functions with      maximum timeout limits of 14 minutes. This constraint ensures that the event source mapping can properly      handle function errors and retries."
                                ]
                            },
                            {
                                "sub_header": "Polling and stream starting positions",
                                "content": [
                                    "Be aware that stream polling during event source mapping creation and updates is eventually consistent.",
                                    "  1.During event source mapping creation, it may take several minutes to start polling events from the stream.",
                                    "  2.During event source mapping updates, it may take several minutes to stop and restart polling events from the stream.",
                                    "This behavior means that if you specify LATEST as the starting position for the stream, the event source mapping could     miss events during creation or updates. To ensure that no events are missed, specify the stream starting position as TRIM_HORIZON     or AT_TIMESTAMP."
                                ]
                            },
                            {
                                "sub_header": "Amazon CloudWatch metrics",
                                "content": [
                                    "Lambda emits the OffsetLag metric while your function processes records. The value of this metric      is the difference in offset between the last record written to the Kafka event source topic and the last record that your function's       consumer group processed. You can use OffsetLag to estimate the latency between when a record is added and when      your consumer group processes it.",
                                    "An increasing trend in OffsetLag can indicate issues with pollers in your function's consumer group. For more information, see      Using CloudWatch metrics with Lambda."
                                ]
                            },
                            {
                                "sub_header": "Message throughput scaling behavior for Amazon MSK event source mappings",
                                "content": [
                                    "You can choose between two modes of message throughput scaling behavior for your Amazon MSK            event source mapping:",
                                    "  1.Default (on-demand) mode",
                                    "  2.Provisioned mode",
                                    {
                                        "sub_header": "Default (on-demand) mode",
                                        "content": [
                                            "When you initially create an Amazon MSK event source, Lambda allocates a default number of event                pollers to process all partitions in the Kafka topic. Lambda automatically scales up or down the                number of event pollers based on message load.",
                                            "In one-minute intervals, Lambda evaluates the offset lag                 of all the partitions in the topic. If the offset lag is too high, the partition is                receiving messages faster than Lambda can process them. If necessary, Lambda adds or removes                event pollers from the topic. This autoscaling process of adding or removing event pollers                occurs within three minutes of evaluation.",
                                            "If your target Lambda function is throttled, Lambda reduces the number of event pollers. This                action reduces the workload on the function by reducing the number of messages that event                pollers can retrieve and send to the function."
                                        ]
                                    },
                                    {
                                        "sub_header": "Configuring provisioned mode",
                                        "content": [
                                            "For workloads where you need to fine-tune the throughput of your event source mapping,                you can use provisioned mode. In provisioned mode, you define minimum and maximum limits                for the amount of provisioned event pollers. These provisioned event pollers are dedicated                to your event source mapping, and can handle unexpected message spikes through responsive                autoscaling. We recommend that you use provisioned mode for Kafka workloads that have strict                performance requirements.",
                                            "In Lambda, an event poller is a compute unit capable of handling up to 5 MBps of throughput.    For reference, suppose your event source produces an average payload of 1MB, and the average function duration is 1 sec.    If the payload doesn’t undergo any transformation (such as filtering), a single poller can support 5 MBps throughput,    and 5 concurrent Lambda invocations. Using provisioned mode incurs additional costs. For pricing estimates,    see AWS Lambda pricing.",
                                            "Note",
                                            "When using provisioned mode, you don't need to create AWS PrivateLink VPC endpoints                    or grant the associated permissions as part of your                    network configuration.",
                                            "In provisioned mode, the range of accepted values for the minimum number of event pollers                (MinimumPollers) is between 1 and 200, inclusive. The range of                accepted values for the maximum number of event pollers (MaximumPollers)                is between 1 and 2,000, inclusive. MaximumPollers must be greater than                or equal to MinimumPollers. In addition, to maintain ordered                processing within partitions, Lambda caps the MaximumPollers to the                number of partitions in the topic.",
                                            "For more details about choosing appropriate values for minimum and maximum event pollers,                see Best practices and considerations when using provisioned mode.",
                                            "You can configure provisioned mode for your Amazon MSK event source mapping using the console                or the Lambda API.",
                                            "To configure provisioned mode for an existing Amazon MSK event source mapping (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Choose the function with the Amazon MSK event source mapping you want to configure                        provisioned mode for.",
                                            "  3 : Choose Configuration, then choose Triggers.",
                                            "  4 : Choose the Amazon MSK event source mapping that you want to configure provisioned mode for,                        then choose Edit.",
                                            "  5 : Under Event source mapping configuration, choose                         Configure provisioned mode.For Minimum event pollers, enter a value between 1 and 200.                                If you don't specify a value, Lambda chooses a default value of 1.For Maximum event pollers, enter a value between 1 and 2,000.                                This value must be greater than or equal to your value for Minimum event                                pollers. If you don't specify a value, Lambda chooses a default value of 200.",
                                            "  6 : Choose Save.",
                                            "You can configure provisioned mode programmatically using the ProvisionedPollerConfig object                in your                 EventSourceMappingConfiguration. For example, the following UpdateEventSourceMapping CLI                command configures a MinimumPollers value of 5, and a                MaximumPollers value of 100.",
                                            "aws lambda update-event-source-mapping \\    --uuid a1b2c3d4-5678-90ab-cdef-EXAMPLE11111 \\    --provisioned-poller-config '{\"MinimumPollers\": 5, \"MaximumPollers\": 100}'",
                                            "After configuring provisioned mode, you can observe the usage of event pollers for your workload by monitoring    the ProvisionedPollers metric. For more information, see Event source mapping metrics.",
                                            "To disable provisioned mode and return to default (on-demand) mode,                you can use the following UpdateEventSourceMapping CLI                command:",
                                            "aws lambda update-event-source-mapping \\    --uuid a1b2c3d4-5678-90ab-cdef-EXAMPLE11111 \\    --provisioned-poller-config '{}'"
                                        ]
                                    },
                                    {
                                        "sub_header": "Best practices and considerations when using provisioned mode",
                                        "content": [
                                            "The optimal configuration of minimum and maximum event pollers for your event source mapping                depends on your application's performance requirements. We recommend that you start with the                default minimum event pollers to baseline the performance profile. Adjust your configuration                based on observed message processing patterns and your desired performance profile.",
                                            "For workloads with spiky traffic and strict performance needs, increase the minimum event                pollers to handle sudden surges in messages. To determine the minimum event pollers required,                consider your workload's messages per second and average payload size, and use the throughput                capacity of a single event poller (up to 5 MBps) as a reference.",
                                            "To maintain ordered processing within a partition, Lambda limits the maximum event pollers                to the number of partitions in the topic. Additionally, the maximum event pollers your event                source mapping can scale to depends on the function's concurrency settings.",
                                            "When activating provisioned mode, update your network settings to remove AWS PrivateLink VPC                endpoints and associated permissions."
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-msk-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for Amazon MSK event sources.",
                            "Topics",
                            {
                                "sub_header": "Amazon MSK event filtering basics",
                                "content": [
                                    "Suppose a producer is writing messages to a topic in your Amazon MSK cluster, either in valid JSON format or as plain strings. An example record             would look like the following, with the message converted to a Base64 encoded string in the value field.",
                                    "{    \"mytopic-0\":[        {            \"topic\":\"mytopic\",            \"partition\":0,            \"offset\":15,            \"timestamp\":1545084650987,            \"timestampType\":\"CREATE_TIME\",            \"value\":\"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",            \"headers\":[]        }    ]}",
                                    "Suppose your Apache Kafka producer is writing messages to your topic in the following JSON format.",
                                    "{    \"device_ID\": \"AB1234\",    \"session\":{        \"start_time\": \"yyyy-mm-ddThh:mm:ss\",        \"duration\": 162    }}",
                                    "You can use the value key to filter records. Suppose you wanted to filter only those records where device_ID             begins with the letters AB. The FilterCriteria object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\": \\\"AB\\\" } ] } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"value\": {        \"device_ID\": [ { \"prefix\": \"AB\" } ]      }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : { \\\"device_ID\\\" : [ { \\\"prefix\\\":  \\\"AB\\\" } ] } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"value\" : { \"device_ID\" : [ { \"prefix\":  \"AB\" } ] } }"
                                    },
                                    "With Amazon MSK, you can also filter records where the message is a plain string. Suppose you want to ignore those messages where the string is             \"error\". The FilterCriteria object would look as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON.",
                                    "{    \"value\": [        {        \"anything-but\": [ \"error\" ]        }    ]}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:kafka:us-east-2:123456789012:cluster/my-cluster/b-8ac7cc01-5898-482d-be2f-a6b596050ea8 \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"value\\\" : [ { \\\"anything-but\\\": [ \\\"error\\\" ] } ] }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"value\" : [ { \"anything-but\": [ \"error\" ] } ] }"
                                    },
                                    "Amazon MSK messages must be UTF-8 encoded strings, either plain strings or in JSON format. That's because Lambda decodes Amazon MSK byte arrays into UTF-8 before             applying filter criteria. If your messages use another encoding, such as UTF-16 or ASCII, or if the message format doesn't match the             FilterCriteria format, Lambda processes metadata filters only. The following table summarizes the specific behavior:",
                                    "Incoming message formatFilter pattern format for message propertiesResulting actionPlain stringPlain stringLambda filters based on your filter criteria.Plain stringNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Plain stringValid JSONLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONPlain stringLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONValid JSONLambda filters based on your filter criteria.Non-UTF-8 encoded stringJSON, plain string, or no patternLambda filters (on the other metadata properties only) based on your filter criteria."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "On-failure destinations",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-msk-on-failure.html",
                        "sections": [
                            "To retain records of failed event source mapping invocations, add a destination to your function's event source mapping. Each record sent to the destination is a JSON document containing metadata about the failed invocation. For Amazon S3 destinations, Lambda also sends the entire invocation record along with the metadata. You can configure any Amazon SNS topic, Amazon SQS queue, or S3 bucket as a destination.",
                            "With Amazon S3 destinations, you can use the Amazon S3 Event Notifications feature to receive notifications when objects are uploaded to your destination S3 bucket. You can also configure S3 Event Notifications to invoke another Lambda function to perform automated processing on failed batches.",
                            "Your execution role must have permissions for the destination:",
                            "  1.For SQS destinations: :  sqs:SendMessage",
                            "  2.For SNS destinations: :  sns:Publish",
                            "  3.For S3 bucket destinations: :   s3:PutObject and s3:ListBucket",
                            "You must deploy a VPC endpoint for your on-failure destination service inside your Amazon MSK cluster VPC.",
                            "Additionally, if you configured a KMS key on your destination, Lambda needs the following        permissions depending on the destination type:",
                            "  1.If you've enabled encryption with your own KMS key for an S3 destination,            kms:GenerateDataKey is required.            If the KMS key and S3 bucket destination are in a different account from your Lambda function            and execution role, configure the KMS key to trust the execution role to allow            kms:GenerateDataKey.",
                            "  2.If you've enabled encryption with your own KMS key for SQS destination,            kms:Decrypt and            kms:GenerateDataKey are            required. If the KMS key and SQS queue destination are in a different account from your            Lambda function and execution role, configure the KMS key to trust the execution role to            allow kms:Decrypt, kms:GenerateDataKey,            kms:DescribeKey, and            kms:ReEncrypt.",
                            "  3.If you've enabled encryption with your own KMS key for SNS destination,            kms:Decrypt and            kms:GenerateDataKey are            required. If the KMS key and SNS topic destination are in a different account from your            Lambda function and execution role, configure the KMS key to trust the execution role to            allow kms:Decrypt, kms:GenerateDataKey,            kms:DescribeKey, and            kms:ReEncrypt.",
                            {
                                "sub_header": "Configuring on-failure destinations for an Amazon MSK event source mapping",
                                "content": [
                                    "To configure an on-failure destination using the console, follow these steps:",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose a function.",
                                    "  3 : Under Function overview, choose Add destination.",
                                    "  4 : For Source, choose Event source mapping invocation.",
                                    "  5 : For Event source mapping, choose an event source that's configured              for this function.",
                                    "  6 : For Condition, select On failure. For event              source mapping invocations, this is the only accepted condition.",
                                    "  7 : For Destination type, choose the destination type that Lambda sends              invocation records to.",
                                    "  8 : For Destination, choose a resource.",
                                    "  9 : Choose Save.",
                                    "You can also configure an on-failure destination using the AWS CLI. For example, the following          create-event-source-mapping command adds an event source mapping with an SQS on-failure destination to          MyFunction:",
                                    "aws lambda create-event-source-mapping \\--function-name \"MyFunction\" \\--event-source-arn arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2 \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:sqs:us-east-1:123456789012:dest-queue\"}}'",
                                    "The following update-event-source-mapping command adds an S3 on-failure destination to the event source associated with the input uuid:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"arn:aws:s3:::dest-bucket\"}}'",
                                    "To remove a destination, supply an empty string as the argument to the          destination-config parameter:",
                                    "aws lambda update-event-source-mapping \\--uuid f89f8514-cdd9-4602-9e1f-01a5b77d449b \\--destination-config '{\"OnFailure\": {\"Destination\": \"\"}}'",
                                    {
                                        "sub_header": "Security best practices for Amazon S3 destinations",
                                        "content": [
                                            "Deleting an S3 bucket that's configured as a destination without removing the destination from your function's configuration can create a security risk. If another       user knows your destination bucket's name, they can recreate the bucket in their AWS account. Records of failed invocations will be sent to their bucket, potentially       exposing data from your function.",
                                            "Warning",
                                            "To ensure that invocation records from your function can't be sent to an S3 bucket in another AWS account, add a condition to your function's execution role         that limits s3:PutObject permissions to buckets in your account. ",
                                            "The following example shows an IAM policy that limits your function's s3:PutObject permissions to buckets in your account. This policy also gives Lambda        the s3:ListBucket permission it needs to use an S3 bucket as a destination.",
                                            "{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Sid\": \"S3BucketResourceAccountWrite\",            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\",                \"s3:ListBucket\"            ],            \"Resource\": \"arn:aws:s3:::*/*\",            \"Condition\": {                \"StringEquals\": {                    \"s3:ResourceAccount\": \"111122223333\"                }            }        }    ]}",
                                            "To add a permissions policy to your funcion's execution role using the AWS Management Console or AWS CLI, refer to the instructions in the following procedures:",
                                            "  1.Console : \nTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.\nSelect the Lambda function whose execution role you want to modify.\n\nIn the Configuration tab, select Permissions.\n\nIn the Execution role tab, select your function's Role name to open the role's IAM console page.\n\nAdd a permissions policy to the role by doing the following:\n\nIn the Permissions policies pane, choose Add permissions and select Create inline policy.\n\nIn Policy editor, select JSON.\n\nPaste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.\n\nUnder Policy details, enter a Policy name.\n\nChoose Create policy.\n\n\n",
                                            "  2.AWS CLI : put-role-policy",
                                            "ConsoleTo add a permissions policy to a function's execution role (console)Open the Functions page of the Lambda console.Select the Lambda function whose execution role you want to modify.In the Configuration tab, select Permissions.In the Execution role tab, select your function's Role name to open the role's IAM console page.Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy.AWS CLITo add a permissions policy to a function's execution role (CLI)Create a JSON policy document with the required permissions and save it in a local directory.Use the IAM put-role-policy CLI command to add the permissions to your function's execution role. Run the following command from the                 directory you saved your JSON policy document in and replace the role name, policy name, and policy document with your own values.aws iam put-role-policy \\--role-name my_lambda_role \\--policy-name LambdaS3DestinationPolicy \\--policy-document file://my_policy.json",
                                            "anchor",
                                            "anchor",
                                            "To add a permissions policy to a function's execution role (console)",
                                            "  1 : Open the Functions page of the Lambda console.",
                                            "  2 : Select the Lambda function whose execution role you want to modify.",
                                            "  3 : In the Configuration tab, select Permissions.",
                                            "  4 : In the Execution role tab, select your function's Role name to open the role's IAM console page.",
                                            "  5 : Add a permissions policy to the role by doing the following:In the Permissions policies pane, choose Add permissions and select Create inline policy.In Policy editor, select JSON.Paste the policy you want to add into the editor (replacing the existing JSON), and then choose Next.Under Policy details, enter a Policy name.Choose Create policy."
                                        ]
                                    },
                                    {
                                        "sub_header": "SNS and SQS example invocation record",
                                        "content": [
                                            "The following example shows what Lambda sends to an SNS topic or SQS queue destination for a          failed Kafka event source invocation. Each of the keys under recordsInfo contains          both the Kafka topic and partition, separated by a hyphen. For example, for the key          \"Topic-0\", Topic is the Kafka topic, and 0 is the          partition. For each topic and partition, you can use the offsets and timestamp data to find          the original invocation records.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\" | \"MaximumPayloadSizeExceeded\",        \"approximateInvokeCount\": 1    },    \"responseContext\": { // null if record is MaximumPayloadSizeExceeded        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KafkaBatchInfo\": {        \"batchSize\": 500,        \"eventSourceArn\": \"arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2\",        \"bootstrapServers\": \"...\",        \"payloadSize\": 2039086, // In bytes        \"recordsInfo\": {            \"Topic-0\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            },            \"Topic-1\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            }        }    }}"
                                        ]
                                    },
                                    {
                                        "sub_header": "S3 destination example invocation record",
                                        "content": [
                                            "For S3 destinations, Lambda sends the entire invocation record along with the metadata          to the destination. The following example shows that Lambda sends to an S3 bucket destination          for a failed Kafka event source invocation. In addition to all of the fields from the previous          example for SQS and SNS destinations, the payload field contains the original          invocation record as an escaped JSON string.",
                                            "{    \"requestContext\": {        \"requestId\": \"316aa6d0-8154-xmpl-9af7-85d5f4a6bc81\",        \"functionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:myfunction\",        \"condition\": \"RetryAttemptsExhausted\" | \"MaximumPayloadSizeExceeded\",        \"approximateInvokeCount\": 1    },    \"responseContext\": { // null if record is MaximumPayloadSizeExceeded        \"statusCode\": 200,        \"executedVersion\": \"$LATEST\",        \"functionError\": \"Unhandled\"    },    \"version\": \"1.0\",    \"timestamp\": \"2019-11-14T00:38:06.021Z\",    \"KafkaBatchInfo\": {        \"batchSize\": 500,        \"eventSourceArn\": \"arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2\",        \"bootstrapServers\": \"...\",        \"payloadSize\": 2039086, // In bytes        \"recordsInfo\": {            \"Topic-0\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            },            \"Topic-1\": {                \"firstRecordOffset\": \"49601189658422359378836298521827638475320189012309704722\",                \"lastRecordOffset\": \"49601189658422359378836298522902373528957594348623495186\",                \"firstRecordTimestamp\": \"2019-11-14T00:38:04.835Z\",                \"lastRecordTimestamp\": \"2019-11-14T00:38:05.580Z\",            }        }    },    \"payload\": \"<Whole Event>\" // Only available in S3}",
                                            "Tip",
                                            "We recommend enabling S3 versioning on your destination bucket."
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-msk-tutorial.html",
                        "sections": [
                            "In this tutorial, you will perform the following:",
                            "  1.Create a Lambda function in the same AWS account as an existing Amazon MSK cluster.",
                            "  2.Configure networking and authentication for Lambda to communicate with Amazon MSK.",
                            "  3.Set up a Lambda Amazon MSK event source mapping, which runs your Lambda function when events show up in the topic.",
                            "After you are finished with these steps, when events are sent to Amazon MSK, you will be able to set up a Lambda        function to process those events automatically with your own custom Lambda code.",
                            " What can you do with this feature? ",
                            "Example solution: Use an MSK event source mapping to deliver live scores to your        customers.",
                            "Consider the following scenario: Your company hosts a web application where        your customers can view information about live events, such as sports games. Information updates from the game        are provided to your team through a Kafka topic on Amazon MSK. You want to design a solution that consumes updates        from the MSK topic to provide an updated view of the live event to customers inside an application you develop.        You have decided on the following design approach: Your client applications will communicate with a serverless        backend hosted in AWS. Clients will connect over websocket sessions using the Amazon API Gateway WebSocket API.",
                            "In this solution, you need a component that reads MSK events, performs some custom logic to prepare those        events for the application layer and then forwards that information to the API Gateway API. You can implement this        component with AWS Lambda, by providing your custom logic in a Lambda function, then calling it with a        AWS Lambda Amazon MSK event source mapping.",
                            "For more information about implementing solutions using the Amazon API Gateway WebSocket API, see WebSocket API        tutorials in the API Gateway documentation.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "An AWS account with the following preconfigured resources:",
                                    "To fulfill these prerequisites, we recommend following Getting started using Amazon MSK in the Amazon MSK            documentation.",
                                    "  1.An Amazon MSK cluster. See Create an Amazon MSK cluster in Getting started using Amazon MSK.",
                                    "  2.The following configuration:Ensure IAM role-based authentication is Enabled                            in your cluster security settings. This improves your security by limiting your Lambda                            function to only access the Amazon MSK resources needed. This is enabled by default on new Amazon MSK                            clusters.Ensure Public access is off in your cluster networking settings.                            Restricting your Amazon MSK cluster's access to the internet improves your security by limiting                            how many intermediaries handle your data. This is enabled by default on new Amazon MSK                            clusters.",
                                    "  3.IAM role-based authentication : Ensure  is Enabled                            in your cluster security settings. This improves your security by limiting your Lambda                            function to only access the Amazon MSK resources needed. This is enabled by default on new Amazon MSK                            clusters.",
                                    "  4.Public access : Ensure  is off in your cluster networking settings.                            Restricting your Amazon MSK cluster's access to the internet improves your security by limiting                            how many intermediaries handle your data. This is enabled by default on new Amazon MSK                            clusters.",
                                    "  5.A Kafka topic in your Amazon MSK cluster to use for this solution.  See Create a topic in Getting started using Amazon MSK.",
                                    "  6.A Kafka admin host set up to retrieve information from your Kafka cluster and send Kafka events to your topic                    for testing, such as an Amazon EC2 instance with the Kafka admin CLI and Amazon MSK IAM library                    installed. See Create a client machine in Getting started using Amazon MSK.",
                                    "Once you have set up these resources, gather the following information from your AWS account to confirm that you are ready to continue.",
                                    "  1.The name of your Amazon MSK cluster. You can find this information in the Amazon MSK console.",
                                    "  2.The cluster UUID, part of the ARN for                    your Amazon MSK cluster, which you can find in the Amazon MSK console. Follow                    the procedures in Listing clusters in the Amazon MSK                    documentation to find this information.",
                                    "  3.The security groups associated with your Amazon MSK cluster. You can find this information in the Amazon MSK                    console. In the following steps, refer to these as your clusterSecurityGroups.",
                                    "  4.The id of the Amazon VPC containing your Amazon MSK cluster. You can find this                    information by identifying subnets associated with your Amazon MSK cluster in the Amazon MSK console,                    then identifying the Amazon VPC associated with the subnet in the Amazon VPC Console.",
                                    "  5.The name of the Kafka topic used in your solution. You can find this information by calling your                    Amazon MSK cluster with the Kafka topics CLI from your Kafka admin host. For more                    information about the topics CLI, see Adding and removing topics                    in the Kafka documentation.",
                                    "  6.The name of a consumer group for your Kafka topic, suitable for use by your Lambda                    function. This group can be created automatically by Lambda, so you don't need to create it with the                    Kafka CLI. If you do need to manage your consumer groups, to learn more about the consumer-groups                    CLI, see Managing                    Consumer Groups in the Kafka documentation.",
                                    "The following permissions in your AWS account:",
                                    "  1.Permission to create and manage a Lambda function.",
                                    "  2.Permission to create IAM policies and associate them with your Lambda function.",
                                    "  3.Permission to create Amazon VPC endpoints and alter networking configuration in the Amazon VPC hosting your Amazon MSK cluster."
                                ]
                            },
                            {
                                "sub_header": "Configure network connectivity for Lambda to communicate with Amazon MSK",
                                "content": [
                                    " Use AWS PrivateLink to connect Lambda and Amazon MSK. You can do so by creating interface            Amazon VPC endpoints in the Amazon VPC console. For more information about networking configuration, see Configure network security.        ",
                                    "When a Amazon MSK event source mapping runs on the behalf of a Lambda function, it assumes the Lambda function’s execution role. This IAM role            authorizes the mapping to access resources secured by IAM, such as your Amazon MSK cluster. Although the            components share an execution role, the Amazon MSK mapping and your Lambda function have separate connectivity            requirements for their respective tasks, as shown in the following diagram.",
                                    "Your event source mapping belongs to your Amazon MSK cluster security group. In this networking step, create            Amazon VPC endpoints from your Amazon MSK cluster VPC to connect the event source mapping to the Lambda and STS            services. Secure these endpoints to accept traffic from your Amazon MSK cluster security group. Then, adjust the            Amazon MSK cluster security groups to allow the event source mapping to communicate with the Amazon MSK            cluster.",
                                    " You can configure the following steps using the AWS Management Console.",
                                    "To configure interface Amazon VPC endpoints to connect Lambda and Amazon MSK",
                                    "  1 : Create a security group for your interface Amazon VPC endpoints, endpointSecurityGroup, that allows                    inbound TCP traffic on 443 from clusterSecurityGroups. Follow the procedure in Create a                    security group in the Amazon EC2 documentation to create a security group. Then, follow the                    procedure in Add                    rules to a security group in the Amazon EC2 documentation to add appropriate rules. Create a security group with the following information:When adding your inbound rules, create a rule for each security group in                    clusterSecurityGroups. For each rule:For Type,                            select HTTPS.For Source, select one of                            clusterSecurityGroups.",
                                    " 2 :  Create an endpoint connecting the Lambda service to the Amazon VPC containing your Amazon MSK cluster.                    Follow the procedure in Create an interface endpoint.Create an interface endpoint with the following information:For Service name, select com.amazonaws.regionName.lambda, where regionName                            hosts your Lambda function.For VPC, select                            the Amazon VPC containing your Amazon MSK cluster.For Security groups, select                            endpointSecurityGroup, which you created earlier.For Subnets, select the subnets that host your Amazon MSK cluster.For Policy, provide the following policy document, which secures the endpoint for use by the Lambda service principal for the                            lambda:InvokeFunction action. Ensure Enable DNS name remains set.",
                                    {
                                        "code_example": "{\n    \"Statement\": [\n        {\n            \"Action\": \"lambda:InvokeFunction\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": [\n                    \"lambda.amazonaws.com\"\n                ]\n            },\n            \"Resource\": \"*\"\n        }\n    ]\n}"
                                    },
                                    " 3 :  Create an endpoint connecting the AWS STS service to the Amazon VPC containing your Amazon MSK cluster.                    Follow the procedure in Create an interface endpoint.Create an interface endpoint with the following information:For Service name, select AWS STS.For VPC, select                            the Amazon VPC containing your Amazon MSK cluster.For Security groups, select                            endpointSecurityGroup.For Subnets, select the subnets that host your Amazon MSK cluster.For Policy, provide the following policy document,                            which secures the endpoint for use by                            the Lambda service principal for the sts:AssumeRole action. Ensure Enable DNS name remains set.",
                                    {
                                        "code_example": "{\n    \"Statement\": [\n        {\n            \"Action\": \"sts:AssumeRole\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": [\n                    \"lambda.amazonaws.com\"\n                ]\n            },\n            \"Resource\": \"*\"\n        }\n    ]\n}"
                                    },
                                    "  4 : For each security group associated with your Amazon MSK cluster, that is, in                    clusterSecurityGroups, allow the following:Allow all inbound and outbound TCP traffic on 9098                            to all of clusterSecurityGroups, including within itself.Allow all outbound TCP traffic on 443.Some of this traffic is allowed by default security group                    rules, so if your cluster is attached to a single security group, and that group has default rules, additional rules                    are not necessary. To adjust security group rules, follow the procedures in Add                    rules to a security group in the Amazon EC2 documentation.Add rules to your security groups with the following information:For each inbound rule or outbound rule for port 9098, provideFor Type, select Custom TCP.For Port range, provide 9098.For Source, provide one of clusterSecurityGroups.For each inbound rule for port 443, for Type,                            select HTTPS."
                                ]
                            },
                            {
                                "sub_header": "Create an IAM role for Lambda to read from your Amazon MSK topic",
                                "content": [
                                    "Identify the auth requirements for Lambda to read from your Amazon MSK topic, then define them in a policy.            Create a role, lambdaAuthRole, that authorizes Lambda to use those            permissions. Authorize actions on your Amazon MSK cluster using kafka-cluster            IAM actions. Then, authorize Lambda to perform Amazon MSK kafka and Amazon EC2 actions            needed to discover and connect to your Amazon MSK cluster, as well as CloudWatch actions so Lambda can log what it has            done.",
                                    "To describe the auth requirements for Lambda to read from Amazon MSK",
                                    " 1 : Write an IAM policy document (a JSON document), clusterAuthPolicy, that allows Lambda to read from your Kafka topic in                    your Amazon MSK cluster using your Kafka consumer group. Lambda                    requires a Kafka consumer group to be set when reading.Alter the following template to align with your prerequisites: For more information, consult IAM role-based authentication. When writing your                    policy:For region and                            account-id, provide those that host your Amazon MSK cluster.For mskClusterName, provide the name of your Amazon MSK cluster.For cluster-uuid, provide the UUID in the ARN for                            your Amazon MSK cluster.For mskTopicName, provide the name of your Kafka topic.For mskGroupName, provide the name of your Kafka consumer                            group.",
                                    {
                                        "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kafka-cluster:Connect\",\n                \"kafka-cluster:DescribeGroup\",\n                \"kafka-cluster:AlterGroup\",\n                \"kafka-cluster:DescribeTopic\",\n                \"kafka-cluster:ReadData\",\n                \"kafka-cluster:DescribeClusterDynamicConfiguration\"\n            ],\n            \"Resource\": [\n                \"arn:aws:kafka:region:account-id:cluster/mskClusterName/cluster-uuid\",\n                \"arn:aws:kafka:region:account-id:topic/mskClusterName/cluster-uuid/mskTopicName\",\n                \"arn:aws:kafka:region:account-id:group/mskClusterName/cluster-uuid/mskGroupName\"\n            ]\n        }\n    ]\n}       "
                                    },
                                    "  2 : Identify the Amazon MSK, Amazon EC2 and CloudWatch permissions required for Lambda to discover and connect your Amazon MSK cluster, and log those events.The AWSLambdaMSKExecutionRole managed policy permissively defines the required permissions. Use it in the following steps.In a production environment, assess AWSLambdaMSKExecutionRole to restrict your execution role policy based on the principle of least privilege, then                     write a policy for your role that replaces this managed policy.",
                                    "For details about the IAM policy language, see            the IAM documentation.",
                                    "Now that you have written your policy document, create an IAM policy so you can attach it to your role. You can do this using the console with the following procedure.",
                                    "To create an IAM policy from your policy document",
                                    "  1 : Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.",
                                    "  2 : In the navigation pane on the left, choose Policies. ",
                                    "  3 : Choose Create policy.",
                                    "  4 : In the Policy editor section, choose the                    JSON option.",
                                    "  5 : Paste clusterAuthPolicy.",
                                    "  6 : When you are finished adding permissions to the policy, choose                    Next.",
                                    "  7 : On the Review and create page, type a Policy                    Name and a Description (optional) for the policy that                    you are creating. Review Permissions defined in this policy to see                    the permissions that are granted by your policy.",
                                    "  8 : Choose Create policy to save your new policy.",
                                    "For more information, see Creating IAM policies in the IAM documentation.",
                                    "Now that you have appropriate IAM policies, create a role and attach them to it. You can do this using the console with the following procedure.",
                                    "To create an execution role in the IAM console",
                                    "  1 : Open the Roles page in the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : Under Trusted entity type, choose AWS service.",
                                    "  4 : Under Use case, choose Lambda.",
                                    "  5 : Choose Next.",
                                    "  6 : Select the following policies:clusterAuthPolicyAWSLambdaMSKExecutionRole",
                                    "  7 : Choose Next.",
                                    "  8 : For Role name, enter lambdaAuthRole and then choose Create role.",
                                    "For more information, see Defining Lambda function permissions with an execution role."
                                ]
                            },
                            {
                                "sub_header": "Create a Lambda function to read from your Amazon MSK topic",
                                "content": [
                                    "Create a Lambda function configured to use your            IAM role. You can create your Lambda function using the console.",
                                    "To create a Lambda function using your auth configuration",
                                    "  1 :                 Open the Lambda console and select Create function from the header.            ",
                                    "  2 : Select Author from scratch.",
                                    "  3 : For Function name, provide an appropriate name of your choice.",
                                    "  4 : For Runtime, choose the Latest supported version of Node.js to use the code provided in this tutorial.",
                                    "  5 : Choose Change default execution role.",
                                    "  6 : Select Use an existing role.",
                                    "  7 : For Existing role, select lambdaAuthRole.",
                                    "In a production environment, you usually need to add further policies to the execution role for your Lambda function to             meaningfully process your Amazon MSK events. For more information on adding policies to your role, see Add or            remove identity permissions in the IAM documentation."
                                ]
                            },
                            {
                                "sub_header": "Create an event source mapping to your Lambda function",
                                "content": [
                                    "Your Amazon MSK event source mapping provides the Lambda service the information necessary to invoke your            Lambda when appropriate Amazon MSK events occur. You can create a Amazon MSK mapping using the console. Create a Lambda            trigger, then the event source mapping is automatically set up.",
                                    "To create a Lambda trigger (and event source mapping)",
                                    "  1 : Navigate to your Lambda function's overview page.",
                                    "  2 : In the function overview section, choose Add trigger on the bottom left.",
                                    "  3 : In the Select a source dropdown, select Amazon MSK.",
                                    "  4 : Don't set authentication.",
                                    "  5 : For MSK cluster, select your cluster's name.",
                                    "  6 : For Batch size, enter 1. This step makes this feature easier to test, and is not an ideal value in production.",
                                    "  7 : For Topic name, provide the name of your Kafka topic.",
                                    "  8 : For Consumer group ID, provide the id of your Kafka consumer group."
                                ]
                            },
                            {
                                "sub_header": "Update your Lambda function to read your streaming data",
                                "content": [
                                    "            Lambda provides information about Kafka events through the event method parameter. For an example structure of a Amazon MSK event, see  Example event.            After you understand how to interpret Lambda forwarded Amazon MSK events, you can alter your Lambda function code to use the information they provide.        ",
                                    "            Provide the following code to your Lambda function to log the contents of a Lambda Amazon MSK event for testing purposes:        ",
                                    "  1..NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                                    "  2.AWS SDK for .NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                                    "  3.Go : \npackage main\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.KafkaEvent) {\n\tfor key, records := range event.Records {\n\t\tfmt.Println(\"Key:\", key)\n\n\t\tfor _, record := range records {\n\t\t\tfmt.Println(\"Record:\", record)\n\n\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\n\t\t\tmessage := string(decodedValue)\n\t\t\tfmt.Println(\"Message:\", message)\n\t\t}\n\t}\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n",
                                    "  4.SDK for Go V2 : \npackage main\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.KafkaEvent) {\n\tfor key, records := range event.Records {\n\t\tfmt.Println(\"Key:\", key)\n\n\t\tfor _, record := range records {\n\t\t\tfmt.Println(\"Record:\", record)\n\n\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\n\t\t\tmessage := string(decodedValue)\n\t\t\tfmt.Println(\"Message:\", message)\n\t\t}\n\t}\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n",
                                    "  5.Java : \nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;\n\nimport java.util.Base64;\nimport java.util.Map;\n\npublic class Example implements RequestHandler<KafkaEvent, Void> {\n\n    @Override\n    public Void handleRequest(KafkaEvent event, Context context) {\n        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {\n            String key = entry.getKey();\n            System.out.println(\"Key: \" + key);\n\n            for (KafkaEventRecord record : entry.getValue()) {\n                System.out.println(\"Record: \" + record);\n\n                byte[] value = Base64.getDecoder().decode(record.getValue());\n                String message = new String(value);\n                System.out.println(\"Message: \" + message);\n            }\n        }\n\n        return null;\n    }\n}\n\n",
                                    "  6.SDK for Java 2.x : \nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;\n\nimport java.util.Base64;\nimport java.util.Map;\n\npublic class Example implements RequestHandler<KafkaEvent, Void> {\n\n    @Override\n    public Void handleRequest(KafkaEvent event, Context context) {\n        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {\n            String key = entry.getKey();\n            System.out.println(\"Key: \" + key);\n\n            for (KafkaEventRecord record : entry.getValue()) {\n                System.out.println(\"Record: \" + record);\n\n                byte[] value = Base64.getDecoder().decode(record.getValue());\n                String message = new String(value);\n                System.out.println(\"Message: \" + message);\n            }\n        }\n\n        return null;\n    }\n}\n\n",
                                    "  7.JavaScript : \nexports.handler = async (event) => {\n    // Iterate through keys\n    for (let key in event.records) {\n      console.log('Key: ', key)\n      // Iterate through records\n      event.records[key].map((record) => {\n        console.log('Record: ', record)\n        // Decode base64\n        const msg = Buffer.from(record.value, 'base64').toString()\n        console.log('Message:', msg)\n      }) \n    }\n}\n",
                                    "  8.SDK for JavaScript (v3) : \nexports.handler = async (event) => {\n    // Iterate through keys\n    for (let key in event.records) {\n      console.log('Key: ', key)\n      // Iterate through records\n      event.records[key].map((record) => {\n        console.log('Record: ', record)\n        // Decode base64\n        const msg = Buffer.from(record.value, 'base64').toString()\n        console.log('Message:', msg)\n      }) \n    }\n}\n",
                                    "  9.PHP : <?php\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n\n// using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kafka\\KafkaEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): void\n    {\n        $kafkaEvent = new KafkaEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kafkaEvent->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                $key = $record->getKey();\n                $this->logger->info(\"Key: $key\");\n\n                $values = $record->getValue();\n                $this->logger->info(json_encode($values));\n\n                foreach ($values as $value) {\n                    $this->logger->info(\"Value: $value\");\n                }\n                \n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  10.SDK for PHP : <?php\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n\n// using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kafka\\KafkaEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): void\n    {\n        $kafkaEvent = new KafkaEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kafkaEvent->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                $key = $record->getKey();\n                $this->logger->info(\"Key: $key\");\n\n                $values = $record->getValue();\n                $this->logger->info(json_encode($values));\n\n                foreach ($values as $value) {\n                    $this->logger->info(\"Value: $value\");\n                }\n                \n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  11.Python : \nimport base64\n\ndef lambda_handler(event, context):\n    # Iterate through keys\n    for key in event['records']:\n        print('Key:', key)\n        # Iterate through records\n        for record in event['records'][key]:\n            print('Record:', record)\n            # Decode base64\n            msg = base64.b64decode(record['value']).decode('utf-8')\n            print('Message:', msg)\n",
                                    "  12.SDK for Python (Boto3) : \nimport base64\n\ndef lambda_handler(event, context):\n    # Iterate through keys\n    for key in event['records']:\n        print('Key:', key)\n        # Iterate through records\n        for record in event['records'][key]:\n            print('Record:', record)\n            # Decode base64\n            msg = base64.b64decode(record['value']).decode('utf-8')\n            print('Message:', msg)\n",
                                    "  13.Ruby : \nrequire 'base64'\n\ndef lambda_handler(event:, context:)\n  # Iterate through keys\n  event['records'].each do |key, records|\n    puts \"Key: #{key}\"\n\n    # Iterate through records\n    records.each do |record|\n      puts \"Record: #{record}\"\n\n      # Decode base64\n      msg = Base64.decode64(record['value'])\n      puts \"Message: #{msg}\"\n    end\n  end\nend\n",
                                    "  14.SDK for Ruby : \nrequire 'base64'\n\ndef lambda_handler(event:, context:)\n  # Iterate through keys\n  event['records'].each do |key, records|\n    puts \"Key: #{key}\"\n\n    # Iterate through records\n    records.each do |record|\n      puts \"Record: #{record}\"\n\n      # Decode base64\n      msg = Base64.decode64(record['value'])\n      puts \"Message: #{msg}\"\n    end\n  end\nend\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using .NET.using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KafkaEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace MSKLambda;public class Function{            /// <param name=\"input\">The event for the Lambda function handler to process.</param>    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>    /// <returns></returns>    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            Console.WriteLine(\"Key:\" + record.Key);             foreach (var eventRecord in record.Value)            {                var valueBytes = eventRecord.Value.ToArray();                    var valueText = Encoding.UTF8.GetString(valueBytes);                                Console.WriteLine(\"Message:\" + valueText);            }        }    }    }GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Go.package mainimport (\t\"encoding/base64\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(event events.KafkaEvent) {\tfor key, records := range event.Records {\t\tfmt.Println(\"Key:\", key)\t\tfor _, record := range records {\t\t\tfmt.Println(\"Record:\", record)\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\t\t\tmessage := string(decodedValue)\t\t\tfmt.Println(\"Message:\", message)\t\t}\t}}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KafkaEvent;import com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;import java.util.Base64;import java.util.Map;public class Example implements RequestHandler<KafkaEvent, Void> {    @Override    public Void handleRequest(KafkaEvent event, Context context) {        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {            String key = entry.getKey();            System.out.println(\"Key: \" + key);            for (KafkaEventRecord record : entry.getValue()) {                System.out.println(\"Record: \" + record);                byte[] value = Base64.getDecoder().decode(record.getValue());                String message = new String(value);                System.out.println(\"Message: \" + message);            }        }        return null;    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using JavaScript.exports.handler = async (event) => {    // Iterate through keys    for (let key in event.records) {      console.log('Key: ', key)      // Iterate through records      event.records[key].map((record) => {        console.log('Record: ', record)        // Decode base64        const msg = Buffer.from(record.value, 'base64').toString()        console.log('Message:', msg)      })     }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using PHP.<?php// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0// using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kafka\\KafkaEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): void    {        $kafkaEvent = new KafkaEvent($event);        $this->logger->info(\"Processing records\");        $records = $kafkaEvent->getRecords();        foreach ($records as $record) {            try {                $key = $record->getKey();                $this->logger->info(\"Key: $key\");                $values = $record->getValue();                $this->logger->info(json_encode($values));                foreach ($values as $value) {                    $this->logger->info(\"Value: $value\");                }                            } catch (Exception $e) {                $this->logger->error($e->getMessage());            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Python.import base64def lambda_handler(event, context):    # Iterate through keys    for key in event['records']:        print('Key:', key)        # Iterate through records        for record in event['records'][key]:            print('Record:', record)            # Decode base64            msg = base64.b64decode(record['value']).decode('utf-8')            print('Message:', msg)RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Ruby.require 'base64'def lambda_handler(event:, context:)  # Iterate through keys  event['records'].each do |key, records|    puts \"Key: #{key}\"    # Iterate through records    records.each do |record|      puts \"Record: #{record}\"      # Decode base64      msg = Base64.decode64(record['value'])      puts \"Message: #{msg}\"    end  endend",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using .NET.using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KafkaEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace MSKLambda;public class Function{            /// <param name=\"input\">The event for the Lambda function handler to process.</param>    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>    /// <returns></returns>    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            Console.WriteLine(\"Key:\" + record.Key);             foreach (var eventRecord in record.Value)            {                var valueBytes = eventRecord.Value.ToArray();                    var valueText = Encoding.UTF8.GetString(valueBytes);                                Console.WriteLine(\"Message:\" + valueText);            }        }    }    }",
                                    "You can provide function code to your Lambda using the console.",
                                    "To update function code using the console code editor",
                                    "  1 : Open the Functions page of the Lambda console and select your function.",
                                    "  2 : Select the Code tab.",
                                    "  3 : In the Code source pane, select your source code file and edit it in the integrated code editor.",
                                    "  4 : In the DEPLOY section, choose Deploy to update your function's code:"
                                ]
                            },
                            {
                                "sub_header": "Test your Lambda function to verify it is connected to your Amazon MSK topic",
                                "content": [
                                    "You can now verify whether or not your Lambda is being invoked by the event source by inspecting CloudWatch event logs.",
                                    "To verify whether your Lambda function is being invoked",
                                    "  1 : Use your Kafka admin host to generate Kafka events using the                    kafka-console-producer CLI. For more information, see Write some events into the topic in the Kafka                    documentation. Send enough events to fill up the batch defined by batch size for your event source mapping                    defined in the previous step, or Lambda will wait for more information to invoke.",
                                    "  2 : If your function runs, Lambda writes what happened to CloudWatch. In the console, navigate to your                    Lambda function's detail page.",
                                    "  3 : Select the Configuration tab.",
                                    "  4 : From the sidebar, select Monitoring                    and operations tools.",
                                    "  5 : Identify the CloudWatch log group under                    Logging configuration. The log group should start with                    /aws/lambda. Choose the link to the log group.",
                                    "  6 : In the CloudWatch console, inspect the Log events for the log events Lambda has sent to the log stream.                    Identify if there are log events containing the message from your Kafka event, as in the following image. If there are, you                    have successfully connected a Lambda function to Amazon MSK with a Lambda event source mapping."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "Note",
                    "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                    "Amazon Managed Streaming for Apache Kafka (Amazon MSK) is a    fully managed service that you can use to build and run applications that use Apache Kafka to process streaming data.    Amazon MSK simplifies the setup, scaling, and management of clusters running Kafka. Amazon MSK also makes it easier to    configure your application for multiple Availability Zones and for security with AWS Identity and Access Management (IAM). Amazon MSK supports    multiple open-source versions of Kafka.",
                    "Amazon MSK as an event source operates similarly to using Amazon Simple Queue Service (Amazon SQS) or Amazon Kinesis. Lambda internally polls for    new messages from the event source and then synchronously invokes the target Lambda function. Lambda reads the    messages in batches and provides these to your function as an event payload. The maximum batch size is configurable    (the default is 100 messages). For more information, see    Batching behavior.",
                    "By default, Lambda autoscales the number of event pollers for    your Amazon MSK event source mapping. To optimize the throughput of your Amazon MSK event source mapping, configure    provisioned mode. In provisioned mode, you can define the minimum and maximum number of event pollers allocated    to your event source mapping. This can improve the ability of your event source mapping to handle unexpected    message spikes. For more information, see provisioned mode.",
                    "Warning",
                    "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                    "For an example of how to configure Amazon MSK as an event source, see Using Amazon MSK as an event source for    AWS Lambda on the AWS Compute Blog. For a complete tutorial, see  Amazon MSK Lambda Integration in the Amazon MSK    Labs.",
                    "Topics",
                    {
                        "sub_header": " Example event",
                        "content": [
                            "Lambda sends the batch of messages in the event parameter when it invokes your function. The event payload      contains an array of messages. Each array item contains details of the Amazon MSK topic and partition identifier,      together with a timestamp and a base64-encoded message.",
                            "{   \"eventSource\":\"aws:kafka\",   \"eventSourceArn\":\"arn:aws:kafka:us-east-1:123456789012:cluster/vpc-2priv-2pub/751d2973-a626-431c-9d4e-d7975eb44dd7-2\",   \"bootstrapServers\":\"b-2.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092,b-1.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092\",   \"records\":{      \"mytopic-0\":[         {            \"topic\":\"mytopic\",            \"partition\":0,            \"offset\":15,            \"timestamp\":1545084650987,            \"timestampType\":\"CREATE_TIME\",            \"key\":\"abcDEFghiJKLmnoPQRstuVWXyz1234==\",            \"value\":\"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",            \"headers\":[               {                  \"headerKey\":[                     104,                     101,                     97,                     100,                     101,                     114,                     86,                     97,                     108,                     117,                     101                  ]               }            ]         }      ]   }}"
                        ]
                    }
                ]
            },
            {
                "title": "RDS",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html",
                "sections": [
                    "You can connect a Lambda function to an Amazon Relational Database Service (Amazon RDS) database directly and through    an Amazon RDS Proxy. Direct connections are useful in simple scenarios, and proxies are recommended    for production. A database proxy manages a pool of shared database connections which enables    your function to reach high concurrency levels without exhausting database connections.",
                    "We recommend using Amazon RDS Proxy for Lambda functions that make frequent short database    connections, or open and close large numbers of database connections. For more information,    see     Automatically connecting a Lambda function and a DB instance in the Amazon Relational Database Service Developer Guide.",
                    {
                        "sub_header": "Configuring your function to work with RDS resources",
                        "content": [
                            "In the Lambda console, you can provision, and configure, Amazon RDS database instances and      proxy resources. You can do this by navigating to RDS databases under      the Configuration tab. Alternatively, you can also create and configure      connections to Lambda functions in the Amazon RDS console. When configuring an RDS database      instance to use with Lambda, note the following criteria:",
                            "  1.To connect to a database, your function must be in the same Amazon VPC where your          database runs.",
                            "  2.You can use Amazon RDS databases with MySQL, MariaDB, PostgreSQL, or Microsoft SQL Server          engines.",
                            "  3.You can also use Aurora DB clusters with MySQL or PostgreSQL engines.",
                            "  4.You need to provide a Secrets Manager secret for database authentication.",
                            "  5.An IAM role must provide permission to use the secret, and a trust policy must          allow Amazon RDS to assume the role.",
                            "  6.          The IAM principal that uses the console to configure the Amazon RDS resource, and connect          it to your function must have the following permissions:        Note            You need the Amazon RDS Proxy permissions only if you configure an Amazon RDS Proxy to             manage a pool of your database connections.          Example permission policy{  \"Version\": \"2012-10-17\",  \"Statement\": [    {      \"Effect\": \"Allow\",      \"Action\": [        \"ec2:CreateSecurityGroup\",        \"ec2:DescribeSecurityGroups\",        \"ec2:DescribeSubnets\",        \"ec2:DescribeVpcs\",        \"ec2:AuthorizeSecurityGroupIngress\",        \"ec2:AuthorizeSecurityGroupEgress\",        \"ec2:RevokeSecurityGroupEgress\",        \"ec2:CreateNetworkInterface\",        \"ec2:DeleteNetworkInterface\",        \"ec2:DescribeNetworkInterfaces\"      ],      \"Resource\": \"*\"    },    {      \"Effect\": \"Allow\",      \"Action\": [        \"rds-db:connect\",        \"rds:CreateDBProxy\",        \"rds:CreateDBInstance\",        \"rds:CreateDBSubnetGroup\",        \"rds:DescribeDBClusters\",        \"rds:DescribeDBInstances\",        \"rds:DescribeDBSubnetGroups\",        \"rds:DescribeDBProxies\",        \"rds:DescribeDBProxyTargets\",        \"rds:DescribeDBProxyTargetGroups\",        \"rds:RegisterDBProxyTargets\",        \"rds:ModifyDBInstance\",        \"rds:ModifyDBProxy\"      ],      \"Resource\": \"*\"    },    {      \"Effect\": \"Allow\",      \"Action\": [        \"lambda:CreateFunction\",        \"lambda:ListFunctions\",        \"lambda:UpdateFunctionConfiguration\"      ],      \"Resource\": \"*\"    },    {      \"Effect\": \"Allow\",      \"Action\": [        \"iam:AttachRolePolicy\",        \"iam:AttachPolicy\",        \"iam:CreateRole\",        \"iam:CreatePolicy\"      ],      \"Resource\": \"*\"    },    {      \"Effect\": \"Allow\",      \"Action\": [        \"secretsmanager:GetResourcePolicy\",        \"secretsmanager:GetSecretValue\",        \"secretsmanager:DescribeSecret\",        \"secretsmanager:ListSecretVersionIds\",        \"secretsmanager:CreateSecret\"      ],      \"Resource\": \"*\"    }  ]}",
                            {
                                "code_example": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:CreateSecurityGroup\",\n        \"ec2:DescribeSecurityGroups\",\n        \"ec2:DescribeSubnets\",\n        \"ec2:DescribeVpcs\",\n        \"ec2:AuthorizeSecurityGroupIngress\",\n        \"ec2:AuthorizeSecurityGroupEgress\",\n        \"ec2:RevokeSecurityGroupEgress\",\n        \"ec2:CreateNetworkInterface\",\n        \"ec2:DeleteNetworkInterface\",\n        \"ec2:DescribeNetworkInterfaces\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"rds-db:connect\",\n        \"rds:CreateDBProxy\",\n        \"rds:CreateDBInstance\",\n        \"rds:CreateDBSubnetGroup\",\n        \"rds:DescribeDBClusters\",\n        \"rds:DescribeDBInstances\",\n        \"rds:DescribeDBSubnetGroups\",\n        \"rds:DescribeDBProxies\",\n        \"rds:DescribeDBProxyTargets\",\n        \"rds:DescribeDBProxyTargetGroups\",\n        \"rds:RegisterDBProxyTargets\",\n        \"rds:ModifyDBInstance\",\n        \"rds:ModifyDBProxy\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"lambda:CreateFunction\",\n        \"lambda:ListFunctions\",\n        \"lambda:UpdateFunctionConfiguration\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"iam:AttachRolePolicy\",\n        \"iam:AttachPolicy\",\n        \"iam:CreateRole\",\n        \"iam:CreatePolicy\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetResourcePolicy\",\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\",\n        \"secretsmanager:ListSecretVersionIds\",\n        \"secretsmanager:CreateSecret\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n"
                            },
                            "Amazon RDS charges an hourly rate for proxies based on the database instance size, see      RDS Proxy pricing for details.      For more information on proxy connections in general, see      Using Amazon RDS Proxy in the Amazon RDS User Guide.",
                            "Lambda and Amazon RDS setup",
                            "Both Lambda and Amazon RDS consoles will assist you in automatically configuring some of        the required resources to make a connection between Lambda and Amazon RDS."
                        ]
                    },
                    {
                        "sub_header": "Connecting to an Amazon RDS database in a Lambda function",
                        "content": [
                            "The following code example shows how to implement a Lambda function that connects      to an Amazon RDS database. The function makes a simple database request and returns the result.",
                            "  1.Go : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  2.SDK for Go V2 : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  3.Java : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;\nimport software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.rdsdata.RdsDataClient;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;\nimport software.amazon.awssdk.services.rdsdata.model.Field;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\n\npublic class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {\n\n    @Override\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {\n        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\n        try {\n            // Obtain auth token\n            String token = createAuthToken();\n\n            // Define connection configuration\n            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",\n                    System.getenv(\"ProxyHostName\"),\n                    System.getenv(\"Port\"),\n                    System.getenv(\"DBName\"));\n\n            // Establish a connection to the database\n            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);\n                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {\n\n                statement.setInt(1, 3);\n                statement.setInt(2, 2);\n\n                try (ResultSet resultSet = statement.executeQuery()) {\n                    if (resultSet.next()) {\n                        int sum = resultSet.getInt(\"sum\");\n                        response.setStatusCode(200);\n                        response.setBody(\"The selected sum is: \" + sum);\n                    }\n                }\n            }\n\n        } catch (Exception e) {\n            response.setStatusCode(500);\n            response.setBody(\"Error: \" + e.getMessage());\n        }\n\n        return response;\n    }\n\n    private String createAuthToken() {\n        // Create RDS Data Service client\n        RdsDataClient rdsDataClient = RdsDataClient.builder()\n                .region(Region.of(System.getenv(\"AWS_REGION\")))\n                .credentialsProvider(DefaultCredentialsProvider.create())\n                .build();\n\n        // Define authentication request\n        ExecuteStatementRequest request = ExecuteStatementRequest.builder()\n                .resourceArn(System.getenv(\"ProxyHostName\"))\n                .secretArn(System.getenv(\"DBUserName\"))\n                .database(System.getenv(\"DBName\"))\n                .sql(\"SELECT 'RDS IAM Authentication'\")\n                .build();\n\n        // Execute request and obtain authentication token\n        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);\n        Field tokenField = response.records().get(0).get(0);\n\n        return tokenField.stringValue();\n    }\n}\n\n",
                            "  4.SDK for Java 2.x : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;\nimport software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.rdsdata.RdsDataClient;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;\nimport software.amazon.awssdk.services.rdsdata.model.Field;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\n\npublic class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {\n\n    @Override\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {\n        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\n        try {\n            // Obtain auth token\n            String token = createAuthToken();\n\n            // Define connection configuration\n            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",\n                    System.getenv(\"ProxyHostName\"),\n                    System.getenv(\"Port\"),\n                    System.getenv(\"DBName\"));\n\n            // Establish a connection to the database\n            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);\n                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {\n\n                statement.setInt(1, 3);\n                statement.setInt(2, 2);\n\n                try (ResultSet resultSet = statement.executeQuery()) {\n                    if (resultSet.next()) {\n                        int sum = resultSet.getInt(\"sum\");\n                        response.setStatusCode(200);\n                        response.setBody(\"The selected sum is: \" + sum);\n                    }\n                }\n            }\n\n        } catch (Exception e) {\n            response.setStatusCode(500);\n            response.setBody(\"Error: \" + e.getMessage());\n        }\n\n        return response;\n    }\n\n    private String createAuthToken() {\n        // Create RDS Data Service client\n        RdsDataClient rdsDataClient = RdsDataClient.builder()\n                .region(Region.of(System.getenv(\"AWS_REGION\")))\n                .credentialsProvider(DefaultCredentialsProvider.create())\n                .build();\n\n        // Define authentication request\n        ExecuteStatementRequest request = ExecuteStatementRequest.builder()\n                .resourceArn(System.getenv(\"ProxyHostName\"))\n                .secretArn(System.getenv(\"DBUserName\"))\n                .database(System.getenv(\"DBName\"))\n                .sql(\"SELECT 'RDS IAM Authentication'\")\n                .build();\n\n        // Execute request and obtain authentication token\n        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);\n        Field tokenField = response.records().get(0).get(0);\n\n        return tokenField.stringValue();\n    }\n}\n\n",
                            "  5.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/* \nNode.js code here.\n*/\n// ES6+ example\nimport { Signer } from \"@aws-sdk/rds-signer\";\nimport mysql from 'mysql2/promise';\n\nasync function createAuthToken() {\n  // Define connection authentication parameters\n  const dbinfo = {\n\n    hostname: process.env.ProxyHostName,\n    port: process.env.Port,\n    username: process.env.DBUserName,\n    region: process.env.AWS_REGION,\n\n  }\n\n  // Create RDS Signer object\n  const signer = new Signer(dbinfo);\n\n  // Request authorization token from RDS, specifying the username\n  const token = await signer.getAuthToken();\n  return token;\n}\n\nasync function dbOps() {\n\n  // Obtain auth token\n  const token = await createAuthToken();\n  // Define connection configuration\n  let connectionConfig = {\n    host: process.env.ProxyHostName,\n    user: process.env.DBUserName,\n    password: token,\n    database: process.env.DBName,\n    ssl: 'Amazon RDS'\n  }\n  // Create the connection to the DB\n  const conn = await mysql.createConnection(connectionConfig);\n  // Obtain the result of the query\n  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);\n  return res;\n\n}\n\nexport const handler = async (event) => {\n  // Execute database flow\n  const result = await dbOps();\n  // Return result\n  return {\n    statusCode: 200,\n    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)\n  }\n};\n\n",
                            "  6.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/* \nNode.js code here.\n*/\n// ES6+ example\nimport { Signer } from \"@aws-sdk/rds-signer\";\nimport mysql from 'mysql2/promise';\n\nasync function createAuthToken() {\n  // Define connection authentication parameters\n  const dbinfo = {\n\n    hostname: process.env.ProxyHostName,\n    port: process.env.Port,\n    username: process.env.DBUserName,\n    region: process.env.AWS_REGION,\n\n  }\n\n  // Create RDS Signer object\n  const signer = new Signer(dbinfo);\n\n  // Request authorization token from RDS, specifying the username\n  const token = await signer.getAuthToken();\n  return token;\n}\n\nasync function dbOps() {\n\n  // Obtain auth token\n  const token = await createAuthToken();\n  // Define connection configuration\n  let connectionConfig = {\n    host: process.env.ProxyHostName,\n    user: process.env.DBUserName,\n    password: token,\n    database: process.env.DBName,\n    ssl: 'Amazon RDS'\n  }\n  // Create the connection to the DB\n  const conn = await mysql.createConnection(connectionConfig);\n  // Obtain the result of the query\n  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);\n  return res;\n\n}\n\nexport const handler = async (event) => {\n  // Execute database flow\n  const result = await dbOps();\n  // Return result\n  return {\n    statusCode: 200,\n    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)\n  }\n};\n\n",
                            "  7.PHP : <?php\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\nuse Aws\\Rds\\AuthTokenGenerator;\nuse Aws\\Credentials\\CredentialProvider;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n\n    private function getAuthToken(): string {\n        // Define connection authentication parameters\n        $dbConnection = [\n            'hostname' => getenv('DB_HOSTNAME'),\n            'port' => getenv('DB_PORT'),\n            'username' => getenv('DB_USERNAME'),\n            'region' => getenv('AWS_REGION'),\n        ];\n\n        // Create RDS AuthTokenGenerator object\n        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());\n\n        // Request authorization token from RDS, specifying the username\n        return $generator->createToken(\n            $dbConnection['hostname'] . ':' . $dbConnection['port'],\n            $dbConnection['region'],\n            $dbConnection['username']\n        );\n    }\n\n    private function getQueryResults() {\n        // Obtain auth token\n        $token = $this->getAuthToken();\n\n        // Define connection configuration\n        $connectionConfig = [\n            'host' => getenv('DB_HOSTNAME'),\n            'user' => getenv('DB_USERNAME'),\n            'password' => $token,\n            'database' => getenv('DB_NAME'),\n        ];\n\n        // Create the connection to the DB\n        $conn = new PDO(\n            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",\n            $connectionConfig['user'],\n            $connectionConfig['password'],\n            [\n                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',\n                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,\n            ]\n        );\n\n        // Obtain the result of the query\n        $stmt = $conn->prepare('SELECT ?+? AS sum');\n        $stmt->execute([3, 2]);\n\n        return $stmt->fetch(PDO::FETCH_ASSOC);\n    }\n\n    /**\n     * @param mixed $event\n     * @param Context $context\n     * @return array\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $this->logger->info(\"Processing query\");\n\n        // Execute database flow\n        $result = $this->getQueryResults();\n\n        return [\n            'sum' => $result['sum']\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  8.SDK for PHP : <?php\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\nuse Aws\\Rds\\AuthTokenGenerator;\nuse Aws\\Credentials\\CredentialProvider;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n\n    private function getAuthToken(): string {\n        // Define connection authentication parameters\n        $dbConnection = [\n            'hostname' => getenv('DB_HOSTNAME'),\n            'port' => getenv('DB_PORT'),\n            'username' => getenv('DB_USERNAME'),\n            'region' => getenv('AWS_REGION'),\n        ];\n\n        // Create RDS AuthTokenGenerator object\n        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());\n\n        // Request authorization token from RDS, specifying the username\n        return $generator->createToken(\n            $dbConnection['hostname'] . ':' . $dbConnection['port'],\n            $dbConnection['region'],\n            $dbConnection['username']\n        );\n    }\n\n    private function getQueryResults() {\n        // Obtain auth token\n        $token = $this->getAuthToken();\n\n        // Define connection configuration\n        $connectionConfig = [\n            'host' => getenv('DB_HOSTNAME'),\n            'user' => getenv('DB_USERNAME'),\n            'password' => $token,\n            'database' => getenv('DB_NAME'),\n        ];\n\n        // Create the connection to the DB\n        $conn = new PDO(\n            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",\n            $connectionConfig['user'],\n            $connectionConfig['password'],\n            [\n                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',\n                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,\n            ]\n        );\n\n        // Obtain the result of the query\n        $stmt = $conn->prepare('SELECT ?+? AS sum');\n        $stmt->execute([3, 2]);\n\n        return $stmt->fetch(PDO::FETCH_ASSOC);\n    }\n\n    /**\n     * @param mixed $event\n     * @param Context $context\n     * @return array\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $this->logger->info(\"Processing query\");\n\n        // Execute database flow\n        $result = $this->getQueryResults();\n\n        return [\n            'sum' => $result['sum']\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  9.Python : import json\nimport os\nimport boto3\nimport pymysql\n\n# RDS settings\nproxy_host_name = os.environ['PROXY_HOST_NAME']\nport = int(os.environ['PORT'])\ndb_name = os.environ['DB_NAME']\ndb_user_name = os.environ['DB_USER_NAME']\naws_region = os.environ['AWS_REGION']\n\n\n# Fetch RDS Auth Token\ndef get_auth_token():\n    client = boto3.client('rds')\n    token = client.generate_db_auth_token(\n        DBHostname=proxy_host_name,\n        Port=port\n        DBUsername=db_user_name\n        Region=aws_region\n    )\n    return token\n\ndef lambda_handler(event, context):\n    token = get_auth_token()\n    try:\n        connection = pymysql.connect(\n            host=proxy_host_name,\n            user=db_user_name,\n            password=token,\n            db=db_name,\n            port=port,\n            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection\n        )\n        \n        with connection.cursor() as cursor:\n            cursor.execute('SELECT %s + %s AS sum', (3, 2))\n            result = cursor.fetchone()\n\n        return result\n        \n    except Exception as e:\n        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs \n    \n",
                            "  10.SDK for Python (Boto3) : import json\nimport os\nimport boto3\nimport pymysql\n\n# RDS settings\nproxy_host_name = os.environ['PROXY_HOST_NAME']\nport = int(os.environ['PORT'])\ndb_name = os.environ['DB_NAME']\ndb_user_name = os.environ['DB_USER_NAME']\naws_region = os.environ['AWS_REGION']\n\n\n# Fetch RDS Auth Token\ndef get_auth_token():\n    client = boto3.client('rds')\n    token = client.generate_db_auth_token(\n        DBHostname=proxy_host_name,\n        Port=port\n        DBUsername=db_user_name\n        Region=aws_region\n    )\n    return token\n\ndef lambda_handler(event, context):\n    token = get_auth_token()\n    try:\n        connection = pymysql.connect(\n            host=proxy_host_name,\n            user=db_user_name,\n            password=token,\n            db=db_name,\n            port=port,\n            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection\n        )\n        \n        with connection.cursor() as cursor:\n            cursor.execute('SELECT %s + %s AS sum', (3, 2))\n            result = cursor.fetchone()\n\n        return result\n        \n    except Exception as e:\n        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs \n    \n",
                            "  11.Ruby : # Ruby code here.\n\nrequire 'aws-sdk-rds'\nrequire 'json'\nrequire 'mysql2'\n\ndef lambda_handler(event:, context:)\n  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"\n  port = ENV['Port']           # 3306\n  user = ENV['DBUser']\n  region = ENV['DBRegion']     # 'us-east-1'\n  db_name = ENV['DBName']\n\n  credentials = Aws::Credentials.new(\n    ENV['AWS_ACCESS_KEY_ID'],\n    ENV['AWS_SECRET_ACCESS_KEY'],\n    ENV['AWS_SESSION_TOKEN']\n  )\n  rds_client = Aws::RDS::AuthTokenGenerator.new(\n    region: region, \n    credentials: credentials\n  )\n\n  token = rds_client.auth_token(\n    endpoint: endpoint+ ':' + port,\n    user_name: user,\n    region: region\n  )\n\n  begin\n    conn = Mysql2::Client.new(\n      host: endpoint,\n      username: user,\n      password: token,\n      port: port,\n      database: db_name,\n      sslca: '/var/task/global-bundle.pem', \n      sslverify: true,\n      enable_cleartext_plugin: true\n    )\n    a = 3\n    b = 2\n    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']\n    puts result\n    conn.close\n    {\n      statusCode: 200,\n      body: result.to_json\n    }\n  rescue => e\n    puts \"Database connection failed due to #{e}\"\n  end\nend\n",
                            "  12.SDK for Ruby : # Ruby code here.\n\nrequire 'aws-sdk-rds'\nrequire 'json'\nrequire 'mysql2'\n\ndef lambda_handler(event:, context:)\n  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"\n  port = ENV['Port']           # 3306\n  user = ENV['DBUser']\n  region = ENV['DBRegion']     # 'us-east-1'\n  db_name = ENV['DBName']\n\n  credentials = Aws::Credentials.new(\n    ENV['AWS_ACCESS_KEY_ID'],\n    ENV['AWS_SECRET_ACCESS_KEY'],\n    ENV['AWS_SESSION_TOKEN']\n  )\n  rds_client = Aws::RDS::AuthTokenGenerator.new(\n    region: region, \n    credentials: credentials\n  )\n\n  token = rds_client.auth_token(\n    endpoint: endpoint+ ':' + port,\n    user_name: user,\n    region: region\n  )\n\n  begin\n    conn = Mysql2::Client.new(\n      host: endpoint,\n      username: user,\n      password: token,\n      port: port,\n      database: db_name,\n      sslca: '/var/task/global-bundle.pem', \n      sslverify: true,\n      enable_cleartext_plugin: true\n    )\n    a = 3\n    b = 2\n    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']\n    puts result\n    conn.close\n    {\n      statusCode: 200,\n      body: result.to_json\n    }\n  rescue => e\n    puts \"Database connection failed due to #{e}\"\n  end\nend\n",
                            "  13.Rust : use aws_config::BehaviorVersion;\nuse aws_credential_types::provider::ProvideCredentials;\nuse aws_sigv4::{\n    http_request::{sign, SignableBody, SignableRequest, SigningSettings},\n    sign::v4,\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse serde_json::{json, Value};\nuse sqlx::postgres::PgConnectOptions;\nuse std::env;\nuse std::time::{Duration, SystemTime};\n\nconst RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");\n\nasync fn generate_rds_iam_token(\n    db_hostname: &str,\n    port: u16,\n    db_username: &str,\n) -> Result<String, Error> {\n    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;\n\n    let credentials = config\n        .credentials_provider()\n        .expect(\"no credentials provider found\")\n        .provide_credentials()\n        .await\n        .expect(\"unable to load credentials\");\n    let identity = credentials.into();\n    let region = config.region().unwrap().to_string();\n\n    let mut signing_settings = SigningSettings::default();\n    signing_settings.expires_in = Some(Duration::from_secs(900));\n    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;\n\n    let signing_params = v4::SigningParams::builder()\n        .identity(&identity)\n        .region(&region)\n        .name(\"rds-db\")\n        .time(SystemTime::now())\n        .settings(signing_settings)\n        .build()?;\n\n    let url = format!(\n        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",\n        db_hostname = db_hostname,\n        port = port,\n        db_user = db_username\n    );\n\n    let signable_request =\n        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))\n            .expect(\"signable request\");\n\n    let (signing_instructions, _signature) =\n        sign(signable_request, &signing_params.into())?.into_parts();\n\n    let mut url = url::Url::parse(&url).unwrap();\n    for (name, value) in signing_instructions.params() {\n        url.query_pairs_mut().append_pair(name, &value);\n    }\n\n    let response = url.to_string().split_off(\"https://\".len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(handler)).await\n}\n\nasync fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {\n    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");\n    let db_port = env::var(\"DB_PORT\")\n        .expect(\"DB_PORT must be set\")\n        .parse::<u16>()\n        .expect(\"PORT must be a valid number\");\n    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");\n    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");\n\n    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;\n\n    let opts = PgConnectOptions::new()\n        .host(&db_host)\n        .port(db_port)\n        .username(&db_user_name)\n        .password(&token)\n        .database(&db_name)\n        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())\n        .ssl_mode(sqlx::postgres::PgSslMode::Require);\n\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .connect_with(opts)\n        .await?;\n\n    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")\n        .bind(3)\n        .bind(2)\n        .fetch_one(&pool)\n        .await?;\n\n    println!(\"Result: {:?}\", result);\n\n    Ok(json!({\n        \"statusCode\": 200,\n        \"content-type\": \"text/plain\",\n        \"body\": format!(\"The selected sum is: {result}\")\n    }))\n}\n\n",
                            "  14.SDK for Rust : use aws_config::BehaviorVersion;\nuse aws_credential_types::provider::ProvideCredentials;\nuse aws_sigv4::{\n    http_request::{sign, SignableBody, SignableRequest, SigningSettings},\n    sign::v4,\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse serde_json::{json, Value};\nuse sqlx::postgres::PgConnectOptions;\nuse std::env;\nuse std::time::{Duration, SystemTime};\n\nconst RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");\n\nasync fn generate_rds_iam_token(\n    db_hostname: &str,\n    port: u16,\n    db_username: &str,\n) -> Result<String, Error> {\n    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;\n\n    let credentials = config\n        .credentials_provider()\n        .expect(\"no credentials provider found\")\n        .provide_credentials()\n        .await\n        .expect(\"unable to load credentials\");\n    let identity = credentials.into();\n    let region = config.region().unwrap().to_string();\n\n    let mut signing_settings = SigningSettings::default();\n    signing_settings.expires_in = Some(Duration::from_secs(900));\n    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;\n\n    let signing_params = v4::SigningParams::builder()\n        .identity(&identity)\n        .region(&region)\n        .name(\"rds-db\")\n        .time(SystemTime::now())\n        .settings(signing_settings)\n        .build()?;\n\n    let url = format!(\n        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",\n        db_hostname = db_hostname,\n        port = port,\n        db_user = db_username\n    );\n\n    let signable_request =\n        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))\n            .expect(\"signable request\");\n\n    let (signing_instructions, _signature) =\n        sign(signable_request, &signing_params.into())?.into_parts();\n\n    let mut url = url::Url::parse(&url).unwrap();\n    for (name, value) in signing_instructions.params() {\n        url.query_pairs_mut().append_pair(name, &value);\n    }\n\n    let response = url.to_string().split_off(\"https://\".len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(handler)).await\n}\n\nasync fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {\n    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");\n    let db_port = env::var(\"DB_PORT\")\n        .expect(\"DB_PORT must be set\")\n        .parse::<u16>()\n        .expect(\"PORT must be a valid number\");\n    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");\n    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");\n\n    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;\n\n    let opts = PgConnectOptions::new()\n        .host(&db_host)\n        .port(db_port)\n        .username(&db_user_name)\n        .password(&token)\n        .database(&db_name)\n        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())\n        .ssl_mode(sqlx::postgres::PgSslMode::Require);\n\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .connect_with(opts)\n        .await?;\n\n    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")\n        .bind(3)\n        .bind(2)\n        .fetch_one(&pool)\n        .await?;\n\n    println!(\"Result: {:?}\", result);\n\n    Ok(json!({\n        \"statusCode\": 200,\n        \"content-type\": \"text/plain\",\n        \"body\": format!(\"The selected sum is: {result}\")\n    }))\n}\n\n",
                            "GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Go./*Golang v2 code here.*/package mainimport (\t\"context\"\t\"database/sql\"\t\"encoding/json\"\t\"fmt\"\t\"os\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\t_ \"github.com/go-sql-driver/mysql\")type MyEvent struct {\tName string `json:\"name\"`}func HandleRequest(event *MyEvent) (map[string]interface{}, error) {\tvar dbName string = os.Getenv(\"DatabaseName\")\tvar dbUser string = os.Getenv(\"DatabaseUser\")\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\tvar region string = os.Getenv(\"AWS_REGION\")\tcfg, err := config.LoadDefaultConfig(context.TODO())\tif err != nil {\t\tpanic(\"configuration error: \" + err.Error())\t}\tauthenticationToken, err := auth.BuildAuthToken(\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\tif err != nil {\t\tpanic(\"failed to create authentication token: \" + err.Error())\t}\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\t\tdbUser, authenticationToken, dbEndpoint, dbName,\t)\tdb, err := sql.Open(\"mysql\", dsn)\tif err != nil {\t\tpanic(err)\t}\tdefer db.Close()\tvar sum int\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\tif err != nil {\t\tpanic(err)\t}\ts := fmt.Sprint(sum)\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\tmessageBytes, err := json.Marshal(message)\tif err != nil {\t\treturn nil, err\t}\tmessageString := string(messageBytes)\treturn map[string]interface{}{\t\t\"statusCode\": 200,\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\t\t\"body\":       messageString,\t}, nil}func main() {\tlambda.Start(HandleRequest)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;import software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;import software.amazon.awssdk.regions.Region;import software.amazon.awssdk.services.rdsdata.RdsDataClient;import software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;import software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;import software.amazon.awssdk.services.rdsdata.model.Field;import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;import java.sql.ResultSet;public class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {    @Override    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();        try {            // Obtain auth token            String token = createAuthToken();            // Define connection configuration            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",                    System.getenv(\"ProxyHostName\"),                    System.getenv(\"Port\"),                    System.getenv(\"DBName\"));            // Establish a connection to the database            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {                statement.setInt(1, 3);                statement.setInt(2, 2);                try (ResultSet resultSet = statement.executeQuery()) {                    if (resultSet.next()) {                        int sum = resultSet.getInt(\"sum\");                        response.setStatusCode(200);                        response.setBody(\"The selected sum is: \" + sum);                    }                }            }        } catch (Exception e) {            response.setStatusCode(500);            response.setBody(\"Error: \" + e.getMessage());        }        return response;    }    private String createAuthToken() {        // Create RDS Data Service client        RdsDataClient rdsDataClient = RdsDataClient.builder()                .region(Region.of(System.getenv(\"AWS_REGION\")))                .credentialsProvider(DefaultCredentialsProvider.create())                .build();        // Define authentication request        ExecuteStatementRequest request = ExecuteStatementRequest.builder()                .resourceArn(System.getenv(\"ProxyHostName\"))                .secretArn(System.getenv(\"DBUserName\"))                .database(System.getenv(\"DBName\"))                .sql(\"SELECT 'RDS IAM Authentication'\")                .build();        // Execute request and obtain authentication token        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);        Field tokenField = response.records().get(0).get(0);        return tokenField.stringValue();    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0/* Node.js code here.*/// ES6+ exampleimport { Signer } from \"@aws-sdk/rds-signer\";import mysql from 'mysql2/promise';async function createAuthToken() {  // Define connection authentication parameters  const dbinfo = {    hostname: process.env.ProxyHostName,    port: process.env.Port,    username: process.env.DBUserName,    region: process.env.AWS_REGION,  }  // Create RDS Signer object  const signer = new Signer(dbinfo);  // Request authorization token from RDS, specifying the username  const token = await signer.getAuthToken();  return token;}async function dbOps() {  // Obtain auth token  const token = await createAuthToken();  // Define connection configuration  let connectionConfig = {    host: process.env.ProxyHostName,    user: process.env.DBUserName,    password: token,    database: process.env.DBName,    ssl: 'Amazon RDS'  }  // Create the connection to the DB  const conn = await mysql.createConnection(connectionConfig);  // Obtain the result of the query  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);  return res;}export const handler = async (event) => {  // Execute database flow  const result = await dbOps();  // Return result  return {    statusCode: 200,    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)  }};Connecting to an Amazon RDS database in a Lambda function using TypeScript.import { Signer } from \"@aws-sdk/rds-signer\";import mysql from 'mysql2/promise';// RDS settings// Using '!' (non-null assertion operator) to tell the TypeScript compiler that the DB settings are not null or undefined,const proxy_host_name = process.env.PROXY_HOST_NAME!const port = parseInt(process.env.PORT!)const db_name = process.env.DB_NAME!const db_user_name = process.env.DB_USER_NAME!const aws_region = process.env.AWS_REGION!async function createAuthToken(): Promise<string> {    // Create RDS Signer object    const signer = new Signer({        hostname: proxy_host_name,        port: port,        region: aws_region,        username: db_user_name    });    // Request authorization token from RDS, specifying the username    const token = await signer.getAuthToken();    return token;}async function dbOps(): Promise<mysql.QueryResult | undefined> {    try {        // Obtain auth token        const token = await createAuthToken();        const conn = await mysql.createConnection({            host: proxy_host_name,            user: db_user_name,            password: token,            database: db_name,            ssl: 'Amazon RDS' // Ensure you have the CA bundle for SSL connection        });        const [rows, fields] = await conn.execute('SELECT ? + ? AS sum', [3, 2]);        console.log('result:', rows);        return rows;    }    catch (err) {        console.log(err);    }}export const lambdaHandler = async (event: any): Promise<{ statusCode: number; body: string }> => {    // Execute database flow    const result = await dbOps();    // Return error is result is undefined    if (result == undefined)        return {            statusCode: 500,            body: JSON.stringify(`Error with connection to DB host`)        }    // Return result    return {        statusCode: 200,        body: JSON.stringify(`The selected sum is: ${result[0].sum}`)    };};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using PHP.<?php# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;use Aws\\Rds\\AuthTokenGenerator;use Aws\\Credentials\\CredentialProvider;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    private function getAuthToken(): string {        // Define connection authentication parameters        $dbConnection = [            'hostname' => getenv('DB_HOSTNAME'),            'port' => getenv('DB_PORT'),            'username' => getenv('DB_USERNAME'),            'region' => getenv('AWS_REGION'),        ];        // Create RDS AuthTokenGenerator object        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());        // Request authorization token from RDS, specifying the username        return $generator->createToken(            $dbConnection['hostname'] . ':' . $dbConnection['port'],            $dbConnection['region'],            $dbConnection['username']        );    }    private function getQueryResults() {        // Obtain auth token        $token = $this->getAuthToken();        // Define connection configuration        $connectionConfig = [            'host' => getenv('DB_HOSTNAME'),            'user' => getenv('DB_USERNAME'),            'password' => $token,            'database' => getenv('DB_NAME'),        ];        // Create the connection to the DB        $conn = new PDO(            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",            $connectionConfig['user'],            $connectionConfig['password'],            [                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,            ]        );        // Obtain the result of the query        $stmt = $conn->prepare('SELECT ?+? AS sum');        $stmt->execute([3, 2]);        return $stmt->fetch(PDO::FETCH_ASSOC);    }    /**     * @param mixed $event     * @param Context $context     * @return array     */    public function handle(mixed $event, Context $context): array    {        $this->logger->info(\"Processing query\");        // Execute database flow        $result = $this->getQueryResults();        return [            'sum' => $result['sum']        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Python.import jsonimport osimport boto3import pymysql# RDS settingsproxy_host_name = os.environ['PROXY_HOST_NAME']port = int(os.environ['PORT'])db_name = os.environ['DB_NAME']db_user_name = os.environ['DB_USER_NAME']aws_region = os.environ['AWS_REGION']# Fetch RDS Auth Tokendef get_auth_token():    client = boto3.client('rds')    token = client.generate_db_auth_token(        DBHostname=proxy_host_name,        Port=port        DBUsername=db_user_name        Region=aws_region    )    return tokendef lambda_handler(event, context):    token = get_auth_token()    try:        connection = pymysql.connect(            host=proxy_host_name,            user=db_user_name,            password=token,            db=db_name,            port=port,            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection        )                with connection.cursor() as cursor:            cursor.execute('SELECT %s + %s AS sum', (3, 2))            result = cursor.fetchone()        return result            except Exception as e:        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs     RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Ruby.# Ruby code here.require 'aws-sdk-rds'require 'json'require 'mysql2'def lambda_handler(event:, context:)  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"  port = ENV['Port']           # 3306  user = ENV['DBUser']  region = ENV['DBRegion']     # 'us-east-1'  db_name = ENV['DBName']  credentials = Aws::Credentials.new(    ENV['AWS_ACCESS_KEY_ID'],    ENV['AWS_SECRET_ACCESS_KEY'],    ENV['AWS_SESSION_TOKEN']  )  rds_client = Aws::RDS::AuthTokenGenerator.new(    region: region,     credentials: credentials  )  token = rds_client.auth_token(    endpoint: endpoint+ ':' + port,    user_name: user,    region: region  )  begin    conn = Mysql2::Client.new(      host: endpoint,      username: user,      password: token,      port: port,      database: db_name,      sslca: '/var/task/global-bundle.pem',       sslverify: true,      enable_cleartext_plugin: true    )    a = 3    b = 2    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']    puts result    conn.close    {      statusCode: 200,      body: result.to_json    }  rescue => e    puts \"Database connection failed due to #{e}\"  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Rust.use aws_config::BehaviorVersion;use aws_credential_types::provider::ProvideCredentials;use aws_sigv4::{    http_request::{sign, SignableBody, SignableRequest, SigningSettings},    sign::v4,};use lambda_runtime::{run, service_fn, Error, LambdaEvent};use serde_json::{json, Value};use sqlx::postgres::PgConnectOptions;use std::env;use std::time::{Duration, SystemTime};const RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");async fn generate_rds_iam_token(    db_hostname: &str,    port: u16,    db_username: &str,) -> Result<String, Error> {    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;    let credentials = config        .credentials_provider()        .expect(\"no credentials provider found\")        .provide_credentials()        .await        .expect(\"unable to load credentials\");    let identity = credentials.into();    let region = config.region().unwrap().to_string();    let mut signing_settings = SigningSettings::default();    signing_settings.expires_in = Some(Duration::from_secs(900));    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;    let signing_params = v4::SigningParams::builder()        .identity(&identity)        .region(&region)        .name(\"rds-db\")        .time(SystemTime::now())        .settings(signing_settings)        .build()?;    let url = format!(        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",        db_hostname = db_hostname,        port = port,        db_user = db_username    );    let signable_request =        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))            .expect(\"signable request\");    let (signing_instructions, _signature) =        sign(signable_request, &signing_params.into())?.into_parts();    let mut url = url::Url::parse(&url).unwrap();    for (name, value) in signing_instructions.params() {        url.query_pairs_mut().append_pair(name, &value);    }    let response = url.to_string().split_off(\"https://\".len());    Ok(response)}#[tokio::main]async fn main() -> Result<(), Error> {    run(service_fn(handler)).await}async fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");    let db_port = env::var(\"DB_PORT\")        .expect(\"DB_PORT must be set\")        .parse::<u16>()        .expect(\"PORT must be a valid number\");    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;    let opts = PgConnectOptions::new()        .host(&db_host)        .port(db_port)        .username(&db_user_name)        .password(&token)        .database(&db_name)        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())        .ssl_mode(sqlx::postgres::PgSslMode::Require);    let pool = sqlx::postgres::PgPoolOptions::new()        .connect_with(opts)        .await?;    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")        .bind(3)        .bind(2)        .fetch_one(&pool)        .await?;    println!(\"Result: {:?}\", result);    Ok(json!({        \"statusCode\": 200,        \"content-type\": \"text/plain\",        \"body\": format!(\"The selected sum is: {result}\")    }))}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.SDK for Go V2 : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "SDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Go./*Golang v2 code here.*/package mainimport (\t\"context\"\t\"database/sql\"\t\"encoding/json\"\t\"fmt\"\t\"os\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\t_ \"github.com/go-sql-driver/mysql\")type MyEvent struct {\tName string `json:\"name\"`}func HandleRequest(event *MyEvent) (map[string]interface{}, error) {\tvar dbName string = os.Getenv(\"DatabaseName\")\tvar dbUser string = os.Getenv(\"DatabaseUser\")\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\tvar region string = os.Getenv(\"AWS_REGION\")\tcfg, err := config.LoadDefaultConfig(context.TODO())\tif err != nil {\t\tpanic(\"configuration error: \" + err.Error())\t}\tauthenticationToken, err := auth.BuildAuthToken(\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\tif err != nil {\t\tpanic(\"failed to create authentication token: \" + err.Error())\t}\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\t\tdbUser, authenticationToken, dbEndpoint, dbName,\t)\tdb, err := sql.Open(\"mysql\", dsn)\tif err != nil {\t\tpanic(err)\t}\tdefer db.Close()\tvar sum int\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\tif err != nil {\t\tpanic(err)\t}\ts := fmt.Sprint(sum)\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\tmessageBytes, err := json.Marshal(message)\tif err != nil {\t\treturn nil, err\t}\tmessageString := string(messageBytes)\treturn map[string]interface{}{\t\t\"statusCode\": 200,\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\t\t\"body\":       messageString,\t}, nil}func main() {\tlambda.Start(HandleRequest)}"
                        ]
                    },
                    {
                        "sub_header": "Processing event notifications from Amazon RDS",
                        "content": [
                            "You can use Lambda to process event notifications from an Amazon RDS database. Amazon RDS sends      notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function.      Amazon SNS wraps the message from Amazon RDS in its own event document and sends it to your function.",
                            "For more information about configuring an Amazon RDS database to send notifications, see      Using Amazon RDS      event notifications.    ",
                            "Example Amazon RDS message in an Amazon SNS event",
                            {
                                "code_example": "{\n        \"Records\": [\n          {\n            \"EventVersion\": \"1.0\",\n            \"EventSubscriptionArn\": \"arn:aws:sns:us-east-2:123456789012:rds-lambda:21be56ed-a058-49f5-8c98-aedd2564c486\",\n            \"EventSource\": \"aws:sns\",\n            \"Sns\": {\n              \"SignatureVersion\": \"1\",\n              \"Timestamp\": \"2023-01-02T12:45:07.000Z\",\n              \"Signature\": \"tcc6faL2yUC6dgZdmrwh1Y4cGa/ebXEkAi6RibDsvpi+tE/1+82j...65r==\",\n              \"SigningCertUrl\": \"https://sns.us-east-2.amazonaws.com/SimpleNotificationService-ac565b8b1a6c5d002d285f9598aa1d9b.pem\",\n              \"MessageId\": \"95df01b4-ee98-5cb9-9903-4c221d41eb5e\",\n              \"Message\": \"{\\\"Event Source\\\":\\\"db-instance\\\",\\\"Event Time\\\":\\\"2023-01-02 12:45:06.000\\\",\\\"Identifier Link\\\":\\\"https://console.aws.amazon.com/rds/home?region=eu-west-1#dbinstance:id=dbinstanceid\\\",\\\"Source ID\\\":\\\"dbinstanceid\\\",\\\"Event ID\\\":\\\"http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_Events.html#RDS-EVENT-0002\\\",\\\"Event Message\\\":\\\"Finished DB Instance backup\\\"}\",\n              \"MessageAttributes\": {},\n              \"Type\": \"Notification\",\n              \"UnsubscribeUrl\": \"https://sns.us-east-2.amazonaws.com/?Action=Unsubscribe&amp;SubscriptionArn=arn:aws:sns:us-east-2:123456789012:test-lambda:21be56ed-a058-49f5-8c98-aedd2564c486\",\n              \"TopicArn\":\"arn:aws:sns:us-east-2:123456789012:sns-lambda\",\n              \"Subject\": \"RDS Notification Message\"\n            }\n          }\n        ]\n      }"
                            }
                        ]
                    },
                    {
                        "sub_header": "Complete Lambda and Amazon RDS tutorial",
                        "content": [
                            "  1.          Using a Lambda function to access an Amazon RDS database –          From the Amazon RDS User Guide, learn how to use a Lambda function to write data to an Amazon RDS          database through an Amazon RDS Proxy. Your Lambda function will read records from an Amazon SQS          queue and write new items to a table in your database whenever a message is added."
                        ]
                    }
                ]
            },
            {
                "title": "S3",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-s3.html",
                "contents": [
                    {
                        "title": "Tutorial: Use an S3 trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html",
                        "sections": [
                            "In this tutorial, you use the console to create a Lambda function and configure a trigger for an Amazon Simple Storage Service (Amazon S3) bucket. Every time that you     add an object to your Amazon S3 bucket, your function runs and outputs the object type to Amazon CloudWatch Logs.",
                            "This tutorial demonstrates how to:",
                            "  1 : Create an Amazon S3 bucket.",
                            "  2 : Create a Lambda function that returns the object type of objects in an Amazon S3 bucket.",
                            "  3 : Configure a Lambda trigger that invokes your function when objects are uploaded to your bucket.",
                            "  4 : Test your function, first with a dummy event, and then using the trigger.",
                            "By completing these steps, you’ll learn how to configure a Lambda function to run whenever objects are added to or deleted from an     Amazon S3 bucket. You can complete this tutorial using only the AWS Management Console.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide."
                                ]
                            },
                            {
                                "sub_header": "Create an Amazon S3 bucket",
                                "content": [
                                    "To create an Amazon S3 bucket",
                                    "  1 : Open the Amazon S3 console and select the Buckets page.",
                                    "  2 : Choose Create bucket.",
                                    "  3 : Under General configuration, do the following:For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules.               Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-).For AWS Region, choose a Region. Later in the tutorial, you must create your Lambda function in the same Region.",
                                    "  4 : Leave all other options set to their default values and choose Create bucket."
                                ]
                            },
                            {
                                "sub_header": "Upload a test object to your bucket",
                                "content": [
                                    "To upload a test object",
                                    "  1 : Open the Buckets page of the Amazon S3 console and choose the bucket you created during the           previous step.",
                                    "  2 : Choose Upload.",
                                    "  3 : Choose Add files and select the object that you want to upload. You can select any file (for example, HappyFace.jpg).",
                                    "  4 : Choose Open, then choose Upload.",
                                    "Later in the tutorial, you’ll test your Lambda function using this object."
                                ]
                            },
                            {
                                "sub_header": "Create a permissions policy",
                                "content": [
                                    "Create a permissions policy that allows Lambda to get objects from an Amazon S3 bucket and to write to Amazon CloudWatch Logs. ",
                                    "To create the policy",
                                    "  1 : Open the Policies page of the IAM console.",
                                    "  2 : Choose Create Policy.",
                                    " 3 : Choose the JSON tab, and then paste the following custom policy into the JSON          editor. ",
                                    {
                                        "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:PutLogEvents\",\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        }\n    ]\n}"
                                    },
                                    "  4 : Choose Next: Tags.",
                                    "  5 : Choose Next: Review.",
                                    "  6 : Under Review policy, for the policy Name, enter          s3-trigger-tutorial.",
                                    "  7 : Choose Create policy."
                                ]
                            },
                            {
                                "sub_header": "Create an execution role",
                                "content": [
                                    "An execution role is an AWS Identity and Access Management (IAM) role that grants a Lambda function permission to access AWS services and resources. In this step, create an execution role using the permissions policy that you created in the previous step.",
                                    "To create an execution role and attach your custom permissions policy",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : For the type of trusted entity, choose AWS service, then for the use case, choose Lambda.",
                                    "  4 : Choose Next.",
                                    "  5 : In the policy search box, enter s3-trigger-tutorial.",
                                    "  6 : In the search results, select the policy that you created (s3-trigger-tutorial), and          then choose Next.",
                                    "  7 : Under Role details, for the Role name, enter          lambda-s3-trigger-role, then choose Create role."
                                ]
                            },
                            {
                                "sub_header": "Create the Lambda function",
                                "content": [
                                    "Create a Lambda function in the console using the Python 3.12 runtime.",
                                    "To create the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Make sure you're working in the same AWS Region you created your Amazon S3 bucket in. You can change your Region using the drop-down list         at the top of the screen.",
                                    "  3 : Choose Create function.",
                                    "  4 : Choose Author from scratch",
                                    "  5 : Under Basic information, do the following:For Function name, enter s3-trigger-tutorialFor Runtime, choose Python 3.12.For Architecture, choose x86_64.",
                                    "  6 : In the Change default execution role tab, do the following:Expand the tab, then choose Use an existing role.Select the lambda-s3-trigger-role you created earlier.",
                                    "  7 : Choose Create function."
                                ]
                            },
                            {
                                "sub_header": "Deploy the function code",
                                "content": [
                                    "This tutorial uses the Python 3.12 runtime, but we’ve also provided example code files for other runtimes. You can select the       tab in the following box to see the code for the runtime you’re interested in.",
                                    "The Lambda function retrieves the key name of the uploaded object and the name of the bucket from the event parameter it receives       from Amazon S3. The function then uses the get_object  method from the AWS SDK for Python (Boto3) to retrieve the object's metadata, including the content type (MIME type) of the uploaded object.",
                                    "To deploy the function code",
                                    " 1 : Choose the Python tab in the following box and copy the code..NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using .NET. GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"log\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/s3\")func handler(ctx context.Context, s3Event events.S3Event) error {\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Printf(\"failed to load default config: %s\", err)\t\treturn err\t}\ts3Client := s3.NewFromConfig(sdkConfig)\tfor _, record := range s3Event.Records {\t\tbucket := record.S3.Bucket.Name\t\tkey := record.S3.Object.URLDecodedKey\t\theadOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{\t\t\tBucket: &bucket,\t\t\tKey:    &key,\t\t})\t\tif err != nil {\t\t\tlog.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err)\t\t\treturn err\t\t}\t\tlog.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key, *headOutput.ContentType)\t}\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import software.amazon.awssdk.services.s3.model.HeadObjectRequest;import software.amazon.awssdk.services.s3.model.HeadObjectResponse;import software.amazon.awssdk.services.s3.S3Client;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.S3Event;import com.amazonaws.services.lambda.runtime.events.models.s3.S3EventNotification.S3EventNotificationRecord;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Handler implements RequestHandler<S3Event, String> {    private static final Logger logger = LoggerFactory.getLogger(Handler.class);    @Override    public String handleRequest(S3Event s3event, Context context) {        try {          S3EventNotificationRecord record = s3event.getRecords().get(0);          String srcBucket = record.getS3().getBucket().getName();          String srcKey = record.getS3().getObject().getUrlDecodedKey();          S3Client s3Client = S3Client.builder().build();          HeadObjectResponse headObject = getHeadObject(s3Client, srcBucket, srcKey);          logger.info(\"Successfully retrieved \" + srcBucket + \"/\" + srcKey + \" of type \" + headObject.contentType());          return \"Ok\";        } catch (Exception e) {          throw new RuntimeException(e);        }    }    private HeadObjectResponse getHeadObject(S3Client s3Client, String bucket, String key) {        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()                .bucket(bucket)                .key(key)                .build();        return s3Client.headObject(headObjectRequest);    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using JavaScript.import { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";const client = new S3Client();export const handler = async (event, context) => {    // Get the object from the event and show its content type    const bucket = event.Records[0].s3.bucket.name;    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));    try {        const { ContentType } = await client.send(new HeadObjectCommand({            Bucket: bucket,            Key: key,        }));        console.log('CONTENT TYPE:', ContentType);        return ContentType;    } catch (err) {        console.log(err);        const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;        console.log(message);        throw new Error(message);    }};Consuming an S3 event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { S3Event } from 'aws-lambda';import { S3Client, HeadObjectCommand } from '@aws-sdk/client-s3';const s3 = new S3Client({ region: process.env.AWS_REGION });export const handler = async (event: S3Event): Promise<string | undefined> => {  // Get the object from the event and show its content type  const bucket = event.Records[0].s3.bucket.name;  const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));  const params = {    Bucket: bucket,    Key: key,  };  try {    const { ContentType } = await s3.send(new HeadObjectCommand(params));    console.log('CONTENT TYPE:', ContentType);    return ContentType;  } catch (err) {    console.log(err);    const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;    console.log(message);    throw new Error(message);  }};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using PHP.<?phpuse Bref\\Context\\Context;use Bref\\Event\\S3\\S3Event;use Bref\\Event\\S3\\S3Handler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends S3Handler {    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }        public function handleS3(S3Event $event, Context $context) : void    {        $this->logger->info(\"Processing S3 records\");        // Get the object from the event and show its content type        $records = $event->getRecords();                foreach ($records as $record)         {            $bucket = $record->getBucket()->getName();            $key = urldecode($record->getObject()->getKey());            try {                $fileSize = urldecode($record->getObject()->getSize());                echo \"File Size: \" . $fileSize . \"\\n\";                // TODO: Implement your custom processing logic here            } catch (Exception $e) {                echo $e->getMessage() . \"\\n\";                echo 'Error getting object ' . $key . ' from bucket ' . $bucket . '. Make sure they exist and your bucket is in the same region as this function.' . \"\\n\";                throw $e;            }        }    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0import jsonimport urllib.parseimport boto3print('Loading function')s3 = boto3.client('s3')def lambda_handler(event, context):    #print(\"Received event: \" + json.dumps(event, indent=2))    # Get the object from the event and show its content type    bucket = event['Records'][0]['s3']['bucket']['name']    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')    try:        response = s3.get_object(Bucket=bucket, Key=key)        print(\"CONTENT TYPE: \" + response['ContentType'])        return response['ContentType']    except Exception as e:        print(e)        print('Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))        raise e              RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Ruby.require 'json'require 'uri'require 'aws-sdk'puts 'Loading function'def lambda_handler(event:, context:)  s3 = Aws::S3::Client.new(region: 'region') # Your AWS region  # puts \"Received event: #{JSON.dump(event)}\"  # Get the object from the event and show its content type  bucket = event['Records'][0]['s3']['bucket']['name']  key = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'], Encoding::UTF_8)  begin    response = s3.get_object(bucket: bucket, key: key)    puts \"CONTENT TYPE: #{response.content_type}\"    return response.content_type  rescue StandardError => e    puts e.message    puts \"Error getting object #{key} from bucket #{bucket}. Make sure they exist and your bucket is in the same region as this function.\"    raise e  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::s3::S3Event;use aws_sdk_s3::{Client};use lambda_runtime::{run, service_fn, Error, LambdaEvent};/// Main function#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        .with_target(false)        .without_time()        .init();    // Initialize the AWS SDK for Rust    let config = aws_config::load_from_env().await;    let s3_client = Client::new(&config);    let res = run(service_fn(|request: LambdaEvent<S3Event>| {        function_handler(&s3_client, request)    })).await;    res}async fn function_handler(    s3_client: &Client,    evt: LambdaEvent<S3Event>) -> Result<(), Error> {    tracing::info!(records = ?evt.payload.records.len(), \"Received request from SQS\");    if evt.payload.records.len() == 0 {        tracing::info!(\"Empty S3 event received\");    }    let bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket name to exist\");    let key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to exist\");    tracing::info!(\"Request is for {} and object {}\", bucket, key);    let s3_get_object_result = s3_client        .get_object()        .bucket(bucket)        .key(key)        .send()        .await;    match s3_get_object_result {        Ok(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult contains a 'body' property of type ByteStream\"),        Err(_) => tracing::info!(\"Failure with S3 Get Object request\")    }    Ok(())}anchoranchoranchoranchoranchoranchoranchoranchor.NETGoJavaJavaScriptPHPPythonRubyRustAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using .NET. ",
                                    {
                                        "code_example": "// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nusing Amazon.Lambda.S3Events;\nusing System.Web;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace S3Integration\n{\n    public class Function\n    {\n        private static AmazonS3Client _s3Client;\n        public Function() : this(null)\n        {\n        }\n\n        internal Function(AmazonS3Client s3Client)\n        {\n            _s3Client = s3Client ?? new AmazonS3Client();\n        }\n\n        public async Task<string> Handler(S3Event evt, ILambdaContext context)\n        {\n            try\n            {\n                if (evt.Records.Count <= 0)\n                {\n                    context.Logger.LogLine(\"Empty S3 Event received\");\n                    return string.Empty;\n                }\n\n                var bucket = evt.Records[0].S3.Bucket.Name;\n                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);\n\n                context.Logger.LogLine($\"Request is for {bucket} and {key}\");\n\n                var objectResult = await _s3Client.GetObjectAsync(bucket, key);\n\n                context.Logger.LogLine($\"Returning {objectResult.Key}\");\n\n                return objectResult.Key;\n            }\n            catch (Exception e)\n            {\n                context.Logger.LogLine($\"Error processing request - {e.Message}\");\n\n                return string.Empty;\n            }\n        }\n    }\n}\n"
                                    },
                                    "  2 : In the Code source pane on the Lambda console, paste the code into the code editor, replacing the code that           Lambda created.",
                                    "  3 : In the DEPLOY section, choose Deploy to update your function's code:"
                                ]
                            },
                            {
                                "sub_header": "Create the Amazon S3 trigger",
                                "content": [
                                    "To create the Amazon S3 trigger",
                                    "  1 : In the Function overview pane, choose Add trigger.",
                                    "  2 : Select S3.",
                                    "  3 : Under Bucket, select the bucket you created earlier in the tutorial.",
                                    "  4 : Under Event types, be sure that All object create events is selected.",
                                    "  5 : Under Recursive invocation, select the check box to acknowledge that using the same Amazon S3 bucket for input and           output is not recommended.",
                                    "  6 : Choose Add.",
                                    "Note",
                                    "When you create an Amazon S3 trigger for a Lambda function using the Lambda console, Amazon S3 configures an event notification         on the bucket you specify. Before configuring this event notification, Amazon S3 performs a series of checks to confirm that the event destination exists         and has the required IAM policies. Amazon S3 also performs these tests on any other event notifications configured for that bucket.",
                                    "Because of this check, if the bucket has previously configured event destinations for resources that no longer exist, or for resources that don't have         the required permissions policies, Amazon S3 won't be able to create the new event notification. You'll see the following error message indicating that your trigger         couldn't be created:",
                                    {
                                        "code_example": "An error occurred when creating the trigger: Unable to validate the following destination configurations."
                                    },
                                    "You can see this error if you previously configured a trigger for another Lambda function using the same bucket, and you have since           deleted the function or modified its permissions policies."
                                ]
                            },
                            {
                                "sub_header": "Test your Lambda function with a dummy event",
                                "content": [
                                    "To test the Lambda function with a dummy event",
                                    "  1 : In the Lambda console page for your function, choose the Test tab.",
                                    "  2 : For Event name, enter MyTestEvent.",
                                    " 3 : In the Event JSON, paste the following test event. Be sure to replace these values:Replace us-east-1 with the region you created your Amazon S3 bucket in.Replace both instances of amzn-s3-demo-bucket with the name of your own Amazon S3 bucket.Replace test%2FKey with the name of the test object you uploaded to your bucket earlier (for example,               HappyFace.jpg). ",
                                    {
                                        "code_example": "{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.0\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-1\",\n      \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"userIdentity\": {\n        \"principalId\": \"EXAMPLE\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"127.0.0.1\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"EXAMPLE123456789\",\n        \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"testConfigRule\",\n        \"bucket\": {\n          \"name\": \"amzn-s3-demo-bucket\",\n          \"ownerIdentity\": {\n            \"principalId\": \"EXAMPLE\"\n          },\n          \"arn\": \"arn:aws:s3:::amzn-s3-demo-bucket\"\n        },\n        \"object\": {\n          \"key\": \"test%2Fkey\",\n          \"size\": 1024,\n          \"eTag\": \"0123456789abcdef0123456789abcdef\",\n          \"sequencer\": \"0A1B2C3D4E5F678901\"\n        }\n      }\n    }\n  ]\n}"
                                    },
                                    "  4 : Choose Save.",
                                    "  5 : Choose Test.",
                                    " 6 : If your function runs successfully, you’ll see output similar to the following in the Execution results tab. ",
                                    {
                                        "code_example": "Response\n\"image/jpeg\"\n\nFunction Logs\nSTART RequestId: 12b3cae7-5f4e-415e-93e6-416b8f8b66e6 Version: $LATEST\n2021-02-18T21:40:59.280Z    12b3cae7-5f4e-415e-93e6-416b8f8b66e6    INFO    INPUT BUCKET AND KEY:  { Bucket: 'amzn-s3-demo-bucket', Key: 'HappyFace.jpg' }\n2021-02-18T21:41:00.215Z    12b3cae7-5f4e-415e-93e6-416b8f8b66e6    INFO    CONTENT TYPE: image/jpeg\nEND RequestId: 12b3cae7-5f4e-415e-93e6-416b8f8b66e6\nREPORT RequestId: 12b3cae7-5f4e-415e-93e6-416b8f8b66e6    Duration: 976.25 ms    Billed Duration: 977 ms    Memory Size: 128 MB    Max Memory Used: 90 MB    Init Duration: 430.47 ms        \n\nRequest ID\n12b3cae7-5f4e-415e-93e6-416b8f8b66e6"
                                    },
                                    {
                                        "sub_header": "Test the Lambda function with the Amazon S3 trigger",
                                        "content": [
                                            "To test your function with the configured trigger, upload an object to your Amazon S3 bucket using the console. To verify that your Lambda         function ran as expected, use CloudWatch Logs to view your function’s output.",
                                            "To upload an object to your Amazon S3 bucket",
                                            "  1 : Open the Buckets page of the Amazon S3 console and choose the bucket that you created earlier.",
                                            "  2 : Choose Upload.",
                                            "  3 : Choose Add files and use the file selector to choose an object you want to upload. This object can be any file             you choose.",
                                            "  4 : Choose Open, then choose Upload.",
                                            "To verify the function invocation using CloudWatch Logs",
                                            "  1 : Open the CloudWatch console.",
                                            "  2 : Make sure you're working in the same AWS Region you created your Lambda function in. You can change your Region using the drop-down             list at the top of the screen.",
                                            "  3 : Choose Logs, then choose Log groups.",
                                            "  4 : Choose the log group for your function (/aws/lambda/s3-trigger-tutorial).",
                                            "  5 : Under Log streams, choose the most recent log stream.",
                                            " 6 : If your function was invoked correctly in response to your Amazon S3 trigger, you’ll see output similar to the following. The           CONTENT TYPE you see depends on the type of file you uploaded to your bucket. ",
                                            {
                                                "code_example": "2022-05-09T23:17:28.702Z\t0cae7f5a-b0af-4c73-8563-a3430333cc10\tINFO\tCONTENT TYPE: image/jpeg\n"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the S3 bucket",
                                    "  1 : Open the Amazon S3 console.",
                                    "  2 : Select the bucket you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the bucket in the text input field.",
                                    "  5 : Choose Delete bucket."
                                ]
                            },
                            {
                                "sub_header": "Next steps",
                                "content": [
                                    "In Tutorial: Using an Amazon S3 trigger to create thumbnail images, the Amazon S3 trigger invokes a function that creates a thumbnail image for each image file that is uploaded to a      bucket. This tutorial requires a moderate level of AWS and Lambda domain knowledge. It demonstrates how to create resources using the AWS Command Line Interface (AWS CLI) and how to create a .zip file archive deployment package for the function and its dependencies."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Tutorial: Use an Amazon S3 trigger to create thumbnails",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-s3-tutorial.html",
                        "sections": [
                            "In this tutorial, you create and configure a Lambda function that resizes images added to an Amazon Simple Storage Service (Amazon S3) bucket. When you add an image     file to your bucket, Amazon S3 invokes your Lambda function. The function then creates a thumbnail version of the image and outputs it to a different     Amazon S3 bucket.",
                            "To complete this tutorial, you carry out the following steps:",
                            "  1 : Create source and destination Amazon S3 buckets and upload a sample image.",
                            "  2 : Create a Lambda function that resizes an image and outputs a thumbnail to an Amazon S3 bucket.",
                            "  3 : Configure a Lambda trigger that invokes your function when objects are uploaded to your source bucket.",
                            "  4 : Test your function, first with a dummy event, and then by uploading an image to your source bucket.",
                            "By completing these steps, you’ll learn how to use Lambda to carry out a file processing task on objects added to an Amazon S3 bucket. You can     complete this tutorial using the AWS Command Line Interface (AWS CLI) or the AWS Management Console.",
                            "If you're looking for a simpler example to learn how to configure an Amazon S3 trigger for Lambda, you can try Tutorial: Using an Amazon S3 trigger to invoke a Lambda function.",
                            "Topics",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "If you want to use the AWS CLI to complete the tutorial, install the latest version of the AWS Command Line Interface.",
                                    "For your Lambda function code, you can use Python or Node.js. Install the language support tools and a package manager for the       language that you want to use. "
                                ]
                            },
                            {
                                "sub_header": "Create two Amazon S3 buckets",
                                "content": [
                                    "First create two Amazon S3 buckets. The first bucket is the source bucket you will upload your images to. The second bucket is used by     Lambda to save the resized thumbnail when you invoke your function.",
                                    "  1.AWS Management Console : amzn-s3-demo-source-bucket-resized",
                                    "  2.AWS CLI : region",
                                    "AWS Management ConsoleTo create the Amazon S3 buckets (console)Open the Buckets page of the Amazon S3 console.Choose Create bucket.Under General configuration, do the following:For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules.                     Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-). For AWS Region, choose the AWS Region                     closest to your geographical location. Later in the tutorial, you must create your Lambda function in the same AWS Region, so                     make a note of the region you chose.Leave all other options set to their default values and choose Create bucket.Repeat steps 1 to 4 to create your destination bucket. For Bucket name, enter amzn-s3-demo-source-bucket-resized,                 where amzn-s3-demo-source-bucket is the name of the source bucket you just created.AWS CLITo create the Amazon S3 buckets (AWS CLI)Run the following CLI command to create your source bucket. The name you choose for your bucket must be globally unique and                 follow the Amazon S3 Bucket naming rules.                 Names can only contain lower case letters, numbers, dots (.), and hyphens (-). For region and LocationConstraint,                 choose the AWS Region closest to your geographical                 location.aws s3api create-bucket --bucket amzn-s3-demo-source-bucket --region us-east-1 \\--create-bucket-configuration LocationConstraint=us-east-1Later in the tutorial, you must create your Lambda function in the same AWS Region as your source bucket, so make a note of the                 region you chose.Run the following command to create your destination bucket. For the bucket name, you must use amzn-s3-demo-source-bucket-resized,                 where amzn-s3-demo-source-bucket is the name of the source bucket you created in step 1. For region                 and LocationConstraint, choose the same AWS Region you used to create your source bucket.aws s3api create-bucket --bucket amzn-s3-demo-source-bucket-resized --region us-east-1 \\--create-bucket-configuration LocationConstraint=us-east-1",
                                    "anchor",
                                    "anchor",
                                    "To create the Amazon S3 buckets (console)",
                                    "  1 : Open the Buckets page of the Amazon S3 console.",
                                    "  2 : Choose Create bucket.",
                                    "  3 : Under General configuration, do the following:For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules.                     Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-). For AWS Region, choose the AWS Region                     closest to your geographical location. Later in the tutorial, you must create your Lambda function in the same AWS Region, so                     make a note of the region you chose.",
                                    "  4 : Leave all other options set to their default values and choose Create bucket.",
                                    "  5 : Repeat steps 1 to 4 to create your destination bucket. For Bucket name, enter amzn-s3-demo-source-bucket-resized,                 where amzn-s3-demo-source-bucket is the name of the source bucket you just created."
                                ]
                            },
                            {
                                "sub_header": "Upload a test image to your source bucket",
                                "content": [
                                    "Later in the tutorial, you’ll test your Lambda function by invoking it using the AWS CLI or the Lambda console. To confirm that your function       is operating correctly, your source bucket needs to contain a test image. This image can be any JPG or PNG file you choose.",
                                    "  1.AWS Management Console : \nTo upload a test image to your source bucket (console)\nOpen the Buckets page of the Amazon S3 console.\n\nSelect the source bucket you created in the previous step.\n\nChoose Upload.\n\nChoose Add files and use the file selector to choose the object you want to upload.\n\nChoose Open, then choose Upload.\n\n",
                                    "  2.AWS CLI : --bucket",
                                    "AWS Management ConsoleTo upload a test image to your source bucket (console)Open the Buckets page of the Amazon S3 console.Select the source bucket you created in the previous step.Choose Upload.Choose Add files and use the file selector to choose the object you want to upload.Choose Open, then choose Upload.AWS CLITo upload a test image to your source bucket (AWS CLI)From the directory containing the image you want to upload, run the following CLI command. Replace the --bucket                 parameter with the name of your source bucket. For the --key and --body parameters, use the filename of                 your test image.aws s3api put-object --bucket amzn-s3-demo-source-bucket --key HappyFace.jpg --body ./HappyFace.jpg",
                                    "anchor",
                                    "anchor",
                                    "To upload a test image to your source bucket (console)",
                                    "  1 : Open the Buckets page of the Amazon S3 console.",
                                    "  2 : Select the source bucket you created in the previous step.",
                                    "  3 : Choose Upload.",
                                    "  4 : Choose Add files and use the file selector to choose the object you want to upload.",
                                    "  5 : Choose Open, then choose Upload."
                                ]
                            },
                            {
                                "sub_header": "Create a permissions policy",
                                "content": [
                                    "The first step in creating your Lambda function is to create a permissions policy. This policy gives your function the permissions it needs       to access other AWS resources. For this tutorial, the policy gives Lambda read and write permissions for Amazon S3 buckets and allows it to write       to Amazon CloudWatch Logs.",
                                    "  1.AWS Management Console : {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:PutLogEvents\",\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        }\n    ]\n}",
                                    "  2.AWS CLI : policy.json",
                                    "AWS Management ConsoleTo create the policy (console)Open the Policies page of the AWS Identity and Access Management (IAM) console.Choose Create policy.Choose the JSON tab, and then paste the following custom policy into the JSON editor.{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"logs:PutLogEvents\",                \"logs:CreateLogGroup\",                \"logs:CreateLogStream\"            ],            \"Resource\": \"arn:aws:logs:*:*:*\"        },        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:GetObject\"            ],            \"Resource\": \"arn:aws:s3:::*/*\"        },        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\"            ],            \"Resource\": \"arn:aws:s3:::*/*\"        }    ]}Choose Next.Under Policy details, for Policy name, enter LambdaS3Policy.Choose Create policy.AWS CLITo create the policy (AWS CLI)Save the following JSON in a file named policy.json.{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"logs:PutLogEvents\",                \"logs:CreateLogGroup\",                \"logs:CreateLogStream\"            ],            \"Resource\": \"arn:aws:logs:*:*:*\"        },        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:GetObject\"            ],            \"Resource\": \"arn:aws:s3:::*/*\"        },        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:PutObject\"            ],            \"Resource\": \"arn:aws:s3:::*/*\"        }    ]}From the directory you saved the JSON policy document in, run the following CLI command.aws iam create-policy --policy-name LambdaS3Policy --policy-document file://policy.json",
                                    "anchor",
                                    "anchor",
                                    "To create the policy (console)",
                                    "  1 : Open the Policies page of the AWS Identity and Access Management (IAM) console.",
                                    "  2 : Choose Create policy.",
                                    " 3 : Choose the JSON tab, and then paste the following custom policy into the JSON editor. ",
                                    {
                                        "code_example": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:PutLogEvents\",\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        }\n    ]\n}"
                                    },
                                    "  4 : Choose Next.",
                                    "  5 : Under Policy details, for Policy name, enter LambdaS3Policy.",
                                    "  6 : Choose Create policy."
                                ]
                            },
                            {
                                "sub_header": "Create an execution role",
                                "content": [
                                    "An execution role is an IAM role that grants a Lambda function permission to access AWS services and resources. To give your function       read and write access to an Amazon S3 bucket, you attach the permissions policy you created in the previous step.",
                                    "  1.AWS Management Console : LambdaS3Policy",
                                    "  2.AWS CLI : trust-policy.json",
                                    "AWS Management ConsoleTo create an execution role and attach your permissions policy (console)Open the Roles page of the (IAM) console.Choose Create role.For Trusted entity type, select AWS service, and for Use case,              select Lambda.Choose Next.Add the permissions policy you created in the previous step by doing the following:In the policy search box, enter LambdaS3Policy.In the search results, select the check box for LambdaS3Policy.Choose Next.Under Role details, for the Role name enter LambdaS3Role.Choose Create role.AWS CLITo create an execution role and attach your permissions policy (AWS CLI)Save the following JSON in a file named trust-policy.json. This trust policy allows Lambda to use the role’s                permissions by giving the service principal lambda.amazonaws.com permission to call the AWS Security Token Service (AWS STS) AssumeRole                action.{  \"Version\": \"2012-10-17\",  \"Statement\": [    {      \"Effect\": \"Allow\",      \"Principal\": {        \"Service\": \"lambda.amazonaws.com\"      },      \"Action\": \"sts:AssumeRole\"    }  ]}From the directory you saved the JSON trust policy document in, run the following CLI command to create the execution role.aws iam create-role --role-name LambdaS3Role --assume-role-policy-document file://trust-policy.jsonTo attach the permissions policy you created in the previous step, run the following CLI command. Replace the AWS account number                in the policy’s ARN with your own account number.aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::123456789012:policy/LambdaS3Policy",
                                    "anchor",
                                    "anchor",
                                    "To create an execution role and attach your permissions policy (console)",
                                    "  1 : Open the Roles page of the (IAM) console.",
                                    "  2 : Choose Create role.",
                                    "  3 : For Trusted entity type, select AWS service, and for Use case,              select Lambda.",
                                    "  4 : Choose Next.",
                                    "  5 : Add the permissions policy you created in the previous step by doing the following:In the policy search box, enter LambdaS3Policy.In the search results, select the check box for LambdaS3Policy.Choose Next.",
                                    "  6 : Under Role details, for the Role name enter LambdaS3Role.",
                                    "  7 : Choose Create role."
                                ]
                            },
                            {
                                "sub_header": "Create the function deployment package",
                                "content": [
                                    "To create your function, you create a deployment package containing your function code and its dependencies. For this       CreateThumbnail function, your function code uses a separate library for the image resizing. Follow the instructions for your       chosen language to create a deployment package containing the required library.",
                                    "  1.Node.js : lambda-s3",
                                    "  2.Python : lambda_function.py",
                                    "Node.jsTo create the deployment package (Node.js)Create a directory named lambda-s3 for your function code and dependencies and navigate into it.mkdir lambda-s3cd lambda-s3Create a new Node.js project with npm. To accept the default options provided in the interactive experience, press Enter.npm initSave the following function code in a file named index.mjs. Make sure to replace us-east-1 with the               AWS Region in which you created your own source and destination buckets.// dependenciesimport { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';import { Readable } from 'stream';import sharp from 'sharp';import util from 'util';// create S3 clientconst s3 = new S3Client({region: 'us-east-1'});// define the handler functionexport const handler = async (event, context) => {// Read options from the event parameter and get the source bucketconsole.log(\"Reading options from event:\\n\", util.inspect(event, {depth: 5}));  const srcBucket = event.Records[0].s3.bucket.name;  // Object key may have spaces or unicode non-ASCII charactersconst srcKey    = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, \" \"));const dstBucket = srcBucket + \"-resized\";const dstKey    = \"resized-\" + srcKey;// Infer the image type from the file suffixconst typeMatch = srcKey.match(/\\.([^.]*)$/);if (!typeMatch) {  console.log(\"Could not determine the image type.\");  return;}// Check that the image type is supportedconst imageType = typeMatch[1].toLowerCase();if (imageType != \"jpg\" && imageType != \"png\") {  console.log(`Unsupported image type: ${imageType}`);  return;}// Get the image from the source bucket. GetObjectCommand returns a stream.try {  const params = {    Bucket: srcBucket,    Key: srcKey  };  var response = await s3.send(new GetObjectCommand(params));  var stream = response.Body;  // Convert stream to buffer to pass to sharp resize function.  if (stream instanceof Readable) {    var content_buffer = Buffer.concat(await stream.toArray());      } else {    throw new Error('Unknown object stream type');  }} catch (error) {  console.log(error);  return;}  // set thumbnail width. Resize will set the height automatically to maintain aspect ratio.const width  = 200;// Use the sharp module to resize the image and save in a buffer.try {      var output_buffer = await sharp(content_buffer).resize(width).toBuffer();} catch (error) {  console.log(error);  return;}// Upload the thumbnail image to the destination buckettry {  const destparams = {    Bucket: dstBucket,    Key: dstKey,    Body: output_buffer,    ContentType: \"image\"  };  const putResult = await s3.send(new PutObjectCommand(destparams));  } catch (error) {    console.log(error);    return;  }  console.log('Successfully resized ' + srcBucket + '/' + srcKey +    ' and uploaded to ' + dstBucket + '/' + dstKey);  };In your lambda-s3 directory, install the sharp library using npm. Note that the latest version of sharp (0.33) isn't               compatible with Lambda. Install version 0.32.6 to complete this tutorial.npm install sharp@0.32.6The npm install command creates a node_modules directory for your modules. After this step, your                 directory structure should look like the following.lambda-s3|- index.mjs|- node_modules|  |- base64js|  |- bl|  |- buffer...|- package-lock.json|- package.jsonCreate a .zip deployment package containing your function code and its dependencies. In MacOS and Linux, run the following                 command.zip -r function.zip .In Windows, use your preferred zip utility to create a .zip file. Ensure that your index.mjs,                 package.json, and package-lock.json files and your node_modules directory are all at the root                 of your .zip file.PythonTo create the deployment package (Python)Save the example code as a file named          lambda_function.py.import boto3import osimport sysimport uuidfrom urllib.parse import unquote_plusfrom PIL import Imageimport PIL.Image            s3_client = boto3.client('s3')            def resize_image(image_path, resized_path):  with Image.open(image_path) as image:    image.thumbnail(tuple(x / 2 for x in image.size))    image.save(resized_path)            def lambda_handler(event, context):  for record in event['Records']:    bucket = record['s3']['bucket']['name']    key = unquote_plus(record['s3']['object']['key'])    tmpkey = key.replace('/', '')    download_path = '/tmp/{}{}'.format(uuid.uuid4(), tmpkey)    upload_path = '/tmp/resized-{}'.format(tmpkey)    s3_client.download_file(bucket, key, download_path)    resize_image(download_path, upload_path)    s3_client.upload_file(upload_path, '{}-resized'.format(bucket), 'resized-{}'.format(key))In the same directory in which you created your lambda_function.py file, create a new directory named           package and install the Pillow (PIL) library and the           AWS SDK for Python (Boto3). Although the Lambda Python runtime includes a version of the Boto3 SDK, we recommend that you add all of your function's           dependencies to your deployment package, even if they are included in the runtime. For more information, see           Runtime dependencies in Python.mkdir packagepip install \\--platform manylinux2014_x86_64 \\--target=package \\--implementation cp \\--python-version 3.12 \\--only-binary=:all: --upgrade \\pillow boto3The Pillow library contains C/C++ code. By using the --platform manylinux_2014_x86_64 and --only-binary=:all:           options, pip will download and install a version of Pillow that contains pre-compiled binaries compatible with the Amazon Linux 2 operating           system. This ensures that your deployment package will work in the Lambda execution environment, regardless of the operating system and           architecture of your local build machine.Create a .zip file containing your application code and the Pillow and Boto3 libraries. In Linux or MacOS, run the following commands from your           command line interface.cd packagezip -r ../lambda_function.zip .cd ..zip lambda_function.zip lambda_function.py In Windows, use your preferred zip tool to create the lambda_function.zip file. Make sure that your         lambda_function.py file and the folders containing your dependencies are all at the root of the .zip file.You can also create your deployment package using a Python virtual environment. See Working with .zip file archives for Python Lambda functions",
                                    "anchor",
                                    "anchor",
                                    "To create the deployment package (Node.js)",
                                    " 1 : Create a directory named lambda-s3 for your function code and dependencies and navigate into it. ",
                                    {
                                        "code_example": "mkdir lambda-s3\ncd lambda-s3"
                                    },
                                    " 2 : Create a new Node.js project with npm. To accept the default options provided in the interactive experience, press Enter. ",
                                    {
                                        "code_example": "npm init"
                                    },
                                    " 3 : Save the following function code in a file named index.mjs. Make sure to replace us-east-1 with the               AWS Region in which you created your own source and destination buckets. ",
                                    {
                                        "code_example": "// dependencies\nimport { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';\n\nimport { Readable } from 'stream';\n\nimport sharp from 'sharp';\nimport util from 'util';\n\n\n// create S3 client\nconst s3 = new S3Client({region: 'us-east-1'});\n\n// define the handler function\nexport const handler = async (event, context) => {\n\n// Read options from the event parameter and get the source bucket\nconsole.log(\"Reading options from event:\\n\", util.inspect(event, {depth: 5}));\n  const srcBucket = event.Records[0].s3.bucket.name;\n  \n// Object key may have spaces or unicode non-ASCII characters\nconst srcKey    = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, \" \"));\nconst dstBucket = srcBucket + \"-resized\";\nconst dstKey    = \"resized-\" + srcKey;\n\n// Infer the image type from the file suffix\nconst typeMatch = srcKey.match(/\\.([^.]*)$/);\nif (!typeMatch) {\n  console.log(\"Could not determine the image type.\");\n  return;\n}\n\n// Check that the image type is supported\nconst imageType = typeMatch[1].toLowerCase();\nif (imageType != \"jpg\" && imageType != \"png\") {\n  console.log(`Unsupported image type: ${imageType}`);\n  return;\n}\n\n// Get the image from the source bucket. GetObjectCommand returns a stream.\ntry {\n  const params = {\n    Bucket: srcBucket,\n    Key: srcKey\n  };\n  var response = await s3.send(new GetObjectCommand(params));\n  var stream = response.Body;\n  \n// Convert stream to buffer to pass to sharp resize function.\n  if (stream instanceof Readable) {\n    var content_buffer = Buffer.concat(await stream.toArray());\n    \n  } else {\n    throw new Error('Unknown object stream type');\n  }\n\n\n} catch (error) {\n  console.log(error);\n  return;\n}\n\n  \n// set thumbnail width. Resize will set the height automatically to maintain aspect ratio.\nconst width  = 200;\n\n// Use the sharp module to resize the image and save in a buffer.\ntry {    \n  var output_buffer = await sharp(content_buffer).resize(width).toBuffer();\n\n} catch (error) {\n  console.log(error);\n  return;\n}\n\n// Upload the thumbnail image to the destination bucket\ntry {\n  const destparams = {\n    Bucket: dstBucket,\n    Key: dstKey,\n    Body: output_buffer,\n    ContentType: \"image\"\n  };\n\n  const putResult = await s3.send(new PutObjectCommand(destparams));\n\n  } catch (error) {\n    console.log(error);\n    return;\n  }\n\n  console.log('Successfully resized ' + srcBucket + '/' + srcKey +\n    ' and uploaded to ' + dstBucket + '/' + dstKey);\n  };"
                                    },
                                    " 4 : In your lambda-s3 directory, install the sharp library using npm. Note that the latest version of sharp (0.33) isn't               compatible with Lambda. Install version 0.32.6 to complete this tutorial. The npm install command creates a node_modules directory for your modules. After this step, your                 directory structure should look like the following.lambda-s3|- index.mjs|- node_modules|  |- base64js|  |- bl|  |- buffer...|- package-lock.json|- package.json",
                                    {
                                        "code_example": "npm install sharp@0.32.6"
                                    },
                                    " 5 : Create a .zip deployment package containing your function code and its dependencies. In MacOS and Linux, run the following                 command. In Windows, use your preferred zip utility to create a .zip file. Ensure that your index.mjs,                 package.json, and package-lock.json files and your node_modules directory are all at the root                 of your .zip file.",
                                    {
                                        "code_example": "zip -r function.zip ."
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create the Lambda function",
                                "content": [
                                    "You can create your Lambda function using either the AWS CLI or the Lambda console. Follow the instructions for your chosen language to create       the function.",
                                    "  1.AWS Management Console : CreateThumbnail",
                                    "  2.AWS CLI : role",
                                    "AWS Management ConsoleTo create the function (console)To create your Lambda function using the console, you first create a basic function containing some ‘Hello world’ code. You then           replace this code with your own function code by uploading the.zip or JAR file you created in the previous step.Open the Functions page of the Lambda console.Make sure you're working in the same AWS Region you created your Amazon S3 bucket in. You can change your region using the drop-down             list at the top of the screen.Choose Create function.Choose Author from scratch.Under Basic information, do the following:For Function name, enter CreateThumbnail.For Runtime, choose either Node.js 22.x or Python 3.12 according to the language you chose for your function.For Architecture, choose x86_64.In the Change default execution role tab, do the following:Expand the tab, then choose Use an existing role.Select the LambdaS3Role you created earlier.Choose Create function.To upload the function code (console)In the Code source pane, choose Upload from.Choose .zip file. Choose Upload.In the file selector, select your .zip file and choose Open.Choose Save.AWS CLITo create the function (AWS CLI)Run the CLI command for the language you chose. For the role parameter, make sure to replace 123456789012             with your own AWS account ID. For the region parameter, replace us-east-1 with the region you created your             Amazon S3 buckets in.For Node.js, run the following command from the directory containing your function.zip               file.aws lambda create-function --function-name CreateThumbnail \\--zip-file fileb://function.zip --handler index.handler --runtime nodejs22.x \\--timeout 10 --memory-size 1024 \\--role arn:aws:iam::123456789012:role/LambdaS3Role --region us-east-1For Python, run the following command from the directory containing your lambda_function.zip                 file.aws lambda create-function --function-name CreateThumbnail \\--zip-file fileb://lambda_function.zip --handler lambda_function.lambda_handler \\--runtime python3.13 --timeout 10 --memory-size 1024 \\--role arn:aws:iam::123456789012:role/LambdaS3Role --region us-east-1",
                                    "anchor",
                                    "anchor",
                                    "To create the function (console)",
                                    "To create your Lambda function using the console, you first create a basic function containing some ‘Hello world’ code. You then           replace this code with your own function code by uploading the.zip or JAR file you created in the previous step.",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Make sure you're working in the same AWS Region you created your Amazon S3 bucket in. You can change your region using the drop-down             list at the top of the screen.",
                                    "  3 : Choose Create function.",
                                    "  4 : Choose Author from scratch.",
                                    "  5 : Under Basic information, do the following:For Function name, enter CreateThumbnail.For Runtime, choose either Node.js 22.x or Python 3.12 according to the language you chose for your function.For Architecture, choose x86_64.",
                                    "  6 : In the Change default execution role tab, do the following:Expand the tab, then choose Use an existing role.Select the LambdaS3Role you created earlier.",
                                    "  7 : Choose Create function.",
                                    "To upload the function code (console)",
                                    "  1 : In the Code source pane, choose Upload from.",
                                    "  2 : Choose .zip file. ",
                                    "  3 : Choose Upload.",
                                    "  4 : In the file selector, select your .zip file and choose Open.",
                                    "  5 : Choose Save."
                                ]
                            },
                            {
                                "sub_header": "Configure Amazon S3 to invoke the function",
                                "content": [
                                    "For your Lambda function to run when you upload an image to your source bucket, you need to configure a trigger for your function. You can     configure the Amazon S3 trigger using either the console or the AWS CLI.",
                                    "Important",
                                    "This procedure configures the Amazon S3 bucket to invoke your function every time that an object is created in the bucket. Be sure to       configure this only on the source bucket. If your Lambda function creates objects in the same bucket that invokes it, your function can be         invoked continuously in a loop. This can result         in un expected charges being billed to your AWS account.",
                                    "  1.AWS Management Console : CreateThumbnail",
                                    "  2.AWS CLI : source-account",
                                    "AWS Management ConsoleTo configure the Amazon S3 trigger (console)Open the Functions page of the Lambda console and choose your function (CreateThumbnail).Choose Add trigger.Select S3.Under Bucket, select your source bucket.Under Event types, select All object create events.Under Recursive invocation, select the check box to acknowledge that using the same Amazon S3 bucket for input                 and output is not recommended. You can learn more about recursive invocation patterns in Lambda by reading                Recursive patterns that cause run-away Lambda functions                in Serverless Land.Choose Add.When you create a trigger using the Lambda console, Lambda automatically creates a resource based policy                 to give the service you select permission to invoke your function. AWS CLITo configure the Amazon S3 trigger (AWS CLI)For your Amazon S3 source bucket to invoke your function when you add an image file, you first need to configure permissions for your                 function using a resource based policy.                 A resource-based policy statement gives other AWS services permission to invoke your function. To give Amazon S3 permission to invoke                 your function, run the following CLI command. Be sure to replace the source-account parameter with your own AWS account ID and to                 use your own source bucket name.aws lambda add-permission --function-name CreateThumbnail \\--principal s3.amazonaws.com --statement-id s3invoke --action \"lambda:InvokeFunction\" \\--source-arn arn:aws:s3:::amzn-s3-demo-source-bucket \\--source-account 123456789012The policy you define with this command allows Amazon S3 to invoke your function only when an action takes place on your source bucket.NoteAlthough Amazon S3 bucket names are globally unique, when using resource-based policies it is best practice to specify that the                 bucket must belong to your account.  This is because if you delete a bucket, it is possible for another AWS account to create a                 bucket with the same Amazon Resource Name (ARN).Save the following JSON in a file named notification.json. When applied to your source bucket, this JSON                 configures the bucket to send a notification to your Lambda function every time a new object is added. Replace the AWS account               number and AWS Region in the Lambda function ARN with your own account number and region.{\"LambdaFunctionConfigurations\": [    {      \"Id\": \"CreateThumbnailEventConfiguration\",      \"LambdaFunctionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:CreateThumbnail\",      \"Events\": [ \"s3:ObjectCreated:Put\" ]    }  ]}Run the following CLI command to apply the notification settings in the JSON file you created to your source bucket. Replace                 amzn-s3-demo-source-bucket with the name of your own source bucket.aws s3api put-bucket-notification-configuration --bucket amzn-s3-demo-source-bucket \\--notification-configuration file://notification.jsonTo learn more about the put-bucket-notification-configuration command and the                 notification-configuration option, see put-bucket-notification-configuration                 in the AWS CLI Command Reference.",
                                    "anchor",
                                    "anchor",
                                    "To configure the Amazon S3 trigger (console)",
                                    "  1 : Open the Functions page of the Lambda console and choose your function (CreateThumbnail).",
                                    "  2 : Choose Add trigger.",
                                    "  3 : Select S3.",
                                    "  4 : Under Bucket, select your source bucket.",
                                    "  5 : Under Event types, select All object create events.",
                                    "  6 : Under Recursive invocation, select the check box to acknowledge that using the same Amazon S3 bucket for input                 and output is not recommended. You can learn more about recursive invocation patterns in Lambda by reading                Recursive patterns that cause run-away Lambda functions                in Serverless Land.",
                                    "  7 : Choose Add.When you create a trigger using the Lambda console, Lambda automatically creates a resource based policy                 to give the service you select permission to invoke your function. "
                                ]
                            },
                            {
                                "sub_header": "Test your Lambda function with a dummy event",
                                "content": [
                                    "Before you test your whole setup by adding an image file to your Amazon S3 source bucket, you test that your Lambda function is working       correctly by invoking it with a dummy event. An event in Lambda is a JSON-formatted document that contains data for your function to process.       When your function is invoked by Amazon S3, the event sent to your function contains information such as the bucket name, bucket ARN, and object       key.",
                                    "  1.AWS Management Console : CreateThumbnail",
                                    "  2.AWS CLI : dummyS3Event.json",
                                    "AWS Management ConsoleTo test your Lambda function with a dummy event (console)Open the Functions page of the Lambda console and choose your              function (CreateThumbnail).Choose the Test tab.To create your test event, in the Test event pane, do the following:Under Test event action, select Create new event.For Event name, enter myTestEvent.For Template, select S3 Put.Replace the values for the following parameters with your own values.For awsRegion, replace us-east-1 with the AWS Region you created your Amazon S3 buckets in.For name, replace amzn-s3-demo-bucket with the name of your own Amazon S3 source bucket.For key, replace test%2Fkey with the filename of the test object you uploaded to your source                        bucket in the step Upload a test image to your source bucket.{  \"Records\": [    {      \"eventVersion\": \"2.0\",      \"eventSource\": \"aws:s3\",      \"awsRegion\": \"us-east-1\",      \"eventTime\": \"1970-01-01T00:00:00.000Z\",      \"eventName\": \"ObjectCreated:Put\",      \"userIdentity\": {        \"principalId\": \"EXAMPLE\"      },      \"requestParameters\": {        \"sourceIPAddress\": \"127.0.0.1\"      },      \"responseElements\": {        \"x-amz-request-id\": \"EXAMPLE123456789\",        \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\"      },      \"s3\": {        \"s3SchemaVersion\": \"1.0\",        \"configurationId\": \"testConfigRule\",        \"bucket\": {          \"name\": \"amzn-s3-demo-bucket\",          \"ownerIdentity\": {            \"principalId\": \"EXAMPLE\"          },          \"arn\": \"arn:aws:s3:::amzn-s3-demo-bucket\"        },        \"object\": {          \"key\": \"test%2Fkey\",          \"size\": 1024,          \"eTag\": \"0123456789abcdef0123456789abcdef\",          \"sequencer\": \"0A1B2C3D4E5F678901\"        }      }    }  ]}Choose Save.In the Test event pane, choose Test.To check the your function has created a resized verison of your image and stored it in your target Amazon S3 bucket, do the following:Open the Buckets page of the Amazon S3 console.Choose your target bucket and confirm that your resized file is listed in the Objects pane.AWS CLITo test your Lambda function with a dummy event (AWS CLI)Save the following JSON in a file named dummyS3Event.json. Replace the values for the following parameters                 with your own values:For awsRegion, replace us-east-1 with the AWS Region you created your Amazon S3 buckets in.For name, replace amzn-s3-demo-bucket with the name of your own Amazon S3 source bucket.For key, replace test%2Fkey with the filename of the test object you uploaded to your source                        bucket in the step Upload a test image to your source bucket.{  \"Records\": [    {      \"eventVersion\": \"2.0\",      \"eventSource\": \"aws:s3\",      \"awsRegion\": \"us-east-1\",      \"eventTime\": \"1970-01-01T00:00:00.000Z\",      \"eventName\": \"ObjectCreated:Put\",      \"userIdentity\": {        \"principalId\": \"EXAMPLE\"      },      \"requestParameters\": {        \"sourceIPAddress\": \"127.0.0.1\"      },      \"responseElements\": {        \"x-amz-request-id\": \"EXAMPLE123456789\",        \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\"      },      \"s3\": {        \"s3SchemaVersion\": \"1.0\",        \"configurationId\": \"testConfigRule\",        \"bucket\": {          \"name\": \"amzn-s3-demo-bucket\",          \"ownerIdentity\": {            \"principalId\": \"EXAMPLE\"          },          \"arn\": \"arn:aws:s3:::amzn-s3-demo-bucket\"        },        \"object\": {          \"key\": \"test%2Fkey\",          \"size\": 1024,          \"eTag\": \"0123456789abcdef0123456789abcdef\",          \"sequencer\": \"0A1B2C3D4E5F678901\"        }      }    }  ]}From the directory you saved your dummyS3Event.json file in, invoke the function by running the following                 CLI command. This command invokes your Lambda function synchronously by specifying RequestResponse as the value of the                 invocation-type parameter. To learn more about synchronous and asynchronous invocation, see Invoking Lambda functions.aws lambda invoke --function-name CreateThumbnail \\--invocation-type RequestResponse --cli-binary-format raw-in-base64-out \\--payload file://dummyS3Event.json outputfile.txtThe cli-binary-format option is required if you are using version 2 of the AWS CLI. To make this the default setting, run                 aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options.Verify that your function has created a thumbnail version of your image and saved it to your target Amazon S3 bucket. Run the                 following CLI command, replacing amzn-s3-demo-source-bucket-resized with the name of your own destination bucket.aws s3api list-objects-v2 --bucket amzn-s3-demo-source-bucket-resizedYou should see output similar to the following. The Key parameter shows the filename of your resized image file.{    \"Contents\": [        {            \"Key\": \"resized-HappyFace.jpg\",            \"LastModified\": \"2023-06-06T21:40:07+00:00\",            \"ETag\": \"\\\"d8ca652ffe83ba6b721ffc20d9d7174a\\\"\",            \"Size\": 2633,            \"StorageClass\": \"STANDARD\"        }    ]}",
                                    "anchor",
                                    "anchor",
                                    "To test your Lambda function with a dummy event (console)",
                                    "  1 : Open the Functions page of the Lambda console and choose your              function (CreateThumbnail).",
                                    "  2 : Choose the Test tab.",
                                    " 3 : To create your test event, in the Test event pane, do the following:Under Test event action, select Create new event.For Event name, enter myTestEvent.For Template, select S3 Put.Replace the values for the following parameters with your own values.For awsRegion, replace us-east-1 with the AWS Region you created your Amazon S3 buckets in.For name, replace amzn-s3-demo-bucket with the name of your own Amazon S3 source bucket.For key, replace test%2Fkey with the filename of the test object you uploaded to your source                        bucket in the step Upload a test image to your source bucket. Choose Save.",
                                    {
                                        "code_example": "{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.0\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-1\",\n      \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"userIdentity\": {\n        \"principalId\": \"EXAMPLE\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"127.0.0.1\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"EXAMPLE123456789\",\n        \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"testConfigRule\",\n        \"bucket\": {\n          \"name\": \"amzn-s3-demo-bucket\",\n          \"ownerIdentity\": {\n            \"principalId\": \"EXAMPLE\"\n          },\n          \"arn\": \"arn:aws:s3:::amzn-s3-demo-bucket\"\n        },\n        \"object\": {\n          \"key\": \"test%2Fkey\",\n          \"size\": 1024,\n          \"eTag\": \"0123456789abcdef0123456789abcdef\",\n          \"sequencer\": \"0A1B2C3D4E5F678901\"\n        }\n      }\n    }\n  ]\n}"
                                    },
                                    "  4 : In the Test event pane, choose Test.",
                                    "  5 : To check the your function has created a resized verison of your image and stored it in your target Amazon S3 bucket, do the following:Open the Buckets page of the Amazon S3 console.Choose your target bucket and confirm that your resized file is listed in the Objects pane."
                                ]
                            },
                            {
                                "sub_header": "Test your function using the Amazon S3 trigger",
                                "content": [
                                    "Now that you’ve confirmed your Lambda function is operating correctly, you’re ready to test your complete setup by adding an image file to       your Amazon S3 source bucket. When you add your image to the source bucket, your Lambda function should be automatically invoked. Your function       creates a resized version of the file and stores it in your target bucket.",
                                    "  1.AWS Management Console : \nTo test your Lambda function using the Amazon S3 trigger (console)\nTo upload an image to your Amazon S3 bucket, do the following:\n\nOpen the Buckets page of the Amazon S3 console and choose your source bucket.\n\nChoose Upload.\n\nChoose Add files and use the file selector to choose the image file you want to upload. Your image \n                  object can be any .jpg or .png file.\n\nChoose Open, then choose Upload.\n\n\nVerify that Lambda has saved a resized version of your image file in your target bucket by doing the following:\n\nNavigate back to the Buckets page of the Amazon S3 console and choose your destination bucket.\n\nIn the Objects pane, you should now see two resized image files, one from each test of your Lambda function.\n                  To download your resized image, select the file, then choose Download.\n\n\n",
                                    "  2.AWS CLI : --bucket",
                                    "AWS Management ConsoleTo test your Lambda function using the Amazon S3 trigger (console)To upload an image to your Amazon S3 bucket, do the following:Open the Buckets page of the Amazon S3 console and choose your source bucket.Choose Upload.Choose Add files and use the file selector to choose the image file you want to upload. Your image                   object can be any .jpg or .png file.Choose Open, then choose Upload.Verify that Lambda has saved a resized version of your image file in your target bucket by doing the following:Navigate back to the Buckets page of the Amazon S3 console and choose your destination bucket.In the Objects pane, you should now see two resized image files, one from each test of your Lambda function.                  To download your resized image, select the file, then choose Download.AWS CLITo test your Lambda function using the Amazon S3 trigger (AWS CLI)From the directory containing the image you want to upload, run the following CLI command. Replace the --bucket                 parameter with the name of your source bucket. For the --key and --body parameters, use the filename of                 your test image. Your test image can be any .jpg or .png file.aws s3api put-object --bucket amzn-s3-demo-source-bucket --key SmileyFace.jpg --body ./SmileyFace.jpgVerify that your function has created a thumbnail version of your image and saved it to your target Amazon S3 bucket. Run the                 following CLI command, replacing amzn-s3-demo-source-bucket-resized with the name of your own destination bucket.aws s3api list-objects-v2 --bucket amzn-s3-demo-source-bucket-resizedIf your function runs successfully, you’ll see output similar to the following. Your target bucket should now contain two resized files.{    \"Contents\": [        {            \"Key\": \"resized-HappyFace.jpg\",            \"LastModified\": \"2023-06-07T00:15:50+00:00\",            \"ETag\": \"\\\"7781a43e765a8301713f533d70968a1e\\\"\",            \"Size\": 2763,            \"StorageClass\": \"STANDARD\"        },        {            \"Key\": \"resized-SmileyFace.jpg\",            \"LastModified\": \"2023-06-07T00:13:18+00:00\",            \"ETag\": \"\\\"ca536e5a1b9e32b22cd549e18792cdbc\\\"\",            \"Size\": 1245,            \"StorageClass\": \"STANDARD\"        }    ]}",
                                    "anchor",
                                    "anchor",
                                    "To test your Lambda function using the Amazon S3 trigger (console)",
                                    "  1 : To upload an image to your Amazon S3 bucket, do the following:Open the Buckets page of the Amazon S3 console and choose your source bucket.Choose Upload.Choose Add files and use the file selector to choose the image file you want to upload. Your image                   object can be any .jpg or .png file.Choose Open, then choose Upload.",
                                    "  2 : Verify that Lambda has saved a resized version of your image file in your target bucket by doing the following:Navigate back to the Buckets page of the Amazon S3 console and choose your destination bucket.In the Objects pane, you should now see two resized image files, one from each test of your Lambda function.                  To download your resized image, select the file, then choose Download."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the policy that you created",
                                    "  1 : Open the Policies page of the IAM console.",
                                    "  2 : Select the policy that you created (AWSLambdaS3Policy).",
                                    "  3 : Choose Policy actions, Delete.",
                                    "  4 : Choose Delete.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the S3 bucket",
                                    "  1 : Open the Amazon S3 console.",
                                    "  2 : Select the bucket you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the bucket in the text input field.",
                                    "  5 : Choose Delete bucket."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "You can use Lambda to process event notifications from    Amazon Simple Storage Service. Amazon S3 can send an event to a Lambda function when an object is created or deleted. You configure    notification settings on a bucket, and grant Amazon S3 permission to invoke a function on the function's resource-based    permissions policy.",
                    "Warning",
                    "If your Lambda function uses the same bucket that triggers it, it could cause      the function to run in a loop. For example, if the bucket triggers a function each time an object is uploaded,      and the function uploads an object to the bucket, then the function indirectly triggers itself. To avoid this, use      two buckets, or configure the trigger to only apply to a prefix used for incoming objects.",
                    "Amazon S3 invokes your function asynchronously with an event that contains    details about the object. The following example shows an event that Amazon S3 sent when a deployment package was uploaded    to Amazon S3.",
                    "Example Amazon S3 notification event",
                    {
                        "code_example": "{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.1\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventTime\": \"2019-09-03T19:37:27.192Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"userIdentity\": {\n        \"principalId\": \"AWS:AIDAINPONIXQXHT3IKHL2\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"205.255.255.255\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"D82B88E5F771F645\",\n        \"x-amz-id-2\": \"vlR7PnpV2Ce81l0PRw6jlUpck7Jo5ZsQjryTjKlc5aLWGVHPZLj5NeC6qMa0emYBDXOo6QBU0Wo=\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"828aa6fc-f7b5-4305-8584-487c791949c1\",\n        \"bucket\": {\n          \"name\": \"amzn-s3-demo-bucket\",\n          \"ownerIdentity\": {\n            \"principalId\": \"A3I5XTEXAMAI3E\"\n          },\n          \"arn\": \"arn:aws:s3:::lambda-artifacts-deafc19498e3f2df\"\n        },\n        \"object\": {\n          \"key\": \"b21b84d653bb07b05b1e6b33684dc11b\",\n          \"size\": 1305107,\n          \"eTag\": \"b21b84d653bb07b05b1e6b33684dc11b\",\n          \"sequencer\": \"0C0F6F405D6ED209E1\"\n        }\n      }\n    }\n  ]\n}"
                    },
                    "To invoke your function, Amazon S3 needs permission from the function's resource-based policy. When you configure an Amazon S3 trigger in the Lambda console, the console modifies the    resource-based policy to allow Amazon S3 to invoke the function if the bucket name and account ID match. If you configure    the notification in Amazon S3, you use the Lambda API to update the policy. You can also use the Lambda API to grant    permission to another account, or restrict permission to a designated alias.",
                    "If your function uses the AWS SDK to manage Amazon S3 resources, it also needs Amazon S3 permissions in its execution role. ",
                    "Topics"
                ]
            },
            {
                "title": "SQS",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html",
                "contents": [
                    {
                        "title": "Create mapping",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-configure.html",
                        "sections": [
                            "To process Amazon SQS messages with Lambda, configure your queue with the appropriate settings,        then create a Lambda event source mapping.",
                            {
                                "sub_header": "Configuring a queue to use with Lambda",
                                "content": [
                                    "If you don't already have an existing Amazon SQS queue, create one            to serve as an event source for your Lambda function. The Lambda function and the Amazon SQS queue must be in the same AWS Region, although they can be in different AWS accounts.",
                                    "To allow your function time to process each batch of records, set the source queue's                        visibility timeout to at least six times the configuration            timeout on your function. The extra time allows Lambda to retry if your function is throttled            while processing a previous batch.",
                                    "By default, if Lambda encounters an error at any point while processing a batch, all            messages in that batch return to the queue. After the             visibility timeout, the messages become visible to Lambda again. You can            configure your event source mapping to use             partial batch responses to return only the failed messages back to the queue. In            addition, if your function fails to process a message multiple times, Amazon SQS can send it to a                        dead-letter queue. We recommend setting the maxReceiveCount on your            source queue's             redrive policy to at least 5. This gives Lambda a few chances to retry before            sending failed messages directly to the dead-letter queue."
                                ]
                            },
                            {
                                "sub_header": "Setting up Lambda execution role permissions",
                                "content": [
                                    "The             AWSLambdaSQSQueueExecutionRole AWS managed policy includes the permissions that Lambda needs to read            from your Amazon SQS queue. You can add this managed policy to your function's            execution role.",
                                    "Optionally, if you're using an encrypted queue, you also need to add the following permission to your            execution role:",
                                    "  1.kms:Decrypt"
                                ]
                            },
                            {
                                "sub_header": "Creating an SQS event source mapping",
                                "content": [
                                    "Create an event source mapping to tell Lambda to send items from your queue to a Lambda function.            You can create multiple event source mappings to process items from multiple queues with a single            function. When Lambda invokes the target function, the event can contain multiple items, up to a            configurable maximum batch size.",
                                    "To configure your function to read from Amazon SQS, attach the             AWSLambdaSQSQueueExecutionRole AWS managed policy to your execution role.            Then, create an SQS event source mapping from the console using            the following steps.",
                                    "To add permissions and create a trigger",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose the name of a function.",
                                    "  3 : Choose the Configuration tab, and then choose Permissions.",
                                    "  4 : Under Role name, choose the link to your execution role. This link opens the role in the IAM console.",
                                    "  5 : Choose Add permissions, and then choose Attach policies.",
                                    "  6 : In the search field, enter AWSLambdaSQSQueueExecutionRole.    Add this policy to your execution role. This is an AWS managed policy that contains the permissions    your function needs to read from an Amazon SQS queue. For more information about this policy, see        AWSLambdaSQSQueueExecutionRole in the AWS Managed Policy Reference.",
                                    "  7 : Go back to your function in the Lambda console. Under Function overview, choose Add trigger.",
                                    "  8 : Choose a trigger type.",
                                    "  9 : Configure the required options, and then choose Add.",
                                    "Lambda supports the following configuration options for Amazon SQS event sources:",
                                    "  1.SQS queue : \nThe Amazon SQS queue to read records from. The Lambda function and the Amazon SQS queue must be in the same AWS Region, although they can be in different AWS accounts.\n",
                                    "  2.Enable trigger : \nThe status of the event source mapping. Enable trigger is selected by default.\n",
                                    "  3.Batch size : MaximumBatchingWindowInSeconds",
                                    "  4.Batch window : MaximumBatchingWindowInSeconds",
                                    "  5.Maximum concurrency : \nThe maximum number of concurrent functions that the event source can invoke. For more information,\n                        see Configuring maximum concurrency for Amazon SQS event sources.\n",
                                    "  6.Filter criteria : \nAdd filter criteria to control which events Lambda sends to your function for processing.\n                        For more information, see Control which events Lambda sends to your function.\n",
                                    "SQS queueThe Amazon SQS queue to read records from. The Lambda function and the Amazon SQS queue must be in the same AWS Region, although they can be in different AWS accounts.Enable triggerThe status of the event source mapping. Enable trigger is selected by default.Batch sizeThe maximum number of records to send to the function in each batch. For a standard queue,                        this can be up to 10,000 records. For a FIFO queue, the maximum is 10. For a batch size                        over 10, you must also set the batch window (MaximumBatchingWindowInSeconds)                        to at least 1 second.Configure your                         function timeout to allow enough time to process an entire batch of items. If items                        take a long time to process, choose a smaller batch size. A large batch size can improve                        efficiency for workloads that are very fast or have a lot of overhead. If you configure                        reserved concurrency on your function, set                        a minimum of five concurrent executions to reduce the chance of throttling errors when Lambda                        invokes your function.Lambda passes all of the records in the batch to the function in a single call, as long as                        the total size of the events doesn't exceed the                         invocation payload size quota for synchronous invocation (6 MB). Both Lambda and Amazon SQS                        generate metadata for each record. This additional metadata is counted towards the total                        payload size and can cause the total number of records sent in a batch to be lower than your                        configured batch size. The metadata fields that Amazon SQS sends can be variable in length.                        For more information about the Amazon SQS metadata fields, see the ReceiveMessage                        API operation documentation in the Amazon Simple Queue Service API Reference.Batch windowThe maximum amount of time to gather records before invoking the function, in seconds.                        This applies only to standard queues.If you're using a batch window greater than 0 seconds, you must account for the increased                        processing time in your queue's                                                visibility timeout. We recommend setting your queue's visibility timeout to six times your                        function timeout, plus the value of                        MaximumBatchingWindowInSeconds. This allows time for your Lambda function to process each                        batch of events and to retry in the event of a throttling error.When messages become available, Lambda starts processing messages in batches. Lambda starts                        processing five batches at a time with five concurrent invocations of your function. If messages                        are still available, Lambda adds up to 300 more instances of your function a minute, up to a                        maximum of 1,000 function instances. To learn more about function scaling and concurrency,                        see Lambda function scaling.To process more messages, you can optimize your Lambda function for higher throughput.                        For more information, see                         Understanding how AWS Lambda scales with Amazon SQS standard queues.Maximum concurrencyThe maximum number of concurrent functions that the event source can invoke. For more information,                        see Configuring maximum concurrency for Amazon SQS event sources.Filter criteriaAdd filter criteria to control which events Lambda sends to your function for processing.                        For more information, see Control which events Lambda sends to your function."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Scaling behavior",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-scaling.html",
                        "sections": [
                            "For standard queues, Lambda uses         long polling to poll a queue until it becomes active. When messages are available,        Lambda starts processing five batches at a time with five concurrent invocations of your function.        If messages are still available, Lambda increases the number of processes that are reading batches by up to 300 more instances per minute. The maximum number of batches that an event source mapping can process simultaneously is 1,000.",
                            "For FIFO queues, Lambda sends messages to your function in the order that it receives them. When you send a        message to a FIFO queue, you specify a message group            ID. Amazon SQS ensures that messages in the same group are delivered to Lambda in order. When Lambda reads         your messages into batches, each batch may contain messages from more than one message group, but the order         of the messages is maintained. If your function returns an error, the function attempts all retries on the         affected messages before Lambda receives additional messages from the same        group.",
                            {
                                "sub_header": "Configuring maximum concurrency for Amazon SQS event sources",
                                "content": [
                                    "You can use the maximum concurrency setting to control scaling behavior for your SQS event sources.            The maximum concurrency setting limits the number of concurrent instances of the function that an Amazon SQS            event source can invoke. Maximum concurrency is an event source-level setting. If you have multiple Amazon SQS            event sources mapped to one function, each event source can have a separate maximum concurrency setting.            You can use maximum concurrency to prevent one queue from using all of the function's            reserved concurrency or the rest of the            account's concurrency quota. There is no charge for            configuring maximum concurrency on an Amazon SQS event source.",
                                    "Importantly, maximum concurrency and reserved concurrency are two independent settings. Don't set            maximum concurrency higher than the function's reserved concurrency. If you configure maximum concurrency,            make sure that your function's reserved concurrency is greater than or equal to the total maximum            concurrency for all Amazon SQS event sources on the function. Otherwise, Lambda may throttle your messages.",
                                    "When your account's concurrency quota is set to the default value of 1,000, an Amazon SQS event source mapping can scale             to invoke function instances up to this value, unless you specify a maximum concurrency.",
                                    "If you receive an increase to your account's default concurrency quota, Lambda may not be able to invoke concurrent functions             instances up to your new quota. By default, Lambda can scale to invoke up to 1,250 concurrent function instances             for an Amazon SQS event source mapping. If this is insufficient for your use case, contact AWS support to             discuss an increase to your account's Amazon SQS event source mapping concurrency.",
                                    "Note",
                                    "For FIFO queues, concurrent invocations are capped either by the number of                message group IDs                (messageGroupId) or the maximum concurrency setting—whichever is lower. For example,                if you have six message group IDs and maximum concurrency is set to 10, your function can have a maximum                of six concurrent invocations.",
                                    "You can configure maximum concurrency on new and existing Amazon SQS event source mappings.",
                                    "Configure maximum concurrency using the Lambda console",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose the name of a function.",
                                    "  3 : Under Function overview, choose SQS. This opens the Configuration tab.",
                                    "  4 : Select the Amazon SQS trigger and choose Edit.",
                                    "  5 : For Maximum concurrency, enter a number between 2 and 1,000. To turn off maximum concurrency, leave the box empty.",
                                    "  6 : Choose Save.",
                                    {
                                        "sub_header": "Configure maximum concurrency using the AWS Command Line Interface (AWS CLI)",
                                        "content": [
                                            "Use the update-event-source-mapping command with the --scaling-config option. Example:",
                                            "aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --scaling-config '{\"MaximumConcurrency\":5}'",
                                            "To turn off maximum concurrency, enter an empty value for --scaling-config:",
                                            "aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --scaling-config \"{}\"",
                                            {
                                                "sub_header": "Configure maximum concurrency using the Lambda API",
                                                "content": [
                                                    "Use the CreateEventSourceMapping or UpdateEventSourceMapping action with a ScalingConfig object."
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Error handling",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-errorhandling.html",
                        "sections": [
                            "To handle errors related to an SQS event source, Lambda automatically uses a retry strategy with a        backoff strategy. You can also customize error handling behavior by configuring your SQS event        source mapping to return partial batch responses.",
                            {
                                "sub_header": "Backoff strategy for failed invocations",
                                "content": [
                                    "When an invocation fails, Lambda attempts to retry the invocation while implementing a backoff strategy.            The backoff strategy differs slightly depending on whether Lambda encountered the failure due to an error in            your function code, or due to throttling.",
                                    "  1.function code :                     If your  caused the error, Lambda will stop processing and retrying the invocation.                    In the meantime, Lambda gradually backs off, reducing the amount of concurrency allocated to your Amazon SQS event source mapping.                    After your queue's visibility timeout runs out, the message will again reappear in the queue.                ",
                                    "  2.throttling : If the invocation fails due to , Lambda gradually backs off                    retries by reducing the amount of concurrency allocated to your Amazon SQS event source mapping. Lambda continues                    to retry the message until the message's timestamp exceeds your queue's visibility timeout, at which point                    Lambda drops the message."
                                ]
                            },
                            {
                                "sub_header": "Implementing partial batch responses",
                                "content": [
                                    "When your Lambda function encounters an error while processing a batch, all messages in that batch become            visible in the queue again by default, including messages that Lambda processed successfully. As a result, your            function can end up processing the same message several times.",
                                    "To avoid reprocessing successfully processed messages in a failed batch, you can configure your event            source mapping to make only the failed messages visible again. This is called a partial batch response.            To turn on partial batch responses, specify ReportBatchItemFailures for the            FunctionResponseTypes            action when configuring your event source mapping. This lets your function            return a partial success, which can help reduce the number of unnecessary retries on records.",
                                    "When ReportBatchItemFailures is activated, Lambda doesn't scale down message polling when function invocations fail. If you expect some messages to fail—and you don't want those failures to impact the message processing rate—use ReportBatchItemFailures.",
                                    "Note",
                                    "Keep the following in mind when using partial batch responses:",
                                    "  1.If your function throws an exception, the entire batch is considered a complete failure.",
                                    "  2.If you're using this feature with a FIFO queue, your function should stop processing messages after the                        first failure and return all failed and unprocessed messages in batchItemFailures. This helps                        preserve the ordering of messages in your queue.",
                                    "To activate partial batch reporting",
                                    "  1 : Review the Best practices for implementing partial batch responses.",
                                    " 2 : Run the following command to activate ReportBatchItemFailures for your function. To retrieve your event source mapping's UUID, run the list-event-source-mappings AWS CLI command. ",
                                    {
                                        "code_example": "aws lambda update-event-source-mapping \\\n--uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\\n--function-response-types \"ReportBatchItemFailures\""
                                    },
                                    " 3 : Update your function code to catch all exceptions and return failed messages in a batchItemFailures JSON response. The batchItemFailures response must include a list of message IDs, as itemIdentifier JSON values.For example, suppose you have a batch of five messages, with message IDs id1, id2, id3, id4, and id5. Your function successfully processes id1, id3, and id5. To make messages id2 and id4 visible again in your queue, your function should return the following response:   Here are some examples of function code that return the list of failed message IDs in the batch:.NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace sqsSample;public class Function{    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();        foreach(var message in evnt.Records)        {            try            {                //process your message                await ProcessMessageAsync(message, context);            }            catch (System.Exception)            {                //Add failed message identifier to the batchItemFailures list                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId});             }        }        return new SQSBatchResponse(batchItemFailures);    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        if (String.IsNullOrEmpty(message.Body))        {            throw new Exception(\"No Body in SQS Message.\");        }        context.Logger.LogInformation($\"Processed message {message.Body}\");        // TODO: Do interesting work based on the new message        await Task.CompletedTask;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"encoding/json\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, sqsEvent events.SQSEvent) (map[string]interface{}, error) {\tbatchItemFailures := []map[string]interface{}{}\tfor _, message := range sqsEvent.Records {\t\t\t\tif /* Your message processing condition here */ {\t\t\t\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": message.MessageId})\t\t}\t}\tsqsBatchResponse := map[string]interface{}{\t\t\"batchItemFailures\": batchItemFailures,\t}\treturn sqsBatchResponse, nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SQSEvent;import com.amazonaws.services.lambda.runtime.events.SQSBatchResponse; import java.util.ArrayList;import java.util.List; public class ProcessSQSMessageBatch implements RequestHandler<SQSEvent, SQSBatchResponse> {    @Override    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {          List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new ArrayList<SQSBatchResponse.BatchItemFailure>();         String messageId = \"\";         for (SQSEvent.SQSMessage message : sqsEvent.getRecords()) {             try {                 //process your message                 messageId = message.getMessageId();             } catch (Exception e) {                 //Add failed message identifier to the batchItemFailures list                 batchItemFailures.add(new SQSBatchResponse.BatchItemFailure(messageId));             }         }         return new SQSBatchResponse(batchItemFailures);     }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using JavaScript.// Node.js 20.x Lambda runtime, AWS SDK for Javascript V3export const handler = async (event, context) => {    const batchItemFailures = [];    for (const record of event.Records) {        try {            await processMessageAsync(record, context);        } catch (error) {            batchItemFailures.push({ itemIdentifier: record.messageId });        }    }    return { batchItemFailures };};async function processMessageAsync(record, context) {    if (record.body && record.body.includes(\"error\")) {        throw new Error(\"There is an error in the SQS Message.\");    }    console.log(`Processed message: ${record.body}`);}Reporting SQS batch item failures with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SQSEvent, SQSBatchResponse, Context, SQSBatchItemFailure, SQSRecord } from 'aws-lambda';export const handler = async (event: SQSEvent, context: Context): Promise<SQSBatchResponse> => {    const batchItemFailures: SQSBatchItemFailure[] = [];    for (const record of event.Records) {        try {            await processMessageAsync(record);        } catch (error) {            batchItemFailures.push({ itemIdentifier: record.messageId });        }    }    return {batchItemFailures: batchItemFailures};};async function processMessageAsync(record: SQSRecord): Promise<void> {    if (record.body && record.body.includes(\"error\")) {        throw new Error('There is an error in the SQS Message.');    }    console.log(`Processed message ${record.body}`);}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?phpuse Bref\\Context\\Context;use Bref\\Event\\Sqs\\SqsEvent;use Bref\\Event\\Sqs\\SqsHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends SqsHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleSqs(SqsEvent $event, Context $context): void    {        $this->logger->info(\"Processing SQS records\");        $records = $event->getRecords();        foreach ($records as $record) {            try {                // Assuming the SQS message is in JSON format                $message = json_decode($record->getBody(), true);                $this->logger->info(json_encode($message));                // TODO: Implement your custom processing logic here            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $this->markAsFailed($record);            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords SQS records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    if event:        batch_item_failures = []        sqs_batch_response = {}             for record in event[\"Records\"]:            try:                # process message            except Exception as e:                batch_item_failures.append({\"itemIdentifier\": record['messageId']})                sqs_batch_response[\"batchItemFailures\"] = batch_item_failures        return sqs_batch_responseRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'json'def lambda_handler(event:, context:)  if event    batch_item_failures = []    sqs_batch_response = {}    event[\"Records\"].each do |record|      begin        # process message      rescue StandardError => e        batch_item_failures << {\"itemIdentifier\" => record['messageId']}      end    end    sqs_batch_response[\"batchItemFailures\"] = batch_item_failures    return sqs_batch_response  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::{    event::sqs::{SqsBatchResponse, SqsEvent},    sqs::{BatchItemFailure, SqsMessage},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn process_record(_: &SqsMessage) -> Result<(), Error> {    Err(Error::from(\"Error processing message\"))}async fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<SqsBatchResponse, Error> {    let mut batch_item_failures = Vec::new();    for record in event.payload.records {        match process_record(&record).await {            Ok(_) => (),            Err(_) => batch_item_failures.push(BatchItemFailure {                item_identifier: record.message_id.unwrap(),            }),        }    }    Ok(SqsBatchResponse {        batch_item_failures,    })}#[tokio::main]async fn main() -> Result<(), Error> {    run(service_fn(function_handler)).await}anchoranchoranchoranchoranchoranchoranchoranchor.NETGoJavaJavaScriptPHPPythonRubyRustAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace sqsSample;public class Function{    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();        foreach(var message in evnt.Records)        {            try            {                //process your message                await ProcessMessageAsync(message, context);            }            catch (System.Exception)            {                //Add failed message identifier to the batchItemFailures list                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId});             }        }        return new SQSBatchResponse(batchItemFailures);    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        if (String.IsNullOrEmpty(message.Body))        {            throw new Exception(\"No Body in SQS Message.\");        }        context.Logger.LogInformation($\"Processed message {message.Body}\");        // TODO: Do interesting work based on the new message        await Task.CompletedTask;    }}",
                                    {
                                        "code_example": "{ \n  \"batchItemFailures\": [ \n        {\n            \"itemIdentifier\": \"id2\"\n        },\n        {\n            \"itemIdentifier\": \"id4\"\n        }\n    ]\n}"
                                    },
                                    "If the failed events do not return to the queue, see How do I troubleshoot Lambda function SQS ReportBatchItemFailures? in the AWS Knowledge Center.",
                                    {
                                        "sub_header": "Success and failure conditions",
                                        "content": [
                                            "Lambda treats a batch as a complete success if your function returns any of the following:",
                                            "  1.An empty batchItemFailures list",
                                            "  2.A null batchItemFailures list",
                                            "  3.An empty EventResponse",
                                            "  4.A null EventResponse",
                                            "Lambda treats a batch as a complete failure if your function returns any of the following:",
                                            "  1.An invalid JSON response",
                                            "  2.An empty string itemIdentifier",
                                            "  3.A null itemIdentifier",
                                            "  4.An itemIdentifier with a bad key name",
                                            "  5.An itemIdentifier value with a message ID that doesn't exist"
                                        ]
                                    },
                                    {
                                        "sub_header": "CloudWatch metrics",
                                        "content": [
                                            "To determine whether your function is correctly reporting batch item failures, you can monitor the                NumberOfMessagesDeleted and ApproximateAgeOfOldestMessage Amazon SQS metrics in                Amazon CloudWatch.",
                                            "  1.NumberOfMessagesDeleted tracks the number of messages removed from your queue. If this                        drops to 0, this is a sign that your function response is not correctly returning failed messages.",
                                            "  2.ApproximateAgeOfOldestMessage tracks how long the oldest message has stayed in your queue.                        A sharp increase in this metric can indicate that your function is not correctly returning failed                        messages."
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Parameters",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-parameters.html",
                        "sections": [
                            "All Lambda event source types share the same CreateEventSourceMapping and UpdateEventSourceMapping        API operations. However, only some of the parameters apply to Amazon SQS.",
                            "ParameterRequiredDefaultNotesBatchSizeN10For standard queues, the maximum is 10,000. For FIFO queues, the maximum is 10.EnabledNtruenone EventSourceArnYN/AThe ARN of the data stream or a stream consumerFunctionNameYN/A none FilterCriteriaNN/A Control which events Lambda sends to your functionFunctionResponseTypesNN/A To let your function report specific failures in a batch, include the value                            ReportBatchItemFailures in FunctionResponseTypes. For more information, see                            Implementing partial batch responses.MaximumBatchingWindowInSecondsN0none ScalingConfigNN/A Configuring maximum concurrency for Amazon SQS event sources"
                        ]
                    },
                    {
                        "title": "Event filtering",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sqs-filtering.html",
                        "sections": [
                            "You can use event filtering to control which records from a stream or queue Lambda sends to your function.    For general information about how event filtering works, see Control which events Lambda sends to your function.",
                            "This section focuses on event filtering for Amazon MSK event sources.",
                            "Topics",
                            {
                                "sub_header": "Amazon SQS event filtering basics",
                                "content": [
                                    "Suppose your Amazon SQS queue contains messages in the following JSON format.",
                                    "{    \"RecordNumber\": 1234,    \"TimeStamp\": \"yyyy-mm-ddThh:mm:ss\",    \"RequestCode\": \"AAAA\"}",
                                    "An example record for this queue would look as follows.",
                                    "{    \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",    \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",    \"body\": \"{\\n \"RecordNumber\": 1234,\\n \"TimeStamp\": \"yyyy-mm-ddThh:mm:ss\",\\n \"RequestCode\": \"AAAA\"\\n}\",    \"attributes\": {        \"ApproximateReceiveCount\": \"1\",        \"SentTimestamp\": \"1545082649183\",        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"        },    \"messageAttributes\": {},    \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",    \"eventSource\": \"aws:sqs\",    \"eventSourceARN\": \"arn:aws:sqs:us-west-2:123456789012:my-queue\",    \"awsRegion\": \"us-west-2\"}",
                                    "To filter based on the contents of your Amazon SQS messages, use the body key in the Amazon SQS message record. Suppose you want to process             only those records where the RequestCode in your Amazon SQS message is “BBBB.” The FilterCriteria object would be             as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"body\\\" : { \\\"RequestCode\\\" : [ \\\"BBBB\\\" ] } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON. ",
                                    "{    \"body\": {        \"RequestCode\": [ \"BBBB\" ]        }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"body\" : { \"RequestCode\" : [ \"BBBB\" ] } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:sqs:us-east-2:123456789012:my-queue \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RequestCode\\\" : [ \\\"BBBB\\\" ] } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"body\" : { \"RequestCode\" : [ \"BBBB\" ] } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"body\" : { \"RequestCode\" : [ \"BBBB\" ] } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:sqs:us-east-2:123456789012:my-queue \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RequestCode\\\" : [ \\\"BBBB\\\" ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RequestCode\\\" : [ \\\"BBBB\\\" ] } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"body\" : { \"RequestCode\" : [ \"BBBB\" ] } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"body\" : { \"RequestCode\" : [ \"BBBB\" ] } }"
                                    },
                                    "Suppose you want your function to process only those records where RecordNumber is greater than 9999. The FilterCriteria             object would be as follows.",
                                    "{    \"Filters\": [        {            \"Pattern\": \"{ \\\"body\\\" : { \\\"RecordNumber\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 9999 ] } ] } }\"        }    ]}",
                                    "For added clarity, here is the value of the filter's Pattern expanded in plain JSON. ",
                                    "{    \"body\": {        \"RecordNumber\": [            {                \"numeric\": [ \">\", 9999 ]            }        ]    }}",
                                    "You can add your filter using the console, AWS CLI or an AWS SAM template.",
                                    "  1.Console : { \"body\" : { \"RecordNumber\" : [ { \"numeric\": [ \">\", 9999 ] } ] } }",
                                    "  2.AWS CLI : aws lambda create-event-source-mapping \\\n    --function-name my-function \\\n    --event-source-arn arn:aws:sqs:us-east-2:123456789012:my-queue \\\n    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RecordNumber\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 9999 ] } ] } }\"}]}'",
                                    "  3.AWS SAM : FilterCriteria:\n  Filters:\n    - Pattern: '{ \"body\" : { \"RecordNumber\" : [ { \"numeric\": [ \">\", 9999 ] } ] } }'",
                                    "ConsoleTo add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.{ \"body\" : { \"RecordNumber\" : [ { \"numeric\": [ \">\", 9999 ] } ] } }AWS CLITo create a new event source mapping with these filter criteria using the AWS Command Line Interface (AWS CLI), run the following                        command.aws lambda create-event-source-mapping \\    --function-name my-function \\    --event-source-arn arn:aws:sqs:us-east-2:123456789012:my-queue \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RecordNumber\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 9999 ] } ] } }\"}]}'To add these filter criteria to an existing event source mapping, run the following command.aws lambda update-event-source-mapping \\    --uuid \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\" \\    --filter-criteria '{\"Filters\": [{\"Pattern\": \"{ \\\"body\\\" : { \\\"RecordNumber\\\" : [ { \\\"numeric\\\": [ \\\">\\\", 9999 ] } ] } }\"}]}'AWS SAMTo add this filter using AWS SAM, add the following snippet to the YAML template for your event source.FilterCriteria:  Filters:    - Pattern: '{ \"body\" : { \"RecordNumber\" : [ { \"numeric\": [ \">\", 9999 ] } ] } }'",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "To add this filter using the console, follow the instructions in Attaching filter criteria to an event source mapping (console) and enter the following                         string for the Filter criteria.",
                                    {
                                        "code_example": "{ \"body\" : { \"RecordNumber\" : [ { \"numeric\": [ \">\", 9999 ] } ] } }"
                                    },
                                    "For Amazon SQS, the message body can be any string. However, this can be problematic if your FilterCriteria expect body             to be in a valid JSON format. The reverse scenario is also true—if the incoming message body is in JSON format but your filter criteria             expects body to be a plain string, this can lead to unintended behavior.",
                                    "To avoid this issue, ensure that the format of body in your FilterCriteria matches the expected format of body in messages             that you receive from your queue. Before filtering your messages, Lambda automatically evaluates the format of the incoming message body and             of your filter pattern for body. If there is a mismatch, Lambda drops the message. The following table summarizes this evaluation:",
                                    "Incoming message body formatFilter pattern body formatResulting actionPlain stringPlain stringLambda filters based on your filter criteria.Plain stringNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Plain stringValid JSONLambda drops the message.Valid JSONPlain stringLambda drops the message.Valid JSONNo filter pattern for data propertiesLambda filters (on the other metadata properties only) based on your filter criteria.Valid JSONValid JSONLambda filters based on your filter criteria."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sqs-example.html",
                        "sections": [
                            "In this tutorial, you create a Lambda function that consumes messages from an Amazon Simple Queue Service (Amazon SQS) queue. The Lambda function runs whenever a new message is added to the queue. The function writes the messages to an Amazon CloudWatch Logs stream. The following diagram shows the AWS     resources you use to complete the tutorial.",
                            "To complete this tutorial, you carry out the following steps:",
                            "  1 : Create a Lambda function that writes messages to CloudWatch Logs.",
                            "  2 : Create an Amazon SQS queue.",
                            "  3 : Create a Lambda event source mapping. The event source mapping reads the Amazon SQS queue and invokes your Lambda function when a new message is added.",
                            "  4 : Test the setup by adding messages to your queue and monitoring the results in         CloudWatch Logs.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "Install the AWS Command Line Interface",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          Install the AWS Command Line InterfaceIf you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          "
                                ]
                            },
                            {
                                "sub_header": "Create the execution role",
                                "content": [
                                    "An execution role is an AWS Identity and Access Management (IAM) role that grants a Lambda function permission to access AWS services and resources. To allow       your function to read items from Amazon SQS, attach the AWSLambdaSQSQueueExecutionRole permissions policy.",
                                    "To create an execution role and attach an Amazon SQS permissions policy",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : For Trusted entity type, choose AWS service.",
                                    "  4 : For Use case, choose Lambda.",
                                    "  5 : Choose Next.",
                                    "  6 : In the Permissions policies search box, enter AWSLambdaSQSQueueExecutionRole.",
                                    "  7 : Select the AWSLambdaSQSQueueExecutionRole policy, and          then choose Next.",
                                    "  8 : Under Role details, for Role name, enter          lambda-sqs-role, then choose Create role.",
                                    "After role creation, note down the Amazon Resource Name (ARN) of your execution role. You'll      need it in later steps."
                                ]
                            },
                            {
                                "sub_header": "Create the function",
                                "content": [
                                    "Create a Lambda function that processes your Amazon SQS messages. The function code logs the body of      the Amazon SQS message to CloudWatch Logs.",
                                    "This tutorial uses the Node.js 18.x runtime, but we've also provided      example code in other runtime languages. You can select the tab in the following box to see code      for the runtime you're interested in. The JavaScript code you'll use in this step is in the first      example shown in the JavaScript tab.",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage integration_sqs_to_lambda\n\nimport (\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.SQSEvent) error {\n\tfor _, record := range event.Records {\n\t\terr := processMessage(record)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfmt.Println(\"done\")\n\treturn nil\n}\n\nfunc processMessage(record events.SQSMessage) error {\n\tfmt.Printf(\"Processed message %s\\n\", record.Body)\n\t// TODO: Do interesting work based on the new message\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage integration_sqs_to_lambda\n\nimport (\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.SQSEvent) error {\n\tfor _, record := range event.Records {\n\t\terr := processMessage(record)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfmt.Println(\"done\")\n\treturn nil\n}\n\nfunc processMessage(record events.SQSMessage) error {\n\tfmt.Printf(\"Processed message %s\\n\", record.Body)\n\t// TODO: Do interesting work based on the new message\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;\n\npublic class Function implements RequestHandler<SQSEvent, Void> {\n    @Override\n    public Void handleRequest(SQSEvent sqsEvent, Context context) {\n        for (SQSMessage msg : sqsEvent.getRecords()) {\n            processMessage(msg, context);\n        }\n        context.getLogger().log(\"done\");\n        return null;\n    }\n\n    private void processMessage(SQSMessage msg, Context context) {\n        try {\n            context.getLogger().log(\"Processed message \" + msg.getBody());\n\n            // TODO: Do interesting work based on the new message\n\n        } catch (Exception e) {\n            context.getLogger().log(\"An error occurred\");\n            throw e;\n        }\n\n    }\n}\n",
                                    "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;\n\npublic class Function implements RequestHandler<SQSEvent, Void> {\n    @Override\n    public Void handleRequest(SQSEvent sqsEvent, Context context) {\n        for (SQSMessage msg : sqsEvent.getRecords()) {\n            processMessage(msg, context);\n        }\n        context.getLogger().log(\"done\");\n        return null;\n    }\n\n    private void processMessage(SQSMessage msg, Context context) {\n        try {\n            context.getLogger().log(\"Processed message \" + msg.getBody());\n\n            // TODO: Do interesting work based on the new message\n\n        } catch (Exception e) {\n            context.getLogger().log(\"An error occurred\");\n            throw e;\n        }\n\n    }\n}\n",
                                    "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const message of event.Records) {\n    await processMessageAsync(message);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(message) {\n  try {\n    console.log(`Processed message ${message.body}`);\n    // TODO: Do interesting work based on the new message\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                                    "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const message of event.Records) {\n    await processMessageAsync(message);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(message) {\n  try {\n    console.log(`Processed message ${message.body}`);\n    // TODO: Do interesting work based on the new message\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                                    "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\InvalidLambdaEvent;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $body = $record->getBody();\n            // TODO: Do interesting work based on the new message\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\InvalidLambdaEvent;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $body = $record->getBody();\n            // TODO: Do interesting work based on the new message\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                                    "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for message in event['Records']:\n        process_message(message)\n    print(\"done\")\n\ndef process_message(message):\n    try:\n        print(f\"Processed message {message['body']}\")\n        # TODO: Do interesting work based on the new message\n    except Exception as err:\n        print(\"An error occurred\")\n        raise err\n\n",
                                    "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for message in event['Records']:\n        process_message(message)\n    print(\"done\")\n\ndef process_message(message):\n    try:\n        print(f\"Processed message {message['body']}\")\n        # TODO: Do interesting work based on the new message\n    except Exception as err:\n        print(\"An error occurred\")\n        raise err\n\n",
                                    "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].each do |message|\n    process_message(message)\n  end\n  puts \"done\"\nend\n\ndef process_message(message)\n  begin\n    puts \"Processed message #{message['body']}\"\n    # TODO: Do interesting work based on the new message\n  rescue StandardError => err\n    puts \"An error occurred\"\n    raise err\n  end\nend\n",
                                    "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].each do |message|\n    process_message(message)\n  end\n  puts \"done\"\nend\n\ndef process_message(message)\n  begin\n    puts \"Processed message #{message['body']}\"\n    # TODO: Do interesting work based on the new message\n  rescue StandardError => err\n    puts \"An error occurred\"\n    raise err\n  end\nend\n",
                                    "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sqs::SqsEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {\n    event.payload.records.iter().for_each(|record| {\n        // process the record\n        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())\n    });\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sqs::SqsEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {\n    event.payload.records.iter().for_each(|record| {\n        // process the record\n        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())\n    });\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SqsIntegrationSampleCode{    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        foreach (var message in evnt.Records)        {            await ProcessMessageAsync(message, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed message {message.Body}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package integration_sqs_to_lambdaimport (\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(event events.SQSEvent) error {\tfor _, record := range event.Records {\t\terr := processMessage(record)\t\tif err != nil {\t\t\treturn err\t\t}\t}\tfmt.Println(\"done\")\treturn nil}func processMessage(record events.SQSMessage) error {\tfmt.Printf(\"Processed message %s\\n\", record.Body)\t// TODO: Do interesting work based on the new message\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SQSEvent;import com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;public class Function implements RequestHandler<SQSEvent, Void> {    @Override    public Void handleRequest(SQSEvent sqsEvent, Context context) {        for (SQSMessage msg : sqsEvent.getRecords()) {            processMessage(msg, context);        }        context.getLogger().log(\"done\");        return null;    }    private void processMessage(SQSMessage msg, Context context) {        try {            context.getLogger().log(\"Processed message \" + msg.getBody());            // TODO: Do interesting work based on the new message        } catch (Exception e) {            context.getLogger().log(\"An error occurred\");            throw e;        }    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const message of event.Records) {    await processMessageAsync(message);  }  console.info(\"done\");};async function processMessageAsync(message) {  try {    console.log(`Processed message ${message.body}`);    // TODO: Do interesting work based on the new message    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}Consuming an SQS event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SQSEvent, Context, SQSHandler, SQSRecord } from \"aws-lambda\";export const functionHandler: SQSHandler = async (  event: SQSEvent,  context: Context): Promise<void> => {  for (const message of event.Records) {    await processMessageAsync(message);  }  console.info(\"done\");};async function processMessageAsync(message: SQSRecord): Promise<any> {  try {    console.log(`Processed message ${message.body}`);    // TODO: Do interesting work based on the new message    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\InvalidLambdaEvent;use Bref\\Event\\Sqs\\SqsEvent;use Bref\\Event\\Sqs\\SqsHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends SqsHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws InvalidLambdaEvent     */    public function handleSqs(SqsEvent $event, Context $context): void    {        foreach ($event->getRecords() as $record) {            $body = $record->getBody();            // TODO: Do interesting work based on the new message        }    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    for message in event['Records']:        process_message(message)    print(\"done\")def process_message(message):    try:        print(f\"Processed message {message['body']}\")        # TODO: Do interesting work based on the new message    except Exception as err:        print(\"An error occurred\")        raise errRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event:, context:)  event['Records'].each do |message|    process_message(message)  end  puts \"done\"enddef process_message(message)  begin    puts \"Processed message #{message['body']}\"    # TODO: Do interesting work based on the new message  rescue StandardError => err    puts \"An error occurred\"    raise err  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::sqs::SqsEvent;use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {    event.payload.records.iter().for_each(|record| {        // process the record        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())    });    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SqsIntegrationSampleCode{    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        foreach (var message in evnt.Records)        {            await ProcessMessageAsync(message, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed message {message.Body}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}",
                                    "To create a Node.js Lambda function",
                                    " 1 : Create a directory for the project, and then switch to that directory. ",
                                    {
                                        "code_example": "mkdir sqs-tutorial\ncd sqs-tutorial"
                                    },
                                    "  2 : Copy the sample JavaScript code into a new file named index.js.",
                                    " 3 : Create a deployment package using the following zip command. ",
                                    {
                                        "code_example": "zip function.zip index.js"
                                    },
                                    " 4 : Create a Lambda function using the create-function          AWS CLI command. For the role parameter, enter the ARN of the execution role          that you created earlier.NoteThe Lambda function and the Amazon SQS queue must be in the same AWS Region. ",
                                    {
                                        "code_example": "aws lambda create-function --function-name ProcessSQSRecord \\\n--zip-file fileb://function.zip --handler index.handler --runtime nodejs18.x \\\n--role arn:aws:iam::111122223333:role/lambda-sqs-role"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Test the function",
                                "content": [
                                    "Invoke your Lambda function manually using the invoke AWS CLI command and a sample Amazon SQS      event.",
                                    "To invoke the Lambda function with a sample event",
                                    " 1 : Save the following JSON as a file named input.json. This JSON simulates an event that Amazon SQS might send to your Lambda function, where            \"body\" contains the actual message from the queue. In this example, the message is \"test\".Example  Amazon SQS eventThis is a test event—you don't need to change the message or the account number. ",
                                    {
                                        "code_example": "{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n            \"body\": \"test\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"098f6bcd4621d373cade4e832627b4f6\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-1:111122223333:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        }\n    ]\n}"
                                    },
                                    " 2 : Run the following invoke AWS CLI command. This command returns CloudWatch logs in the response. For more information about retrieving logs, see Access logs with the AWS CLI. The cli-binary-format option is required if you're using AWS CLI version 2. To make this the default setting, run aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide for Version 2.",
                                    {
                                        "code_example": "aws lambda invoke --function-name ProcessSQSRecord --payload file://input.json out --log-type Tail \\\n--query 'LogResult' --output text --cli-binary-format raw-in-base64-out | base64 --decode"
                                    },
                                    " 3 : Find the INFO log in the response. This is where the Lambda function logs the message body.          You should see logs that look like this: ",
                                    {
                                        "code_example": "2023-09-11T22:45:04.271Z\t348529ce-2211-4222-9099-59d07d837b60\tINFO\tProcessed message test\n2023-09-11T22:45:04.288Z\t348529ce-2211-4222-9099-59d07d837b60\tINFO\tdone"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create an Amazon SQS queue",
                                "content": [
                                    "Create an Amazon SQS queue that the Lambda function can use as an event source. The Lambda function and the Amazon SQS queue must be in the same AWS Region.",
                                    "To create a queue",
                                    "  1 : Open the Amazon SQS console.",
                                    "  2 : Choose Create queue.",
                                    "  3 : Enter a name for the queue. Leave all other options at the default settings.",
                                    "  4 : Choose Create queue.",
                                    "After creating the queue, note down its ARN. You need this in the next step when you      associate the queue with your Lambda function."
                                ]
                            },
                            {
                                "sub_header": "Configure the event source",
                                "content": [
                                    "Connect the Amazon SQS queue to your Lambda function by creating an event source mapping. The event source mapping reads the Amazon SQS queue and invokes your Lambda function when a new message is added.",
                                    "To create a mapping between your Amazon SQS queue and your Lambda function, use the create-event-source-mapping AWS CLI command. Example:",
                                    "aws lambda create-event-source-mapping --function-name ProcessSQSRecord  --batch-size 10 \\--event-source-arn arn:aws:sqs:us-east-1:111122223333:my-queue",
                                    "To get a list of your event source mappings, use the list-event-source-mappings command. Example:",
                                    "aws lambda list-event-source-mappings --function-name ProcessSQSRecord"
                                ]
                            },
                            {
                                "sub_header": "Send a test message",
                                "content": [
                                    "To send an Amazon SQS message to the Lambda function",
                                    "  1 : Open the Amazon SQS console.",
                                    "  2 : Choose the queue that you created earlier.",
                                    "  3 : Choose Send and receive messages.",
                                    "  4 : Under Message body, enter a test message, such as \"this is a test message.\"",
                                    "  5 : Choose Send message.",
                                    "Lambda polls the queue for updates. When there is a new message, Lambda invokes your function with this new      event data from the queue. If the function handler returns without exceptions, Lambda considers the message successfully processed and      begins reading new messages in the queue. After successfully processing a message, Lambda automatically deletes it      from the queue. If the handler throws an exception, Lambda considers the batch of messages not successfully      processed, and Lambda invokes the function with the same batch of messages."
                                ]
                            },
                            {
                                "sub_header": "Check the CloudWatch logs",
                                "content": [
                                    "To confirm that the function processed the message",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Choose the ProcessSQSRecord function.",
                                    "  3 : Choose Monitor.",
                                    "  4 : Choose View CloudWatch logs.",
                                    "  5 : In the CloudWatch console, choose the Log stream for the function.",
                                    " 6 : Find the INFO log. This is where the Lambda function logs the message body. You should see the message that you sent from the Amazon SQS queue. Example: ",
                                    {
                                        "code_example": "2023-09-11T22:49:12.730Z b0c41e9c-0556-5a8b-af83-43e59efeec71 INFO Processed message this is a test message."
                                    }
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the Amazon SQS queue",
                                    "  1 : Sign in to the AWS Management Console and open the Amazon SQS console at         https://console.aws.amazon.com/sqs/.",
                                    "  2 : Select the queue you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter confirm in the text input field.",
                                    "  5 : Choose Delete."
                                ]
                            }
                        ]
                    },
                    {
                        "title": "SQS cross-account tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sqs-cross-account-example.html",
                        "sections": [
                            "In this tutorial, you create a Lambda function that consumes messages from an Amazon Simple Queue Service (Amazon SQS) queue in a    different AWS account. This tutorial involves two AWS accounts: Account A refers to the    account that contains your Lambda function, and Account B refers to the account that contains    the Amazon SQS queue.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "This tutorial assumes that you have some knowledge of basic Lambda operations and the Lambda console. If you      haven't already, follow the instructions in Create a Lambda function with the console to create your first Lambda function.",
                                    "To complete the following steps, you need the AWS CLI version 2. Commands and the expected output are listed in separate blocks:",
                                    "aws --version",
                                    "You should see the following output:",
                                    "aws-cli/2.13.27 Python/3.11.6 Linux/4.14.328-248.540.amzn2.x86_64 exe/x86_64.amzn.2",
                                    "For long commands, an escape character (\\) is used to split a command over multiple lines.",
                                    "On Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.     To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.     Example CLI commands in this guide use Linux formatting. Commands which include inline JSON documents must be reformatted if you are using the Windows CLI.    "
                                ]
                            },
                            {
                                "sub_header": "Create the execution role (Account A)",
                                "content": [
                                    "In Account A, create an execution role      that gives your function permission to access the required AWS resources.",
                                    "To create an execution role",
                                    "  1 : Open the Roles page in the AWS Identity and Access Management (IAM)          console.",
                                    "  2 : Choose Create role.",
                                    "  3 : Create a role with the following properties.Trusted entity –              AWS LambdaPermissions –              AWSLambdaSQSQueueExecutionRoleRole name –              cross-account-lambda-sqs-role",
                                    "The AWSLambdaSQSQueueExecutionRole policy has the permissions that the function needs to      read items from Amazon SQS and to write logs to Amazon CloudWatch Logs."
                                ]
                            },
                            {
                                "sub_header": "Create the function (Account A)",
                                "content": [
                                    "In Account A, create a Lambda function that processes your Amazon SQS messages. The Lambda function and the Amazon SQS queue must be in the same AWS Region.",
                                    "The following Node.js 18 code example writes each message to a log in CloudWatch Logs.",
                                    "Example index.mjs",
                                    {
                                        "code_example": "export const handler = async function(event, context) {\n  event.Records.forEach(record => {\n    const { body } = record;\n    console.log(body);\n  });\n  return {};\n}"
                                    },
                                    "To create the function",
                                    "Note",
                                    "Following these steps creates a function in Node.js 18. For other languages, the steps are similar, but          some details are different.",
                                    "  1 : Save the code example as a file named index.mjs.",
                                    " 2 : Create a deployment package. ",
                                    {
                                        "code_example": "zip function.zip index.mjs"
                                    },
                                    " 3 : Create the function using the create-function AWS Command Line Interface (AWS CLI) command. ",
                                    {
                                        "code_example": "aws lambda create-function --function-name CrossAccountSQSExample \\\n--zip-file fileb://function.zip --handler index.handler --runtime nodejs18.x \\\n--role arn:aws:iam::<AccountA_ID>:role/cross-account-lambda-sqs-role"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Test the function (Account A)",
                                "content": [
                                    "In Account A, test your Lambda function manually using the invoke AWS CLI      command and a sample Amazon SQS event.",
                                    "If the handler returns normally without exceptions, Lambda considers the message to be successfully processed      and begins reading new messages in the queue. After successfully processing a message, Lambda automatically deletes      it from the queue. If the handler throws an exception, Lambda considers the batch of messages not successfully      processed, and Lambda invokes the function with the same batch of messages.",
                                    " 1 : Save the following JSON as a file named input.txt. The preceding JSON simulates an event that Amazon SQS might send to your Lambda function, where            \"body\" contains the actual message from the queue.",
                                    {
                                        "code_example": "{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n            \"body\": \"test\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"098f6bcd4621d373cade4e832627b4f6\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-1:111122223333:example-queue\",\n            \"awsRegion\": \"us-east-1\"\n        }\n    ]\n}"
                                    },
                                    " 2 : Run the following invoke AWS CLI command. The cli-binary-format option is required if you're using AWS CLI version 2. To make this the default setting, run aws configure set cli-binary-format raw-in-base64-out. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide for Version 2.",
                                    {
                                        "code_example": "aws lambda invoke --function-name CrossAccountSQSExample \\\n--cli-binary-format raw-in-base64-out \\\n--payload file://input.txt outputfile.txt"
                                    },
                                    "  3 : Verify the output in the file outputfile.txt."
                                ]
                            },
                            {
                                "sub_header": "Create an Amazon SQS queue (Account B)",
                                "content": [
                                    "In Account B, create an Amazon SQS queue that the Lambda function in Account      A can use as an event source. The Lambda function and the Amazon SQS queue must be in the same AWS Region.",
                                    "To create a queue",
                                    "  1 : Open the Amazon SQS console.",
                                    "  2 : Choose Create queue.",
                                    " 3 : Create a queue with the following properties.Type – StandardName – LambdaCrossAccountQueueConfiguration – Keep the default settings.Access policy – Choose Advanced. Paste in the              following JSON policy: This policy grants the Lambda execution role in Account A permissions to consume              messages from this Amazon SQS queue.",
                                    {
                                        "code_example": "{\n   \"Version\": \"2012-10-17\",\n   \"Id\": \"Queue1_Policy_UUID\",\n   \"Statement\": [{\n      \"Sid\":\"Queue1_AllActions\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n         \"AWS\": [\n            \"arn:aws:iam::<AccountA_ID>:role/cross-account-lambda-sqs-role\"\n         ]\n      },\n      \"Action\": \"sqs:*\",\n      \"Resource\": \"arn:aws:sqs:us-east-1:<AccountB_ID>:LambdaCrossAccountQueue\"\n    }\n  ]\n}"
                                    },
                                    "  4 : After creating the queue, record its Amazon Resource Name (ARN). You need this in the next step when you          associate the queue with your Lambda function."
                                ]
                            },
                            {
                                "sub_header": "Configure the event source (Account A)",
                                "content": [
                                    "In Account A, create an event source mapping between the Amazon SQS queue in Account        B and your Lambda function by running the following create-event-source-mapping AWS CLI      command.",
                                    "aws lambda create-event-source-mapping --function-name CrossAccountSQSExample --batch-size 10 \\--event-source-arn arn:aws:sqs:us-east-1:<AccountB_ID>:LambdaCrossAccountQueue",
                                    "To get a list of your event source mappings, run the following command.",
                                    "aws lambda list-event-source-mappings --function-name CrossAccountSQSExample \\--event-source-arn arn:aws:sqs:us-east-1:<AccountB_ID>:LambdaCrossAccountQueue"
                                ]
                            },
                            {
                                "sub_header": "Test the setup",
                                "content": [
                                    "You can now test the setup as follows:",
                                    "  1 : In Account B, open the Amazon SQS console.",
                                    "  2 : Choose LambdaCrossAccountQueue, which you created earlier.",
                                    "  3 : Choose Send and receive messages.",
                                    "  4 : Under Message body, enter a test message.",
                                    "  5 : Choose Send message.",
                                    "Your Lambda function in Account A should receive the message. Lambda will continue to poll      the queue for updates. When there is a new message, Lambda invokes your function with this new event data from the      queue. Your function runs and creates logs in Amazon CloudWatch. You can view the logs in the CloudWatch console."
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "In Account A, clean up your execution role and Lambda function.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "In Account B, clean up the Amazon SQS queue.",
                                    "To delete the Amazon SQS queue",
                                    "  1 : Sign in to the AWS Management Console and open the Amazon SQS console at         https://console.aws.amazon.com/sqs/.",
                                    "  2 : Select the queue you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter confirm in the text input field.",
                                    "  5 : Choose Delete."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "Note",
                    "If you want to send data to a target other than a Lambda function or enrich the data before sending it, see     Amazon EventBridge Pipes.",
                    "You can use a Lambda function to process messages in an Amazon Simple Queue Service (Amazon SQS) queue. Lambda    supports both     standard queues and       first-in, first-out (FIFO) queues for event source mappings. The Lambda function and the Amazon SQS queue must be in the same AWS Region, although they can be in different AWS accounts.",
                    "Topics",
                    {
                        "sub_header": "Understanding polling and batching behavior for Amazon SQS event source mappings",
                        "content": [
                            "With Amazon SQS event source mappings, Lambda polls the queue and invokes your function       synchronously with an event. Each event can contain a batch of multiple messages from the queue. Lambda receives      these events one batch at a time, and invokes your function once for each batch. When your function successfully      processes a batch, Lambda deletes its messages from the queue.",
                            "When Lambda receives a batch, the messages stay in the queue but are hidden for the length of the queue's            visibility timeout. If your function successfully processes all messages in the batch, Lambda deletes      the messages from the queue. By default, if your function encounters an error while processing a batch, all      messages in that batch become visible in the queue again after the visibility timeout expires. For this reason,      your function code must be able to process the same message multiple times without unintended side effects.",
                            "Warning",
                            "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                            "To prevent Lambda from processing a message multiple times, you can either configure your event source      mapping to include batch item failures in your      function response, or you can use the DeleteMessage API to      remove messages from the queue as  your Lambda function successfully processes them.",
                            "For more information about configuration parameters that Lambda supports for SQS event source      mappings, see Creating an SQS event source mapping."
                        ]
                    },
                    {
                        "sub_header": "Example standard queue message event",
                        "content": [
                            "Example Amazon SQS message event (standard queue)",
                            {
                                "code_example": "{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n            \"body\": \"Test message.\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {\n                \"myAttribute\": {\n                    \"stringValue\": \"myValue\", \n                    \"stringListValues\": [], \n                    \"binaryListValues\": [], \n                    \"dataType\": 'String'\n                }\n            },\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n            \"awsRegion\": \"us-east-2\"\n        },\n        {\n            \"messageId\": \"2e1424d4-f796-459a-8184-9c92662be6da\",\n            \"receiptHandle\": \"AQEBzWwaftRI0KuVm4tP+/7q1rGgNqicHq...\",\n            \"body\": \"Test message.\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082650636\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082650649\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n            \"awsRegion\": \"us-east-2\"\n        }\n    ]\n}"
                            },
                            "By default, Lambda polls up to 10 messages in your queue at once and sends that batch to your function. To avoid      invoking the function with a small number of records, you can configure the event source to buffer records for up      to 5 minutes by configuring a batch window. Before invoking the function, Lambda continues to poll messages from the      standard queue until the batch window expires, the invocation payload size      quota is reached, or the configured maximum batch size is reached.",
                            "If you're using a batch window and your SQS queue contains very low traffic, Lambda might wait for up to 20      seconds before invoking your function. This is true even if you set a batch window lower than 20 seconds.    ",
                            "Note",
                            "In Java, you might experience null pointer errors when deserializing JSON. This could be due to how case of  \"Records\" and \"eventSourceARN\" is converted by the JSON object mapper."
                        ]
                    },
                    {
                        "sub_header": " Example FIFO queue message event",
                        "content": [
                            "For FIFO queues, records contain additional attributes that are related to deduplication and sequencing.",
                            "Example Amazon SQS message event (FIFO queue)",
                            {
                                "code_example": "{\n    \"Records\": [\n        {\n            \"messageId\": \"11d6ee51-4cc7-4302-9e22-7cd8afdaadf5\",\n            \"receiptHandle\": \"AQEBBX8nesZEXmkhsmZeyIE8iQAMig7qw...\",\n            \"body\": \"Test message.\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1573251510774\",\n                \"SequenceNumber\": \"18849496460467696128\",\n                \"MessageGroupId\": \"1\",\n                \"SenderId\": \"AIDAIO23YVJENQZJOL4VO\",\n                \"MessageDeduplicationId\": \"1\",\n                \"ApproximateFirstReceiveTimestamp\": \"1573251510774\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:fifo.fifo\",\n            \"awsRegion\": \"us-east-2\"\n        }\n    ]\n}"
                            }
                        ]
                    }
                ]
            },
            {
                "title": "S3 Batch",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/services-s3-batch.html",
                "sections": [
                    "You can use Amazon S3 batch operations to invoke a Lambda function on a large set of Amazon S3 objects. Amazon S3    tracks the progress of batch operations, sends notifications, and stores a completion report that shows the status    of each action. ",
                    "To run a batch operation, you create an Amazon S3 batch operations job. When you create    the job, you provide a manifest (the list of objects) and configure the action to perform on those objects. ",
                    "When the batch job starts, Amazon S3 invokes the Lambda function synchronously for each object in the manifest.    The event parameter includes the names of the bucket and the object. ",
                    "The following example shows the event that Amazon S3 sends to the Lambda function for an object that is named      customerImage1.jpg in the amzn-s3-demo-bucket    bucket.",
                    "Example Amazon S3 batch request event",
                    {
                        "code_example": "\n{\n\"invocationSchemaVersion\": \"1.0\",\n    \"invocationId\": \"YXNkbGZqYWRmaiBhc2RmdW9hZHNmZGpmaGFzbGtkaGZza2RmaAo\",\n    \"job\": {\n        \"id\": \"f3cc4f60-61f6-4a2b-8a21-d07600c373ce\"\n    },\n    \"tasks\": [\n        {\n            \"taskId\": \"dGFza2lkZ29lc2hlcmUK\",\n            \"s3Key\": \"customerImage1.jpg\",\n            \"s3VersionId\": \"1\",\n            \"s3BucketArn\": \"arn:aws:s3:::amzn-s3-demo-bucket\"\n        }\n    ]  \n}"
                    },
                    "Your Lambda function must return a JSON object with the fields as shown in the following example. You can copy the    invocationId and taskId from the event parameter. You can return a string in the resultString.    Amazon S3 saves the resultString values in the completion report. ",
                    "Example Amazon S3 batch request response",
                    {
                        "code_example": "\n{\n  \"invocationSchemaVersion\": \"1.0\",\n  \"treatMissingKeysAs\" : \"PermanentFailure\",\n  \"invocationId\" : \"YXNkbGZqYWRmaiBhc2RmdW9hZHNmZGpmaGFzbGtkaGZza2RmaAo\",\n  \"results\": [\n    {\n      \"taskId\": \"dGFza2lkZ29lc2hlcmUK\",\n      \"resultCode\": \"Succeeded\",\n      \"resultString\": \"[\\\"Alice\\\", \\\"Bob\\\"]\"\n    }\n  ]\n}\n  "
                    },
                    {
                        "sub_header": "Invoking Lambda functions from Amazon S3 batch operations ",
                        "content": [
                            "You can invoke the Lambda function with an unqualified or qualified function ARN. If you want to use the same      function version for the entire batch job, configure a specific function version in the FunctionARN      parameter when you create your job. If you configure an alias or the $LATEST qualifier, the batch job immediately      starts calling the new version of the function if the alias or $LATEST is updated during the job execution. ",
                            "Note that you can't reuse an existing Amazon S3 event-based function for batch operations. This is because the Amazon S3      batch operation passes a different event parameter to the Lambda function and expects a return message with a      specific JSON structure.",
                            "In the resource-based policy that you create for the Amazon S3      batch job, ensure that you set permission for the job to invoke your Lambda function.",
                            "In the execution role for the function, set a trust policy for Amazon S3 to assume the role when it runs your      function.",
                            "If your function uses the AWS SDK to manage Amazon S3 resources, you need to add Amazon S3 permissions in the  execution role. ",
                            "When the job runs, Amazon S3 starts multiple function instances to process the Amazon S3 objects in parallel, up to      the concurrency limit of the function. Amazon S3 limits the initial ramp-up of instances      to avoid excess cost for smaller jobs. ",
                            "If the Lambda function returns a TemporaryFailure response code, Amazon S3 retries the operation. ",
                            "For more information about Amazon S3 batch operations, see Performing batch operations in the        Amazon S3 Developer Guide. ",
                            "For an example of how to use a Lambda function in Amazon S3 batch operations, see Invoking a Lambda function from Amazon S3        batch operations in the Amazon S3 Developer Guide. "
                        ]
                    }
                ]
            },
            {
                "title": "SNS",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sns.html",
                "contents": [
                    {
                        "title": "Tutorial",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/with-sns-example.html",
                        "sections": [
                            "In this tutorial, you use a Lambda function in one AWS account to subscribe to an Amazon Simple Notification Service (Amazon SNS) topic in a separate AWS account. When     you publish messages to your Amazon SNS topic, your Lambda function reads the contents of the message and outputs it to Amazon CloudWatch Logs. To complete this     tutorial, you use the AWS Command Line Interface (AWS CLI).",
                            "To complete this tutorial, you perform the following steps:",
                            "  1.account A : In , create an Amazon SNS topic.",
                            "  2.account B : In , create a Lambda function that will read messages from the topic.",
                            "  3.account B : In , create a subscription to the topic.",
                            "  4.account A : Publish messages to the Amazon SNS topic in  and confirm that the Lambda function in         account B outputs them to CloudWatch Logs.",
                            "By completing these steps, you will learn how to configure an Amazon SNS topic to invoke a Lambda function. You will also learn how to create an    AWS Identity and Access Management (IAM) policy that gives permission for a resource in another AWS account to invoke Lambda.",
                            "In the tutorial, you use two separate AWS accounts. The AWS CLI commands illustrate this by using two named profiles called accountA     and accountB, each configured for use with a different AWS account. To learn how to configure the AWS CLI to use different profiles,     see Configuration and credential file settings in the     AWS Command Line Interface User Guide for Version 2. Be sure to configure the same default AWS Region for both profiles.",
                            "If the AWS CLI profiles you create for the two AWS accounts use different names, or if you use the default profile and one named profile,     modify the AWS CLI commands in the following steps as needed.",
                            {
                                "sub_header": "Prerequisites",
                                "content": [
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "Sign up for an AWS account",
                                    "If you do not have an AWS account, complete the following steps to create one.",
                                    "To sign up for an AWS account",
                                    "  1 : Open https://portal.aws.amazon.com/billing/signup.",
                                    "  2 : Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.",
                                    "AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "If you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.Sign up for an AWS accountIf you do not have an AWS account, complete the following steps to create one.To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.Follow the online instructions.Part of the sign-up procedure involves receiving a phone call and entering   a verification code on the phone keypad.When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.AWS sends you a confirmation email after the sign-up process iscomplete. At any time, you can view your current account activity and manage your account bygoing to https://aws.amazon.com/ and choosing My  Account.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "Create a user with administrative access",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.",
                                    "Secure your AWS account root user",
                                    "  1 :  Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.",
                                    "  2 : Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.",
                                    "Create a user with administrative access",
                                    "  1 : Enable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.",
                                    "  2 : In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.",
                                    "Sign in as the user with administrative access",
                                    "  1.To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.",
                                    "Assign access to additional users",
                                    "  1 : In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.",
                                    "  2 : Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.Create a user with administrative accessAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you don't use the root user for everyday tasks.Secure your AWS account root user Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.Turn on multi-factor authentication (MFA) for your root user.For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide.Create a user with administrative accessEnable IAM Identity Center.For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User Guide.In IAM Identity Center, grant administrative access to a user.For a tutorial about using the IAM Identity Center directory as your identity source, see  Configure user access with the default IAM Identity Center directory in the AWS IAM Identity Center User Guide.Sign in as the user with administrative accessTo sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.Assign access to additional usersIn IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.For instructions, see  Create a permission set in the AWS IAM Identity Center User Guide.Assign users to a group, and then assign single sign-on access to the group.For instructions, see  Add groups in the AWS IAM Identity Center User Guide.",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "Install the AWS Command Line Interface",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.",
                                    "The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.",
                                    "Note",
                                    "In Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          ",
                                    "If you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          Install the AWS Command Line InterfaceIf you have not yet installed the AWS Command Line Interface, follow the steps at  Installing or updating the latest version of the AWS CLI           to install it.The tutorial requires a command line terminal or shell to run commands. In Linux and macOS, use your preferred shell and package manager.NoteIn Windows, some Bash CLI commands that you commonly use with Lambda (such as zip) are not supported by the operating system's built-in terminals.             To get a Windows-integrated version of Ubuntu and Bash, install the Windows Subsystem for Linux.          "
                                ]
                            },
                            {
                                "sub_header": "Create an Amazon SNS topic (account A)",
                                "content": [
                                    "To create the topic",
                                    "  1.account A : In , create an Amazon SNS standard topic using the following AWS CLI command.aws sns create-topic --name sns-topic-for-lambda --profile accountAYou should see output similar to the following.{    \"TopicArn\": \"arn:aws:sns:us-west-2:123456789012:sns-topic-for-lambda\"}Make a note of the Amazon Resource Name (ARN) of your topic. You’ll need it later in the tutorial when you add permissions to your           Lambda function to subscribe to the topic.",
                                    {
                                        "code_example": "aws sns create-topic --name sns-topic-for-lambda --profile accountA"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create a function execution role (account B)",
                                "content": [
                                    "An execution role is an IAM role that grants a Lambda function permission to access AWS services and resources. Before you create your       function in account B, you create a role that gives the function basic permissions to write logs to       CloudWatch Logs. We’ll add the permissions to read from your Amazon SNS topic in a later step.",
                                    "To create an execution role",
                                    "  1 : In account B open the roles page in the           IAM console.",
                                    "  2 : Choose Create role.",
                                    "  3 : For Trusted entity type, choose AWS service.",
                                    "  4 : For Use case, choose Lambda.",
                                    "  5 : Choose Next.",
                                    "  6 : Add a basic permissions policy to the role by doing the following:In the Permissions policies search box, enter AWSLambdaBasicExecutionRole.Choose Next.",
                                    "  7 : Finalize the role creation by doing the following:Under Role details, enter lambda-sns-role for Role name.Choose Create role."
                                ]
                            },
                            {
                                "sub_header": "Create a Lambda function (account B)",
                                "content": [
                                    "Create a Lambda function that processes your Amazon SNS messages. The function code logs the message      contents of each record to Amazon CloudWatch Logs.",
                                    "This tutorial uses the Node.js 18.x runtime, but we've also provided example code in other      runtime languages. You can select the tab in the following box to see code for the runtime      you're interested in. The JavaScript code you'll use in this step is in the first example      shown in the JavaScript tab.",
                                    "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                                    "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                                    "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, snsEvent events.SNSEvent) {\n\tfor _, record := range snsEvent.Records {\n\t\tprocessMessage(record)\n\t}\n\tfmt.Println(\"done\")\n}\n\nfunc processMessage(record events.SNSEventRecord) {\n\tmessage := record.SNS.Message\n\tfmt.Printf(\"Processed message: %s\\n\", message)\n\t// TODO: Process your record here\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, snsEvent events.SNSEvent) {\n\tfor _, record := range snsEvent.Records {\n\t\tprocessMessage(record)\n\t}\n\tfmt.Println(\"done\")\n}\n\nfunc processMessage(record events.SNSEventRecord) {\n\tmessage := record.SNS.Message\n\tfmt.Printf(\"Processed message: %s\\n\", message)\n\t// TODO: Process your record here\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                                    "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;\n\n\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {\n    LambdaLogger logger;\n\n    @Override\n    public Boolean handleRequest(SNSEvent event, Context context) {\n        logger = context.getLogger();\n        List<SNSRecord> records = event.getRecords();\n        if (!records.isEmpty()) {\n            Iterator<SNSRecord> recordsIter = records.iterator();\n            while (recordsIter.hasNext()) {\n                processRecord(recordsIter.next());\n            }\n        }\n        return Boolean.TRUE;\n    }\n\n    public void processRecord(SNSRecord record) {\n        try {\n            String message = record.getSNS().getMessage();\n            logger.log(\"message: \" + message);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n\n\n\n\n",
                                    "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;\n\n\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {\n    LambdaLogger logger;\n\n    @Override\n    public Boolean handleRequest(SNSEvent event, Context context) {\n        logger = context.getLogger();\n        List<SNSRecord> records = event.getRecords();\n        if (!records.isEmpty()) {\n            Iterator<SNSRecord> recordsIter = records.iterator();\n            while (recordsIter.hasNext()) {\n                processRecord(recordsIter.next());\n            }\n        }\n        return Boolean.TRUE;\n    }\n\n    public void processRecord(SNSRecord record) {\n        try {\n            String message = record.getSNS().getMessage();\n            logger.log(\"message: \" + message);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n\n\n\n\n",
                                    "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    await processMessageAsync(record);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(record) {\n  try {\n    const message = JSON.stringify(record.Sns.Message);\n    console.log(`Processed message ${message}`);\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                                    "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    await processMessageAsync(record);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(record) {\n  try {\n    const message = JSON.stringify(record.Sns.Message);\n    console.log(`Processed message ${message}`);\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                                    "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n/* \nSince native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.\nFor more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/function\n\nAnother approach would be to create a custom runtime. \nA practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/\n*/\n\n// Additional composer packages may be required when using Bref or any other PHP functions runtime.\n// require __DIR__ . '/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sns\\SnsEvent;\nuse Bref\\Event\\Sns\\SnsHandler;\n\nclass Handler extends SnsHandler\n{\n    public function handleSns(SnsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $message = $record->getMessage();\n\n            // TODO: Implement your custom processing logic here\n            // Any exception thrown will be logged and the invocation will be marked as failed\n\n            echo \"Processed Message: $message\" . PHP_EOL;\n        }\n    }\n}\n\nreturn new Handler();\n\n",
                                    "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n/* \nSince native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.\nFor more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/function\n\nAnother approach would be to create a custom runtime. \nA practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/\n*/\n\n// Additional composer packages may be required when using Bref or any other PHP functions runtime.\n// require __DIR__ . '/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sns\\SnsEvent;\nuse Bref\\Event\\Sns\\SnsHandler;\n\nclass Handler extends SnsHandler\n{\n    public function handleSns(SnsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $message = $record->getMessage();\n\n            // TODO: Implement your custom processing logic here\n            // Any exception thrown will be logged and the invocation will be marked as failed\n\n            echo \"Processed Message: $message\" . PHP_EOL;\n        }\n    }\n}\n\nreturn new Handler();\n\n",
                                    "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        process_message(record)\n    print(\"done\")\n\ndef process_message(record):\n    try:\n        message = record['Sns']['Message']\n        print(f\"Processed message {message}\")\n        # TODO; Process your record here\n        \n    except Exception as e:\n        print(\"An error occurred\")\n        raise e\n\n",
                                    "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        process_message(record)\n    print(\"done\")\n\ndef process_message(record):\n    try:\n        message = record['Sns']['Message']\n        print(f\"Processed message {message}\")\n        # TODO; Process your record here\n        \n    except Exception as e:\n        print(\"An error occurred\")\n        raise e\n\n",
                                    "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].map { |record| process_message(record) }\nend\n\ndef process_message(record)\n  message = record['Sns']['Message']\n  puts(\"Processing message: #{message}\")\nrescue StandardError => e\n  puts(\"Error processing message: #{e}\")\n  raise\nend\n\n",
                                    "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].map { |record| process_message(record) }\nend\n\ndef process_message(record)\n  message = record['Sns']['Message']\n  puts(\"Processing message: #{message}\")\nrescue StandardError => e\n  puts(\"Error processing message: #{e}\")\n  raise\nend\n\n",
                                    "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sns::SnsEvent;\nuse aws_lambda_events::sns::SnsRecord;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse tracing::info;\n\n// Built with the following dependencies:\n//  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }\n//  lambda_runtime = \"0.8.1\"\n//  tokio = { version = \"1\", features = [\"macros\"] }\n//  tracing = { version = \"0.1\", features = [\"log\"] }\n//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n\nasync fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {\n    for event in event.payload.records {\n        process_record(&event)?;\n    }\n    \n    Ok(())\n}\n\nfn process_record(record: &SnsRecord) -> Result<(), Error> {\n    info!(\"Processing SNS Message: {}\", record.sns.message);\n\n    // Implement your record handling code here.\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sns::SnsEvent;\nuse aws_lambda_events::sns::SnsRecord;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse tracing::info;\n\n// Built with the following dependencies:\n//  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }\n//  lambda_runtime = \"0.8.1\"\n//  tokio = { version = \"1\", features = [\"macros\"] }\n//  tracing = { version = \"0.1\", features = [\"log\"] }\n//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n\nasync fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {\n    for event in event.payload.records {\n        process_record(&event)?;\n    }\n    \n    Ok(())\n}\n\nfn process_record(record: &SnsRecord) -> Result<(), Error> {\n    info!(\"Processing SNS Message: {}\", record.sns.message);\n\n    // Implement your record handling code here.\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SNSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SnsIntegration;public class Function{    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            await ProcessRecordAsync(record, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, snsEvent events.SNSEvent) {\tfor _, record := range snsEvent.Records {\t\tprocessMessage(record)\t}\tfmt.Println(\"done\")}func processMessage(record events.SNSEventRecord) {\tmessage := record.SNS.Message\tfmt.Printf(\"Processed message: %s\\n\", message)\t// TODO: Process your record here}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.LambdaLogger;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SNSEvent;import com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;import java.util.Iterator;import java.util.List;public class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {    LambdaLogger logger;    @Override    public Boolean handleRequest(SNSEvent event, Context context) {        logger = context.getLogger();        List<SNSRecord> records = event.getRecords();        if (!records.isEmpty()) {            Iterator<SNSRecord> recordsIter = records.iterator();            while (recordsIter.hasNext()) {                processRecord(recordsIter.next());            }        }        return Boolean.TRUE;    }    public void processRecord(SNSRecord record) {        try {            String message = record.getSNS().getMessage();            logger.log(\"message: \" + message);        } catch (Exception e) {            throw new RuntimeException(e);        }    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    await processMessageAsync(record);  }  console.info(\"done\");};async function processMessageAsync(record) {  try {    const message = JSON.stringify(record.Sns.Message);    console.log(`Processed message ${message}`);    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}Consuming an SNS event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SNSEvent, Context, SNSHandler, SNSEventRecord } from \"aws-lambda\";export const functionHandler: SNSHandler = async (  event: SNSEvent,  context: Context): Promise<void> => {  for (const record of event.Records) {    await processMessageAsync(record);  }  console.info(\"done\");};async function processMessageAsync(record: SNSEventRecord): Promise<any> {  try {    const message: string = JSON.stringify(record.Sns.Message);    console.log(`Processed message ${message}`);    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php/* Since native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.For more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/functionAnother approach would be to create a custom runtime. A practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/*/// Additional composer packages may be required when using Bref or any other PHP functions runtime.// require __DIR__ . '/vendor/autoload.php';use Bref\\Context\\Context;use Bref\\Event\\Sns\\SnsEvent;use Bref\\Event\\Sns\\SnsHandler;class Handler extends SnsHandler{    public function handleSns(SnsEvent $event, Context $context): void    {        foreach ($event->getRecords() as $record) {            $message = $record->getMessage();            // TODO: Implement your custom processing logic here            // Any exception thrown will be logged and the invocation will be marked as failed            echo \"Processed Message: $message\" . PHP_EOL;        }    }}return new Handler();PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    for record in event['Records']:        process_message(record)    print(\"done\")def process_message(record):    try:        message = record['Sns']['Message']        print(f\"Processed message {message}\")        # TODO; Process your record here            except Exception as e:        print(\"An error occurred\")        raise eRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event:, context:)  event['Records'].map { |record| process_message(record) }enddef process_message(record)  message = record['Sns']['Message']  puts(\"Processing message: #{message}\")rescue StandardError => e  puts(\"Error processing message: #{e}\")  raiseendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::sns::SnsEvent;use aws_lambda_events::sns::SnsRecord;use lambda_runtime::{run, service_fn, Error, LambdaEvent};use tracing::info;// Built with the following dependencies://  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }//  lambda_runtime = \"0.8.1\"//  tokio = { version = \"1\", features = [\"macros\"] }//  tracing = { version = \"0.1\", features = [\"log\"] }//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }async fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {    for event in event.payload.records {        process_record(&event)?;    }        Ok(())}fn process_record(record: &SnsRecord) -> Result<(), Error> {    info!(\"Processing SNS Message: {}\", record.sns.message);    // Implement your record handling code here.    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        .with_target(false)        .without_time()        .init();    run(service_fn(function_handler)).await}",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SNSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SnsIntegration;public class Function{    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            await ProcessRecordAsync(record, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}",
                                    "To create the function",
                                    " 1 : Create a directory for the project, and then switch to that directory. ",
                                    {
                                        "code_example": "mkdir sns-tutorial\ncd sns-tutorial"
                                    },
                                    "  2 : Copy the sample JavaScript code into a new file named index.js.",
                                    " 3 : Create a deployment package using the following zip command. ",
                                    {
                                        "code_example": "zip function.zip index.js"
                                    },
                                    " 4 : Run the following AWS CLI command to create your Lambda function in account B. You should see output similar to the following.{    \"FunctionName\": \"Function-With-SNS\",    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:Function-With-SNS\",    \"Runtime\": \"nodejs18.x\",    \"Role\": \"arn:aws:iam::123456789012:role/lambda_basic_role\",    \"Handler\": \"index.handler\",    ...    \"RuntimeVersionConfig\": {        \"RuntimeVersionArn\": \"arn:aws:lambda:us-west-2::runtime:7d5f06b69c951da8a48b926ce280a9daf2e8bb1a74fc4a2672580c787d608206\"    }}",
                                    {
                                        "code_example": "aws lambda create-function --function-name Function-With-SNS \\\n    --zip-file fileb://function.zip --handler index.handler --runtime nodejs18.x \\\n    --role arn:aws:iam::<AccountB_ID>:role/lambda-sns-role  \\\n    --timeout 60 --profile accountB"
                                    },
                                    "  5 : Record the Amazon Resource Name (ARN) of your function. You’ll need it later in the tutorial          when you add permissions to allow Amazon SNS to invoke your function."
                                ]
                            },
                            {
                                "sub_header": "Add permissions to function (account B)",
                                "content": [
                                    "For Amazon SNS to invoke your function, you need to grant it permission in a statement on a resource-based policy.       You add this statement using the AWS CLI add-permission command.",
                                    "To grant Amazon SNS permission to invoke your function",
                                    "  1.account B : In , run the following AWS CLI command using the ARN for your Amazon SNS topic you recorded earlier.aws lambda add-permission --function-name Function-With-SNS \\    --source-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\    --statement-id function-with-sns --action \"lambda:InvokeFunction\" \\    --principal sns.amazonaws.com --profile accountBYou should see output similar to the following.{    \"Statement\": \"{\\\"Condition\\\":{\\\"ArnLike\\\":{\\\"AWS:SourceArn\\\":      \\\"arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda\\\"}},      \\\"Action\\\":[\\\"lambda:InvokeFunction\\\"],      \\\"Resource\\\":\\\"arn:aws:lambda:us-east-1:<AccountB_ID>:function:Function-With-SNS\\\",      \\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"sns.amazonaws.com\\\"},      \\\"Sid\\\":\\\"function-with-sns\\\"}\"}",
                                    {
                                        "code_example": "aws lambda add-permission --function-name Function-With-SNS \\\n    --source-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\\n    --statement-id function-with-sns --action \"lambda:InvokeFunction\" \\\n    --principal sns.amazonaws.com --profile accountB"
                                    },
                                    "Note",
                                    "If the account with the Amazon SNS topic is hosted in an opt-in AWS Region,         you need to specify the region in the principal. For example, if you're working with an Amazon SNS topic in the Asia Pacific (Hong Kong) region,         you need to specify sns.ap-east-1.amazonaws.com instead of sns.amazonaws.com for the principal. "
                                ]
                            },
                            {
                                "sub_header": "Grant cross-account permission for Amazon SNS subscription (account A)",
                                "content": [
                                    "For your Lambda function in account B to subscribe to the Amazon SNS topic you created in account A,       you need to grant permission for account B to subscribe to your topic. You grant this permission using the       AWS CLI add-permission command. ",
                                    "To grant permission for account B to subscribe to the topic",
                                    "  1.account A : In , run the following AWS CLI command. Use the ARN for the Amazon SNS topic you recorded earlier.aws sns add-permission --label lambda-access --aws-account-id <AccountB_ID> \\    --topic-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\      --action-name Subscribe ListSubscriptionsByTopic --profile accountA",
                                    {
                                        "code_example": "aws sns add-permission --label lambda-access --aws-account-id <AccountB_ID> \\\n    --topic-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\  \n    --action-name Subscribe ListSubscriptionsByTopic --profile accountA"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Create a subscription (account B)",
                                "content": [
                                    "In account B, you now subscribe your Lambda function to the Amazon SNS topic you created at the beginning of the     tutorial in account A. When a message is sent to this topic (sns-topic-for-lambda), Amazon SNS invokes     your Lambda function Function-With-SNS in account B. ",
                                    "To create a subscription",
                                    "  1.account B : In , run the following AWS CLI command. Use your default region you created your topic in and the      ARNs for your topic and Lambda function.aws sns subscribe --protocol lambda \\    --region us-east-1 \\    --topic-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\    --notification-endpoint arn:aws:lambda:us-east-1:<AccountB_ID>:function:Function-With-SNS \\    --profile accountBYou should see output similar to the following.{    \"SubscriptionArn\": \"arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda:5d906xxxx-7c8x-45dx-a9dx-0484e31c98xx\"}",
                                    {
                                        "code_example": "aws sns subscribe --protocol lambda \\\n    --region us-east-1 \\\n    --topic-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\\n    --notification-endpoint arn:aws:lambda:us-east-1:<AccountB_ID>:function:Function-With-SNS \\\n    --profile accountB"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Publish messages to topic (account A and account B)",
                                "content": [
                                    "Now that your Lambda function in account B is subscribed to your Amazon SNS topic in account A,       it’s time to test your setup by publishing messages to your topic. To confirm that Amazon SNS has invoked your Lambda function, you use CloudWatch Logs to view       your function’s output.",
                                    "To publish a message to your topic and view your function's output",
                                    "  1 : Enter Hello World into a text file and save it as message.txt.",
                                    " 2 : From the same directory you saved your text file in, run the following AWS CLI command in account A.         Use the ARN for your own topic. This will return a message ID with a unique identifier, indicating that Amazon SNS has accepted the message. Amazon SNS then attempts to deliver           the message to the topic’s subscribers. To confirm that Amazon SNS has invoked your Lambda function, use CloudWatch Logs to view your function’s output:",
                                    {
                                        "code_example": "aws sns publish --message file://message.txt --subject Test \\\n    --topic-arn arn:aws:sns:us-east-1:<AccountA_ID>:sns-topic-for-lambda \\\n    --profile accountA"
                                    },
                                    "  3 : In account B, open the Log groups page of the Amazon CloudWatch console.",
                                    "  4 : Choose the log group for your function (/aws/lambda/Function-With-SNS).",
                                    "  5 : Choose the most recent log stream.",
                                    " 6 : If your function was correctly invoked, you’ll see output similar to the following showing the contents of the message you published to           your topic. ",
                                    {
                                        "code_example": "2023-07-31T21:42:51.250Z c1cba6b8-ade9-4380-aa32-d1a225da0e48 INFO Processed message Hello World\n2023-07-31T21:42:51.250Z c1cba6b8-ade9-4380-aa32-d1a225da0e48 INFO done"
                                    }
                                ]
                            },
                            {
                                "sub_header": "Clean up your resources",
                                "content": [
                                    "You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.",
                                    "In Account A, clean up your Amazon SNS topic.",
                                    "To delete the Amazon SNS topic",
                                    "  1 : Open the Topics page of the Amazon SNS console.",
                                    "  2 : Select the topic you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter delete me in the text input field.",
                                    "  5 : Choose Delete.",
                                    "In Account B, clean up your execution role, Lambda function, and Amazon SNS subscription.",
                                    "To delete the execution role",
                                    "  1 : Open the Roles page of the IAM console.",
                                    "  2 : Select the execution role that you created.",
                                    "  3 : Choose Delete.",
                                    "  4 : Enter the name of the role in the text input field and choose Delete.",
                                    "To delete the Lambda function",
                                    "  1 : Open the Functions page of the Lambda console.",
                                    "  2 : Select the function that you created.",
                                    "  3 : Choose Actions, Delete.",
                                    "  4 : Type delete in the text input field and choose Delete.",
                                    "To delete the Amazon SNS subscription",
                                    "  1 : Open the Subscriptions page of the Amazon SNS console.",
                                    "  2 : Select the subscription you created.",
                                    "  3 : Choose Delete, Delete."
                                ]
                            }
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "You can use a Lambda function to process Amazon Simple Notification Service (Amazon SNS) notifications. Amazon SNS supports Lambda functions as a    target for messages sent to a topic. You can subscribe your function to topics in the same account or in other AWS    accounts. For a detailed walkthrough, see Tutorial: Using AWS Lambda with Amazon Simple Notification Service.",
                    "Lambda supports SNS triggers for standard SNS topics only. FIFO topics aren't supported.",
                    "For asynchronous invocation, Lambda queues the message and handles retries. If Amazon SNS can't reach Lambda or the    message is rejected, Amazon SNS retries at increasing intervals over several hours. For details, see Reliability in the Amazon SNS FAQs.",
                    "Warning",
                    "Lambda event source mappings process each event at least once, and duplicate processing of records can occur. To avoid potential issues related to duplicate events, we strongly recommend that you make your function code idempotent. To learn more, see How do I make my Lambda function idempotent in the AWS Knowledge Center.",
                    "Topics",
                    {
                        "sub_header": "Adding an Amazon SNS topic trigger for a Lambda function using the console",
                        "content": [
                            "To add an SNS topic as a trigger for a Lambda function, the easiest way is to use      the Lambda console. When you add the trigger via the console, Lambda automatically      sets up the necessary permissions and subscriptions to start receiving events from      the SNS topic.",
                            "To add an SNS topic as a trigger for a Lambda function (console)",
                            "  1 : Open the Functions page of the Lambda console.",
                            "  2 : Choose the name of a function you want to add the trigger for.",
                            "  3 : Choose Configuration, and then choose Triggers.",
                            "  4 : Choose Add trigger.",
                            "  5 : Under Trigger configuration, in the dropdown menu, choose          SNS.",
                            "  6 : For SNS topic, choose the SNS topic to subscribe to."
                        ]
                    },
                    {
                        "sub_header": "Manually adding an Amazon SNS topic trigger for a Lambda function",
                        "content": [
                            "To set up an SNS trigger for a Lambda function manually, you need to complete the following      steps:",
                            "  1.Define a resource-based policy for your function to allow SNS to invoke it.",
                            "  2.Subscribe your Lambda function to the Amazon SNS topic.NoteIf your SNS topic and your Lambda function are in different AWS accounts, you also            need to grant extra permissions to allow cross-account subscriptions to the SNS topic.            For more information, see Grant            cross-account permission for Amazon SNS subscription.",
                            "You can use the AWS Command Line Interface (AWS CLI) to complete both of these steps. First, to define      a resource-based policy for a Lambda function that allows SNS invocations, use the following      AWS CLI command. Be sure to replace the value of --function-name with your      Lambda function name, and the value of --source-arn with your SNS topic ARN.",
                            "aws lambda add-permission --function-name example-function \\    --source-arn arn:aws:sns:us-east-1:123456789012:sns-topic-for-lambda \\    --statement-id function-with-sns --action \"lambda:InvokeFunction\" \\    --principal sns.amazonaws.com",
                            "To subscribe your function to the SNS topic, use the following AWS CLI command. Replace      the value of --topic-arn with your SNS topic ARN, and the value of      --notification-endpoint with your Lambda function ARN.",
                            "aws sns subscribe --protocol lambda \\    --region us-east-1 \\    --topic-arn arn:aws:sns:us-east-1:123456789012:sns-topic-for-lambda \\    --notification-endpoint arn:aws:lambda:us-east-1:123456789012:function:example-function"
                        ]
                    },
                    {
                        "sub_header": "Sample SNS event shape",
                        "content": [
                            "Amazon SNS invokes your function asynchronously with an event that contains a      message and metadata.",
                            "Example Amazon SNS message event",
                            {
                                "code_example": "{\n  \"Records\": [\n    {\n      \"EventVersion\": \"1.0\",\n      \"EventSubscriptionArn\": \"arn:aws:sns:us-east-1:123456789012:sns-lambda:21be56ed-a058-49f5-8c98-aedd2564c486\",\n      \"EventSource\": \"aws:sns\",\n      \"Sns\": {\n        \"SignatureVersion\": \"1\",\n        \"Timestamp\": \"2019-01-02T12:45:07.000Z\",\n        \"Signature\": \"tcc6faL2yUC6dgZdmrwh1Y4cGa/ebXEkAi6RibDsvpi+tE/1+82j...65r==\",\n        \"SigningCertURL\": \"https://sns.us-east-1.amazonaws.com/SimpleNotificationService-ac565b8b1a6c5d002d285f9598aa1d9b.pem\",\n        \"MessageId\": \"95df01b4-ee98-5cb9-9903-4c221d41eb5e\",\n        \"Message\": \"Hello from SNS!\",\n        \"MessageAttributes\": {\n          \"Test\": {\n            \"Type\": \"String\",\n            \"Value\": \"TestString\"\n          },\n          \"TestBinary\": {\n            \"Type\": \"Binary\",\n            \"Value\": \"TestBinary\"\n          }\n        },\n        \"Type\": \"Notification\",\n        \"UnsubscribeUrl\": \"https://sns.us-east-1.amazonaws.com/?Action=Unsubscribe&amp;SubscriptionArn=arn:aws:sns:us-east-1:123456789012:test-lambda:21be56ed-a058-49f5-8c98-aedd2564c486\",\n        \"TopicArn\":\"arn:aws:sns:us-east-1:123456789012:sns-lambda\",\n        \"Subject\": \"TestInvoke\"\n      }\n    }\n  ]\n}"
                            }
                        ]
                    }
                ]
            }
        ],
        "sections": [
            "Some AWS services can directly invoke Lambda functions using triggers. These services push events to Lambda, and the function is invoked immediately when the specified event occurs. Triggers are suitable for discrete events and real-time processing. When you create a trigger using the Lambda console, the console interacts with the corresponding AWS service to configure the event notification on that service. The trigger is actually stored and managed by the service that generates the events, not by Lambda.",
            "The events are data structured in JSON format. The JSON structure varies depending on the service that    generates it and the event type, but they all contain the data that the function needs to process the    event.",
            "A function can have multiple triggers. Each trigger acts as a client invoking your function independently, and each event that    Lambda passes to your function has data from only one trigger. Lambda converts the event document into an object and passes it to your function handler.",
            "Depending on the service, the event-driven invocation can be synchronous or asynchronous.",
            "  1.For synchronous invocation, the service that generates the event waits for the response from your        function. That service defines the data that the function needs to return in the response. The service        controls the error strategy, such as whether to retry on errors.",
            "  2.For asynchronous invocation, Lambda queues the event before passing it to your function. When Lambda        queues the event, it immediately sends a success response to the service that generated the event. After the        function processes the event, Lambda doesn’t return a response to the event-generating service.",
            {
                "sub_header": "Creating a trigger",
                "content": [
                    "The easiest way to create a trigger is to use the Lambda console. When you create a trigger using the console, Lambda automatically adds the required permissions to the function's resource-based policy.",
                    "To create a trigger using the Lambda console",
                    "  1 : Open the Functions page of the Lambda console.",
                    "  2 : Select the function you want to create a trigger for.",
                    "  3 : In the Function overview pane, choose          Add trigger.",
                    "  4 : Select the AWS service you want to invoke your function.",
                    "  5 : Fill out the options in the Trigger configuration pane          and choose Add. Depending on the AWS service you choose to          invoke your function, the trigger configuration options will be different."
                ]
            },
            {
                "sub_header": "Services that can invoke Lambda functions",
                "content": [
                    "The following table lists services that can invoke Lambda functions.",
                    "ServiceMethod of invocationAmazon Managed Streaming for Apache KafkaEvent source mappingSelf-managed Apache KafkaEvent source mappingAmazon API GatewayEvent-driven; synchronous invocationAWS CloudFormationEvent-driven; asynchronous invocationAmazon CloudWatch LogsEvent-driven; asynchronous invocationAWS CodeCommitEvent-driven; asynchronous invocationAWS CodePipelineEvent-driven; asynchronous invocationAmazon CognitoEvent-driven; synchronous invocationAWS ConfigEvent-driven; asynchronous invocationAmazon ConnectEvent-driven; synchronous invocationAmazon DynamoDBEvent source mappingAmazon Elastic File SystemSpecial integrationElastic Load Balancing (Application Load Balancer)Event-driven; synchronous invocationAmazon EventBridge (CloudWatch Events)Event-driven; asynchronous invocation (event buses), synchronous or asynchronous invocation (pipes and schedules)AWS IoTEvent-driven; asynchronous invocationAmazon KinesisEvent source mappingAmazon Data FirehoseEvent-driven; synchronous invocationAmazon LexEvent-driven; synchronous invocationAmazon MQEvent source mappingAmazon Simple Email ServiceEvent-driven; asynchronous invocationAmazon Simple Notification ServiceEvent-driven; asynchronous invocationAmazon Simple Queue ServiceEvent source mappingAmazon Simple Storage Service (Amazon S3)Event-driven; asynchronous invocationAmazon Simple Storage Service BatchEvent-driven; synchronous invocationSecrets ManagerSpecial integrationAWS Step FunctionsEvent-driven; synchronous or asynchronous invocationAmazon VPC LatticeEvent-driven; synchronous invocationAWS X-RaySpecial integration"
                ]
            }
        ]
    },
    {
        "title": "Code examples",
        "href": "https://docs.aws.amazon.com/lambda/latest/dg/service_code_examples.html",
        "contents": [
            {
                "title": "Basics",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/service_code_examples_basics.html",
                "contents": [
                    {
                        "title": "Hello Lambda",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_Hello_section.html",
                        "sections": [
                            "The following code examples show how to get started using Lambda.",
                            "  1..NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
                            "  2.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
                            "  3.C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
                            "  4.SDK for C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
                            "  5.Go : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
                            "  6.SDK for Go V2 : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
                            "  7.Java :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                            "  8.SDK for Java 2.x :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                            "  9.JavaScript : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
                            "  10.SDK for JavaScript (v3) : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
                            "  11.Python : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
                            "  12.SDK for Python (Boto3) : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
                            "  13.Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
                            "  14.SDK for Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    ",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    ",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Learn the basics",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_Scenario_GettingStartedFunctions_section.html",
                        "sections": [
                            "The following code examples show how to:",
                            "  1.Create an IAM role and Lambda function, then upload handler code.",
                            "  2.Invoke the function with a single parameter and get results.",
                            "  3.Update the function code and configure with an environment variable.",
                            "  4.Invoke the function with new parameters and get results. Display the returned execution log.",
                            "  5.List the functions for your account, then clean up resources.",
                            "For more information, see Create a Lambda function with the console.",
                            "  1..NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\nusing Amazon.Lambda.Model;\n\n/// <summary>\n/// A class that implements AWS Lambda methods.\n/// </summary>\npublic class LambdaWrapper\n{\n    private readonly IAmazonLambda _lambdaService;\n\n    /// <summary>\n    /// Constructor for the LambdaWrapper class.\n    /// </summary>\n    /// <param name=\"lambdaService\">An initialized Lambda service client.</param>\n    public LambdaWrapper(IAmazonLambda lambdaService)\n    {\n        _lambdaService = lambdaService;\n    }\n\n    /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n    /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n    /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n    /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n    /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n    /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n    /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n}\n\n\n",
                            "  2.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\nusing Amazon.Lambda.Model;\n\n/// <summary>\n/// A class that implements AWS Lambda methods.\n/// </summary>\npublic class LambdaWrapper\n{\n    private readonly IAmazonLambda _lambdaService;\n\n    /// <summary>\n    /// Constructor for the LambdaWrapper class.\n    /// </summary>\n    /// <param name=\"lambdaService\">An initialized Lambda service client.</param>\n    public LambdaWrapper(IAmazonLambda lambdaService)\n    {\n        _lambdaService = lambdaService;\n    }\n\n    /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n    /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n    /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n    /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n    /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n    /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n    /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n}\n\n\n",
                            "  3.C++ : //! Get started with functions scenario.\n/*!\n \\param clientConfig: AWS client configuration.\n \\return bool: Successful completion.\n */\nbool AwsDoc::Lambda::getStartedWithFunctionsScenario(\n        const Aws::Client::ClientConfiguration &clientConfig) {\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    // 1. Create an AWS Identity and Access Management (IAM) role for Lambda function.\n    Aws::String roleArn;\n    if (!getIamRoleArn(roleArn, clientConfig)) {\n        return false;\n    }\n\n    // 2. Create a Lambda function.\n    int seconds = 0;\n    do {\n        Aws::Lambda::Model::CreateFunctionRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.\n#if USE_CPP_LAMBDA_FUNCTION\n        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);\n        request.SetTimeout(15);\n        request.SetMemorySize(128);\n\n        // Assume the AWS Lambda function was built in Docker with same architecture\n        // as this code.\n#if  defined(__x86_64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});\n#elif defined(__aarch64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});\n#else\n#error \"Unimplemented architecture\"\n#endif // defined(architecture)\n#else\n        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);\n#endif\n        request.SetRole(roleArn);\n        request.SetHandler(LAMBDA_HANDLER_NAME);\n        request.SetPublish(true);\n        Aws::Lambda::Model::FunctionCode code;\n        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n\n        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                               buffer.str().length()));\n        request.SetCode(code);\n\n        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda function was successfully created. \" << seconds\n                      << \" seconds elapsed.\" << std::endl;\n            break;\n        }\n        else if (outcome.GetError().GetErrorType() ==\n                 Aws::Lambda::LambdaErrors::INVALID_PARAMETER_VALUE &&\n                 outcome.GetError().GetMessage().find(\"role\") >= 0) {\n            if ((seconds % 5) == 0) { // Log status every 10 seconds.\n                std::cout\n                        << \"Waiting for the IAM role to become available as a CreateFunction parameter. \"\n                        << seconds\n                        << \" seconds elapsed.\" << std::endl;\n\n                std::cout << outcome.GetError().GetMessage() << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with CreateFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            deleteIamRole(clientConfig);\n            return false;\n        }\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n    } while (60 > seconds);\n\n    std::cout << \"The current Lambda function increments 1 by an input.\" << std::endl;\n\n    // 3.  Invoke the Lambda function.\n    {\n        int increment = askQuestionForInt(\"Enter an increment integer: \");\n\n        Aws::Lambda::Model::InvokeResult invokeResult;\n        Aws::Utils::Json::JsonValue jsonPayload;\n        jsonPayload.WithString(\"action\", \"increment\");\n        jsonPayload.WithInteger(\"number\", increment);\n        if (invokeLambdaFunction(jsonPayload, Aws::Lambda::Model::LogType::Tail,\n                                 invokeResult, client)) {\n            Aws::Utils::Json::JsonValue jsonValue(invokeResult.GetPayload());\n            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =\n                    jsonValue.View().GetAllObjects();\n            auto iter = values.find(\"result\");\n            if (iter != values.end() && iter->second.IsIntegerType()) {\n                {\n                    std::cout << INCREMENT_RESUlT_PREFIX\n                              << iter->second.AsInteger() << std::endl;\n                }\n            }\n            else {\n                std::cout << \"There was an error in execution. Here is the log.\"\n                          << std::endl;\n                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(\n                        invokeResult.GetLogResult());\n                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;\n            }\n        }\n    }\n\n    std::cout\n            << \"The Lambda function will now be updated with new code. Press return to continue, \";\n    Aws::String answer;\n    std::getline(std::cin, answer);\n\n    // 4.  Update the Lambda function code.\n    {\n        Aws::Lambda::Model::UpdateFunctionCodeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteLambdaFunction(client);\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n        request.SetZipFile(\n                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                       buffer.str().length()));\n        request.SetPublish(true);\n\n        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda code was successfully updated.\" << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    }\n\n    std::cout\n            << \"This function uses an environment variable to control the logging level.\"\n            << std::endl;\n    std::cout\n            << \"UpdateFunctionConfiguration will be used to set the LOG_LEVEL to DEBUG.\"\n            << std::endl;\n    seconds = 0;\n\n    // 5.  Update the Lambda function configuration.\n    do {\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        Aws::Lambda::Model::Environment environment;\n        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");\n        request.SetEnvironment(environment);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda configuration was successfully updated.\"\n                      << std::endl;\n            break;\n        }\n\n            // RESOURCE_IN_USE: function code update not completed.\n        else if (outcome.GetError().GetErrorType() !=\n                 Aws::Lambda::LambdaErrors::RESOURCE_IN_USE) {\n            if ((seconds % 10) == 0) { // Log status every 10 seconds.\n                std::cout << \"Lambda function update in progress . After \" << seconds\n                          << \" seconds elapsed.\" << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n    } while (0 < seconds);\n\n    if (0 > seconds) {\n        std::cerr << \"Function failed to become active.\" << std::endl;\n    }\n    else {\n        std::cout << \"Updated function active after \" << seconds << \" seconds.\"\n                  << std::endl;\n    }\n\n    std::cout\n            << \"\\nThe new code applies an arithmetic operator to two variables, x an y.\"\n            << std::endl;\n    std::vector<Aws::String> operators = {\"plus\", \"minus\", \"times\", \"divided-by\"};\n    for (size_t i = 0; i < operators.size(); ++i) {\n        std::cout << \"   \" << i + 1 << \" \" << operators[i] << std::endl;\n    }\n\n    // 6.  Invoke the updated Lambda function.\n    do {\n        int operatorIndex = askQuestionForIntRange(\"Select an operator index 1 - 4 \", 1,\n                                                   4);\n        int x = askQuestionForInt(\"Enter an integer for the x value \");\n        int y = askQuestionForInt(\"Enter an integer for the y value \");\n\n        Aws::Utils::Json::JsonValue calculateJsonPayload;\n        calculateJsonPayload.WithString(\"action\", operators[operatorIndex - 1]);\n        calculateJsonPayload.WithInteger(\"x\", x);\n        calculateJsonPayload.WithInteger(\"y\", y);\n        Aws::Lambda::Model::InvokeResult calculatedResult;\n        if (invokeLambdaFunction(calculateJsonPayload,\n                                 Aws::Lambda::Model::LogType::Tail,\n                                 calculatedResult, client)) {\n            Aws::Utils::Json::JsonValue jsonValue(calculatedResult.GetPayload());\n            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =\n                    jsonValue.View().GetAllObjects();\n            auto iter = values.find(\"result\");\n            if (iter != values.end() && iter->second.IsIntegerType()) {\n                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"\n                          << operators[operatorIndex - 1] << \" \"\n                          << y << \" is \" << iter->second.AsInteger() << std::endl;\n            }\n            else if (iter != values.end() && iter->second.IsFloatingPointType()) {\n                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"\n                          << operators[operatorIndex - 1] << \" \"\n                          << y << \" is \" << iter->second.AsDouble() << std::endl;\n            }\n            else {\n                std::cout << \"There was an error in execution. Here is the log.\"\n                          << std::endl;\n                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(\n                        calculatedResult.GetLogResult());\n                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;\n            }\n        }\n\n        answer = askQuestion(\"Would you like to try another operation? (y/n) \");\n    } while (answer == \"y\");\n\n    std::cout\n            << \"A list of the lambda functions will be retrieved. Press return to continue, \";\n    std::getline(std::cin, answer);\n\n    // 7.  List the Lambda functions.\n\n    std::vector<Aws::String> functions;\n    Aws::String marker;\n\n    do {\n        Aws::Lambda::Model::ListFunctionsRequest request;\n        if (!marker.empty()) {\n            request.SetMarker(marker);\n        }\n\n        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(\n                request);\n\n        if (outcome.IsSuccess()) {\n            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();\n            std::cout << result.GetFunctions().size()\n                      << \" lambda functions were retrieved.\" << std::endl;\n\n            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {\n                functions.push_back(functionConfiguration.GetFunctionName());\n                std::cout << functions.size() << \"  \"\n                          << functionConfiguration.GetDescription() << std::endl;\n                std::cout << \"   \"\n                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(\n                                  functionConfiguration.GetRuntime()) << \": \"\n                          << functionConfiguration.GetHandler()\n                          << std::endl;\n            }\n            marker = result.GetNextMarker();\n        }\n        else {\n            std::cerr << \"Error with Lambda::ListFunctions. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    } while (!marker.empty());\n\n    // 8.  Get a Lambda function.\n    if (!functions.empty()) {\n        std::stringstream question;\n        question << \"Choose a function to retrieve between 1 and \" << functions.size()\n                 << \" \";\n        int functionIndex = askQuestionForIntRange(question.str(), 1,\n                                                   static_cast<int>(functions.size()));\n\n        Aws::String functionName = functions[functionIndex - 1];\n\n        Aws::Lambda::Model::GetFunctionRequest request;\n        request.SetFunctionName(functionName);\n\n        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"Function retrieve.\\n\" <<\n                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()\n                      << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::GetFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    }\n\n    std::cout << \"The resources will be deleted. Press return to continue, \";\n    std::getline(std::cin, answer);\n\n    // 9.  Delete the Lambda function.\n    bool result = deleteLambdaFunction(client);\n\n    // 10. Delete the IAM role.\n    return result && deleteIamRole(clientConfig);\n}\n\n//! Routine which invokes a Lambda function and returns the result.\n/*!\n \\param jsonPayload: Payload for invoke function.\n \\param logType: Log type setting for invoke function.\n \\param invokeResult: InvokeResult object to receive the result.\n \\param client: Lambda client.\n \\return bool: Successful completion.\n */\nbool\nAwsDoc::Lambda::invokeLambdaFunction(const Aws::Utils::Json::JsonValue &jsonPayload,\n                                     Aws::Lambda::Model::LogType logType,\n                                     Aws::Lambda::Model::InvokeResult &invokeResult,\n                                     const Aws::Lambda::LambdaClient &client) {\n    int seconds = 0;\n    bool result = false;\n    /*\n     * In this example, the Invoke function can be called before recently created resources are\n     * available.  The Invoke function is called repeatedly until the resources are\n     * available.\n     */\n    do {\n        Aws::Lambda::Model::InvokeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetLogType(logType);\n        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(\n                \"FunctionTest\");\n        *payload << jsonPayload.View().WriteReadable();\n        request.SetBody(payload);\n        request.SetContentType(\"application/json\");\n        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);\n\n        if (outcome.IsSuccess()) {\n            invokeResult = std::move(outcome.GetResult());\n            result = true;\n            break;\n        }\n\n            // ACCESS_DENIED: because the role is not available yet.\n            // RESOURCE_CONFLICT: because the Lambda function is being created or updated.\n        else if ((outcome.GetError().GetErrorType() ==\n                  Aws::Lambda::LambdaErrors::ACCESS_DENIED) ||\n                 (outcome.GetError().GetErrorType() ==\n                  Aws::Lambda::LambdaErrors::RESOURCE_CONFLICT)) {\n            if ((seconds % 5) == 0) { // Log status every 10 seconds.\n                std::cout << \"Waiting for the invoke api to be available, status \" <<\n                          ((outcome.GetError().GetErrorType() ==\n                            Aws::Lambda::LambdaErrors::ACCESS_DENIED ?\n                            \"ACCESS_DENIED\" : \"RESOURCE_CONFLICT\")) << \". \" << seconds\n                          << \" seconds elapsed.\" << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with Lambda::InvokeRequest. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            break;\n        }\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n    } while (seconds < 60);\n\n    return result;\n}\n\n",
                            "  4.SDK for C++ : //! Get started with functions scenario.\n/*!\n \\param clientConfig: AWS client configuration.\n \\return bool: Successful completion.\n */\nbool AwsDoc::Lambda::getStartedWithFunctionsScenario(\n        const Aws::Client::ClientConfiguration &clientConfig) {\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    // 1. Create an AWS Identity and Access Management (IAM) role for Lambda function.\n    Aws::String roleArn;\n    if (!getIamRoleArn(roleArn, clientConfig)) {\n        return false;\n    }\n\n    // 2. Create a Lambda function.\n    int seconds = 0;\n    do {\n        Aws::Lambda::Model::CreateFunctionRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.\n#if USE_CPP_LAMBDA_FUNCTION\n        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);\n        request.SetTimeout(15);\n        request.SetMemorySize(128);\n\n        // Assume the AWS Lambda function was built in Docker with same architecture\n        // as this code.\n#if  defined(__x86_64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});\n#elif defined(__aarch64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});\n#else\n#error \"Unimplemented architecture\"\n#endif // defined(architecture)\n#else\n        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);\n#endif\n        request.SetRole(roleArn);\n        request.SetHandler(LAMBDA_HANDLER_NAME);\n        request.SetPublish(true);\n        Aws::Lambda::Model::FunctionCode code;\n        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n\n        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                               buffer.str().length()));\n        request.SetCode(code);\n\n        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda function was successfully created. \" << seconds\n                      << \" seconds elapsed.\" << std::endl;\n            break;\n        }\n        else if (outcome.GetError().GetErrorType() ==\n                 Aws::Lambda::LambdaErrors::INVALID_PARAMETER_VALUE &&\n                 outcome.GetError().GetMessage().find(\"role\") >= 0) {\n            if ((seconds % 5) == 0) { // Log status every 10 seconds.\n                std::cout\n                        << \"Waiting for the IAM role to become available as a CreateFunction parameter. \"\n                        << seconds\n                        << \" seconds elapsed.\" << std::endl;\n\n                std::cout << outcome.GetError().GetMessage() << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with CreateFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            deleteIamRole(clientConfig);\n            return false;\n        }\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n    } while (60 > seconds);\n\n    std::cout << \"The current Lambda function increments 1 by an input.\" << std::endl;\n\n    // 3.  Invoke the Lambda function.\n    {\n        int increment = askQuestionForInt(\"Enter an increment integer: \");\n\n        Aws::Lambda::Model::InvokeResult invokeResult;\n        Aws::Utils::Json::JsonValue jsonPayload;\n        jsonPayload.WithString(\"action\", \"increment\");\n        jsonPayload.WithInteger(\"number\", increment);\n        if (invokeLambdaFunction(jsonPayload, Aws::Lambda::Model::LogType::Tail,\n                                 invokeResult, client)) {\n            Aws::Utils::Json::JsonValue jsonValue(invokeResult.GetPayload());\n            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =\n                    jsonValue.View().GetAllObjects();\n            auto iter = values.find(\"result\");\n            if (iter != values.end() && iter->second.IsIntegerType()) {\n                {\n                    std::cout << INCREMENT_RESUlT_PREFIX\n                              << iter->second.AsInteger() << std::endl;\n                }\n            }\n            else {\n                std::cout << \"There was an error in execution. Here is the log.\"\n                          << std::endl;\n                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(\n                        invokeResult.GetLogResult());\n                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;\n            }\n        }\n    }\n\n    std::cout\n            << \"The Lambda function will now be updated with new code. Press return to continue, \";\n    Aws::String answer;\n    std::getline(std::cin, answer);\n\n    // 4.  Update the Lambda function code.\n    {\n        Aws::Lambda::Model::UpdateFunctionCodeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteLambdaFunction(client);\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n        request.SetZipFile(\n                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                       buffer.str().length()));\n        request.SetPublish(true);\n\n        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda code was successfully updated.\" << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    }\n\n    std::cout\n            << \"This function uses an environment variable to control the logging level.\"\n            << std::endl;\n    std::cout\n            << \"UpdateFunctionConfiguration will be used to set the LOG_LEVEL to DEBUG.\"\n            << std::endl;\n    seconds = 0;\n\n    // 5.  Update the Lambda function configuration.\n    do {\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        Aws::Lambda::Model::Environment environment;\n        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");\n        request.SetEnvironment(environment);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda configuration was successfully updated.\"\n                      << std::endl;\n            break;\n        }\n\n            // RESOURCE_IN_USE: function code update not completed.\n        else if (outcome.GetError().GetErrorType() !=\n                 Aws::Lambda::LambdaErrors::RESOURCE_IN_USE) {\n            if ((seconds % 10) == 0) { // Log status every 10 seconds.\n                std::cout << \"Lambda function update in progress . After \" << seconds\n                          << \" seconds elapsed.\" << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n    } while (0 < seconds);\n\n    if (0 > seconds) {\n        std::cerr << \"Function failed to become active.\" << std::endl;\n    }\n    else {\n        std::cout << \"Updated function active after \" << seconds << \" seconds.\"\n                  << std::endl;\n    }\n\n    std::cout\n            << \"\\nThe new code applies an arithmetic operator to two variables, x an y.\"\n            << std::endl;\n    std::vector<Aws::String> operators = {\"plus\", \"minus\", \"times\", \"divided-by\"};\n    for (size_t i = 0; i < operators.size(); ++i) {\n        std::cout << \"   \" << i + 1 << \" \" << operators[i] << std::endl;\n    }\n\n    // 6.  Invoke the updated Lambda function.\n    do {\n        int operatorIndex = askQuestionForIntRange(\"Select an operator index 1 - 4 \", 1,\n                                                   4);\n        int x = askQuestionForInt(\"Enter an integer for the x value \");\n        int y = askQuestionForInt(\"Enter an integer for the y value \");\n\n        Aws::Utils::Json::JsonValue calculateJsonPayload;\n        calculateJsonPayload.WithString(\"action\", operators[operatorIndex - 1]);\n        calculateJsonPayload.WithInteger(\"x\", x);\n        calculateJsonPayload.WithInteger(\"y\", y);\n        Aws::Lambda::Model::InvokeResult calculatedResult;\n        if (invokeLambdaFunction(calculateJsonPayload,\n                                 Aws::Lambda::Model::LogType::Tail,\n                                 calculatedResult, client)) {\n            Aws::Utils::Json::JsonValue jsonValue(calculatedResult.GetPayload());\n            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =\n                    jsonValue.View().GetAllObjects();\n            auto iter = values.find(\"result\");\n            if (iter != values.end() && iter->second.IsIntegerType()) {\n                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"\n                          << operators[operatorIndex - 1] << \" \"\n                          << y << \" is \" << iter->second.AsInteger() << std::endl;\n            }\n            else if (iter != values.end() && iter->second.IsFloatingPointType()) {\n                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"\n                          << operators[operatorIndex - 1] << \" \"\n                          << y << \" is \" << iter->second.AsDouble() << std::endl;\n            }\n            else {\n                std::cout << \"There was an error in execution. Here is the log.\"\n                          << std::endl;\n                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(\n                        calculatedResult.GetLogResult());\n                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;\n            }\n        }\n\n        answer = askQuestion(\"Would you like to try another operation? (y/n) \");\n    } while (answer == \"y\");\n\n    std::cout\n            << \"A list of the lambda functions will be retrieved. Press return to continue, \";\n    std::getline(std::cin, answer);\n\n    // 7.  List the Lambda functions.\n\n    std::vector<Aws::String> functions;\n    Aws::String marker;\n\n    do {\n        Aws::Lambda::Model::ListFunctionsRequest request;\n        if (!marker.empty()) {\n            request.SetMarker(marker);\n        }\n\n        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(\n                request);\n\n        if (outcome.IsSuccess()) {\n            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();\n            std::cout << result.GetFunctions().size()\n                      << \" lambda functions were retrieved.\" << std::endl;\n\n            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {\n                functions.push_back(functionConfiguration.GetFunctionName());\n                std::cout << functions.size() << \"  \"\n                          << functionConfiguration.GetDescription() << std::endl;\n                std::cout << \"   \"\n                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(\n                                  functionConfiguration.GetRuntime()) << \": \"\n                          << functionConfiguration.GetHandler()\n                          << std::endl;\n            }\n            marker = result.GetNextMarker();\n        }\n        else {\n            std::cerr << \"Error with Lambda::ListFunctions. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    } while (!marker.empty());\n\n    // 8.  Get a Lambda function.\n    if (!functions.empty()) {\n        std::stringstream question;\n        question << \"Choose a function to retrieve between 1 and \" << functions.size()\n                 << \" \";\n        int functionIndex = askQuestionForIntRange(question.str(), 1,\n                                                   static_cast<int>(functions.size()));\n\n        Aws::String functionName = functions[functionIndex - 1];\n\n        Aws::Lambda::Model::GetFunctionRequest request;\n        request.SetFunctionName(functionName);\n\n        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"Function retrieve.\\n\" <<\n                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()\n                      << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::GetFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    }\n\n    std::cout << \"The resources will be deleted. Press return to continue, \";\n    std::getline(std::cin, answer);\n\n    // 9.  Delete the Lambda function.\n    bool result = deleteLambdaFunction(client);\n\n    // 10. Delete the IAM role.\n    return result && deleteIamRole(clientConfig);\n}\n\n//! Routine which invokes a Lambda function and returns the result.\n/*!\n \\param jsonPayload: Payload for invoke function.\n \\param logType: Log type setting for invoke function.\n \\param invokeResult: InvokeResult object to receive the result.\n \\param client: Lambda client.\n \\return bool: Successful completion.\n */\nbool\nAwsDoc::Lambda::invokeLambdaFunction(const Aws::Utils::Json::JsonValue &jsonPayload,\n                                     Aws::Lambda::Model::LogType logType,\n                                     Aws::Lambda::Model::InvokeResult &invokeResult,\n                                     const Aws::Lambda::LambdaClient &client) {\n    int seconds = 0;\n    bool result = false;\n    /*\n     * In this example, the Invoke function can be called before recently created resources are\n     * available.  The Invoke function is called repeatedly until the resources are\n     * available.\n     */\n    do {\n        Aws::Lambda::Model::InvokeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetLogType(logType);\n        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(\n                \"FunctionTest\");\n        *payload << jsonPayload.View().WriteReadable();\n        request.SetBody(payload);\n        request.SetContentType(\"application/json\");\n        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);\n\n        if (outcome.IsSuccess()) {\n            invokeResult = std::move(outcome.GetResult());\n            result = true;\n            break;\n        }\n\n            // ACCESS_DENIED: because the role is not available yet.\n            // RESOURCE_CONFLICT: because the Lambda function is being created or updated.\n        else if ((outcome.GetError().GetErrorType() ==\n                  Aws::Lambda::LambdaErrors::ACCESS_DENIED) ||\n                 (outcome.GetError().GetErrorType() ==\n                  Aws::Lambda::LambdaErrors::RESOURCE_CONFLICT)) {\n            if ((seconds % 5) == 0) { // Log status every 10 seconds.\n                std::cout << \"Waiting for the invoke api to be available, status \" <<\n                          ((outcome.GetError().GetErrorType() ==\n                            Aws::Lambda::LambdaErrors::ACCESS_DENIED ?\n                            \"ACCESS_DENIED\" : \"RESOURCE_CONFLICT\")) << \". \" << seconds\n                          << \" seconds elapsed.\" << std::endl;\n            }\n        }\n        else {\n            std::cerr << \"Error with Lambda::InvokeRequest. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            break;\n        }\n        ++seconds;\n        std::this_thread::sleep_for(std::chrono::seconds(1));\n    } while (seconds < 60);\n\n    return result;\n}\n\n",
                            "  5.Go : \nimport (\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/iam\"\n\tiamtypes \"github.com/aws/aws-sdk-go-v2/service/iam/types\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/lambda/actions\"\n)\n\n// GetStartedFunctionsScenario shows you how to use AWS Lambda to perform the following\n// actions:\n//\n//  1. Create an AWS Identity and Access Management (IAM) role and Lambda function, then upload handler code.\n//  2. Invoke the function with a single parameter and get results.\n//  3. Update the function code and configure with an environment variable.\n//  4. Invoke the function with new parameters and get results. Display the returned execution log.\n//  5. List the functions for your account, then clean up resources.\ntype GetStartedFunctionsScenario struct {\n\tsdkConfig       aws.Config\n\tfunctionWrapper actions.FunctionWrapper\n\tquestioner      demotools.IQuestioner\n\thelper          IScenarioHelper\n\tisTestRun       bool\n}\n\n// NewGetStartedFunctionsScenario constructs a GetStartedFunctionsScenario instance from a configuration.\n// It uses the specified config to get a Lambda client and create wrappers for the actions\n// used in the scenario.\nfunc NewGetStartedFunctionsScenario(sdkConfig aws.Config, questioner demotools.IQuestioner,\n\thelper IScenarioHelper) GetStartedFunctionsScenario {\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\treturn GetStartedFunctionsScenario{\n\t\tsdkConfig:       sdkConfig,\n\t\tfunctionWrapper: actions.FunctionWrapper{LambdaClient: lambdaClient},\n\t\tquestioner:      questioner,\n\t\thelper:          helper,\n\t}\n}\n\n// Run runs the interactive scenario.\nfunc (scenario GetStartedFunctionsScenario) Run(ctx context.Context) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Printf(\"Something went wrong with the demo.\\n\")\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Welcome to the AWS Lambda get started with functions demo.\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\trole := scenario.GetOrCreateRole(ctx)\n\tfuncName := scenario.CreateFunction(ctx, role)\n\tscenario.InvokeIncrement(ctx, funcName)\n\tscenario.UpdateFunction(ctx, funcName)\n\tscenario.InvokeCalculator(ctx, funcName)\n\tscenario.ListFunctions(ctx)\n\tscenario.Cleanup(ctx, role, funcName)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// GetOrCreateRole checks whether the specified role exists and returns it if it does.\n// Otherwise, a role is created that specifies Lambda as a trusted principal.\n// The AWSLambdaBasicExecutionRole managed policy is attached to the role and the role\n// is returned.\nfunc (scenario GetStartedFunctionsScenario) GetOrCreateRole(ctx context.Context) *iamtypes.Role {\n\tvar role *iamtypes.Role\n\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\n\tlog.Println(\"First, we need an IAM role that Lambda can assume.\")\n\troleName := scenario.questioner.Ask(\"Enter a name for the role:\", demotools.NotEmpty{})\n\tgetOutput, err := iamClient.GetRole(ctx, &iam.GetRoleInput{\n\t\tRoleName: aws.String(roleName)})\n\tif err != nil {\n\t\tvar noSuch *iamtypes.NoSuchEntityException\n\t\tif errors.As(err, &noSuch) {\n\t\t\tlog.Printf(\"Role %v doesn't exist. Creating it....\\n\", roleName)\n\t\t} else {\n\t\t\tlog.Panicf(\"Couldn't check whether role %v exists. Here's why: %v\\n\",\n\t\t\t\troleName, err)\n\t\t}\n\t} else {\n\t\trole = getOutput.Role\n\t\tlog.Printf(\"Found role %v.\\n\", *role.RoleName)\n\t}\n\tif role == nil {\n\t\ttrustPolicy := PolicyDocument{\n\t\t\tVersion: \"2012-10-17\",\n\t\t\tStatement: []PolicyStatement{{\n\t\t\t\tEffect:    \"Allow\",\n\t\t\t\tPrincipal: map[string]string{\"Service\": \"lambda.amazonaws.com\"},\n\t\t\t\tAction:    []string{\"sts:AssumeRole\"},\n\t\t\t}},\n\t\t}\n\t\tpolicyArn := \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n\t\tcreateOutput, err := iamClient.CreateRole(ctx, &iam.CreateRoleInput{\n\t\t\tAssumeRolePolicyDocument: aws.String(trustPolicy.String()),\n\t\t\tRoleName:                 aws.String(roleName),\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't create role %v. Here's why: %v\\n\", roleName, err)\n\t\t}\n\t\trole = createOutput.Role\n\t\t_, err = iamClient.AttachRolePolicy(ctx, &iam.AttachRolePolicyInput{\n\t\t\tPolicyArn: aws.String(policyArn),\n\t\t\tRoleName:  aws.String(roleName),\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't attach a policy to role %v. Here's why: %v\\n\", roleName, err)\n\t\t}\n\t\tlog.Printf(\"Created role %v.\\n\", *role.RoleName)\n\t\tlog.Println(\"Let's give AWS a few seconds to propagate resources...\")\n\t\tscenario.helper.Pause(10)\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn role\n}\n\n// CreateFunction creates a Lambda function and uploads a handler written in Python.\n// The code for the Python handler is packaged as a []byte in .zip format.\nfunc (scenario GetStartedFunctionsScenario) CreateFunction(ctx context.Context, role *iamtypes.Role) string {\n\tlog.Println(\"Let's create a function that increments a number.\\n\" +\n\t\t\"The function uses the 'lambda_handler_basic.py' script found in the \\n\" +\n\t\t\"'handlers' directory of this project.\")\n\tfuncName := scenario.questioner.Ask(\"Enter a name for the Lambda function:\", demotools.NotEmpty{})\n\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_basic.py\", fmt.Sprintf(\"%v.py\", funcName))\n\tlog.Printf(\"Creating function %v and waiting for it to be ready.\", funcName)\n\tfuncState := scenario.functionWrapper.CreateFunction(ctx, funcName, fmt.Sprintf(\"%v.lambda_handler\", funcName),\n\t\trole.Arn, zipPackage)\n\tlog.Printf(\"Your function is %v.\", funcState)\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn funcName\n}\n\n// InvokeIncrement invokes a Lambda function that increments a number. The function\n// parameters are contained in a Go struct that is used to serialize the parameters to\n// a JSON payload that is passed to the function.\n// The result payload is deserialized into a Go struct that contains an int value.\nfunc (scenario GetStartedFunctionsScenario) InvokeIncrement(ctx context.Context, funcName string) {\n\tparameters := actions.IncrementParameters{Action: \"increment\"}\n\tlog.Println(\"Let's invoke our function. This function increments a number.\")\n\tparameters.Number = scenario.questioner.AskInt(\"Enter a number to increment:\", demotools.NotEmpty{})\n\tlog.Printf(\"Invoking %v with %v...\\n\", funcName, parameters.Number)\n\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, parameters, false)\n\tvar payload actions.LambdaResultInt\n\terr := json.Unmarshal(invokeOutput.Payload, &payload)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\n\t\t\tfuncName, err)\n\t}\n\tlog.Printf(\"Invoking %v with %v returned %v.\\n\", funcName, parameters.Number, payload)\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// UpdateFunction updates the code for a Lambda function by uploading a simple arithmetic\n// calculator written in Python. The code for the Python handler is packaged as a\n// []byte in .zip format.\n// After the code is updated, the configuration is also updated with a new log\n// level that instructs the handler to log additional information.\nfunc (scenario GetStartedFunctionsScenario) UpdateFunction(ctx context.Context, funcName string) {\n\tlog.Println(\"Let's update the function to an arithmetic calculator.\\n\" +\n\t\t\"The function uses the 'lambda_handler_calculator.py' script found in the \\n\" +\n\t\t\"'handlers' directory of this project.\")\n\tscenario.questioner.Ask(\"Press Enter when you're ready.\")\n\tlog.Println(\"Creating deployment package...\")\n\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_calculator.py\",\n\t\tfmt.Sprintf(\"%v.py\", funcName))\n\tlog.Println(\"...and updating the Lambda function and waiting for it to be ready.\")\n\tfuncState := scenario.functionWrapper.UpdateFunctionCode(ctx, funcName, zipPackage)\n\tlog.Printf(\"Updated function %v. Its current state is %v.\", funcName, funcState)\n\tlog.Println(\"This function uses an environment variable to control logging level.\")\n\tlog.Println(\"Let's set it to DEBUG to get the most logging.\")\n\tscenario.functionWrapper.UpdateFunctionConfiguration(ctx, funcName,\n\t\tmap[string]string{\"LOG_LEVEL\": \"DEBUG\"})\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// InvokeCalculator invokes the Lambda calculator function. The parameters are stored in a\n// Go struct that is used to serialize the parameters to a JSON payload. That payload is then passed\n// to the function.\n// The result payload is deserialized to a Go struct that stores the result as either an\n// int or float32, depending on the kind of operation that was specified.\nfunc (scenario GetStartedFunctionsScenario) InvokeCalculator(ctx context.Context, funcName string) {\n\twantInvoke := true\n\tchoices := []string{\"plus\", \"minus\", \"times\", \"divided-by\"}\n\tfor wantInvoke {\n\t\tchoice := scenario.questioner.AskChoice(\"Select an arithmetic operation:\\n\", choices)\n\t\tx := scenario.questioner.AskInt(\"Enter a value for x:\", demotools.NotEmpty{})\n\t\ty := scenario.questioner.AskInt(\"Enter a value for y:\", demotools.NotEmpty{})\n\t\tlog.Printf(\"Invoking %v %v %v...\", x, choices[choice], y)\n\t\tcalcParameters := actions.CalculatorParameters{\n\t\t\tAction: choices[choice],\n\t\t\tX:      x,\n\t\t\tY:      y,\n\t\t}\n\t\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, calcParameters, true)\n\t\tvar payload any\n\t\tif choice == 3 { // divide-by results in a float.\n\t\t\tpayload = actions.LambdaResultFloat{}\n\t\t} else {\n\t\t\tpayload = actions.LambdaResultInt{}\n\t\t}\n\t\terr := json.Unmarshal(invokeOutput.Payload, &payload)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\n\t\t\t\tfuncName, err)\n\t\t}\n\t\tlog.Printf(\"Invoking %v with %v %v %v returned %v.\\n\", funcName,\n\t\t\tcalcParameters.X, calcParameters.Action, calcParameters.Y, payload)\n\t\tscenario.questioner.Ask(\"Press Enter to see the logs from the call.\")\n\t\tlogRes, err := base64.StdEncoding.DecodeString(*invokeOutput.LogResult)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't decode log result. Here's why: %v\\n\", err)\n\t\t}\n\t\tlog.Println(string(logRes))\n\t\twantInvoke = scenario.questioner.AskBool(\"Do you want to calculate again? (y/n)\", \"y\")\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// ListFunctions lists up to the specified number of functions for your account.\nfunc (scenario GetStartedFunctionsScenario) ListFunctions(ctx context.Context) {\n\tcount := scenario.questioner.AskInt(\n\t\t\"Let's list functions for your account. How many do you want to see?\", demotools.NotEmpty{})\n\tfunctions := scenario.functionWrapper.ListFunctions(ctx, count)\n\tlog.Printf(\"Found %v functions:\", len(functions))\n\tfor _, function := range functions {\n\t\tlog.Printf(\"\\t%v\", *function.FunctionName)\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Cleanup removes the IAM and Lambda resources created by the example.\nfunc (scenario GetStartedFunctionsScenario) Cleanup(ctx context.Context, role *iamtypes.Role, funcName string) {\n\tif scenario.questioner.AskBool(\"Do you want to clean up resources created for this example? (y/n)\",\n\t\t\"y\") {\n\t\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\n\t\tpoliciesOutput, err := iamClient.ListAttachedRolePolicies(ctx,\n\t\t\t&iam.ListAttachedRolePoliciesInput{RoleName: role.RoleName})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't get policies attached to role %v. Here's why: %v\\n\",\n\t\t\t\t*role.RoleName, err)\n\t\t}\n\t\tfor _, policy := range policiesOutput.AttachedPolicies {\n\t\t\t_, err = iamClient.DetachRolePolicy(ctx, &iam.DetachRolePolicyInput{\n\t\t\t\tPolicyArn: policy.PolicyArn, RoleName: role.RoleName,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Panicf(\"Couldn't detach policy %v from role %v. Here's why: %v\\n\",\n\t\t\t\t\t*policy.PolicyArn, *role.RoleName, err)\n\t\t\t}\n\t\t}\n\t\t_, err = iamClient.DeleteRole(ctx, &iam.DeleteRoleInput{RoleName: role.RoleName})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't delete role %v. Here's why: %v\\n\", *role.RoleName, err)\n\t\t}\n\t\tlog.Printf(\"Deleted role %v.\\n\", *role.RoleName)\n\n\t\tscenario.functionWrapper.DeleteFunction(ctx, funcName)\n\t\tlog.Printf(\"Deleted function %v.\\n\", funcName)\n\t} else {\n\t\tlog.Println(\"Okay. Don't forget to delete the resources when you're done with them.\")\n\t}\n}\n\n// IScenarioHelper abstracts I/O and wait functions from a scenario so that they\n// can be mocked for unit testing.\ntype IScenarioHelper interface {\n\tPause(secs int)\n\tCreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer\n}\n\n// ScenarioHelper lets the caller specify the path to Lambda handler functions.\ntype ScenarioHelper struct {\n\tHandlerPath string\n}\n\n// Pause waits for the specified number of seconds.\nfunc (helper *ScenarioHelper) Pause(secs int) {\n\ttime.Sleep(time.Duration(secs) * time.Second)\n}\n\n// CreateDeploymentPackage creates an AWS Lambda deployment package from a source file. The\n// deployment package is stored in .zip format in a bytes.Buffer. The buffer can be\n// used to pass a []byte to Lambda when creating the function.\n// The specified destinationFile is the name to give the file when it's deployed to Lambda.\nfunc (helper *ScenarioHelper) CreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer {\n\tvar err error\n\tbuffer := &bytes.Buffer{}\n\twriter := zip.NewWriter(buffer)\n\tzFile, err := writer.Create(destinationFile)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't create destination archive %v. Here's why: %v\\n\", destinationFile, err)\n\t}\n\tsourceBody, err := os.ReadFile(fmt.Sprintf(\"%v/%v\", helper.HandlerPath, sourceFile))\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't read handler source file %v. Here's why: %v\\n\",\n\t\t\tsourceFile, err)\n\t} else {\n\t\t_, err = zFile.Write(sourceBody)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't write handler %v to zip archive. Here's why: %v\\n\",\n\t\t\t\tsourceFile, err)\n\t\t}\n\t}\n\terr = writer.Close()\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't close zip writer. Here's why: %v\\n\", err)\n\t}\n\treturn buffer\n}\n\n\n",
                            "  6.SDK for Go V2 : \nimport (\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/iam\"\n\tiamtypes \"github.com/aws/aws-sdk-go-v2/service/iam/types\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/lambda/actions\"\n)\n\n// GetStartedFunctionsScenario shows you how to use AWS Lambda to perform the following\n// actions:\n//\n//  1. Create an AWS Identity and Access Management (IAM) role and Lambda function, then upload handler code.\n//  2. Invoke the function with a single parameter and get results.\n//  3. Update the function code and configure with an environment variable.\n//  4. Invoke the function with new parameters and get results. Display the returned execution log.\n//  5. List the functions for your account, then clean up resources.\ntype GetStartedFunctionsScenario struct {\n\tsdkConfig       aws.Config\n\tfunctionWrapper actions.FunctionWrapper\n\tquestioner      demotools.IQuestioner\n\thelper          IScenarioHelper\n\tisTestRun       bool\n}\n\n// NewGetStartedFunctionsScenario constructs a GetStartedFunctionsScenario instance from a configuration.\n// It uses the specified config to get a Lambda client and create wrappers for the actions\n// used in the scenario.\nfunc NewGetStartedFunctionsScenario(sdkConfig aws.Config, questioner demotools.IQuestioner,\n\thelper IScenarioHelper) GetStartedFunctionsScenario {\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\treturn GetStartedFunctionsScenario{\n\t\tsdkConfig:       sdkConfig,\n\t\tfunctionWrapper: actions.FunctionWrapper{LambdaClient: lambdaClient},\n\t\tquestioner:      questioner,\n\t\thelper:          helper,\n\t}\n}\n\n// Run runs the interactive scenario.\nfunc (scenario GetStartedFunctionsScenario) Run(ctx context.Context) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Printf(\"Something went wrong with the demo.\\n\")\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Welcome to the AWS Lambda get started with functions demo.\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\trole := scenario.GetOrCreateRole(ctx)\n\tfuncName := scenario.CreateFunction(ctx, role)\n\tscenario.InvokeIncrement(ctx, funcName)\n\tscenario.UpdateFunction(ctx, funcName)\n\tscenario.InvokeCalculator(ctx, funcName)\n\tscenario.ListFunctions(ctx)\n\tscenario.Cleanup(ctx, role, funcName)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// GetOrCreateRole checks whether the specified role exists and returns it if it does.\n// Otherwise, a role is created that specifies Lambda as a trusted principal.\n// The AWSLambdaBasicExecutionRole managed policy is attached to the role and the role\n// is returned.\nfunc (scenario GetStartedFunctionsScenario) GetOrCreateRole(ctx context.Context) *iamtypes.Role {\n\tvar role *iamtypes.Role\n\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\n\tlog.Println(\"First, we need an IAM role that Lambda can assume.\")\n\troleName := scenario.questioner.Ask(\"Enter a name for the role:\", demotools.NotEmpty{})\n\tgetOutput, err := iamClient.GetRole(ctx, &iam.GetRoleInput{\n\t\tRoleName: aws.String(roleName)})\n\tif err != nil {\n\t\tvar noSuch *iamtypes.NoSuchEntityException\n\t\tif errors.As(err, &noSuch) {\n\t\t\tlog.Printf(\"Role %v doesn't exist. Creating it....\\n\", roleName)\n\t\t} else {\n\t\t\tlog.Panicf(\"Couldn't check whether role %v exists. Here's why: %v\\n\",\n\t\t\t\troleName, err)\n\t\t}\n\t} else {\n\t\trole = getOutput.Role\n\t\tlog.Printf(\"Found role %v.\\n\", *role.RoleName)\n\t}\n\tif role == nil {\n\t\ttrustPolicy := PolicyDocument{\n\t\t\tVersion: \"2012-10-17\",\n\t\t\tStatement: []PolicyStatement{{\n\t\t\t\tEffect:    \"Allow\",\n\t\t\t\tPrincipal: map[string]string{\"Service\": \"lambda.amazonaws.com\"},\n\t\t\t\tAction:    []string{\"sts:AssumeRole\"},\n\t\t\t}},\n\t\t}\n\t\tpolicyArn := \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n\t\tcreateOutput, err := iamClient.CreateRole(ctx, &iam.CreateRoleInput{\n\t\t\tAssumeRolePolicyDocument: aws.String(trustPolicy.String()),\n\t\t\tRoleName:                 aws.String(roleName),\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't create role %v. Here's why: %v\\n\", roleName, err)\n\t\t}\n\t\trole = createOutput.Role\n\t\t_, err = iamClient.AttachRolePolicy(ctx, &iam.AttachRolePolicyInput{\n\t\t\tPolicyArn: aws.String(policyArn),\n\t\t\tRoleName:  aws.String(roleName),\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't attach a policy to role %v. Here's why: %v\\n\", roleName, err)\n\t\t}\n\t\tlog.Printf(\"Created role %v.\\n\", *role.RoleName)\n\t\tlog.Println(\"Let's give AWS a few seconds to propagate resources...\")\n\t\tscenario.helper.Pause(10)\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn role\n}\n\n// CreateFunction creates a Lambda function and uploads a handler written in Python.\n// The code for the Python handler is packaged as a []byte in .zip format.\nfunc (scenario GetStartedFunctionsScenario) CreateFunction(ctx context.Context, role *iamtypes.Role) string {\n\tlog.Println(\"Let's create a function that increments a number.\\n\" +\n\t\t\"The function uses the 'lambda_handler_basic.py' script found in the \\n\" +\n\t\t\"'handlers' directory of this project.\")\n\tfuncName := scenario.questioner.Ask(\"Enter a name for the Lambda function:\", demotools.NotEmpty{})\n\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_basic.py\", fmt.Sprintf(\"%v.py\", funcName))\n\tlog.Printf(\"Creating function %v and waiting for it to be ready.\", funcName)\n\tfuncState := scenario.functionWrapper.CreateFunction(ctx, funcName, fmt.Sprintf(\"%v.lambda_handler\", funcName),\n\t\trole.Arn, zipPackage)\n\tlog.Printf(\"Your function is %v.\", funcState)\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn funcName\n}\n\n// InvokeIncrement invokes a Lambda function that increments a number. The function\n// parameters are contained in a Go struct that is used to serialize the parameters to\n// a JSON payload that is passed to the function.\n// The result payload is deserialized into a Go struct that contains an int value.\nfunc (scenario GetStartedFunctionsScenario) InvokeIncrement(ctx context.Context, funcName string) {\n\tparameters := actions.IncrementParameters{Action: \"increment\"}\n\tlog.Println(\"Let's invoke our function. This function increments a number.\")\n\tparameters.Number = scenario.questioner.AskInt(\"Enter a number to increment:\", demotools.NotEmpty{})\n\tlog.Printf(\"Invoking %v with %v...\\n\", funcName, parameters.Number)\n\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, parameters, false)\n\tvar payload actions.LambdaResultInt\n\terr := json.Unmarshal(invokeOutput.Payload, &payload)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\n\t\t\tfuncName, err)\n\t}\n\tlog.Printf(\"Invoking %v with %v returned %v.\\n\", funcName, parameters.Number, payload)\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// UpdateFunction updates the code for a Lambda function by uploading a simple arithmetic\n// calculator written in Python. The code for the Python handler is packaged as a\n// []byte in .zip format.\n// After the code is updated, the configuration is also updated with a new log\n// level that instructs the handler to log additional information.\nfunc (scenario GetStartedFunctionsScenario) UpdateFunction(ctx context.Context, funcName string) {\n\tlog.Println(\"Let's update the function to an arithmetic calculator.\\n\" +\n\t\t\"The function uses the 'lambda_handler_calculator.py' script found in the \\n\" +\n\t\t\"'handlers' directory of this project.\")\n\tscenario.questioner.Ask(\"Press Enter when you're ready.\")\n\tlog.Println(\"Creating deployment package...\")\n\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_calculator.py\",\n\t\tfmt.Sprintf(\"%v.py\", funcName))\n\tlog.Println(\"...and updating the Lambda function and waiting for it to be ready.\")\n\tfuncState := scenario.functionWrapper.UpdateFunctionCode(ctx, funcName, zipPackage)\n\tlog.Printf(\"Updated function %v. Its current state is %v.\", funcName, funcState)\n\tlog.Println(\"This function uses an environment variable to control logging level.\")\n\tlog.Println(\"Let's set it to DEBUG to get the most logging.\")\n\tscenario.functionWrapper.UpdateFunctionConfiguration(ctx, funcName,\n\t\tmap[string]string{\"LOG_LEVEL\": \"DEBUG\"})\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// InvokeCalculator invokes the Lambda calculator function. The parameters are stored in a\n// Go struct that is used to serialize the parameters to a JSON payload. That payload is then passed\n// to the function.\n// The result payload is deserialized to a Go struct that stores the result as either an\n// int or float32, depending on the kind of operation that was specified.\nfunc (scenario GetStartedFunctionsScenario) InvokeCalculator(ctx context.Context, funcName string) {\n\twantInvoke := true\n\tchoices := []string{\"plus\", \"minus\", \"times\", \"divided-by\"}\n\tfor wantInvoke {\n\t\tchoice := scenario.questioner.AskChoice(\"Select an arithmetic operation:\\n\", choices)\n\t\tx := scenario.questioner.AskInt(\"Enter a value for x:\", demotools.NotEmpty{})\n\t\ty := scenario.questioner.AskInt(\"Enter a value for y:\", demotools.NotEmpty{})\n\t\tlog.Printf(\"Invoking %v %v %v...\", x, choices[choice], y)\n\t\tcalcParameters := actions.CalculatorParameters{\n\t\t\tAction: choices[choice],\n\t\t\tX:      x,\n\t\t\tY:      y,\n\t\t}\n\t\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, calcParameters, true)\n\t\tvar payload any\n\t\tif choice == 3 { // divide-by results in a float.\n\t\t\tpayload = actions.LambdaResultFloat{}\n\t\t} else {\n\t\t\tpayload = actions.LambdaResultInt{}\n\t\t}\n\t\terr := json.Unmarshal(invokeOutput.Payload, &payload)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\n\t\t\t\tfuncName, err)\n\t\t}\n\t\tlog.Printf(\"Invoking %v with %v %v %v returned %v.\\n\", funcName,\n\t\t\tcalcParameters.X, calcParameters.Action, calcParameters.Y, payload)\n\t\tscenario.questioner.Ask(\"Press Enter to see the logs from the call.\")\n\t\tlogRes, err := base64.StdEncoding.DecodeString(*invokeOutput.LogResult)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't decode log result. Here's why: %v\\n\", err)\n\t\t}\n\t\tlog.Println(string(logRes))\n\t\twantInvoke = scenario.questioner.AskBool(\"Do you want to calculate again? (y/n)\", \"y\")\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// ListFunctions lists up to the specified number of functions for your account.\nfunc (scenario GetStartedFunctionsScenario) ListFunctions(ctx context.Context) {\n\tcount := scenario.questioner.AskInt(\n\t\t\"Let's list functions for your account. How many do you want to see?\", demotools.NotEmpty{})\n\tfunctions := scenario.functionWrapper.ListFunctions(ctx, count)\n\tlog.Printf(\"Found %v functions:\", len(functions))\n\tfor _, function := range functions {\n\t\tlog.Printf(\"\\t%v\", *function.FunctionName)\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Cleanup removes the IAM and Lambda resources created by the example.\nfunc (scenario GetStartedFunctionsScenario) Cleanup(ctx context.Context, role *iamtypes.Role, funcName string) {\n\tif scenario.questioner.AskBool(\"Do you want to clean up resources created for this example? (y/n)\",\n\t\t\"y\") {\n\t\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\n\t\tpoliciesOutput, err := iamClient.ListAttachedRolePolicies(ctx,\n\t\t\t&iam.ListAttachedRolePoliciesInput{RoleName: role.RoleName})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't get policies attached to role %v. Here's why: %v\\n\",\n\t\t\t\t*role.RoleName, err)\n\t\t}\n\t\tfor _, policy := range policiesOutput.AttachedPolicies {\n\t\t\t_, err = iamClient.DetachRolePolicy(ctx, &iam.DetachRolePolicyInput{\n\t\t\t\tPolicyArn: policy.PolicyArn, RoleName: role.RoleName,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Panicf(\"Couldn't detach policy %v from role %v. Here's why: %v\\n\",\n\t\t\t\t\t*policy.PolicyArn, *role.RoleName, err)\n\t\t\t}\n\t\t}\n\t\t_, err = iamClient.DeleteRole(ctx, &iam.DeleteRoleInput{RoleName: role.RoleName})\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't delete role %v. Here's why: %v\\n\", *role.RoleName, err)\n\t\t}\n\t\tlog.Printf(\"Deleted role %v.\\n\", *role.RoleName)\n\n\t\tscenario.functionWrapper.DeleteFunction(ctx, funcName)\n\t\tlog.Printf(\"Deleted function %v.\\n\", funcName)\n\t} else {\n\t\tlog.Println(\"Okay. Don't forget to delete the resources when you're done with them.\")\n\t}\n}\n\n// IScenarioHelper abstracts I/O and wait functions from a scenario so that they\n// can be mocked for unit testing.\ntype IScenarioHelper interface {\n\tPause(secs int)\n\tCreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer\n}\n\n// ScenarioHelper lets the caller specify the path to Lambda handler functions.\ntype ScenarioHelper struct {\n\tHandlerPath string\n}\n\n// Pause waits for the specified number of seconds.\nfunc (helper *ScenarioHelper) Pause(secs int) {\n\ttime.Sleep(time.Duration(secs) * time.Second)\n}\n\n// CreateDeploymentPackage creates an AWS Lambda deployment package from a source file. The\n// deployment package is stored in .zip format in a bytes.Buffer. The buffer can be\n// used to pass a []byte to Lambda when creating the function.\n// The specified destinationFile is the name to give the file when it's deployed to Lambda.\nfunc (helper *ScenarioHelper) CreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer {\n\tvar err error\n\tbuffer := &bytes.Buffer{}\n\twriter := zip.NewWriter(buffer)\n\tzFile, err := writer.Create(destinationFile)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't create destination archive %v. Here's why: %v\\n\", destinationFile, err)\n\t}\n\tsourceBody, err := os.ReadFile(fmt.Sprintf(\"%v/%v\", helper.HandlerPath, sourceFile))\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't read handler source file %v. Here's why: %v\\n\",\n\t\t\tsourceFile, err)\n\t} else {\n\t\t_, err = zFile.Write(sourceBody)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't write handler %v to zip archive. Here's why: %v\\n\",\n\t\t\t\tsourceFile, err)\n\t\t}\n\t}\n\terr = writer.Close()\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't close zip writer. Here's why: %v\\n\", err)\n\t}\n\treturn buffer\n}\n\n\n",
                            "  7.Java : /*\n *  Lambda function names appear as:\n *\n *  arn:aws:lambda:us-west-2:335556666777:function:HelloFunction\n *\n *  To find this value, look at the function in the AWS Management Console.\n *\n *  Before running this Java code example, set up your development environment, including your credentials.\n *\n *  For more information, see this documentation topic:\n *\n *  https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-started.html\n *\n *  This example performs the following tasks:\n *\n * 1. Creates an AWS Lambda function.\n * 2. Gets a specific AWS Lambda function.\n * 3. Lists all Lambda functions.\n * 4. Invokes a Lambda function.\n * 5. Updates the Lambda function code and invokes it again.\n * 6. Updates a Lambda function's configuration value.\n * 7. Deletes a Lambda function.\n */\n\npublic class LambdaScenario {\n    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \"-\");\n\n    public static void main(String[] args) throws InterruptedException {\n        final String usage = \"\"\"\n\n            Usage:\n                <functionName> <role> <handler> <bucketName> <key>\\s\n\n            Where:\n                functionName - The name of the Lambda function.\\s\n                role - The AWS Identity and Access Management (IAM) service role that has Lambda permissions.\\s\n                handler - The fully qualified method name (for example, example.Handler::handleRequest).\\s\n                bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the .zip or .jar used to update the Lambda function's code.\\s\n                key - The Amazon S3 key name that represents the .zip or .jar (for example, LambdaHello-1.0-SNAPSHOT.jar).\n                \"\"\";\n\n        if (args.length != 5) {\n              System.out.println(usage);\n              return;\n        }\n\n        String functionName = args[0];\n        String role = args[1];\n        String handler = args[2];\n        String bucketName = args[3];\n        String key = args[4];\n        LambdaClient awsLambda = LambdaClient.builder()\n            .build();\n\n        System.out.println(DASHES);\n        System.out.println(\"Welcome to the AWS Lambda Basics scenario.\");\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"1. Create an AWS Lambda function.\");\n        String funArn = createLambdaFunction(awsLambda, functionName, key, bucketName, role, handler);\n        System.out.println(\"The AWS Lambda ARN is \" + funArn);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"2. Get the \" + functionName + \" AWS Lambda function.\");\n        getFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"3. List all AWS Lambda functions.\");\n        listFunctions(awsLambda);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"4. Invoke the Lambda function.\");\n        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");\n        Thread.sleep(60000);\n        invokeFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"5. Update the Lambda function code and invoke it again.\");\n        updateFunctionCode(awsLambda, functionName, bucketName, key);\n        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");\n        Thread.sleep(60000);\n        invokeFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"6. Update a Lambda function's configuration value.\");\n        updateFunctionConfiguration(awsLambda, functionName, handler);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"7. Delete the AWS Lambda function.\");\n        LambdaScenario.deleteLambdaFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"The AWS Lambda scenario completed successfully\");\n        System.out.println(DASHES);\n        awsLambda.close();\n    }\n\n    /**\n     * Creates a new Lambda function in AWS using the AWS Lambda Java API.\n     *\n     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service\n     * @param functionName the name of the Lambda function to create\n     * @param key          the S3 key of the function code\n     * @param bucketName   the name of the S3 bucket containing the function code\n     * @param role         the IAM role to assign to the Lambda function\n     * @param handler      the fully qualified class name of the function handler\n     * @return the Amazon Resource Name (ARN) of the created Lambda function\n     */\n    public static String createLambdaFunction(LambdaClient awsLambda,\n                                              String functionName,\n                                              String key,\n                                              String bucketName,\n                                              String role,\n                                              String handler) {\n\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            FunctionCode code = FunctionCode.builder()\n                .s3Key(key)\n                .s3Bucket(bucketName)\n                .build();\n\n            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()\n                .functionName(functionName)\n                .description(\"Created by the Lambda Java API\")\n                .code(code)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .role(role)\n                .build();\n\n            // Create a Lambda function using a waiter\n            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);\n            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            return functionResponse.functionArn();\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n        return \"\";\n    }\n\n    /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Invokes a specific AWS Lambda function.\n     *\n     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to be invoked\n     */\n    public static void invokeFunction(LambdaClient awsLambda, String functionName) {\n        InvokeResponse res;\n        try {\n            // Need a SdkBytes instance for the payload.\n            JSONObject jsonObj = new JSONObject();\n            jsonObj.put(\"inputValue\", \"2000\");\n            String json = jsonObj.toString();\n            SdkBytes payload = SdkBytes.fromUtf8String(json);\n\n            InvokeRequest request = InvokeRequest.builder()\n                .functionName(functionName)\n                .payload(payload)\n                .build();\n\n            res = awsLambda.invoke(request);\n            String value = res.payload().asUtf8String();\n            System.out.println(value);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Updates the code for an AWS Lambda function.\n     *\n     * @param awsLambda  the AWS Lambda client\n     * @param functionName the name of the Lambda function to update\n     * @param bucketName the name of the S3 bucket where the function code is located\n     * @param key the key (file name) of the function code in the S3 bucket\n     * @throws LambdaException if there is an error updating the function code\n     */\n    public static void updateFunctionCode(LambdaClient awsLambda, String functionName, String bucketName, String key) {\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            UpdateFunctionCodeRequest functionCodeRequest = UpdateFunctionCodeRequest.builder()\n                .functionName(functionName)\n                .publish(true)\n                .s3Bucket(bucketName)\n                .s3Key(key)\n                .build();\n\n            UpdateFunctionCodeResponse response = awsLambda.updateFunctionCode(functionCodeRequest);\n            GetFunctionConfigurationRequest getFunctionConfigRequest = GetFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            WaiterResponse<GetFunctionConfigurationResponse> waiterResponse = waiter\n                .waitUntilFunctionUpdated(getFunctionConfigRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            System.out.println(\"The last modified value is \" + response.lastModified());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Updates the configuration of an AWS Lambda function.\n     *\n     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation\n     * @param functionName  the name of the AWS Lambda function to update\n     * @param handler       the new handler for the AWS Lambda function\n     *\n     * @throws LambdaException if there is an error while updating the function configuration\n     */\n    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {\n        try {\n            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .build();\n\n            awsLambda.updateFunctionConfiguration(configurationRequest);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Deletes an AWS Lambda function.\n     *\n     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName  the name of the Lambda function to be deleted\n     *\n     * @throws LambdaException if an error occurs while deleting the Lambda function\n     */\n    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            DeleteFunctionRequest request = DeleteFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            awsLambda.deleteFunction(request);\n            System.out.println(\"The \" + functionName + \" function was deleted\");\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n}\n\n",
                            "  8.SDK for Java 2.x : /*\n *  Lambda function names appear as:\n *\n *  arn:aws:lambda:us-west-2:335556666777:function:HelloFunction\n *\n *  To find this value, look at the function in the AWS Management Console.\n *\n *  Before running this Java code example, set up your development environment, including your credentials.\n *\n *  For more information, see this documentation topic:\n *\n *  https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-started.html\n *\n *  This example performs the following tasks:\n *\n * 1. Creates an AWS Lambda function.\n * 2. Gets a specific AWS Lambda function.\n * 3. Lists all Lambda functions.\n * 4. Invokes a Lambda function.\n * 5. Updates the Lambda function code and invokes it again.\n * 6. Updates a Lambda function's configuration value.\n * 7. Deletes a Lambda function.\n */\n\npublic class LambdaScenario {\n    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \"-\");\n\n    public static void main(String[] args) throws InterruptedException {\n        final String usage = \"\"\"\n\n            Usage:\n                <functionName> <role> <handler> <bucketName> <key>\\s\n\n            Where:\n                functionName - The name of the Lambda function.\\s\n                role - The AWS Identity and Access Management (IAM) service role that has Lambda permissions.\\s\n                handler - The fully qualified method name (for example, example.Handler::handleRequest).\\s\n                bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the .zip or .jar used to update the Lambda function's code.\\s\n                key - The Amazon S3 key name that represents the .zip or .jar (for example, LambdaHello-1.0-SNAPSHOT.jar).\n                \"\"\";\n\n        if (args.length != 5) {\n              System.out.println(usage);\n              return;\n        }\n\n        String functionName = args[0];\n        String role = args[1];\n        String handler = args[2];\n        String bucketName = args[3];\n        String key = args[4];\n        LambdaClient awsLambda = LambdaClient.builder()\n            .build();\n\n        System.out.println(DASHES);\n        System.out.println(\"Welcome to the AWS Lambda Basics scenario.\");\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"1. Create an AWS Lambda function.\");\n        String funArn = createLambdaFunction(awsLambda, functionName, key, bucketName, role, handler);\n        System.out.println(\"The AWS Lambda ARN is \" + funArn);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"2. Get the \" + functionName + \" AWS Lambda function.\");\n        getFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"3. List all AWS Lambda functions.\");\n        listFunctions(awsLambda);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"4. Invoke the Lambda function.\");\n        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");\n        Thread.sleep(60000);\n        invokeFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"5. Update the Lambda function code and invoke it again.\");\n        updateFunctionCode(awsLambda, functionName, bucketName, key);\n        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");\n        Thread.sleep(60000);\n        invokeFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"6. Update a Lambda function's configuration value.\");\n        updateFunctionConfiguration(awsLambda, functionName, handler);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"7. Delete the AWS Lambda function.\");\n        LambdaScenario.deleteLambdaFunction(awsLambda, functionName);\n        System.out.println(DASHES);\n\n        System.out.println(DASHES);\n        System.out.println(\"The AWS Lambda scenario completed successfully\");\n        System.out.println(DASHES);\n        awsLambda.close();\n    }\n\n    /**\n     * Creates a new Lambda function in AWS using the AWS Lambda Java API.\n     *\n     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service\n     * @param functionName the name of the Lambda function to create\n     * @param key          the S3 key of the function code\n     * @param bucketName   the name of the S3 bucket containing the function code\n     * @param role         the IAM role to assign to the Lambda function\n     * @param handler      the fully qualified class name of the function handler\n     * @return the Amazon Resource Name (ARN) of the created Lambda function\n     */\n    public static String createLambdaFunction(LambdaClient awsLambda,\n                                              String functionName,\n                                              String key,\n                                              String bucketName,\n                                              String role,\n                                              String handler) {\n\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            FunctionCode code = FunctionCode.builder()\n                .s3Key(key)\n                .s3Bucket(bucketName)\n                .build();\n\n            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()\n                .functionName(functionName)\n                .description(\"Created by the Lambda Java API\")\n                .code(code)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .role(role)\n                .build();\n\n            // Create a Lambda function using a waiter\n            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);\n            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            return functionResponse.functionArn();\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n        return \"\";\n    }\n\n    /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Invokes a specific AWS Lambda function.\n     *\n     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to be invoked\n     */\n    public static void invokeFunction(LambdaClient awsLambda, String functionName) {\n        InvokeResponse res;\n        try {\n            // Need a SdkBytes instance for the payload.\n            JSONObject jsonObj = new JSONObject();\n            jsonObj.put(\"inputValue\", \"2000\");\n            String json = jsonObj.toString();\n            SdkBytes payload = SdkBytes.fromUtf8String(json);\n\n            InvokeRequest request = InvokeRequest.builder()\n                .functionName(functionName)\n                .payload(payload)\n                .build();\n\n            res = awsLambda.invoke(request);\n            String value = res.payload().asUtf8String();\n            System.out.println(value);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Updates the code for an AWS Lambda function.\n     *\n     * @param awsLambda  the AWS Lambda client\n     * @param functionName the name of the Lambda function to update\n     * @param bucketName the name of the S3 bucket where the function code is located\n     * @param key the key (file name) of the function code in the S3 bucket\n     * @throws LambdaException if there is an error updating the function code\n     */\n    public static void updateFunctionCode(LambdaClient awsLambda, String functionName, String bucketName, String key) {\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            UpdateFunctionCodeRequest functionCodeRequest = UpdateFunctionCodeRequest.builder()\n                .functionName(functionName)\n                .publish(true)\n                .s3Bucket(bucketName)\n                .s3Key(key)\n                .build();\n\n            UpdateFunctionCodeResponse response = awsLambda.updateFunctionCode(functionCodeRequest);\n            GetFunctionConfigurationRequest getFunctionConfigRequest = GetFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            WaiterResponse<GetFunctionConfigurationResponse> waiterResponse = waiter\n                .waitUntilFunctionUpdated(getFunctionConfigRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            System.out.println(\"The last modified value is \" + response.lastModified());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Updates the configuration of an AWS Lambda function.\n     *\n     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation\n     * @param functionName  the name of the AWS Lambda function to update\n     * @param handler       the new handler for the AWS Lambda function\n     *\n     * @throws LambdaException if there is an error while updating the function configuration\n     */\n    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {\n        try {\n            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .build();\n\n            awsLambda.updateFunctionConfiguration(configurationRequest);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    /**\n     * Deletes an AWS Lambda function.\n     *\n     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName  the name of the Lambda function to be deleted\n     *\n     * @throws LambdaException if an error occurs while deleting the Lambda function\n     */\n    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            DeleteFunctionRequest request = DeleteFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            awsLambda.deleteFunction(request);\n            System.out.println(\"The \" + functionName + \" function was deleted\");\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n}\n\n",
                            "  9.JavaScript :     logger.log(`Creating role (${NAME_ROLE_LAMBDA})...`);\n    const response = await createRole(NAME_ROLE_LAMBDA);\n\nimport { AttachRolePolicyCommand, IAMClient } from \"@aws-sdk/client-iam\";\n\nconst client = new IAMClient({});\n\n/**\n *\n * @param {string} policyArn\n * @param {string} roleName\n */\nexport const attachRolePolicy = (policyArn, roleName) => {\n  const command = new AttachRolePolicyCommand({\n    PolicyArn: policyArn,\n    RoleName: roleName,\n  });\n\n  return client.send(command);\n};\n\n",
                            "  10.SDK for JavaScript (v3) :     logger.log(`Creating role (${NAME_ROLE_LAMBDA})...`);\n    const response = await createRole(NAME_ROLE_LAMBDA);\n\nimport { AttachRolePolicyCommand, IAMClient } from \"@aws-sdk/client-iam\";\n\nconst client = new IAMClient({});\n\n/**\n *\n * @param {string} policyArn\n * @param {string} roleName\n */\nexport const attachRolePolicy = (policyArn, roleName) => {\n  const command = new AttachRolePolicyCommand({\n    PolicyArn: policyArn,\n    RoleName: roleName,\n  });\n\n  return client.send(command);\n};\n\n",
                            "  11.Kotlin : suspend fun main(args: Array<String>) {\n    val usage = \"\"\"\n        Usage:\n            <functionName> <role> <handler> <bucketName> <updatedBucketName> <key> \n\n        Where:\n            functionName - The name of the AWS Lambda function. \n            role - The AWS Identity and Access Management (IAM) service role that has AWS Lambda permissions. \n            handler - The fully qualified method name (for example, example.Handler::handleRequest). \n            bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the ZIP or JAR used for the Lambda function's code.\n            updatedBucketName - The Amazon S3 bucket name that contains the .zip or .jar used to update the Lambda function's code. \n            key - The Amazon S3 key name that represents the .zip or .jar file (for example, LambdaHello-1.0-SNAPSHOT.jar).\n            \"\"\"\n\n    if (args.size != 6) {\n        println(usage)\n        exitProcess(1)\n    }\n\n    val functionName = args[0]\n    val role = args[1]\n    val handler = args[2]\n    val bucketName = args[3]\n    val updatedBucketName = args[4]\n    val key = args[5]\n\n    println(\"Creating a Lambda function named $functionName.\")\n    val funArn = createScFunction(functionName, bucketName, key, handler, role)\n    println(\"The AWS Lambda ARN is $funArn\")\n\n    // Get a specific Lambda function.\n    println(\"Getting the $functionName AWS Lambda function.\")\n    getFunction(functionName)\n\n    // List the Lambda functions.\n    println(\"Listing all AWS Lambda functions.\")\n    listFunctionsSc()\n\n    // Invoke the Lambda function.\n    println(\"*** Invoke the Lambda function.\")\n    invokeFunctionSc(functionName)\n\n    // Update the AWS Lambda function code.\n    println(\"*** Update the Lambda function code.\")\n    updateFunctionCode(functionName, updatedBucketName, key)\n\n    // println(\"*** Invoke the function again after updating the code.\")\n    invokeFunctionSc(functionName)\n\n    // Update the AWS Lambda function configuration.\n    println(\"Update the run time of the function.\")\n    updateFunctionConfiguration(functionName, handler)\n\n    // Delete the AWS Lambda function.\n    println(\"Delete the AWS Lambda function.\")\n    delFunction(functionName)\n}\n\nsuspend fun createScFunction(\n    myFunctionName: String,\n    s3BucketName: String,\n    myS3Key: String,\n    myHandler: String,\n    myRole: String,\n): String {\n    val functionCode =\n        FunctionCode {\n            s3Bucket = s3BucketName\n            s3Key = myS3Key\n        }\n\n    val request =\n        CreateFunctionRequest {\n            functionName = myFunctionName\n            code = functionCode\n            description = \"Created by the Lambda Kotlin API\"\n            handler = myHandler\n            role = myRole\n            runtime = Runtime.Java8\n        }\n\n    // Create a Lambda function using a waiter\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val functionResponse = awsLambda.createFunction(request)\n        awsLambda.waitUntilFunctionActive {\n            functionName = myFunctionName\n        }\n        return functionResponse.functionArn.toString()\n    }\n}\n\nsuspend fun getFunction(functionNameVal: String) {\n    val functionRequest =\n        GetFunctionRequest {\n            functionName = functionNameVal\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.getFunction(functionRequest)\n        println(\"The runtime of this Lambda function is ${response.configuration?.runtime}\")\n    }\n}\n\nsuspend fun listFunctionsSc() {\n    val request =\n        ListFunctionsRequest {\n            maxItems = 10\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.listFunctions(request)\n        response.functions?.forEach { function ->\n            println(\"The function name is ${function.functionName}\")\n        }\n    }\n}\n\nsuspend fun invokeFunctionSc(functionNameVal: String) {\n    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"\n    val byteArray = json.trimIndent().encodeToByteArray()\n    val request =\n        InvokeRequest {\n            functionName = functionNameVal\n            payload = byteArray\n            logType = LogType.Tail\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val res = awsLambda.invoke(request)\n        println(\"The function payload is ${res.payload?.toString(Charsets.UTF_8)}\")\n    }\n}\n\nsuspend fun updateFunctionCode(\n    functionNameVal: String?,\n    bucketName: String?,\n    key: String?,\n) {\n    val functionCodeRequest =\n        UpdateFunctionCodeRequest {\n            functionName = functionNameVal\n            publish = true\n            s3Bucket = bucketName\n            s3Key = key\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.updateFunctionCode(functionCodeRequest)\n        awsLambda.waitUntilFunctionUpdated {\n            functionName = functionNameVal\n        }\n        println(\"The last modified value is \" + response.lastModified)\n    }\n}\n\nsuspend fun updateFunctionConfiguration(\n    functionNameVal: String?,\n    handlerVal: String?,\n) {\n    val configurationRequest =\n        UpdateFunctionConfigurationRequest {\n            functionName = functionNameVal\n            handler = handlerVal\n            runtime = Runtime.Java11\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.updateFunctionConfiguration(configurationRequest)\n    }\n}\n\nsuspend fun delFunction(myFunctionName: String) {\n    val request =\n        DeleteFunctionRequest {\n            functionName = myFunctionName\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.deleteFunction(request)\n        println(\"$myFunctionName was deleted\")\n    }\n}\n\n",
                            "  12.SDK for Kotlin : suspend fun main(args: Array<String>) {\n    val usage = \"\"\"\n        Usage:\n            <functionName> <role> <handler> <bucketName> <updatedBucketName> <key> \n\n        Where:\n            functionName - The name of the AWS Lambda function. \n            role - The AWS Identity and Access Management (IAM) service role that has AWS Lambda permissions. \n            handler - The fully qualified method name (for example, example.Handler::handleRequest). \n            bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the ZIP or JAR used for the Lambda function's code.\n            updatedBucketName - The Amazon S3 bucket name that contains the .zip or .jar used to update the Lambda function's code. \n            key - The Amazon S3 key name that represents the .zip or .jar file (for example, LambdaHello-1.0-SNAPSHOT.jar).\n            \"\"\"\n\n    if (args.size != 6) {\n        println(usage)\n        exitProcess(1)\n    }\n\n    val functionName = args[0]\n    val role = args[1]\n    val handler = args[2]\n    val bucketName = args[3]\n    val updatedBucketName = args[4]\n    val key = args[5]\n\n    println(\"Creating a Lambda function named $functionName.\")\n    val funArn = createScFunction(functionName, bucketName, key, handler, role)\n    println(\"The AWS Lambda ARN is $funArn\")\n\n    // Get a specific Lambda function.\n    println(\"Getting the $functionName AWS Lambda function.\")\n    getFunction(functionName)\n\n    // List the Lambda functions.\n    println(\"Listing all AWS Lambda functions.\")\n    listFunctionsSc()\n\n    // Invoke the Lambda function.\n    println(\"*** Invoke the Lambda function.\")\n    invokeFunctionSc(functionName)\n\n    // Update the AWS Lambda function code.\n    println(\"*** Update the Lambda function code.\")\n    updateFunctionCode(functionName, updatedBucketName, key)\n\n    // println(\"*** Invoke the function again after updating the code.\")\n    invokeFunctionSc(functionName)\n\n    // Update the AWS Lambda function configuration.\n    println(\"Update the run time of the function.\")\n    updateFunctionConfiguration(functionName, handler)\n\n    // Delete the AWS Lambda function.\n    println(\"Delete the AWS Lambda function.\")\n    delFunction(functionName)\n}\n\nsuspend fun createScFunction(\n    myFunctionName: String,\n    s3BucketName: String,\n    myS3Key: String,\n    myHandler: String,\n    myRole: String,\n): String {\n    val functionCode =\n        FunctionCode {\n            s3Bucket = s3BucketName\n            s3Key = myS3Key\n        }\n\n    val request =\n        CreateFunctionRequest {\n            functionName = myFunctionName\n            code = functionCode\n            description = \"Created by the Lambda Kotlin API\"\n            handler = myHandler\n            role = myRole\n            runtime = Runtime.Java8\n        }\n\n    // Create a Lambda function using a waiter\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val functionResponse = awsLambda.createFunction(request)\n        awsLambda.waitUntilFunctionActive {\n            functionName = myFunctionName\n        }\n        return functionResponse.functionArn.toString()\n    }\n}\n\nsuspend fun getFunction(functionNameVal: String) {\n    val functionRequest =\n        GetFunctionRequest {\n            functionName = functionNameVal\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.getFunction(functionRequest)\n        println(\"The runtime of this Lambda function is ${response.configuration?.runtime}\")\n    }\n}\n\nsuspend fun listFunctionsSc() {\n    val request =\n        ListFunctionsRequest {\n            maxItems = 10\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.listFunctions(request)\n        response.functions?.forEach { function ->\n            println(\"The function name is ${function.functionName}\")\n        }\n    }\n}\n\nsuspend fun invokeFunctionSc(functionNameVal: String) {\n    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"\n    val byteArray = json.trimIndent().encodeToByteArray()\n    val request =\n        InvokeRequest {\n            functionName = functionNameVal\n            payload = byteArray\n            logType = LogType.Tail\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val res = awsLambda.invoke(request)\n        println(\"The function payload is ${res.payload?.toString(Charsets.UTF_8)}\")\n    }\n}\n\nsuspend fun updateFunctionCode(\n    functionNameVal: String?,\n    bucketName: String?,\n    key: String?,\n) {\n    val functionCodeRequest =\n        UpdateFunctionCodeRequest {\n            functionName = functionNameVal\n            publish = true\n            s3Bucket = bucketName\n            s3Key = key\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val response = awsLambda.updateFunctionCode(functionCodeRequest)\n        awsLambda.waitUntilFunctionUpdated {\n            functionName = functionNameVal\n        }\n        println(\"The last modified value is \" + response.lastModified)\n    }\n}\n\nsuspend fun updateFunctionConfiguration(\n    functionNameVal: String?,\n    handlerVal: String?,\n) {\n    val configurationRequest =\n        UpdateFunctionConfigurationRequest {\n            functionName = functionNameVal\n            handler = handlerVal\n            runtime = Runtime.Java11\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.updateFunctionConfiguration(configurationRequest)\n    }\n}\n\nsuspend fun delFunction(myFunctionName: String) {\n    val request =\n        DeleteFunctionRequest {\n            functionName = myFunctionName\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.deleteFunction(request)\n        println(\"$myFunctionName was deleted\")\n    }\n}\n\n",
                            "  13.PHP : namespace Lambda;\n\nuse Aws\\S3\\S3Client;\nuse GuzzleHttp\\Psr7\\Stream;\nuse Iam\\IAMService;\n\nclass GettingStartedWithLambda\n{\n    public function run()\n    {\n        echo(\"\\n\");\n        echo(\"--------------------------------------\\n\");\n        print(\"Welcome to the AWS Lambda getting started demo using PHP!\\n\");\n        echo(\"--------------------------------------\\n\");\n\n        $clientArgs = [\n            'region' => 'us-west-2',\n            'version' => 'latest',\n            'profile' => 'default',\n        ];\n        $uniqid = uniqid();\n\n        $iamService = new IAMService();\n        $s3client = new S3Client($clientArgs);\n        $lambdaService = new LambdaService();\n\n        echo \"First, let's create a role to run our Lambda code.\\n\";\n        $roleName = \"test-lambda-role-$uniqid\";\n        $rolePolicyDocument = \"{\n            \\\"Version\\\": \\\"2012-10-17\\\",\n            \\\"Statement\\\": [\n                {\n                    \\\"Effect\\\": \\\"Allow\\\",\n                    \\\"Principal\\\": {\n                        \\\"Service\\\": \\\"lambda.amazonaws.com\\\"\n                    },\n                    \\\"Action\\\": \\\"sts:AssumeRole\\\"\n                }\n            ]\n        }\";\n        $role = $iamService->createRole($roleName, $rolePolicyDocument);\n        echo \"Created role {$role['RoleName']}.\\n\";\n\n        $iamService->attachRolePolicy(\n            $role['RoleName'],\n            \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n        );\n        echo \"Attached the AWSLambdaBasicExecutionRole to {$role['RoleName']}.\\n\";\n\n        echo \"\\nNow let's create an S3 bucket and upload our Lambda code there.\\n\";\n        $bucketName = \"test-example-bucket-$uniqid\";\n        $s3client->createBucket([\n            'Bucket' => $bucketName,\n        ]);\n        echo \"Created bucket $bucketName.\\n\";\n\n        $functionName = \"doc_example_lambda_$uniqid\";\n        $codeBasic = __DIR__ . \"/lambda_handler_basic.zip\";\n        $handler = \"lambda_handler_basic\";\n        $file = file_get_contents($codeBasic);\n        $s3client->putObject([\n            'Bucket' => $bucketName,\n            'Key' => $functionName,\n            'Body' => $file,\n        ]);\n        echo \"Uploaded the Lambda code.\\n\";\n\n        $createLambdaFunction = $lambdaService->createFunction($functionName, $role, $bucketName, $handler);\n        // Wait until the function has finished being created.\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['State'] == \"Pending\");\n        echo \"Created Lambda function {$getLambdaFunction['Configuration']['FunctionName']}.\\n\";\n\n        sleep(1);\n\n        echo \"\\nOk, let's invoke that Lambda code.\\n\";\n        $basicParams = [\n            'action' => 'increment',\n            'number' => 3,\n        ];\n        /** @var Stream $invokeFunction */\n        $invokeFunction = $lambdaService->invoke($functionName, $basicParams)['Payload'];\n        $result = json_decode($invokeFunction->getContents())->result;\n        echo \"After invoking the Lambda code with the input of {$basicParams['number']} we received $result.\\n\";\n\n        echo \"\\nSince that's working, let's update the Lambda code.\\n\";\n        $codeCalculator = \"lambda_handler_calculator.zip\";\n        $handlerCalculator = \"lambda_handler_calculator\";\n        echo \"First, put the new code into the S3 bucket.\\n\";\n        $file = file_get_contents($codeCalculator);\n        $s3client->putObject([\n            'Bucket' => $bucketName,\n            'Key' => $functionName,\n            'Body' => $file,\n        ]);\n        echo \"New code uploaded.\\n\";\n\n        $lambdaService->updateFunctionCode($functionName, $bucketName, $functionName);\n        // Wait for the Lambda code to finish updating.\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");\n        echo \"New Lambda code uploaded.\\n\";\n\n        $environment = [\n            'Variable' => ['Variables' => ['LOG_LEVEL' => 'DEBUG']],\n        ];\n        $lambdaService->updateFunctionConfiguration($functionName, $handlerCalculator, $environment);\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");\n        echo \"Lambda code updated with new handler and a LOG_LEVEL of DEBUG for more information.\\n\";\n\n        echo \"Invoke the new code with some new data.\\n\";\n        $calculatorParams = [\n            'action' => 'plus',\n            'x' => 5,\n            'y' => 4,\n        ];\n        $invokeFunction = $lambdaService->invoke($functionName, $calculatorParams, \"Tail\");\n        $result = json_decode($invokeFunction['Payload']->getContents())->result;\n        echo \"Indeed, {$calculatorParams['x']} + {$calculatorParams['y']} does equal $result.\\n\";\n        echo \"Here's the extra debug info: \";\n        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";\n\n        echo \"\\nBut what happens if you try to divide by zero?\\n\";\n        $divZeroParams = [\n            'action' => 'divide',\n            'x' => 5,\n            'y' => 0,\n        ];\n        $invokeFunction = $lambdaService->invoke($functionName, $divZeroParams, \"Tail\");\n        $result = json_decode($invokeFunction['Payload']->getContents())->result;\n        echo \"You get a |$result| result.\\n\";\n        echo \"And an error message: \";\n        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";\n\n        echo \"\\nHere's all the Lambda functions you have in this Region:\\n\";\n        $listLambdaFunctions = $lambdaService->listFunctions(5);\n        $allLambdaFunctions = $listLambdaFunctions['Functions'];\n        $next = $listLambdaFunctions->get('NextMarker');\n        while ($next != false) {\n            $listLambdaFunctions = $lambdaService->listFunctions(5, $next);\n            $next = $listLambdaFunctions->get('NextMarker');\n            $allLambdaFunctions = array_merge($allLambdaFunctions, $listLambdaFunctions['Functions']);\n        }\n        foreach ($allLambdaFunctions as $function) {\n            echo \"{$function['FunctionName']}\\n\";\n        }\n\n        echo \"\\n\\nAnd don't forget to clean up your data!\\n\";\n\n        $lambdaService->deleteFunction($functionName);\n        echo \"Deleted Lambda function.\\n\";\n        $iamService->deleteRole($role['RoleName']);\n        echo \"Deleted Role.\\n\";\n        $deleteObjects = $s3client->listObjectsV2([\n            'Bucket' => $bucketName,\n        ]);\n        $deleteObjects = $s3client->deleteObjects([\n            'Bucket' => $bucketName,\n            'Delete' => [\n                'Objects' => $deleteObjects['Contents'],\n            ]\n        ]);\n        echo \"Deleted all objects from the S3 bucket.\\n\";\n        $s3client->deleteBucket(['Bucket' => $bucketName]);\n        echo \"Deleted the bucket.\\n\";\n    }\n}\n\n",
                            "  14.SDK for PHP : namespace Lambda;\n\nuse Aws\\S3\\S3Client;\nuse GuzzleHttp\\Psr7\\Stream;\nuse Iam\\IAMService;\n\nclass GettingStartedWithLambda\n{\n    public function run()\n    {\n        echo(\"\\n\");\n        echo(\"--------------------------------------\\n\");\n        print(\"Welcome to the AWS Lambda getting started demo using PHP!\\n\");\n        echo(\"--------------------------------------\\n\");\n\n        $clientArgs = [\n            'region' => 'us-west-2',\n            'version' => 'latest',\n            'profile' => 'default',\n        ];\n        $uniqid = uniqid();\n\n        $iamService = new IAMService();\n        $s3client = new S3Client($clientArgs);\n        $lambdaService = new LambdaService();\n\n        echo \"First, let's create a role to run our Lambda code.\\n\";\n        $roleName = \"test-lambda-role-$uniqid\";\n        $rolePolicyDocument = \"{\n            \\\"Version\\\": \\\"2012-10-17\\\",\n            \\\"Statement\\\": [\n                {\n                    \\\"Effect\\\": \\\"Allow\\\",\n                    \\\"Principal\\\": {\n                        \\\"Service\\\": \\\"lambda.amazonaws.com\\\"\n                    },\n                    \\\"Action\\\": \\\"sts:AssumeRole\\\"\n                }\n            ]\n        }\";\n        $role = $iamService->createRole($roleName, $rolePolicyDocument);\n        echo \"Created role {$role['RoleName']}.\\n\";\n\n        $iamService->attachRolePolicy(\n            $role['RoleName'],\n            \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n        );\n        echo \"Attached the AWSLambdaBasicExecutionRole to {$role['RoleName']}.\\n\";\n\n        echo \"\\nNow let's create an S3 bucket and upload our Lambda code there.\\n\";\n        $bucketName = \"test-example-bucket-$uniqid\";\n        $s3client->createBucket([\n            'Bucket' => $bucketName,\n        ]);\n        echo \"Created bucket $bucketName.\\n\";\n\n        $functionName = \"doc_example_lambda_$uniqid\";\n        $codeBasic = __DIR__ . \"/lambda_handler_basic.zip\";\n        $handler = \"lambda_handler_basic\";\n        $file = file_get_contents($codeBasic);\n        $s3client->putObject([\n            'Bucket' => $bucketName,\n            'Key' => $functionName,\n            'Body' => $file,\n        ]);\n        echo \"Uploaded the Lambda code.\\n\";\n\n        $createLambdaFunction = $lambdaService->createFunction($functionName, $role, $bucketName, $handler);\n        // Wait until the function has finished being created.\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['State'] == \"Pending\");\n        echo \"Created Lambda function {$getLambdaFunction['Configuration']['FunctionName']}.\\n\";\n\n        sleep(1);\n\n        echo \"\\nOk, let's invoke that Lambda code.\\n\";\n        $basicParams = [\n            'action' => 'increment',\n            'number' => 3,\n        ];\n        /** @var Stream $invokeFunction */\n        $invokeFunction = $lambdaService->invoke($functionName, $basicParams)['Payload'];\n        $result = json_decode($invokeFunction->getContents())->result;\n        echo \"After invoking the Lambda code with the input of {$basicParams['number']} we received $result.\\n\";\n\n        echo \"\\nSince that's working, let's update the Lambda code.\\n\";\n        $codeCalculator = \"lambda_handler_calculator.zip\";\n        $handlerCalculator = \"lambda_handler_calculator\";\n        echo \"First, put the new code into the S3 bucket.\\n\";\n        $file = file_get_contents($codeCalculator);\n        $s3client->putObject([\n            'Bucket' => $bucketName,\n            'Key' => $functionName,\n            'Body' => $file,\n        ]);\n        echo \"New code uploaded.\\n\";\n\n        $lambdaService->updateFunctionCode($functionName, $bucketName, $functionName);\n        // Wait for the Lambda code to finish updating.\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");\n        echo \"New Lambda code uploaded.\\n\";\n\n        $environment = [\n            'Variable' => ['Variables' => ['LOG_LEVEL' => 'DEBUG']],\n        ];\n        $lambdaService->updateFunctionConfiguration($functionName, $handlerCalculator, $environment);\n        do {\n            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);\n        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");\n        echo \"Lambda code updated with new handler and a LOG_LEVEL of DEBUG for more information.\\n\";\n\n        echo \"Invoke the new code with some new data.\\n\";\n        $calculatorParams = [\n            'action' => 'plus',\n            'x' => 5,\n            'y' => 4,\n        ];\n        $invokeFunction = $lambdaService->invoke($functionName, $calculatorParams, \"Tail\");\n        $result = json_decode($invokeFunction['Payload']->getContents())->result;\n        echo \"Indeed, {$calculatorParams['x']} + {$calculatorParams['y']} does equal $result.\\n\";\n        echo \"Here's the extra debug info: \";\n        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";\n\n        echo \"\\nBut what happens if you try to divide by zero?\\n\";\n        $divZeroParams = [\n            'action' => 'divide',\n            'x' => 5,\n            'y' => 0,\n        ];\n        $invokeFunction = $lambdaService->invoke($functionName, $divZeroParams, \"Tail\");\n        $result = json_decode($invokeFunction['Payload']->getContents())->result;\n        echo \"You get a |$result| result.\\n\";\n        echo \"And an error message: \";\n        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";\n\n        echo \"\\nHere's all the Lambda functions you have in this Region:\\n\";\n        $listLambdaFunctions = $lambdaService->listFunctions(5);\n        $allLambdaFunctions = $listLambdaFunctions['Functions'];\n        $next = $listLambdaFunctions->get('NextMarker');\n        while ($next != false) {\n            $listLambdaFunctions = $lambdaService->listFunctions(5, $next);\n            $next = $listLambdaFunctions->get('NextMarker');\n            $allLambdaFunctions = array_merge($allLambdaFunctions, $listLambdaFunctions['Functions']);\n        }\n        foreach ($allLambdaFunctions as $function) {\n            echo \"{$function['FunctionName']}\\n\";\n        }\n\n        echo \"\\n\\nAnd don't forget to clean up your data!\\n\";\n\n        $lambdaService->deleteFunction($functionName);\n        echo \"Deleted Lambda function.\\n\";\n        $iamService->deleteRole($role['RoleName']);\n        echo \"Deleted Role.\\n\";\n        $deleteObjects = $s3client->listObjectsV2([\n            'Bucket' => $bucketName,\n        ]);\n        $deleteObjects = $s3client->deleteObjects([\n            'Bucket' => $bucketName,\n            'Delete' => [\n                'Objects' => $deleteObjects['Contents'],\n            ]\n        ]);\n        echo \"Deleted all objects from the S3 bucket.\\n\";\n        $s3client->deleteBucket(['Bucket' => $bucketName]);\n        echo \"Deleted the bucket.\\n\";\n    }\n}\n\n",
                            "  15.Python : import logging\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\ndef lambda_handler(event, context):\n    \"\"\"\n    Accepts an action and a single number, performs the specified action on the number,\n    and returns the result. The only allowable action is 'increment'.\n\n    :param event: The event dict that contains the parameters sent when the function\n                  is invoked.\n    :param context: The context in which the function is called.\n    :return: The result of the action.\n    \"\"\"\n    result = None\n    action = event.get(\"action\")\n    if action == \"increment\":\n        result = event.get(\"number\", 0) + 1\n        logger.info(\"Calculated result of %s\", result)\n    else:\n        logger.error(\"%s is not a valid action.\", action)\n\n    response = {\"result\": result}\n    return response\n\n\n\n",
                            "  16.SDK for Python (Boto3) : import logging\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\ndef lambda_handler(event, context):\n    \"\"\"\n    Accepts an action and a single number, performs the specified action on the number,\n    and returns the result. The only allowable action is 'increment'.\n\n    :param event: The event dict that contains the parameters sent when the function\n                  is invoked.\n    :param context: The context in which the function is called.\n    :return: The result of the action.\n    \"\"\"\n    result = None\n    action = event.get(\"action\")\n    if action == \"increment\":\n        result = event.get(\"number\", 0) + 1\n        logger.info(\"Calculated result of %s\", result)\n    else:\n        logger.error(\"%s is not a valid action.\", action)\n\n    response = {\"result\": result}\n    return response\n\n\n\n",
                            "  17.Ruby :   # Get an AWS Identity and Access Management (IAM) role.\n  #\n  # @param iam_role_name: The name of the role to retrieve.\n  # @param action: Whether to create or destroy the IAM apparatus.\n  # @return: The IAM role.\n  def manage_iam(iam_role_name, action)\n    case action\n    when 'create'\n      create_iam_role(iam_role_name)\n    when 'destroy'\n      destroy_iam_role(iam_role_name)\n    else\n      raise \"Incorrect action provided. Must provide 'create' or 'destroy'\"\n    end\n  end\n\n  private\n\n  def create_iam_role(iam_role_name)\n    role_policy = {\n      'Version': '2012-10-17',\n      'Statement': [\n        {\n          'Effect': 'Allow',\n          'Principal': { 'Service': 'lambda.amazonaws.com' },\n          'Action': 'sts:AssumeRole'\n        }\n      ]\n    }\n    role = @iam_client.create_role(\n      role_name: iam_role_name,\n      assume_role_policy_document: role_policy.to_json\n    )\n    @iam_client.attach_role_policy(\n      {\n        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',\n        role_name: iam_role_name\n      }\n    )\n    wait_for_role_to_exist(iam_role_name)\n    @logger.debug(\"Successfully created IAM role: #{role['role']['arn']}\")\n    sleep(10)\n    [role, role_policy.to_json]\n  end\n\n  def destroy_iam_role(iam_role_name)\n    @iam_client.detach_role_policy(\n      {\n        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',\n        role_name: iam_role_name\n      }\n    )\n    @iam_client.delete_role(role_name: iam_role_name)\n    @logger.debug(\"Detached policy & deleted IAM role: #{iam_role_name}\")\n  end\n\n  def wait_for_role_to_exist(iam_role_name)\n    @iam_client.wait_until(:role_exists, { role_name: iam_role_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  end\n\n",
                            "  18.SDK for Ruby :   # Get an AWS Identity and Access Management (IAM) role.\n  #\n  # @param iam_role_name: The name of the role to retrieve.\n  # @param action: Whether to create or destroy the IAM apparatus.\n  # @return: The IAM role.\n  def manage_iam(iam_role_name, action)\n    case action\n    when 'create'\n      create_iam_role(iam_role_name)\n    when 'destroy'\n      destroy_iam_role(iam_role_name)\n    else\n      raise \"Incorrect action provided. Must provide 'create' or 'destroy'\"\n    end\n  end\n\n  private\n\n  def create_iam_role(iam_role_name)\n    role_policy = {\n      'Version': '2012-10-17',\n      'Statement': [\n        {\n          'Effect': 'Allow',\n          'Principal': { 'Service': 'lambda.amazonaws.com' },\n          'Action': 'sts:AssumeRole'\n        }\n      ]\n    }\n    role = @iam_client.create_role(\n      role_name: iam_role_name,\n      assume_role_policy_document: role_policy.to_json\n    )\n    @iam_client.attach_role_policy(\n      {\n        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',\n        role_name: iam_role_name\n      }\n    )\n    wait_for_role_to_exist(iam_role_name)\n    @logger.debug(\"Successfully created IAM role: #{role['role']['arn']}\")\n    sleep(10)\n    [role, role_policy.to_json]\n  end\n\n  def destroy_iam_role(iam_role_name)\n    @iam_client.detach_role_policy(\n      {\n        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',\n        role_name: iam_role_name\n      }\n    )\n    @iam_client.delete_role(role_name: iam_role_name)\n    @logger.debug(\"Detached policy & deleted IAM role: #{iam_role_name}\")\n  end\n\n  def wait_for_role_to_exist(iam_role_name)\n    @iam_client.wait_until(:role_exists, { role_name: iam_role_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  end\n\n",
                            "  19.Rust : [package]\nname = \"lambda-code-examples\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\naws-config = { version = \"1.0.1\", features = [\"behavior-version-latest\"] }\naws-sdk-ec2 = { version = \"1.3.0\" }\naws-sdk-iam = { version = \"1.3.0\" }\naws-sdk-lambda = { version = \"1.3.0\" }\naws-sdk-s3 = { version = \"1.4.0\" }\naws-smithy-types = { version = \"1.0.1\" }\naws-types = { version = \"1.0.1\" }\nclap = { version = \"4.4\", features = [\"derive\"] }\ntokio = { version = \"1.20.1\", features = [\"full\"] }\ntracing-subscriber = { version = \"0.3.15\", features = [\"env-filter\"] }\ntracing = \"0.1.37\"\nserde_json = \"1.0.94\"\nanyhow = \"1.0.71\"\nuuid = { version = \"1.3.3\", features = [\"v4\"] }\nlambda_runtime = \"0.8.0\"\nserde = \"1.0.164\"\n\n",
                            "  20.SDK for Rust : [package]\nname = \"lambda-code-examples\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\naws-config = { version = \"1.0.1\", features = [\"behavior-version-latest\"] }\naws-sdk-ec2 = { version = \"1.3.0\" }\naws-sdk-iam = { version = \"1.3.0\" }\naws-sdk-lambda = { version = \"1.3.0\" }\naws-sdk-s3 = { version = \"1.4.0\" }\naws-smithy-types = { version = \"1.0.1\" }\naws-types = { version = \"1.0.1\" }\nclap = { version = \"4.4\", features = [\"derive\"] }\ntokio = { version = \"1.20.1\", features = [\"full\"] }\ntracing-subscriber = { version = \"0.3.15\", features = [\"env-filter\"] }\ntracing = \"0.1.37\"\nserde_json = \"1.0.94\"\nanyhow = \"1.0.71\"\nuuid = { version = \"1.3.3\", features = [\"v4\"] }\nlambda_runtime = \"0.8.0\"\nserde = \"1.0.164\"\n\n",
                            "  21.SAP ABAP : \n    TRY.\n        \"Create an AWS Identity and Access Management (IAM) role that grants AWS Lambda permission to write to logs.\"\n        DATA(lv_policy_document) = `{` &&\n            `\"Version\":\"2012-10-17\",` &&\n                  `\"Statement\": [` &&\n                    `{` &&\n                      `\"Effect\": \"Allow\",` &&\n                      `\"Action\": [` &&\n                        `\"sts:AssumeRole\"` &&\n                      `],` &&\n                      `\"Principal\": {` &&\n                        `\"Service\": [` &&\n                          `\"lambda.amazonaws.com\"` &&\n                        `]` &&\n                      `}` &&\n                    `}` &&\n                  `]` &&\n                `}`.\n        TRY.\n            DATA(lo_create_role_output) =  lo_iam->createrole(\n                    iv_rolename = iv_role_name\n                    iv_assumerolepolicydocument = lv_policy_document\n                    iv_description = 'Grant lambda permission to write to logs'\n                ).\n            MESSAGE 'IAM role created.' TYPE 'I'.\n            WAIT UP TO 10 SECONDS.            \" Make sure that the IAM role is ready for use. \"\n          CATCH /aws1/cx_iamentityalrdyexex.\n            MESSAGE 'IAM role already exists.' TYPE 'E'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iammalformedplydocex.\n            MESSAGE 'Policy document in the request is malformed.' TYPE 'E'.\n        ENDTRY.\n\n        TRY.\n            lo_iam->attachrolepolicy(\n                iv_rolename  = iv_role_name\n                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n            ).\n            MESSAGE 'Attached policy to the IAM role.' TYPE 'I'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamplynotattachableex.\n            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n        \" Create a Lambda function and upload handler code. \"\n        \" Lambda function performs 'increment' action on a number. \"\n        TRY.\n            lo_lmd->createfunction(\n                 iv_functionname = iv_function_name\n                 iv_runtime = `python3.9`\n                 iv_role = lo_create_role_output->get_role( )->get_arn( )\n                 iv_handler = iv_handler\n                 io_code = io_initial_zip_file\n                 iv_description = 'AWS Lambda code example'\n             ).\n            MESSAGE 'Lambda function created.' TYPE 'I'.\n          CATCH /aws1/cx_lmdcodestorageexcdex.\n            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \" Verify the function is in Active state \"\n        WHILE lo_lmd->getfunction( iv_functionname = iv_function_name )->get_configuration( )->ask_state( ) <> 'Active'.\n          IF sy-index = 10.\n            EXIT.               \" Maximum 10 seconds. \"\n          ENDIF.\n          WAIT UP TO 1 SECONDS.\n        ENDWHILE.\n\n        \"Invoke the function with a single parameter and get results.\"\n        TRY.\n            DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(\n              `{`  &&\n                `\"action\": \"increment\",`  &&\n                `\"number\": 10` &&\n              `}`\n            ).\n            DATA(lo_initial_invoke_output) =  lo_lmd->invoke(\n                       iv_functionname = iv_function_name\n                       iv_payload = lv_json\n                   ).\n            ov_initial_invoke_payload = lo_initial_invoke_output->get_payload( ).           \" ov_initial_invoke_payload is returned for testing purposes. \"\n            DATA(lo_writer_json) = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).\n            CALL TRANSFORMATION id SOURCE XML ov_initial_invoke_payload RESULT XML lo_writer_json.\n            DATA(lv_result) = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).\n            MESSAGE 'Lambda function invoked.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvrequestcontex.\n            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_lmdunsuppedmediatyp00.\n            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n        ENDTRY.\n\n        \" Update the function code and configure its Lambda environment with an environment variable. \"\n        \" Lambda function is updated to perform 'decrement' action also. \"\n        TRY.\n            lo_lmd->updatefunctioncode(\n                  iv_functionname = iv_function_name\n                  iv_zipfile = io_updated_zip_file\n              ).\n            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"\n            MESSAGE 'Lambda function code updated.' TYPE 'I'.\n          CATCH /aws1/cx_lmdcodestorageexcdex.\n            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        TRY.\n            DATA lt_variables TYPE /aws1/cl_lmdenvironmentvaria00=>tt_environmentvariables.\n            DATA ls_variable LIKE LINE OF lt_variables.\n            ls_variable-key = 'LOG_LEVEL'.\n            ls_variable-value = NEW /aws1/cl_lmdenvironmentvaria00( iv_value = 'info' ).\n            INSERT ls_variable INTO TABLE lt_variables.\n\n            lo_lmd->updatefunctionconfiguration(\n                  iv_functionname = iv_function_name\n                  io_environment = NEW /aws1/cl_lmdenvironment( it_variables = lt_variables )\n              ).\n            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"\n            MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourceconflictex.\n            MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \"Invoke the function with new parameters and get results. Display the execution log that's returned from the invocation.\"\n        TRY.\n            lv_json = /aws1/cl_rt_util=>string_to_xstring(\n              `{`  &&\n                `\"action\": \"decrement\",`  &&\n                `\"number\": 10` &&\n              `}`\n            ).\n            DATA(lo_updated_invoke_output) =  lo_lmd->invoke(\n                       iv_functionname = iv_function_name\n                       iv_payload = lv_json\n                   ).\n            ov_updated_invoke_payload = lo_updated_invoke_output->get_payload( ).           \" ov_updated_invoke_payload is returned for testing purposes. \"\n            lo_writer_json = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).\n            CALL TRANSFORMATION id SOURCE XML ov_updated_invoke_payload RESULT XML lo_writer_json.\n            lv_result = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).\n            MESSAGE 'Lambda function invoked.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvrequestcontex.\n            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_lmdunsuppedmediatyp00.\n            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n        ENDTRY.\n\n        \" List the functions for your account. \"\n        TRY.\n            DATA(lo_list_output) = lo_lmd->listfunctions( ).\n            DATA(lt_functions) = lo_list_output->get_functions( ).\n            MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n        ENDTRY.\n\n        \" Delete the Lambda function. \"\n        TRY.\n            lo_lmd->deletefunction( iv_functionname = iv_function_name ).\n            MESSAGE 'Lambda function deleted.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \" Detach role policy. \"\n        TRY.\n            lo_iam->detachrolepolicy(\n                iv_rolename  = iv_role_name\n                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n            ).\n            MESSAGE 'Detached policy from the IAM role.' TYPE 'I'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamplynotattachableex.\n            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n        \" Delete the IAM role. \"\n        TRY.\n            lo_iam->deleterole( iv_rolename = iv_role_name ).\n            MESSAGE 'IAM role deleted.' TYPE 'I'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n      CATCH /aws1/cx_rt_service_generic INTO lo_exception.\n        DATA(lv_error) = lo_exception->get_longtext( ).\n        MESSAGE lv_error TYPE 'E'.\n    ENDTRY.\n\n",
                            "  22.SDK for SAP ABAP : \n    TRY.\n        \"Create an AWS Identity and Access Management (IAM) role that grants AWS Lambda permission to write to logs.\"\n        DATA(lv_policy_document) = `{` &&\n            `\"Version\":\"2012-10-17\",` &&\n                  `\"Statement\": [` &&\n                    `{` &&\n                      `\"Effect\": \"Allow\",` &&\n                      `\"Action\": [` &&\n                        `\"sts:AssumeRole\"` &&\n                      `],` &&\n                      `\"Principal\": {` &&\n                        `\"Service\": [` &&\n                          `\"lambda.amazonaws.com\"` &&\n                        `]` &&\n                      `}` &&\n                    `}` &&\n                  `]` &&\n                `}`.\n        TRY.\n            DATA(lo_create_role_output) =  lo_iam->createrole(\n                    iv_rolename = iv_role_name\n                    iv_assumerolepolicydocument = lv_policy_document\n                    iv_description = 'Grant lambda permission to write to logs'\n                ).\n            MESSAGE 'IAM role created.' TYPE 'I'.\n            WAIT UP TO 10 SECONDS.            \" Make sure that the IAM role is ready for use. \"\n          CATCH /aws1/cx_iamentityalrdyexex.\n            MESSAGE 'IAM role already exists.' TYPE 'E'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iammalformedplydocex.\n            MESSAGE 'Policy document in the request is malformed.' TYPE 'E'.\n        ENDTRY.\n\n        TRY.\n            lo_iam->attachrolepolicy(\n                iv_rolename  = iv_role_name\n                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n            ).\n            MESSAGE 'Attached policy to the IAM role.' TYPE 'I'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamplynotattachableex.\n            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n        \" Create a Lambda function and upload handler code. \"\n        \" Lambda function performs 'increment' action on a number. \"\n        TRY.\n            lo_lmd->createfunction(\n                 iv_functionname = iv_function_name\n                 iv_runtime = `python3.9`\n                 iv_role = lo_create_role_output->get_role( )->get_arn( )\n                 iv_handler = iv_handler\n                 io_code = io_initial_zip_file\n                 iv_description = 'AWS Lambda code example'\n             ).\n            MESSAGE 'Lambda function created.' TYPE 'I'.\n          CATCH /aws1/cx_lmdcodestorageexcdex.\n            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \" Verify the function is in Active state \"\n        WHILE lo_lmd->getfunction( iv_functionname = iv_function_name )->get_configuration( )->ask_state( ) <> 'Active'.\n          IF sy-index = 10.\n            EXIT.               \" Maximum 10 seconds. \"\n          ENDIF.\n          WAIT UP TO 1 SECONDS.\n        ENDWHILE.\n\n        \"Invoke the function with a single parameter and get results.\"\n        TRY.\n            DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(\n              `{`  &&\n                `\"action\": \"increment\",`  &&\n                `\"number\": 10` &&\n              `}`\n            ).\n            DATA(lo_initial_invoke_output) =  lo_lmd->invoke(\n                       iv_functionname = iv_function_name\n                       iv_payload = lv_json\n                   ).\n            ov_initial_invoke_payload = lo_initial_invoke_output->get_payload( ).           \" ov_initial_invoke_payload is returned for testing purposes. \"\n            DATA(lo_writer_json) = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).\n            CALL TRANSFORMATION id SOURCE XML ov_initial_invoke_payload RESULT XML lo_writer_json.\n            DATA(lv_result) = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).\n            MESSAGE 'Lambda function invoked.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvrequestcontex.\n            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_lmdunsuppedmediatyp00.\n            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n        ENDTRY.\n\n        \" Update the function code and configure its Lambda environment with an environment variable. \"\n        \" Lambda function is updated to perform 'decrement' action also. \"\n        TRY.\n            lo_lmd->updatefunctioncode(\n                  iv_functionname = iv_function_name\n                  iv_zipfile = io_updated_zip_file\n              ).\n            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"\n            MESSAGE 'Lambda function code updated.' TYPE 'I'.\n          CATCH /aws1/cx_lmdcodestorageexcdex.\n            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        TRY.\n            DATA lt_variables TYPE /aws1/cl_lmdenvironmentvaria00=>tt_environmentvariables.\n            DATA ls_variable LIKE LINE OF lt_variables.\n            ls_variable-key = 'LOG_LEVEL'.\n            ls_variable-value = NEW /aws1/cl_lmdenvironmentvaria00( iv_value = 'info' ).\n            INSERT ls_variable INTO TABLE lt_variables.\n\n            lo_lmd->updatefunctionconfiguration(\n                  iv_functionname = iv_function_name\n                  io_environment = NEW /aws1/cl_lmdenvironment( it_variables = lt_variables )\n              ).\n            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"\n            MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourceconflictex.\n            MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \"Invoke the function with new parameters and get results. Display the execution log that's returned from the invocation.\"\n        TRY.\n            lv_json = /aws1/cl_rt_util=>string_to_xstring(\n              `{`  &&\n                `\"action\": \"decrement\",`  &&\n                `\"number\": 10` &&\n              `}`\n            ).\n            DATA(lo_updated_invoke_output) =  lo_lmd->invoke(\n                       iv_functionname = iv_function_name\n                       iv_payload = lv_json\n                   ).\n            ov_updated_invoke_payload = lo_updated_invoke_output->get_payload( ).           \" ov_updated_invoke_payload is returned for testing purposes. \"\n            lo_writer_json = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).\n            CALL TRANSFORMATION id SOURCE XML ov_updated_invoke_payload RESULT XML lo_writer_json.\n            lv_result = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).\n            MESSAGE 'Lambda function invoked.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdinvrequestcontex.\n            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_lmdunsuppedmediatyp00.\n            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n        ENDTRY.\n\n        \" List the functions for your account. \"\n        TRY.\n            DATA(lo_list_output) = lo_lmd->listfunctions( ).\n            DATA(lt_functions) = lo_list_output->get_functions( ).\n            MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n        ENDTRY.\n\n        \" Delete the Lambda function. \"\n        TRY.\n            lo_lmd->deletefunction( iv_functionname = iv_function_name ).\n            MESSAGE 'Lambda function deleted.' TYPE 'I'.\n          CATCH /aws1/cx_lmdinvparamvalueex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_lmdresourcenotfoundex.\n            MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n        ENDTRY.\n\n        \" Detach role policy. \"\n        TRY.\n            lo_iam->detachrolepolicy(\n                iv_rolename  = iv_role_name\n                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n            ).\n            MESSAGE 'Detached policy from the IAM role.' TYPE 'I'.\n          CATCH /aws1/cx_iaminvalidinputex.\n            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamplynotattachableex.\n            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n        \" Delete the IAM role. \"\n        TRY.\n            lo_iam->deleterole( iv_rolename = iv_role_name ).\n            MESSAGE 'IAM role deleted.' TYPE 'I'.\n          CATCH /aws1/cx_iamnosuchentityex.\n            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.\n          CATCH /aws1/cx_iamunmodableentityex.\n            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.\n        ENDTRY.\n\n      CATCH /aws1/cx_rt_service_generic INTO lo_exception.\n        DATA(lv_error) = lo_exception->get_longtext( ).\n        MESSAGE lv_error TYPE 'E'.\n    ENDTRY.\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Create methods that perform Lambda actions.namespace LambdaActions;using Amazon.Lambda;using Amazon.Lambda.Model;/// <summary>/// A class that implements AWS Lambda methods./// </summary>public class LambdaWrapper{    private readonly IAmazonLambda _lambdaService;    /// <summary>    /// Constructor for the LambdaWrapper class.    /// </summary>    /// <param name=\"lambdaService\">An initialized Lambda service client.</param>    public LambdaWrapper(IAmazonLambda lambdaService)    {        _lambdaService = lambdaService;    }    /// <summary>    /// Creates a new Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function.</param>    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)    /// bucket where the zip file containing the code is located.</param>    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the    /// appropriate Lambda permissions.</param>    /// <param name=\"handler\">The name of the handler function.</param>    /// <returns>The Amazon Resource Name (ARN) of the newly created    /// Lambda function.</returns>    public async Task<string> CreateLambdaFunctionAsync(        string functionName,        string s3Bucket,        string s3Key,        string role,        string handler)    {        // Defines the location for the function code.        // S3Bucket - The S3 bucket where the file containing        //            the source code is stored.        // S3Key    - The name of the file containing the code.        var functionCode = new FunctionCode        {            S3Bucket = s3Bucket,            S3Key = s3Key,        };        var createFunctionRequest = new CreateFunctionRequest        {            FunctionName = functionName,            Description = \"Created by the Lambda .NET API\",            Code = functionCode,            Handler = handler,            Runtime = Runtime.Dotnet6,            Role = role,        };        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);        return reponse.FunctionArn;    }    /// <summary>    /// Delete an AWS Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// delete.</param>    /// <returns>A Boolean value that indicates the success of the action.</returns>    public async Task<bool> DeleteFunctionAsync(string functionName)    {        var request = new DeleteFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.DeleteFunctionAsync(request);        // A return value of NoContent means that the request was processed.        // In this case, the function was deleted, and the return value        // is intentionally blank.        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;    }    /// <summary>    /// Gets information about a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function for    /// which to retrieve information.</param>    /// <returns>Async Task.</returns>    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)    {        var functionRequest = new GetFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.GetFunctionAsync(functionRequest);        return response.Configuration;    }    /// <summary>    /// Invoke a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// invoke.</param    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>    /// <returns>A System Threading Task.</returns>    public async Task<string> InvokeFunctionAsync(        string functionName,        string parameters)    {        var payload = parameters;        var request = new InvokeRequest        {            FunctionName = functionName,            Payload = payload,        };        var response = await _lambdaService.InvokeAsync(request);        MemoryStream stream = response.Payload;        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());        return returnValue;    }    /// <summary>    /// Get a list of Lambda functions.    /// </summary>    /// <returns>A list of FunctionConfiguration objects.</returns>    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()    {        var functionList = new List<FunctionConfiguration>();        var functionPaginator =            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());        await foreach (var function in functionPaginator.Functions)        {            functionList.Add(function);        }        return functionList;    }    /// <summary>    /// Update an existing Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to update.</param>    /// <param name=\"bucketName\">The bucket where the zip file containing    /// the Lambda function code is stored.</param>    /// <param name=\"key\">The key name of the source code file.</param>    /// <returns>Async Task.</returns>    public async Task UpdateFunctionCodeAsync(        string functionName,        string bucketName,        string key)    {        var functionCodeRequest = new UpdateFunctionCodeRequest        {            FunctionName = functionName,            Publish = true,            S3Bucket = bucketName,            S3Key = key,        };        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");    }    /// <summary>    /// Update the code of a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function to update.</param>    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> UpdateFunctionConfigurationAsync(        string functionName,        string functionHandler,        Dictionary<string, string> environmentVariables)    {        var request = new UpdateFunctionConfigurationRequest        {            Handler = functionHandler,            FunctionName = functionName,            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },        };        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);        Console.WriteLine(response.LastModified);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }}Create a function that runs the scenario.global using System.Threading.Tasks;global using Amazon.IdentityManagement;global using Amazon.Lambda;global using LambdaActions;global using LambdaScenarioCommon;global using Microsoft.Extensions.DependencyInjection;global using Microsoft.Extensions.Hosting;global using Microsoft.Extensions.Logging;global using Microsoft.Extensions.Logging.Console;global using Microsoft.Extensions.Logging.Debug;using Amazon.Lambda.Model;using Microsoft.Extensions.Configuration;namespace LambdaBasics;public class LambdaBasics{    private static ILogger logger = null!;    static async Task Main(string[] args)    {        // Set up dependency injection for the Amazon service.        using var host = Host.CreateDefaultBuilder(args)            .ConfigureLogging(logging =>                logging.AddFilter(\"System\", LogLevel.Debug)                    .AddFilter<DebugLoggerProvider>(\"Microsoft\", LogLevel.Information)                    .AddFilter<ConsoleLoggerProvider>(\"Microsoft\", LogLevel.Trace))            .ConfigureServices((_, services) =>            services.AddAWSService<IAmazonLambda>()            .AddAWSService<IAmazonIdentityManagementService>()            .AddTransient<LambdaWrapper>()            .AddTransient<LambdaRoleWrapper>()            .AddTransient<UIWrapper>()        )        .Build();        var configuration = new ConfigurationBuilder()            .SetBasePath(Directory.GetCurrentDirectory())            .AddJsonFile(\"settings.json\") // Load test settings from .json file.            .AddJsonFile(\"settings.local.json\",            true) // Optionally load local settings.        .Build();        logger = LoggerFactory.Create(builder => { builder.AddConsole(); })            .CreateLogger<LambdaBasics>();        var lambdaWrapper = host.Services.GetRequiredService<LambdaWrapper>();        var lambdaRoleWrapper = host.Services.GetRequiredService<LambdaRoleWrapper>();        var uiWrapper = host.Services.GetRequiredService<UIWrapper>();        string functionName = configuration[\"FunctionName\"]!;        string roleName = configuration[\"RoleName\"]!;        string policyDocument = \"{\" +            \" \\\"Version\\\": \\\"2012-10-17\\\",\" +            \" \\\"Statement\\\": [ \" +            \"    {\" +            \"        \\\"Effect\\\": \\\"Allow\\\",\" +            \"        \\\"Principal\\\": {\" +            \"            \\\"Service\\\": \\\"lambda.amazonaws.com\\\" \" +            \"    },\" +            \"        \\\"Action\\\": \\\"sts:AssumeRole\\\" \" +            \"    }\" +            \"]\" +        \"}\";        var incrementHandler = configuration[\"IncrementHandler\"];        var calculatorHandler = configuration[\"CalculatorHandler\"];        var bucketName = configuration[\"BucketName\"];        var incrementKey = configuration[\"IncrementKey\"];        var calculatorKey = configuration[\"CalculatorKey\"];        var policyArn = configuration[\"PolicyArn\"];        uiWrapper.DisplayLambdaBasicsOverview();        // Create the policy to use with the AWS Lambda functions and then attach the        // policy to a new role.        var roleArn = await lambdaRoleWrapper.CreateLambdaRoleAsync(roleName, policyDocument);        Console.WriteLine(\"Waiting for role to become active.\");        uiWrapper.WaitABit(15, \"Wait until the role is active before trying to use it.\");        // Attach the appropriate AWS Identity and Access Management (IAM) role policy to the new role.        var success = await lambdaRoleWrapper.AttachLambdaRolePolicyAsync(policyArn, roleName);        uiWrapper.WaitABit(10, \"Allow time for the IAM policy to be attached to the role.\");        // Create the Lambda function using a zip file stored in an Amazon Simple Storage Service        // (Amazon S3) bucket.        uiWrapper.DisplayTitle(\"Create Lambda Function\");        Console.WriteLine($\"Creating the AWS Lambda function: {functionName}.\");        var lambdaArn = await lambdaWrapper.CreateLambdaFunctionAsync(            functionName,            bucketName,            incrementKey,            roleArn,            incrementHandler);        Console.WriteLine(\"Waiting for the new function to be available.\");        Console.WriteLine($\"The AWS Lambda ARN is {lambdaArn}\");        // Get the Lambda function.        Console.WriteLine($\"Getting the {functionName} AWS Lambda function.\");        FunctionConfiguration config;        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.State != State.Active);        Console.WriteLine($\"\\nThe function, {functionName} has been created.\");        Console.WriteLine($\"The runtime of this Lambda function is {config.Runtime}.\");        uiWrapper.PressEnter();        // List the Lambda functions.        uiWrapper.DisplayTitle(\"Listing all Lambda functions.\");        var functions = await lambdaWrapper.ListFunctionsAsync();        DisplayFunctionList(functions);        uiWrapper.DisplayTitle(\"Invoke increment function\");        Console.WriteLine(\"Now that it has been created, invoke the Lambda increment function.\");        string? value;        do        {            Console.Write(\"Enter a value to increment: \");            value = Console.ReadLine();        }        while (string.IsNullOrEmpty(value));        string functionParameters = \"{\" +            \"\\\"action\\\": \\\"increment\\\", \" +            \"\\\"x\\\": \\\"\" + value + \"\\\"\" +        \"}\";        var answer = await lambdaWrapper.InvokeFunctionAsync(functionName, functionParameters);        Console.WriteLine($\"{value} + 1 = {answer}.\");        uiWrapper.DisplayTitle(\"Update function\");        Console.WriteLine(\"Now update the Lambda function code.\");        await lambdaWrapper.UpdateFunctionCodeAsync(functionName, bucketName, calculatorKey);        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.LastUpdateStatus == LastUpdateStatus.InProgress);        await lambdaWrapper.UpdateFunctionConfigurationAsync(            functionName,            calculatorHandler,            new Dictionary<string, string> { { \"LOG_LEVEL\", \"DEBUG\" } });        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.LastUpdateStatus == LastUpdateStatus.InProgress);        uiWrapper.DisplayTitle(\"Call updated function\");        Console.WriteLine(\"Now call the updated function...\");        bool done = false;        do        {            string? opSelected;            Console.WriteLine(\"Select the operation to perform:\");            Console.WriteLine(\"\\t1. add\");            Console.WriteLine(\"\\t2. subtract\");            Console.WriteLine(\"\\t3. multiply\");            Console.WriteLine(\"\\t4. divide\");            Console.WriteLine(\"\\tOr enter \\\"q\\\" to quit.\");            Console.WriteLine(\"Enter the number (1, 2, 3, 4, or q) of the operation you want to perform: \");            do            {                Console.Write(\"Your choice? \");                opSelected = Console.ReadLine();            }            while (opSelected == string.Empty);            var operation = (opSelected) switch            {                \"1\" => \"add\",                \"2\" => \"subtract\",                \"3\" => \"multiply\",                \"4\" => \"divide\",                \"q\" => \"quit\",                _ => \"add\",            };            if (operation == \"quit\")            {                done = true;            }            else            {                // Get two numbers and an action from the user.                value = string.Empty;                do                {                    Console.Write(\"Enter the first value: \");                    value = Console.ReadLine();                }                while (value == string.Empty);                string? value2;                do                {                    Console.Write(\"Enter a second value: \");                    value2 = Console.ReadLine();                }                while (value2 == string.Empty);                functionParameters = \"{\" +                    \"\\\"action\\\": \\\"\" + operation + \"\\\", \" +                    \"\\\"x\\\": \\\"\" + value + \"\\\",\" +                    \"\\\"y\\\": \\\"\" + value2 + \"\\\"\" +                \"}\";                answer = await lambdaWrapper.InvokeFunctionAsync(functionName, functionParameters);                Console.WriteLine($\"The answer when we {operation} the two numbers is: {answer}.\");            }            uiWrapper.PressEnter();        } while (!done);        // Delete the function created earlier.        uiWrapper.DisplayTitle(\"Clean up resources\");        // Detach the IAM policy from the IAM role.        Console.WriteLine(\"First detach the IAM policy from the role.\");        success = await lambdaRoleWrapper.DetachLambdaRolePolicyAsync(policyArn, roleName);        uiWrapper.WaitABit(15, \"Let's wait for the policy to be fully detached from the role.\");        Console.WriteLine(\"Delete the AWS Lambda function.\");        success = await lambdaWrapper.DeleteFunctionAsync(functionName);        if (success)        {            Console.WriteLine($\"The {functionName} function was deleted.\");        }        else        {            Console.WriteLine($\"Could not remove the function {functionName}\");        }        // Now delete the IAM role created for use with the functions        // created by the application.        Console.WriteLine(\"Now we can delete the role that we created.\");        success = await lambdaRoleWrapper.DeleteLambdaRoleAsync(roleName);        if (success)        {            Console.WriteLine(\"The role has been successfully removed.\");        }        else        {            Console.WriteLine(\"Couldn't delete the role.\");        }        Console.WriteLine(\"The Lambda Scenario is now complete.\");        uiWrapper.PressEnter();        // Displays a formatted list of existing functions returned by the        // LambdaMethods.ListFunctions.        void DisplayFunctionList(List<FunctionConfiguration> functions)        {            functions.ForEach(functionConfig =>            {                Console.WriteLine($\"{functionConfig.FunctionName}\\t{functionConfig.Description}\");            });        }    }}namespace LambdaActions;using Amazon.IdentityManagement;using Amazon.IdentityManagement.Model;public class LambdaRoleWrapper{    private readonly IAmazonIdentityManagementService _lambdaRoleService;    public LambdaRoleWrapper(IAmazonIdentityManagementService lambdaRoleService)    {        _lambdaRoleService = lambdaRoleService;    }    /// <summary>    /// Attach an AWS Identity and Access Management (IAM) role policy to the    /// IAM role to be assumed by the AWS Lambda functions created for the scenario.    /// </summary>    /// <param name=\"policyArn\">The Amazon Resource Name (ARN) of the IAM policy.</param>    /// <param name=\"roleName\">The name of the IAM role to attach the IAM policy to.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> AttachLambdaRolePolicyAsync(string policyArn, string roleName)    {        var response = await _lambdaRoleService.AttachRolePolicyAsync(new AttachRolePolicyRequest { PolicyArn = policyArn, RoleName = roleName });        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }    /// <summary>    /// Create a new IAM role.    /// </summary>    /// <param name=\"roleName\">The name of the IAM role to create.</param>    /// <param name=\"policyDocument\">The policy document for the new IAM role.</param>    /// <returns>A string representing the ARN for newly created role.</returns>    public async Task<string> CreateLambdaRoleAsync(string roleName, string policyDocument)    {        var request = new CreateRoleRequest        {            AssumeRolePolicyDocument = policyDocument,            RoleName = roleName,        };        var response = await _lambdaRoleService.CreateRoleAsync(request);        return response.Role.Arn;    }    /// <summary>    /// Deletes an IAM role.    /// </summary>    /// <param name=\"roleName\">The name of the role to delete.</param>    /// <returns>A Boolean value indicating the success of the operation.</returns>    public async Task<bool> DeleteLambdaRoleAsync(string roleName)    {        var request = new DeleteRoleRequest        {            RoleName = roleName,        };        var response = await _lambdaRoleService.DeleteRoleAsync(request);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }    public async Task<bool> DetachLambdaRolePolicyAsync(string policyArn, string roleName)    {        var response = await _lambdaRoleService.DetachRolePolicyAsync(new DetachRolePolicyRequest { PolicyArn = policyArn, RoleName = roleName });        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }}namespace LambdaScenarioCommon;public class UIWrapper{    public readonly string SepBar = new('-', Console.WindowWidth);    /// <summary>    /// Show information about the AWS Lambda Basics scenario.    /// </summary>    public void DisplayLambdaBasicsOverview()    {        Console.Clear();        DisplayTitle(\"Welcome to AWS Lambda Basics\");        Console.WriteLine(\"This example application does the following:\");        Console.WriteLine(\"\\t1. Creates an AWS Identity and Access Management (IAM) role that will be assumed by the functions we create.\");        Console.WriteLine(\"\\t2. Attaches an IAM role policy that has Lambda permissions.\");        Console.WriteLine(\"\\t3. Creates a Lambda function that increments the value passed to it.\");        Console.WriteLine(\"\\t4. Calls the increment function and passes a value.\");        Console.WriteLine(\"\\t5. Updates the code so that the function is a simple calculator.\");        Console.WriteLine(\"\\t6. Calls the calculator function with the values entered.\");        Console.WriteLine(\"\\t7. Deletes the Lambda function.\");        Console.WriteLine(\"\\t7. Detaches the IAM role policy.\");        Console.WriteLine(\"\\t8. Deletes the IAM role.\");        PressEnter();    }    /// <summary>    /// Display a message and wait until the user presses enter.    /// </summary>    public void PressEnter()    {        Console.Write(\"\\nPress <Enter> to continue. \");        _ = Console.ReadLine();        Console.WriteLine();    }    /// <summary>    /// Pad a string with spaces to center it on the console display.    /// </summary>    /// <param name=\"strToCenter\">The string to be centered.</param>    /// <returns>The padded string.</returns>    public string CenterString(string strToCenter)    {        var padAmount = (Console.WindowWidth - strToCenter.Length) / 2;        var leftPad = new string(' ', padAmount);        return $\"{leftPad}{strToCenter}\";    }    /// <summary>    /// Display a line of hyphens, the centered text of the title and another    /// line of hyphens.    /// </summary>    /// <param name=\"strTitle\">The string to be displayed.</param>    public void DisplayTitle(string strTitle)    {        Console.WriteLine(SepBar);        Console.WriteLine(CenterString(strTitle));        Console.WriteLine(SepBar);    }    /// <summary>    /// Display a countdown and wait for a number of seconds.    /// </summary>    /// <param name=\"numSeconds\">The number of seconds to wait.</param>    public void WaitABit(int numSeconds, string msg)    {        Console.WriteLine(msg);        // Wait for the requested number of seconds.        for (int i = numSeconds; i > 0; i--)        {            System.Threading.Thread.Sleep(1000);            Console.Write($\"{i}...\");        }        PressEnter();    }}Define a Lambda handler that increments a number.using Amazon.Lambda.Core;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaIncrement;public class Function{    /// <summary>    /// A simple function increments the integer parameter.    /// </summary>    /// <param name=\"input\">A JSON string containing an action, which must be    /// \"increment\" and a string representing the value to increment.</param>    /// <param name=\"context\">The context object passed by Lambda containing    /// information about invocation, function, and execution environment.</param>    /// <returns>A string representing the incremented value of the parameter.</returns>    public int FunctionHandler(Dictionary<string, string> input, ILambdaContext context)    {        if (input[\"action\"] == \"increment\")        {            int inputValue = Convert.ToInt32(input[\"x\"]);            return inputValue + 1;        }        else        {            return 0;        }    }}Define a second Lambda handler that performs arithmetic operations.using Amazon.Lambda.Core;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaCalculator;public class Function{    /// <summary>    /// A simple function that takes two number in string format and performs    /// the requested arithmetic function.    /// </summary>    /// <param name=\"input\">JSON data containing an action, and x and y values.    /// Valid actions include: add, subtract, multiply, and divide.</param>    /// <param name=\"context\">The context object passed by Lambda containing    /// information about invocation, function, and execution environment.</param>    /// <returns>A string representing the results of the calculation.</returns>    public int FunctionHandler(Dictionary<string, string> input, ILambdaContext context)    {        var action = input[\"action\"];        int x = Convert.ToInt32(input[\"x\"]);        int y = Convert.ToInt32(input[\"y\"]);        int result;        switch (action)        {            case \"add\":                result = x + y;                break;            case \"subtract\":                result = x - y;                break;            case \"multiply\":                result = x * y;                break;            case \"divide\":                if (y == 0)                {                    Console.Error.WriteLine(\"Divide by zero error.\");                    result = 0;                }                else                    result = x / y;                break;            default:                Console.Error.WriteLine($\"{action} is not a valid operation.\");                result = 0;                break;        }        return result;    }}For API details, see the following topics in AWS SDK for .NET API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationC++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    //! Get started with functions scenario./*! \\param clientConfig: AWS client configuration. \\return bool: Successful completion. */bool AwsDoc::Lambda::getStartedWithFunctionsScenario(        const Aws::Client::ClientConfiguration &clientConfig) {    Aws::Lambda::LambdaClient client(clientConfig);    // 1. Create an AWS Identity and Access Management (IAM) role for Lambda function.    Aws::String roleArn;    if (!getIamRoleArn(roleArn, clientConfig)) {        return false;    }    // 2. Create a Lambda function.    int seconds = 0;    do {        Aws::Lambda::Model::CreateFunctionRequest request;        request.SetFunctionName(LAMBDA_NAME);        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.#if USE_CPP_LAMBDA_FUNCTION        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);        request.SetTimeout(15);        request.SetMemorySize(128);        // Assume the AWS Lambda function was built in Docker with same architecture        // as this code.#if  defined(__x86_64__)        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});#elif defined(__aarch64__)        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});#else#error \"Unimplemented architecture\"#endif // defined(architecture)#else        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);#endif        request.SetRole(roleArn);        request.SetHandler(LAMBDA_HANDLER_NAME);        request.SetPublish(true);        Aws::Lambda::Model::FunctionCode code;        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),                               std::ios_base::in | std::ios_base::binary);        if (!ifstream.is_open()) {            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;#if USE_CPP_LAMBDA_FUNCTION            std::cerr                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"                    << std::endl;#endif            deleteIamRole(clientConfig);            return false;        }        Aws::StringStream buffer;        buffer << ifstream.rdbuf();        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),                                               buffer.str().length()));        request.SetCode(code);        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda function was successfully created. \" << seconds                      << \" seconds elapsed.\" << std::endl;            break;        }        else if (outcome.GetError().GetErrorType() ==                 Aws::Lambda::LambdaErrors::INVALID_PARAMETER_VALUE &&                 outcome.GetError().GetMessage().find(\"role\") >= 0) {            if ((seconds % 5) == 0) { // Log status every 10 seconds.                std::cout                        << \"Waiting for the IAM role to become available as a CreateFunction parameter. \"                        << seconds                        << \" seconds elapsed.\" << std::endl;                std::cout << outcome.GetError().GetMessage() << std::endl;            }        }        else {            std::cerr << \"Error with CreateFunction. \"                      << outcome.GetError().GetMessage()                      << std::endl;            deleteIamRole(clientConfig);            return false;        }        ++seconds;        std::this_thread::sleep_for(std::chrono::seconds(1));    } while (60 > seconds);    std::cout << \"The current Lambda function increments 1 by an input.\" << std::endl;    // 3.  Invoke the Lambda function.    {        int increment = askQuestionForInt(\"Enter an increment integer: \");        Aws::Lambda::Model::InvokeResult invokeResult;        Aws::Utils::Json::JsonValue jsonPayload;        jsonPayload.WithString(\"action\", \"increment\");        jsonPayload.WithInteger(\"number\", increment);        if (invokeLambdaFunction(jsonPayload, Aws::Lambda::Model::LogType::Tail,                                 invokeResult, client)) {            Aws::Utils::Json::JsonValue jsonValue(invokeResult.GetPayload());            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =                    jsonValue.View().GetAllObjects();            auto iter = values.find(\"result\");            if (iter != values.end() && iter->second.IsIntegerType()) {                {                    std::cout << INCREMENT_RESUlT_PREFIX                              << iter->second.AsInteger() << std::endl;                }            }            else {                std::cout << \"There was an error in execution. Here is the log.\"                          << std::endl;                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(                        invokeResult.GetLogResult());                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;            }        }    }    std::cout            << \"The Lambda function will now be updated with new code. Press return to continue, \";    Aws::String answer;    std::getline(std::cin, answer);    // 4.  Update the Lambda function code.    {        Aws::Lambda::Model::UpdateFunctionCodeRequest request;        request.SetFunctionName(LAMBDA_NAME);        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),                               std::ios_base::in | std::ios_base::binary);        if (!ifstream.is_open()) {            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;#if USE_CPP_LAMBDA_FUNCTION            std::cerr                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"                    << std::endl;#endif            deleteLambdaFunction(client);            deleteIamRole(clientConfig);            return false;        }        Aws::StringStream buffer;        buffer << ifstream.rdbuf();        request.SetZipFile(                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),                                       buffer.str().length()));        request.SetPublish(true);        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda code was successfully updated.\" << std::endl;        }        else {            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }    }    std::cout            << \"This function uses an environment variable to control the logging level.\"            << std::endl;    std::cout            << \"UpdateFunctionConfiguration will be used to set the LOG_LEVEL to DEBUG.\"            << std::endl;    seconds = 0;    // 5.  Update the Lambda function configuration.    do {        ++seconds;        std::this_thread::sleep_for(std::chrono::seconds(1));        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;        request.SetFunctionName(LAMBDA_NAME);        Aws::Lambda::Model::Environment environment;        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");        request.SetEnvironment(environment);        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda configuration was successfully updated.\"                      << std::endl;            break;        }            // RESOURCE_IN_USE: function code update not completed.        else if (outcome.GetError().GetErrorType() !=                 Aws::Lambda::LambdaErrors::RESOURCE_IN_USE) {            if ((seconds % 10) == 0) { // Log status every 10 seconds.                std::cout << \"Lambda function update in progress . After \" << seconds                          << \" seconds elapsed.\" << std::endl;            }        }        else {            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }    } while (0 < seconds);    if (0 > seconds) {        std::cerr << \"Function failed to become active.\" << std::endl;    }    else {        std::cout << \"Updated function active after \" << seconds << \" seconds.\"                  << std::endl;    }    std::cout            << \"\\nThe new code applies an arithmetic operator to two variables, x an y.\"            << std::endl;    std::vector<Aws::String> operators = {\"plus\", \"minus\", \"times\", \"divided-by\"};    for (size_t i = 0; i < operators.size(); ++i) {        std::cout << \"   \" << i + 1 << \" \" << operators[i] << std::endl;    }    // 6.  Invoke the updated Lambda function.    do {        int operatorIndex = askQuestionForIntRange(\"Select an operator index 1 - 4 \", 1,                                                   4);        int x = askQuestionForInt(\"Enter an integer for the x value \");        int y = askQuestionForInt(\"Enter an integer for the y value \");        Aws::Utils::Json::JsonValue calculateJsonPayload;        calculateJsonPayload.WithString(\"action\", operators[operatorIndex - 1]);        calculateJsonPayload.WithInteger(\"x\", x);        calculateJsonPayload.WithInteger(\"y\", y);        Aws::Lambda::Model::InvokeResult calculatedResult;        if (invokeLambdaFunction(calculateJsonPayload,                                 Aws::Lambda::Model::LogType::Tail,                                 calculatedResult, client)) {            Aws::Utils::Json::JsonValue jsonValue(calculatedResult.GetPayload());            Aws::Map<Aws::String, Aws::Utils::Json::JsonView> values =                    jsonValue.View().GetAllObjects();            auto iter = values.find(\"result\");            if (iter != values.end() && iter->second.IsIntegerType()) {                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"                          << operators[operatorIndex - 1] << \" \"                          << y << \" is \" << iter->second.AsInteger() << std::endl;            }            else if (iter != values.end() && iter->second.IsFloatingPointType()) {                std::cout << ARITHMETIC_RESUlT_PREFIX << x << \" \"                          << operators[operatorIndex - 1] << \" \"                          << y << \" is \" << iter->second.AsDouble() << std::endl;            }            else {                std::cout << \"There was an error in execution. Here is the log.\"                          << std::endl;                Aws::Utils::ByteBuffer buffer = Aws::Utils::HashingUtils::Base64Decode(                        calculatedResult.GetLogResult());                std::cout << \"With log \" << buffer.GetUnderlyingData() << std::endl;            }        }        answer = askQuestion(\"Would you like to try another operation? (y/n) \");    } while (answer == \"y\");    std::cout            << \"A list of the lambda functions will be retrieved. Press return to continue, \";    std::getline(std::cin, answer);    // 7.  List the Lambda functions.    std::vector<Aws::String> functions;    Aws::String marker;    do {        Aws::Lambda::Model::ListFunctionsRequest request;        if (!marker.empty()) {            request.SetMarker(marker);        }        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(                request);        if (outcome.IsSuccess()) {            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();            std::cout << result.GetFunctions().size()                      << \" lambda functions were retrieved.\" << std::endl;            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {                functions.push_back(functionConfiguration.GetFunctionName());                std::cout << functions.size() << \"  \"                          << functionConfiguration.GetDescription() << std::endl;                std::cout << \"   \"                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                  functionConfiguration.GetRuntime()) << \": \"                          << functionConfiguration.GetHandler()                          << std::endl;            }            marker = result.GetNextMarker();        }        else {            std::cerr << \"Error with Lambda::ListFunctions. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }    } while (!marker.empty());    // 8.  Get a Lambda function.    if (!functions.empty()) {        std::stringstream question;        question << \"Choose a function to retrieve between 1 and \" << functions.size()                 << \" \";        int functionIndex = askQuestionForIntRange(question.str(), 1,                                                   static_cast<int>(functions.size()));        Aws::String functionName = functions[functionIndex - 1];        Aws::Lambda::Model::GetFunctionRequest request;        request.SetFunctionName(functionName);        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);        if (outcome.IsSuccess()) {            std::cout << \"Function retrieve.\\n\" <<                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()                      << std::endl;        }        else {            std::cerr << \"Error with Lambda::GetFunction. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }    }    std::cout << \"The resources will be deleted. Press return to continue, \";    std::getline(std::cin, answer);    // 9.  Delete the Lambda function.    bool result = deleteLambdaFunction(client);    // 10. Delete the IAM role.    return result && deleteIamRole(clientConfig);}//! Routine which invokes a Lambda function and returns the result./*! \\param jsonPayload: Payload for invoke function. \\param logType: Log type setting for invoke function. \\param invokeResult: InvokeResult object to receive the result. \\param client: Lambda client. \\return bool: Successful completion. */boolAwsDoc::Lambda::invokeLambdaFunction(const Aws::Utils::Json::JsonValue &jsonPayload,                                     Aws::Lambda::Model::LogType logType,                                     Aws::Lambda::Model::InvokeResult &invokeResult,                                     const Aws::Lambda::LambdaClient &client) {    int seconds = 0;    bool result = false;    /*     * In this example, the Invoke function can be called before recently created resources are     * available.  The Invoke function is called repeatedly until the resources are     * available.     */    do {        Aws::Lambda::Model::InvokeRequest request;        request.SetFunctionName(LAMBDA_NAME);        request.SetLogType(logType);        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(                \"FunctionTest\");        *payload << jsonPayload.View().WriteReadable();        request.SetBody(payload);        request.SetContentType(\"application/json\");        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);        if (outcome.IsSuccess()) {            invokeResult = std::move(outcome.GetResult());            result = true;            break;        }            // ACCESS_DENIED: because the role is not available yet.            // RESOURCE_CONFLICT: because the Lambda function is being created or updated.        else if ((outcome.GetError().GetErrorType() ==                  Aws::Lambda::LambdaErrors::ACCESS_DENIED) ||                 (outcome.GetError().GetErrorType() ==                  Aws::Lambda::LambdaErrors::RESOURCE_CONFLICT)) {            if ((seconds % 5) == 0) { // Log status every 10 seconds.                std::cout << \"Waiting for the invoke api to be available, status \" <<                          ((outcome.GetError().GetErrorType() ==                            Aws::Lambda::LambdaErrors::ACCESS_DENIED ?                            \"ACCESS_DENIED\" : \"RESOURCE_CONFLICT\")) << \". \" << seconds                          << \" seconds elapsed.\" << std::endl;            }        }        else {            std::cerr << \"Error with Lambda::InvokeRequest. \"                      << outcome.GetError().GetMessage()                      << std::endl;            break;        }        ++seconds;        std::this_thread::sleep_for(std::chrono::seconds(1));    } while (seconds < 60);    return result;}For API details, see the following topics in AWS SDK for C++ API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationGoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Create an interactive scenario that shows you how to get started with Lambda functions.import (\t\"archive/zip\"\t\"bytes\"\t\"context\"\t\"encoding/base64\"\t\"encoding/json\"\t\"errors\"\t\"fmt\"\t\"log\"\t\"os\"\t\"strings\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/iam\"\tiamtypes \"github.com/aws/aws-sdk-go-v2/service/iam/types\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/lambda/actions\")// GetStartedFunctionsScenario shows you how to use AWS Lambda to perform the following// actions:////  1. Create an AWS Identity and Access Management (IAM) role and Lambda function, then upload handler code.//  2. Invoke the function with a single parameter and get results.//  3. Update the function code and configure with an environment variable.//  4. Invoke the function with new parameters and get results. Display the returned execution log.//  5. List the functions for your account, then clean up resources.type GetStartedFunctionsScenario struct {\tsdkConfig       aws.Config\tfunctionWrapper actions.FunctionWrapper\tquestioner      demotools.IQuestioner\thelper          IScenarioHelper\tisTestRun       bool}// NewGetStartedFunctionsScenario constructs a GetStartedFunctionsScenario instance from a configuration.// It uses the specified config to get a Lambda client and create wrappers for the actions// used in the scenario.func NewGetStartedFunctionsScenario(sdkConfig aws.Config, questioner demotools.IQuestioner,\thelper IScenarioHelper) GetStartedFunctionsScenario {\tlambdaClient := lambda.NewFromConfig(sdkConfig)\treturn GetStartedFunctionsScenario{\t\tsdkConfig:       sdkConfig,\t\tfunctionWrapper: actions.FunctionWrapper{LambdaClient: lambdaClient},\t\tquestioner:      questioner,\t\thelper:          helper,\t}}// Run runs the interactive scenario.func (scenario GetStartedFunctionsScenario) Run(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong with the demo.\\n\")\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Welcome to the AWS Lambda get started with functions demo.\")\tlog.Println(strings.Repeat(\"-\", 88))\trole := scenario.GetOrCreateRole(ctx)\tfuncName := scenario.CreateFunction(ctx, role)\tscenario.InvokeIncrement(ctx, funcName)\tscenario.UpdateFunction(ctx, funcName)\tscenario.InvokeCalculator(ctx, funcName)\tscenario.ListFunctions(ctx)\tscenario.Cleanup(ctx, role, funcName)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}// GetOrCreateRole checks whether the specified role exists and returns it if it does.// Otherwise, a role is created that specifies Lambda as a trusted principal.// The AWSLambdaBasicExecutionRole managed policy is attached to the role and the role// is returned.func (scenario GetStartedFunctionsScenario) GetOrCreateRole(ctx context.Context) *iamtypes.Role {\tvar role *iamtypes.Role\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\tlog.Println(\"First, we need an IAM role that Lambda can assume.\")\troleName := scenario.questioner.Ask(\"Enter a name for the role:\", demotools.NotEmpty{})\tgetOutput, err := iamClient.GetRole(ctx, &iam.GetRoleInput{\t\tRoleName: aws.String(roleName)})\tif err != nil {\t\tvar noSuch *iamtypes.NoSuchEntityException\t\tif errors.As(err, &noSuch) {\t\t\tlog.Printf(\"Role %v doesn't exist. Creating it....\\n\", roleName)\t\t} else {\t\t\tlog.Panicf(\"Couldn't check whether role %v exists. Here's why: %v\\n\",\t\t\t\troleName, err)\t\t}\t} else {\t\trole = getOutput.Role\t\tlog.Printf(\"Found role %v.\\n\", *role.RoleName)\t}\tif role == nil {\t\ttrustPolicy := PolicyDocument{\t\t\tVersion: \"2012-10-17\",\t\t\tStatement: []PolicyStatement{{\t\t\t\tEffect:    \"Allow\",\t\t\t\tPrincipal: map[string]string{\"Service\": \"lambda.amazonaws.com\"},\t\t\t\tAction:    []string{\"sts:AssumeRole\"},\t\t\t}},\t\t}\t\tpolicyArn := \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\t\tcreateOutput, err := iamClient.CreateRole(ctx, &iam.CreateRoleInput{\t\t\tAssumeRolePolicyDocument: aws.String(trustPolicy.String()),\t\t\tRoleName:                 aws.String(roleName),\t\t})\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't create role %v. Here's why: %v\\n\", roleName, err)\t\t}\t\trole = createOutput.Role\t\t_, err = iamClient.AttachRolePolicy(ctx, &iam.AttachRolePolicyInput{\t\t\tPolicyArn: aws.String(policyArn),\t\t\tRoleName:  aws.String(roleName),\t\t})\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't attach a policy to role %v. Here's why: %v\\n\", roleName, err)\t\t}\t\tlog.Printf(\"Created role %v.\\n\", *role.RoleName)\t\tlog.Println(\"Let's give AWS a few seconds to propagate resources...\")\t\tscenario.helper.Pause(10)\t}\tlog.Println(strings.Repeat(\"-\", 88))\treturn role}// CreateFunction creates a Lambda function and uploads a handler written in Python.// The code for the Python handler is packaged as a []byte in .zip format.func (scenario GetStartedFunctionsScenario) CreateFunction(ctx context.Context, role *iamtypes.Role) string {\tlog.Println(\"Let's create a function that increments a number.\\n\" +\t\t\"The function uses the 'lambda_handler_basic.py' script found in the \\n\" +\t\t\"'handlers' directory of this project.\")\tfuncName := scenario.questioner.Ask(\"Enter a name for the Lambda function:\", demotools.NotEmpty{})\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_basic.py\", fmt.Sprintf(\"%v.py\", funcName))\tlog.Printf(\"Creating function %v and waiting for it to be ready.\", funcName)\tfuncState := scenario.functionWrapper.CreateFunction(ctx, funcName, fmt.Sprintf(\"%v.lambda_handler\", funcName),\t\trole.Arn, zipPackage)\tlog.Printf(\"Your function is %v.\", funcState)\tlog.Println(strings.Repeat(\"-\", 88))\treturn funcName}// InvokeIncrement invokes a Lambda function that increments a number. The function// parameters are contained in a Go struct that is used to serialize the parameters to// a JSON payload that is passed to the function.// The result payload is deserialized into a Go struct that contains an int value.func (scenario GetStartedFunctionsScenario) InvokeIncrement(ctx context.Context, funcName string) {\tparameters := actions.IncrementParameters{Action: \"increment\"}\tlog.Println(\"Let's invoke our function. This function increments a number.\")\tparameters.Number = scenario.questioner.AskInt(\"Enter a number to increment:\", demotools.NotEmpty{})\tlog.Printf(\"Invoking %v with %v...\\n\", funcName, parameters.Number)\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, parameters, false)\tvar payload actions.LambdaResultInt\terr := json.Unmarshal(invokeOutput.Payload, &payload)\tif err != nil {\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\t\t\tfuncName, err)\t}\tlog.Printf(\"Invoking %v with %v returned %v.\\n\", funcName, parameters.Number, payload)\tlog.Println(strings.Repeat(\"-\", 88))}// UpdateFunction updates the code for a Lambda function by uploading a simple arithmetic// calculator written in Python. The code for the Python handler is packaged as a// []byte in .zip format.// After the code is updated, the configuration is also updated with a new log// level that instructs the handler to log additional information.func (scenario GetStartedFunctionsScenario) UpdateFunction(ctx context.Context, funcName string) {\tlog.Println(\"Let's update the function to an arithmetic calculator.\\n\" +\t\t\"The function uses the 'lambda_handler_calculator.py' script found in the \\n\" +\t\t\"'handlers' directory of this project.\")\tscenario.questioner.Ask(\"Press Enter when you're ready.\")\tlog.Println(\"Creating deployment package...\")\tzipPackage := scenario.helper.CreateDeploymentPackage(\"lambda_handler_calculator.py\",\t\tfmt.Sprintf(\"%v.py\", funcName))\tlog.Println(\"...and updating the Lambda function and waiting for it to be ready.\")\tfuncState := scenario.functionWrapper.UpdateFunctionCode(ctx, funcName, zipPackage)\tlog.Printf(\"Updated function %v. Its current state is %v.\", funcName, funcState)\tlog.Println(\"This function uses an environment variable to control logging level.\")\tlog.Println(\"Let's set it to DEBUG to get the most logging.\")\tscenario.functionWrapper.UpdateFunctionConfiguration(ctx, funcName,\t\tmap[string]string{\"LOG_LEVEL\": \"DEBUG\"})\tlog.Println(strings.Repeat(\"-\", 88))}// InvokeCalculator invokes the Lambda calculator function. The parameters are stored in a// Go struct that is used to serialize the parameters to a JSON payload. That payload is then passed// to the function.// The result payload is deserialized to a Go struct that stores the result as either an// int or float32, depending on the kind of operation that was specified.func (scenario GetStartedFunctionsScenario) InvokeCalculator(ctx context.Context, funcName string) {\twantInvoke := true\tchoices := []string{\"plus\", \"minus\", \"times\", \"divided-by\"}\tfor wantInvoke {\t\tchoice := scenario.questioner.AskChoice(\"Select an arithmetic operation:\\n\", choices)\t\tx := scenario.questioner.AskInt(\"Enter a value for x:\", demotools.NotEmpty{})\t\ty := scenario.questioner.AskInt(\"Enter a value for y:\", demotools.NotEmpty{})\t\tlog.Printf(\"Invoking %v %v %v...\", x, choices[choice], y)\t\tcalcParameters := actions.CalculatorParameters{\t\t\tAction: choices[choice],\t\t\tX:      x,\t\t\tY:      y,\t\t}\t\tinvokeOutput := scenario.functionWrapper.Invoke(ctx, funcName, calcParameters, true)\t\tvar payload any\t\tif choice == 3 { // divide-by results in a float.\t\t\tpayload = actions.LambdaResultFloat{}\t\t} else {\t\t\tpayload = actions.LambdaResultInt{}\t\t}\t\terr := json.Unmarshal(invokeOutput.Payload, &payload)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't unmarshal payload from invoking %v. Here's why: %v\\n\",\t\t\t\tfuncName, err)\t\t}\t\tlog.Printf(\"Invoking %v with %v %v %v returned %v.\\n\", funcName,\t\t\tcalcParameters.X, calcParameters.Action, calcParameters.Y, payload)\t\tscenario.questioner.Ask(\"Press Enter to see the logs from the call.\")\t\tlogRes, err := base64.StdEncoding.DecodeString(*invokeOutput.LogResult)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't decode log result. Here's why: %v\\n\", err)\t\t}\t\tlog.Println(string(logRes))\t\twantInvoke = scenario.questioner.AskBool(\"Do you want to calculate again? (y/n)\", \"y\")\t}\tlog.Println(strings.Repeat(\"-\", 88))}// ListFunctions lists up to the specified number of functions for your account.func (scenario GetStartedFunctionsScenario) ListFunctions(ctx context.Context) {\tcount := scenario.questioner.AskInt(\t\t\"Let's list functions for your account. How many do you want to see?\", demotools.NotEmpty{})\tfunctions := scenario.functionWrapper.ListFunctions(ctx, count)\tlog.Printf(\"Found %v functions:\", len(functions))\tfor _, function := range functions {\t\tlog.Printf(\"\\t%v\", *function.FunctionName)\t}\tlog.Println(strings.Repeat(\"-\", 88))}// Cleanup removes the IAM and Lambda resources created by the example.func (scenario GetStartedFunctionsScenario) Cleanup(ctx context.Context, role *iamtypes.Role, funcName string) {\tif scenario.questioner.AskBool(\"Do you want to clean up resources created for this example? (y/n)\",\t\t\"y\") {\t\tiamClient := iam.NewFromConfig(scenario.sdkConfig)\t\tpoliciesOutput, err := iamClient.ListAttachedRolePolicies(ctx,\t\t\t&iam.ListAttachedRolePoliciesInput{RoleName: role.RoleName})\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't get policies attached to role %v. Here's why: %v\\n\",\t\t\t\t*role.RoleName, err)\t\t}\t\tfor _, policy := range policiesOutput.AttachedPolicies {\t\t\t_, err = iamClient.DetachRolePolicy(ctx, &iam.DetachRolePolicyInput{\t\t\t\tPolicyArn: policy.PolicyArn, RoleName: role.RoleName,\t\t\t})\t\t\tif err != nil {\t\t\t\tlog.Panicf(\"Couldn't detach policy %v from role %v. Here's why: %v\\n\",\t\t\t\t\t*policy.PolicyArn, *role.RoleName, err)\t\t\t}\t\t}\t\t_, err = iamClient.DeleteRole(ctx, &iam.DeleteRoleInput{RoleName: role.RoleName})\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't delete role %v. Here's why: %v\\n\", *role.RoleName, err)\t\t}\t\tlog.Printf(\"Deleted role %v.\\n\", *role.RoleName)\t\tscenario.functionWrapper.DeleteFunction(ctx, funcName)\t\tlog.Printf(\"Deleted function %v.\\n\", funcName)\t} else {\t\tlog.Println(\"Okay. Don't forget to delete the resources when you're done with them.\")\t}}// IScenarioHelper abstracts I/O and wait functions from a scenario so that they// can be mocked for unit testing.type IScenarioHelper interface {\tPause(secs int)\tCreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer}// ScenarioHelper lets the caller specify the path to Lambda handler functions.type ScenarioHelper struct {\tHandlerPath string}// Pause waits for the specified number of seconds.func (helper *ScenarioHelper) Pause(secs int) {\ttime.Sleep(time.Duration(secs) * time.Second)}// CreateDeploymentPackage creates an AWS Lambda deployment package from a source file. The// deployment package is stored in .zip format in a bytes.Buffer. The buffer can be// used to pass a []byte to Lambda when creating the function.// The specified destinationFile is the name to give the file when it's deployed to Lambda.func (helper *ScenarioHelper) CreateDeploymentPackage(sourceFile string, destinationFile string) *bytes.Buffer {\tvar err error\tbuffer := &bytes.Buffer{}\twriter := zip.NewWriter(buffer)\tzFile, err := writer.Create(destinationFile)\tif err != nil {\t\tlog.Panicf(\"Couldn't create destination archive %v. Here's why: %v\\n\", destinationFile, err)\t}\tsourceBody, err := os.ReadFile(fmt.Sprintf(\"%v/%v\", helper.HandlerPath, sourceFile))\tif err != nil {\t\tlog.Panicf(\"Couldn't read handler source file %v. Here's why: %v\\n\",\t\t\tsourceFile, err)\t} else {\t\t_, err = zFile.Write(sourceBody)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't write handler %v to zip archive. Here's why: %v\\n\",\t\t\t\tsourceFile, err)\t\t}\t}\terr = writer.Close()\tif err != nil {\t\tlog.Panicf(\"Couldn't close zip writer. Here's why: %v\\n\", err)\t}\treturn buffer}Create a struct that wraps individual Lambda actions.import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// GetFunction gets data about the Lambda function specified by functionName.func (wrapper FunctionWrapper) GetFunction(ctx context.Context, functionName string) types.State {\tvar state types.State\tfuncOutput, err := wrapper.LambdaClient.GetFunction(ctx, &lambda.GetFunctionInput{\t\tFunctionName: aws.String(functionName),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't get function %v. Here's why: %v\\n\", functionName, err)\t} else {\t\tstate = funcOutput.Configuration.State\t}\treturn state}// CreateFunction creates a new Lambda function from code contained in the zipPackage// buffer. The specified handlerName must match the name of the file and function// contained in the uploaded code. The role specified by iamRoleArn is assumed by// Lambda and grants specific permissions.// When the function already exists, types.StateActive is returned.// When the function is created, a lambda.FunctionActiveV2Waiter is used to wait until the// function is active.func (wrapper FunctionWrapper) CreateFunction(ctx context.Context, functionName string, handlerName string,\tiamRoleArn *string, zipPackage *bytes.Buffer) types.State {\tvar state types.State\t_, err := wrapper.LambdaClient.CreateFunction(ctx, &lambda.CreateFunctionInput{\t\tCode:         &types.FunctionCode{ZipFile: zipPackage.Bytes()},\t\tFunctionName: aws.String(functionName),\t\tRole:         iamRoleArn,\t\tHandler:      aws.String(handlerName),\t\tPublish:      true,\t\tRuntime:      types.RuntimePython39,\t})\tif err != nil {\t\tvar resConflict *types.ResourceConflictException\t\tif errors.As(err, &resConflict) {\t\t\tlog.Printf(\"Function %v already exists.\\n\", functionName)\t\t\tstate = types.StateActive\t\t} else {\t\t\tlog.Panicf(\"Couldn't create function %v. Here's why: %v\\n\", functionName, err)\t\t}\t} else {\t\twaiter := lambda.NewFunctionActiveV2Waiter(wrapper.LambdaClient)\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\t\t} else {\t\t\tstate = funcOutput.Configuration.State\t\t}\t}\treturn state}// UpdateFunctionCode updates the code for the Lambda function specified by functionName.// The existing code for the Lambda function is entirely replaced by the code in the// zipPackage buffer. After the update action is called, a lambda.FunctionUpdatedV2Waiter// is used to wait until the update is successful.func (wrapper FunctionWrapper) UpdateFunctionCode(ctx context.Context, functionName string, zipPackage *bytes.Buffer) types.State {\tvar state types.State\t_, err := wrapper.LambdaClient.UpdateFunctionCode(ctx, &lambda.UpdateFunctionCodeInput{\t\tFunctionName: aws.String(functionName), ZipFile: zipPackage.Bytes(),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't update code for function %v. Here's why: %v\\n\", functionName, err)\t} else {\t\twaiter := lambda.NewFunctionUpdatedV2Waiter(wrapper.LambdaClient)\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\t\t} else {\t\t\tstate = funcOutput.Configuration.State\t\t}\t}\treturn state}// UpdateFunctionConfiguration updates a map of environment variables configured for// the Lambda function specified by functionName.func (wrapper FunctionWrapper) UpdateFunctionConfiguration(ctx context.Context, functionName string, envVars map[string]string) {\t_, err := wrapper.LambdaClient.UpdateFunctionConfiguration(ctx, &lambda.UpdateFunctionConfigurationInput{\t\tFunctionName: aws.String(functionName),\t\tEnvironment:  &types.Environment{Variables: envVars},\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't update configuration for %v. Here's why: %v\", functionName, err)\t}}// ListFunctions lists up to maxItems functions for the account. This function uses a// lambda.ListFunctionsPaginator to paginate the results.func (wrapper FunctionWrapper) ListFunctions(ctx context.Context, maxItems int) []types.FunctionConfiguration {\tvar functions []types.FunctionConfiguration\tpaginator := lambda.NewListFunctionsPaginator(wrapper.LambdaClient, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tfor paginator.HasMorePages() && len(functions) < maxItems {\t\tpageOutput, err := paginator.NextPage(ctx)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\t}\t\tfunctions = append(functions, pageOutput.Functions...)\t}\treturn functions}// DeleteFunction deletes the Lambda function specified by functionName.func (wrapper FunctionWrapper) DeleteFunction(ctx context.Context, functionName string) {\t_, err := wrapper.LambdaClient.DeleteFunction(ctx, &lambda.DeleteFunctionInput{\t\tFunctionName: aws.String(functionName),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't delete function %v. Here's why: %v\\n\", functionName, err)\t}}// Invoke invokes the Lambda function specified by functionName, passing the parameters// as a JSON payload. When getLog is true, types.LogTypeTail is specified, which tells// Lambda to include the last few log lines in the returned result.func (wrapper FunctionWrapper) Invoke(ctx context.Context, functionName string, parameters any, getLog bool) *lambda.InvokeOutput {\tlogType := types.LogTypeNone\tif getLog {\t\tlogType = types.LogTypeTail\t}\tpayload, err := json.Marshal(parameters)\tif err != nil {\t\tlog.Panicf(\"Couldn't marshal parameters to JSON. Here's why %v\\n\", err)\t}\tinvokeOutput, err := wrapper.LambdaClient.Invoke(ctx, &lambda.InvokeInput{\t\tFunctionName: aws.String(functionName),\t\tLogType:      logType,\t\tPayload:      payload,\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't invoke function %v. Here's why: %v\\n\", functionName, err)\t}\treturn invokeOutput}// IncrementParameters is used to serialize parameters to the increment Lambda handler.type IncrementParameters struct {\tAction string `json:\"action\"`\tNumber int    `json:\"number\"`}// CalculatorParameters is used to serialize parameters to the calculator Lambda handler.type CalculatorParameters struct {\tAction string `json:\"action\"`\tX      int    `json:\"x\"`\tY      int    `json:\"y\"`}// LambdaResultInt is used to deserialize an int result from a Lambda handler.type LambdaResultInt struct {\tResult int `json:\"result\"`}// LambdaResultFloat is used to deserialize a float32 result from a Lambda handler.type LambdaResultFloat struct {\tResult float32 `json:\"result\"`}Define a Lambda handler that increments a number.import logginglogger = logging.getLogger()logger.setLevel(logging.INFO)def lambda_handler(event, context):    \"\"\"    Accepts an action and a single number, performs the specified action on the number,    and returns the result. The only allowable action is 'increment'.    :param event: The event dict that contains the parameters sent when the function                  is invoked.    :param context: The context in which the function is called.    :return: The result of the action.    \"\"\"    result = None    action = event.get(\"action\")    if action == \"increment\":        result = event.get(\"number\", 0) + 1        logger.info(\"Calculated result of %s\", result)    else:        logger.error(\"%s is not a valid action.\", action)    response = {\"result\": result}    return responseDefine a second Lambda handler that performs arithmetic operations.import loggingimport oslogger = logging.getLogger()# Define a list of Python lambda functions that are called by this AWS Lambda function.ACTIONS = {    \"plus\": lambda x, y: x + y,    \"minus\": lambda x, y: x - y,    \"times\": lambda x, y: x * y,    \"divided-by\": lambda x, y: x / y,}def lambda_handler(event, context):    \"\"\"    Accepts an action and two numbers, performs the specified action on the numbers,    and returns the result.    :param event: The event dict that contains the parameters sent when the function                  is invoked.    :param context: The context in which the function is called.    :return: The result of the specified action.    \"\"\"    # Set the log level based on a variable configured in the Lambda environment.    logger.setLevel(os.environ.get(\"LOG_LEVEL\", logging.INFO))    logger.debug(\"Event: %s\", event)    action = event.get(\"action\")    func = ACTIONS.get(action)    x = event.get(\"x\")    y = event.get(\"y\")    result = None    try:        if func is not None and x is not None and y is not None:            result = func(x, y)            logger.info(\"%s %s %s is %s\", x, action, y, result)        else:            logger.error(\"I can't calculate %s %s %s.\", x, action, y)    except ZeroDivisionError:        logger.warning(\"I can't divide %s by 0!\", x)    response = {\"result\": result}    return responseFor API details, see the following topics in AWS SDK for Go API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationJavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    /* *  Lambda function names appear as: * *  arn:aws:lambda:us-west-2:335556666777:function:HelloFunction * *  To find this value, look at the function in the AWS Management Console. * *  Before running this Java code example, set up your development environment, including your credentials. * *  For more information, see this documentation topic: * *  https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-started.html * *  This example performs the following tasks: * * 1. Creates an AWS Lambda function. * 2. Gets a specific AWS Lambda function. * 3. Lists all Lambda functions. * 4. Invokes a Lambda function. * 5. Updates the Lambda function code and invokes it again. * 6. Updates a Lambda function's configuration value. * 7. Deletes a Lambda function. */public class LambdaScenario {    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \"-\");    public static void main(String[] args) throws InterruptedException {        final String usage = \"\"\"            Usage:                <functionName> <role> <handler> <bucketName> <key>\\s            Where:                functionName - The name of the Lambda function.\\s                role - The AWS Identity and Access Management (IAM) service role that has Lambda permissions.\\s                handler - The fully qualified method name (for example, example.Handler::handleRequest).\\s                bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the .zip or .jar used to update the Lambda function's code.\\s                key - The Amazon S3 key name that represents the .zip or .jar (for example, LambdaHello-1.0-SNAPSHOT.jar).                \"\"\";        if (args.length != 5) {              System.out.println(usage);              return;        }        String functionName = args[0];        String role = args[1];        String handler = args[2];        String bucketName = args[3];        String key = args[4];        LambdaClient awsLambda = LambdaClient.builder()            .build();        System.out.println(DASHES);        System.out.println(\"Welcome to the AWS Lambda Basics scenario.\");        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"1. Create an AWS Lambda function.\");        String funArn = createLambdaFunction(awsLambda, functionName, key, bucketName, role, handler);        System.out.println(\"The AWS Lambda ARN is \" + funArn);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"2. Get the \" + functionName + \" AWS Lambda function.\");        getFunction(awsLambda, functionName);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"3. List all AWS Lambda functions.\");        listFunctions(awsLambda);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"4. Invoke the Lambda function.\");        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");        Thread.sleep(60000);        invokeFunction(awsLambda, functionName);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"5. Update the Lambda function code and invoke it again.\");        updateFunctionCode(awsLambda, functionName, bucketName, key);        System.out.println(\"*** Sleep for 1 min to get Lambda function ready.\");        Thread.sleep(60000);        invokeFunction(awsLambda, functionName);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"6. Update a Lambda function's configuration value.\");        updateFunctionConfiguration(awsLambda, functionName, handler);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"7. Delete the AWS Lambda function.\");        LambdaScenario.deleteLambdaFunction(awsLambda, functionName);        System.out.println(DASHES);        System.out.println(DASHES);        System.out.println(\"The AWS Lambda scenario completed successfully\");        System.out.println(DASHES);        awsLambda.close();    }    /**     * Creates a new Lambda function in AWS using the AWS Lambda Java API.     *     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service     * @param functionName the name of the Lambda function to create     * @param key          the S3 key of the function code     * @param bucketName   the name of the S3 bucket containing the function code     * @param role         the IAM role to assign to the Lambda function     * @param handler      the fully qualified class name of the function handler     * @return the Amazon Resource Name (ARN) of the created Lambda function     */    public static String createLambdaFunction(LambdaClient awsLambda,                                              String functionName,                                              String key,                                              String bucketName,                                              String role,                                              String handler) {        try {            LambdaWaiter waiter = awsLambda.waiter();            FunctionCode code = FunctionCode.builder()                .s3Key(key)                .s3Bucket(bucketName)                .build();            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()                .functionName(functionName)                .description(\"Created by the Lambda Java API\")                .code(code)                .handler(handler)                .runtime(Runtime.JAVA17)                .role(role)                .build();            // Create a Lambda function using a waiter            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()                .functionName(functionName)                .build();            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);            waiterResponse.matched().response().ifPresent(System.out::println);            return functionResponse.functionArn();        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }        return \"\";    }    /**     * Retrieves information about an AWS Lambda function.     *     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     * @param functionName the name of the AWS Lambda function to retrieve information about     */    public static void getFunction(LambdaClient awsLambda, String functionName) {        try {            GetFunctionRequest functionRequest = GetFunctionRequest.builder()                .functionName(functionName)                .build();            GetFunctionResponse response = awsLambda.getFunction(functionRequest);            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }    /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }    /**     * Invokes a specific AWS Lambda function.     *     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service     * @param functionName the name of the AWS Lambda function to be invoked     */    public static void invokeFunction(LambdaClient awsLambda, String functionName) {        InvokeResponse res;        try {            // Need a SdkBytes instance for the payload.            JSONObject jsonObj = new JSONObject();            jsonObj.put(\"inputValue\", \"2000\");            String json = jsonObj.toString();            SdkBytes payload = SdkBytes.fromUtf8String(json);            InvokeRequest request = InvokeRequest.builder()                .functionName(functionName)                .payload(payload)                .build();            res = awsLambda.invoke(request);            String value = res.payload().asUtf8String();            System.out.println(value);        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }    /**     * Updates the code for an AWS Lambda function.     *     * @param awsLambda  the AWS Lambda client     * @param functionName the name of the Lambda function to update     * @param bucketName the name of the S3 bucket where the function code is located     * @param key the key (file name) of the function code in the S3 bucket     * @throws LambdaException if there is an error updating the function code     */    public static void updateFunctionCode(LambdaClient awsLambda, String functionName, String bucketName, String key) {        try {            LambdaWaiter waiter = awsLambda.waiter();            UpdateFunctionCodeRequest functionCodeRequest = UpdateFunctionCodeRequest.builder()                .functionName(functionName)                .publish(true)                .s3Bucket(bucketName)                .s3Key(key)                .build();            UpdateFunctionCodeResponse response = awsLambda.updateFunctionCode(functionCodeRequest);            GetFunctionConfigurationRequest getFunctionConfigRequest = GetFunctionConfigurationRequest.builder()                .functionName(functionName)                .build();            WaiterResponse<GetFunctionConfigurationResponse> waiterResponse = waiter                .waitUntilFunctionUpdated(getFunctionConfigRequest);            waiterResponse.matched().response().ifPresent(System.out::println);            System.out.println(\"The last modified value is \" + response.lastModified());        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }    /**     * Updates the configuration of an AWS Lambda function.     *     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation     * @param functionName  the name of the AWS Lambda function to update     * @param handler       the new handler for the AWS Lambda function     *     * @throws LambdaException if there is an error while updating the function configuration     */    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {        try {            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()                .functionName(functionName)                .handler(handler)                .runtime(Runtime.JAVA17)                .build();            awsLambda.updateFunctionConfiguration(configurationRequest);        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }    /**     * Deletes an AWS Lambda function.     *     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     * @param functionName  the name of the Lambda function to be deleted     *     * @throws LambdaException if an error occurs while deleting the Lambda function     */    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {        try {            DeleteFunctionRequest request = DeleteFunctionRequest.builder()                .functionName(functionName)                .build();            awsLambda.deleteFunction(request);            System.out.println(\"The \" + functionName + \" function was deleted\");        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }}For API details, see the following topics in AWS SDK for Java 2.x API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationJavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Create an AWS Identity and Access Management (IAM) role that grants Lambda permission to write to logs.    logger.log(`Creating role (${NAME_ROLE_LAMBDA})...`);    const response = await createRole(NAME_ROLE_LAMBDA);import { AttachRolePolicyCommand, IAMClient } from \"@aws-sdk/client-iam\";const client = new IAMClient({});/** * * @param {string} policyArn * @param {string} roleName */export const attachRolePolicy = (policyArn, roleName) => {  const command = new AttachRolePolicyCommand({    PolicyArn: policyArn,    RoleName: roleName,  });  return client.send(command);};Create a Lambda function and upload handler code.const createFunction = async (funcName, roleArn) => {  const client = new LambdaClient({});  const code = await readFile(`${dirname}../functions/${funcName}.zip`);  const command = new CreateFunctionCommand({    Code: { ZipFile: code },    FunctionName: funcName,    Role: roleArn,    Architectures: [Architecture.arm64],    Handler: \"index.handler\", // Required when sending a .zip file    PackageType: PackageType.Zip, // Required when sending a .zip file    Runtime: Runtime.nodejs16x, // Required when sending a .zip file  });  return client.send(command);};Invoke the function with a single parameter and get results.const invoke = async (funcName, payload) => {  const client = new LambdaClient({});  const command = new InvokeCommand({    FunctionName: funcName,    Payload: JSON.stringify(payload),    LogType: LogType.Tail,  });  const { Payload, LogResult } = await client.send(command);  const result = Buffer.from(Payload).toString();  const logs = Buffer.from(LogResult, \"base64\").toString();  return { logs, result };};Update the function code and configure its Lambda environment with an environment variable.const updateFunctionCode = async (funcName, newFunc) => {  const client = new LambdaClient({});  const code = await readFile(`${dirname}../functions/${newFunc}.zip`);  const command = new UpdateFunctionCodeCommand({    ZipFile: code,    FunctionName: funcName,    Architectures: [Architecture.arm64],    Handler: \"index.handler\", // Required when sending a .zip file    PackageType: PackageType.Zip, // Required when sending a .zip file    Runtime: Runtime.nodejs16x, // Required when sending a .zip file  });  return client.send(command);};const updateFunctionConfiguration = (funcName) => {  const client = new LambdaClient({});  const config = readFileSync(`${dirname}../functions/config.json`).toString();  const command = new UpdateFunctionConfigurationCommand({    ...JSON.parse(config),    FunctionName: funcName,  });  const result = client.send(command);  waitForFunctionUpdated({ FunctionName: funcName });  return result;};List the functions for your account.const listFunctions = () => {  const client = new LambdaClient({});  const command = new ListFunctionsCommand({});  return client.send(command);};Delete the IAM role and the Lambda function.import { DeleteRoleCommand, IAMClient } from \"@aws-sdk/client-iam\";const client = new IAMClient({});/** * * @param {string} roleName */export const deleteRole = (roleName) => {  const command = new DeleteRoleCommand({ RoleName: roleName });  return client.send(command);};/** * @param {string} funcName */const deleteFunction = (funcName) => {  const client = new LambdaClient({});  const command = new DeleteFunctionCommand({ FunctionName: funcName });  return client.send(command);};For API details, see the following topics in AWS SDK for JavaScript API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationKotlinSDK for KotlinNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    suspend fun main(args: Array<String>) {    val usage = \"\"\"        Usage:            <functionName> <role> <handler> <bucketName> <updatedBucketName> <key>         Where:            functionName - The name of the AWS Lambda function.             role - The AWS Identity and Access Management (IAM) service role that has AWS Lambda permissions.             handler - The fully qualified method name (for example, example.Handler::handleRequest).             bucketName - The Amazon Simple Storage Service (Amazon S3) bucket name that contains the ZIP or JAR used for the Lambda function's code.            updatedBucketName - The Amazon S3 bucket name that contains the .zip or .jar used to update the Lambda function's code.             key - The Amazon S3 key name that represents the .zip or .jar file (for example, LambdaHello-1.0-SNAPSHOT.jar).            \"\"\"    if (args.size != 6) {        println(usage)        exitProcess(1)    }    val functionName = args[0]    val role = args[1]    val handler = args[2]    val bucketName = args[3]    val updatedBucketName = args[4]    val key = args[5]    println(\"Creating a Lambda function named $functionName.\")    val funArn = createScFunction(functionName, bucketName, key, handler, role)    println(\"The AWS Lambda ARN is $funArn\")    // Get a specific Lambda function.    println(\"Getting the $functionName AWS Lambda function.\")    getFunction(functionName)    // List the Lambda functions.    println(\"Listing all AWS Lambda functions.\")    listFunctionsSc()    // Invoke the Lambda function.    println(\"*** Invoke the Lambda function.\")    invokeFunctionSc(functionName)    // Update the AWS Lambda function code.    println(\"*** Update the Lambda function code.\")    updateFunctionCode(functionName, updatedBucketName, key)    // println(\"*** Invoke the function again after updating the code.\")    invokeFunctionSc(functionName)    // Update the AWS Lambda function configuration.    println(\"Update the run time of the function.\")    updateFunctionConfiguration(functionName, handler)    // Delete the AWS Lambda function.    println(\"Delete the AWS Lambda function.\")    delFunction(functionName)}suspend fun createScFunction(    myFunctionName: String,    s3BucketName: String,    myS3Key: String,    myHandler: String,    myRole: String,): String {    val functionCode =        FunctionCode {            s3Bucket = s3BucketName            s3Key = myS3Key        }    val request =        CreateFunctionRequest {            functionName = myFunctionName            code = functionCode            description = \"Created by the Lambda Kotlin API\"            handler = myHandler            role = myRole            runtime = Runtime.Java8        }    // Create a Lambda function using a waiter    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val functionResponse = awsLambda.createFunction(request)        awsLambda.waitUntilFunctionActive {            functionName = myFunctionName        }        return functionResponse.functionArn.toString()    }}suspend fun getFunction(functionNameVal: String) {    val functionRequest =        GetFunctionRequest {            functionName = functionNameVal        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val response = awsLambda.getFunction(functionRequest)        println(\"The runtime of this Lambda function is ${response.configuration?.runtime}\")    }}suspend fun listFunctionsSc() {    val request =        ListFunctionsRequest {            maxItems = 10        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val response = awsLambda.listFunctions(request)        response.functions?.forEach { function ->            println(\"The function name is ${function.functionName}\")        }    }}suspend fun invokeFunctionSc(functionNameVal: String) {    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"    val byteArray = json.trimIndent().encodeToByteArray()    val request =        InvokeRequest {            functionName = functionNameVal            payload = byteArray            logType = LogType.Tail        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val res = awsLambda.invoke(request)        println(\"The function payload is ${res.payload?.toString(Charsets.UTF_8)}\")    }}suspend fun updateFunctionCode(    functionNameVal: String?,    bucketName: String?,    key: String?,) {    val functionCodeRequest =        UpdateFunctionCodeRequest {            functionName = functionNameVal            publish = true            s3Bucket = bucketName            s3Key = key        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val response = awsLambda.updateFunctionCode(functionCodeRequest)        awsLambda.waitUntilFunctionUpdated {            functionName = functionNameVal        }        println(\"The last modified value is \" + response.lastModified)    }}suspend fun updateFunctionConfiguration(    functionNameVal: String?,    handlerVal: String?,) {    val configurationRequest =        UpdateFunctionConfigurationRequest {            functionName = functionNameVal            handler = handlerVal            runtime = Runtime.Java11        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        awsLambda.updateFunctionConfiguration(configurationRequest)    }}suspend fun delFunction(myFunctionName: String) {    val request =        DeleteFunctionRequest {            functionName = myFunctionName        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        awsLambda.deleteFunction(request)        println(\"$myFunctionName was deleted\")    }}For API details, see the following topics in AWS SDK for Kotlin API reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationPHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace Lambda;use Aws\\S3\\S3Client;use GuzzleHttp\\Psr7\\Stream;use Iam\\IAMService;class GettingStartedWithLambda{    public function run()    {        echo(\"\\n\");        echo(\"--------------------------------------\\n\");        print(\"Welcome to the AWS Lambda getting started demo using PHP!\\n\");        echo(\"--------------------------------------\\n\");        $clientArgs = [            'region' => 'us-west-2',            'version' => 'latest',            'profile' => 'default',        ];        $uniqid = uniqid();        $iamService = new IAMService();        $s3client = new S3Client($clientArgs);        $lambdaService = new LambdaService();        echo \"First, let's create a role to run our Lambda code.\\n\";        $roleName = \"test-lambda-role-$uniqid\";        $rolePolicyDocument = \"{            \\\"Version\\\": \\\"2012-10-17\\\",            \\\"Statement\\\": [                {                    \\\"Effect\\\": \\\"Allow\\\",                    \\\"Principal\\\": {                        \\\"Service\\\": \\\"lambda.amazonaws.com\\\"                    },                    \\\"Action\\\": \\\"sts:AssumeRole\\\"                }            ]        }\";        $role = $iamService->createRole($roleName, $rolePolicyDocument);        echo \"Created role {$role['RoleName']}.\\n\";        $iamService->attachRolePolicy(            $role['RoleName'],            \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"        );        echo \"Attached the AWSLambdaBasicExecutionRole to {$role['RoleName']}.\\n\";        echo \"\\nNow let's create an S3 bucket and upload our Lambda code there.\\n\";        $bucketName = \"test-example-bucket-$uniqid\";        $s3client->createBucket([            'Bucket' => $bucketName,        ]);        echo \"Created bucket $bucketName.\\n\";        $functionName = \"doc_example_lambda_$uniqid\";        $codeBasic = __DIR__ . \"/lambda_handler_basic.zip\";        $handler = \"lambda_handler_basic\";        $file = file_get_contents($codeBasic);        $s3client->putObject([            'Bucket' => $bucketName,            'Key' => $functionName,            'Body' => $file,        ]);        echo \"Uploaded the Lambda code.\\n\";        $createLambdaFunction = $lambdaService->createFunction($functionName, $role, $bucketName, $handler);        // Wait until the function has finished being created.        do {            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);        } while ($getLambdaFunction['Configuration']['State'] == \"Pending\");        echo \"Created Lambda function {$getLambdaFunction['Configuration']['FunctionName']}.\\n\";        sleep(1);        echo \"\\nOk, let's invoke that Lambda code.\\n\";        $basicParams = [            'action' => 'increment',            'number' => 3,        ];        /** @var Stream $invokeFunction */        $invokeFunction = $lambdaService->invoke($functionName, $basicParams)['Payload'];        $result = json_decode($invokeFunction->getContents())->result;        echo \"After invoking the Lambda code with the input of {$basicParams['number']} we received $result.\\n\";        echo \"\\nSince that's working, let's update the Lambda code.\\n\";        $codeCalculator = \"lambda_handler_calculator.zip\";        $handlerCalculator = \"lambda_handler_calculator\";        echo \"First, put the new code into the S3 bucket.\\n\";        $file = file_get_contents($codeCalculator);        $s3client->putObject([            'Bucket' => $bucketName,            'Key' => $functionName,            'Body' => $file,        ]);        echo \"New code uploaded.\\n\";        $lambdaService->updateFunctionCode($functionName, $bucketName, $functionName);        // Wait for the Lambda code to finish updating.        do {            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");        echo \"New Lambda code uploaded.\\n\";        $environment = [            'Variable' => ['Variables' => ['LOG_LEVEL' => 'DEBUG']],        ];        $lambdaService->updateFunctionConfiguration($functionName, $handlerCalculator, $environment);        do {            $getLambdaFunction = $lambdaService->getFunction($createLambdaFunction['FunctionName']);        } while ($getLambdaFunction['Configuration']['LastUpdateStatus'] !== \"Successful\");        echo \"Lambda code updated with new handler and a LOG_LEVEL of DEBUG for more information.\\n\";        echo \"Invoke the new code with some new data.\\n\";        $calculatorParams = [            'action' => 'plus',            'x' => 5,            'y' => 4,        ];        $invokeFunction = $lambdaService->invoke($functionName, $calculatorParams, \"Tail\");        $result = json_decode($invokeFunction['Payload']->getContents())->result;        echo \"Indeed, {$calculatorParams['x']} + {$calculatorParams['y']} does equal $result.\\n\";        echo \"Here's the extra debug info: \";        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";        echo \"\\nBut what happens if you try to divide by zero?\\n\";        $divZeroParams = [            'action' => 'divide',            'x' => 5,            'y' => 0,        ];        $invokeFunction = $lambdaService->invoke($functionName, $divZeroParams, \"Tail\");        $result = json_decode($invokeFunction['Payload']->getContents())->result;        echo \"You get a |$result| result.\\n\";        echo \"And an error message: \";        echo base64_decode($invokeFunction['LogResult']) . \"\\n\";        echo \"\\nHere's all the Lambda functions you have in this Region:\\n\";        $listLambdaFunctions = $lambdaService->listFunctions(5);        $allLambdaFunctions = $listLambdaFunctions['Functions'];        $next = $listLambdaFunctions->get('NextMarker');        while ($next != false) {            $listLambdaFunctions = $lambdaService->listFunctions(5, $next);            $next = $listLambdaFunctions->get('NextMarker');            $allLambdaFunctions = array_merge($allLambdaFunctions, $listLambdaFunctions['Functions']);        }        foreach ($allLambdaFunctions as $function) {            echo \"{$function['FunctionName']}\\n\";        }        echo \"\\n\\nAnd don't forget to clean up your data!\\n\";        $lambdaService->deleteFunction($functionName);        echo \"Deleted Lambda function.\\n\";        $iamService->deleteRole($role['RoleName']);        echo \"Deleted Role.\\n\";        $deleteObjects = $s3client->listObjectsV2([            'Bucket' => $bucketName,        ]);        $deleteObjects = $s3client->deleteObjects([            'Bucket' => $bucketName,            'Delete' => [                'Objects' => $deleteObjects['Contents'],            ]        ]);        echo \"Deleted all objects from the S3 bucket.\\n\";        $s3client->deleteBucket(['Bucket' => $bucketName]);        echo \"Deleted the bucket.\\n\";    }}For API details, see the following topics in AWS SDK for PHP API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationPythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Define a Lambda handler that increments a number.import logginglogger = logging.getLogger()logger.setLevel(logging.INFO)def lambda_handler(event, context):    \"\"\"    Accepts an action and a single number, performs the specified action on the number,    and returns the result. The only allowable action is 'increment'.    :param event: The event dict that contains the parameters sent when the function                  is invoked.    :param context: The context in which the function is called.    :return: The result of the action.    \"\"\"    result = None    action = event.get(\"action\")    if action == \"increment\":        result = event.get(\"number\", 0) + 1        logger.info(\"Calculated result of %s\", result)    else:        logger.error(\"%s is not a valid action.\", action)    response = {\"result\": result}    return responseDefine a second Lambda handler that performs arithmetic operations.import loggingimport oslogger = logging.getLogger()# Define a list of Python lambda functions that are called by this AWS Lambda function.ACTIONS = {    \"plus\": lambda x, y: x + y,    \"minus\": lambda x, y: x - y,    \"times\": lambda x, y: x * y,    \"divided-by\": lambda x, y: x / y,}def lambda_handler(event, context):    \"\"\"    Accepts an action and two numbers, performs the specified action on the numbers,    and returns the result.    :param event: The event dict that contains the parameters sent when the function                  is invoked.    :param context: The context in which the function is called.    :return: The result of the specified action.    \"\"\"    # Set the log level based on a variable configured in the Lambda environment.    logger.setLevel(os.environ.get(\"LOG_LEVEL\", logging.INFO))    logger.debug(\"Event: %s\", event)    action = event.get(\"action\")    func = ACTIONS.get(action)    x = event.get(\"x\")    y = event.get(\"y\")    result = None    try:        if func is not None and x is not None and y is not None:            result = func(x, y)            logger.info(\"%s %s %s is %s\", x, action, y, result)        else:            logger.error(\"I can't calculate %s %s %s.\", x, action, y)    except ZeroDivisionError:        logger.warning(\"I can't divide %s by 0!\", x)    response = {\"result\": result}    return responseCreate functions that wrap Lambda actions.class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    @staticmethod    def create_deployment_package(source_file, destination_file):        \"\"\"        Creates a Lambda deployment package in .zip format in an in-memory buffer. This        buffer can be passed directly to Lambda when creating the function.        :param source_file: The name of the file that contains the Lambda handler                            function.        :param destination_file: The name to give the file when it's deployed to Lambda.        :return: The deployment package.        \"\"\"        buffer = io.BytesIO()        with zipfile.ZipFile(buffer, \"w\") as zipped:            zipped.write(source_file, destination_file)        buffer.seek(0)        return buffer.read()    def get_iam_role(self, iam_role_name):        \"\"\"        Get an AWS Identity and Access Management (IAM) role.        :param iam_role_name: The name of the role to retrieve.        :return: The IAM role.        \"\"\"        role = None        try:            temp_role = self.iam_resource.Role(iam_role_name)            temp_role.load()            role = temp_role            logger.info(\"Got IAM role %s\", role.name)        except ClientError as err:            if err.response[\"Error\"][\"Code\"] == \"NoSuchEntity\":                logger.info(\"IAM role %s does not exist.\", iam_role_name)            else:                logger.error(                    \"Couldn't get IAM role %s. Here's why: %s: %s\",                    iam_role_name,                    err.response[\"Error\"][\"Code\"],                    err.response[\"Error\"][\"Message\"],                )                raise        return role    def create_iam_role_for_lambda(self, iam_role_name):        \"\"\"        Creates an IAM role that grants the Lambda function basic permissions. If a        role with the specified name already exists, it is used for the demo.        :param iam_role_name: The name of the role to create.        :return: The role and a value that indicates whether the role is newly created.        \"\"\"        role = self.get_iam_role(iam_role_name)        if role is not None:            return role, False        lambda_assume_role_policy = {            \"Version\": \"2012-10-17\",            \"Statement\": [                {                    \"Effect\": \"Allow\",                    \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},                    \"Action\": \"sts:AssumeRole\",                }            ],        }        policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"        try:            role = self.iam_resource.create_role(                RoleName=iam_role_name,                AssumeRolePolicyDocument=json.dumps(lambda_assume_role_policy),            )            logger.info(\"Created role %s.\", role.name)            role.attach_policy(PolicyArn=policy_arn)            logger.info(\"Attached basic execution policy to role %s.\", role.name)        except ClientError as error:            if error.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":                role = self.iam_resource.Role(iam_role_name)                logger.warning(\"The role %s already exists. Using it.\", iam_role_name)            else:                logger.exception(                    \"Couldn't create role %s or attach policy %s.\",                    iam_role_name,                    policy_arn,                )                raise        return role, True    def get_function(self, function_name):        \"\"\"        Gets data about a Lambda function.        :param function_name: The name of the function.        :return: The function data.        \"\"\"        response = None        try:            response = self.lambda_client.get_function(FunctionName=function_name)        except ClientError as err:            if err.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":                logger.info(\"Function %s does not exist.\", function_name)            else:                logger.error(                    \"Couldn't get function %s. Here's why: %s: %s\",                    function_name,                    err.response[\"Error\"][\"Code\"],                    err.response[\"Error\"][\"Message\"],                )                raise        return response    def create_function(        self, function_name, handler_name, iam_role, deployment_package    ):        \"\"\"        Deploys a Lambda function.        :param function_name: The name of the Lambda function.        :param handler_name: The fully qualified name of the handler function. This                             must include the file name and the function name.        :param iam_role: The IAM role to use for the function.        :param deployment_package: The deployment package that contains the function                                   code in .zip format.        :return: The Amazon Resource Name (ARN) of the newly created function.        \"\"\"        try:            response = self.lambda_client.create_function(                FunctionName=function_name,                Description=\"AWS Lambda doc example\",                Runtime=\"python3.9\",                Role=iam_role.arn,                Handler=handler_name,                Code={\"ZipFile\": deployment_package},                Publish=True,            )            function_arn = response[\"FunctionArn\"]            waiter = self.lambda_client.get_waiter(\"function_active_v2\")            waiter.wait(FunctionName=function_name)            logger.info(                \"Created function '%s' with ARN: '%s'.\",                function_name,                response[\"FunctionArn\"],            )        except ClientError:            logger.error(\"Couldn't create function %s.\", function_name)            raise        else:            return function_arn    def delete_function(self, function_name):        \"\"\"        Deletes a Lambda function.        :param function_name: The name of the function to delete.        \"\"\"        try:            self.lambda_client.delete_function(FunctionName=function_name)        except ClientError:            logger.exception(\"Couldn't delete function %s.\", function_name)            raise    def invoke_function(self, function_name, function_params, get_log=False):        \"\"\"        Invokes a Lambda function.        :param function_name: The name of the function to invoke.        :param function_params: The parameters of the function as a dict. This dict                                is serialized to JSON before it is sent to Lambda.        :param get_log: When true, the last 4 KB of the execution log are included in                        the response.        :return: The response from the function invocation.        \"\"\"        try:            response = self.lambda_client.invoke(                FunctionName=function_name,                Payload=json.dumps(function_params),                LogType=\"Tail\" if get_log else \"None\",            )            logger.info(\"Invoked function %s.\", function_name)        except ClientError:            logger.exception(\"Couldn't invoke function %s.\", function_name)            raise        return response    def update_function_code(self, function_name, deployment_package):        \"\"\"        Updates the code for a Lambda function by submitting a .zip archive that contains        the code for the function.        :param function_name: The name of the function to update.        :param deployment_package: The function code to update, packaged as bytes in                                   .zip format.        :return: Data about the update, including the status.        \"\"\"        try:            response = self.lambda_client.update_function_code(                FunctionName=function_name, ZipFile=deployment_package            )        except ClientError as err:            logger.error(                \"Couldn't update function %s. Here's why: %s: %s\",                function_name,                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raise        else:            return response    def update_function_configuration(self, function_name, env_vars):        \"\"\"        Updates the environment variables for a Lambda function.        :param function_name: The name of the function to update.        :param env_vars: A dict of environment variables to update.        :return: Data about the update, including the status.        \"\"\"        try:            response = self.lambda_client.update_function_configuration(                FunctionName=function_name, Environment={\"Variables\": env_vars}            )        except ClientError as err:            logger.error(                \"Couldn't update function configuration %s. Here's why: %s: %s\",                function_name,                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raise        else:            return response    def list_functions(self):        \"\"\"        Lists the Lambda functions for the current account.        \"\"\"        try:            func_paginator = self.lambda_client.get_paginator(\"list_functions\")            for func_page in func_paginator.paginate():                for func in func_page[\"Functions\"]:                    print(func[\"FunctionName\"])                    desc = func.get(\"Description\")                    if desc:                        print(f\"\\t{desc}\")                    print(f\"\\t{func['Runtime']}: {func['Handler']}\")        except ClientError as err:            logger.error(                \"Couldn't list functions. Here's why: %s: %s\",                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raiseCreate a function that runs the scenario.class UpdateFunctionWaiter(CustomWaiter):    \"\"\"A custom waiter that waits until a function is successfully updated.\"\"\"    def __init__(self, client):        super().__init__(            \"UpdateSuccess\",            \"GetFunction\",            \"Configuration.LastUpdateStatus\",            {\"Successful\": WaitState.SUCCESS, \"Failed\": WaitState.FAILURE},            client,        )    def wait(self, function_name):        self._wait(FunctionName=function_name)def run_scenario(lambda_client, iam_resource, basic_file, calculator_file, lambda_name):    \"\"\"    Runs the scenario.    :param lambda_client: A Boto3 Lambda client.    :param iam_resource: A Boto3 IAM resource.    :param basic_file: The name of the file that contains the basic Lambda handler.    :param calculator_file: The name of the file that contains the calculator Lambda handler.    :param lambda_name: The name to give resources created for the scenario, such as the                        IAM role and the Lambda function.    \"\"\"    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")    print(\"-\" * 88)    print(\"Welcome to the AWS Lambda getting started with functions demo.\")    print(\"-\" * 88)    wrapper = LambdaWrapper(lambda_client, iam_resource)    print(\"Checking for IAM role for Lambda...\")    iam_role, should_wait = wrapper.create_iam_role_for_lambda(lambda_name)    if should_wait:        logger.info(\"Giving AWS time to create resources...\")        wait(10)    print(f\"Looking for function {lambda_name}...\")    function = wrapper.get_function(lambda_name)    if function is None:        print(\"Zipping the Python script into a deployment package...\")        deployment_package = wrapper.create_deployment_package(            basic_file, f\"{lambda_name}.py\"        )        print(f\"...and creating the {lambda_name} Lambda function.\")        wrapper.create_function(            lambda_name, f\"{lambda_name}.lambda_handler\", iam_role, deployment_package        )    else:        print(f\"Function {lambda_name} already exists.\")    print(\"-\" * 88)    print(f\"Let's invoke {lambda_name}. This function increments a number.\")    action_params = {        \"action\": \"increment\",        \"number\": q.ask(\"Give me a number to increment: \", q.is_int),    }    print(f\"Invoking {lambda_name}...\")    response = wrapper.invoke_function(lambda_name, action_params)    print(        f\"Incrementing {action_params['number']} resulted in \"        f\"{json.load(response['Payload'])}\"    )    print(\"-\" * 88)    print(f\"Let's update the function to an arithmetic calculator.\")    q.ask(\"Press Enter when you're ready.\")    print(\"Creating a new deployment package...\")    deployment_package = wrapper.create_deployment_package(        calculator_file, f\"{lambda_name}.py\"    )    print(f\"...and updating the {lambda_name} Lambda function.\")    update_waiter = UpdateFunctionWaiter(lambda_client)    wrapper.update_function_code(lambda_name, deployment_package)    update_waiter.wait(lambda_name)    print(f\"This function uses an environment variable to control logging level.\")    print(f\"Let's set it to DEBUG to get the most logging.\")    wrapper.update_function_configuration(        lambda_name, {\"LOG_LEVEL\": logging.getLevelName(logging.DEBUG)}    )    actions = [\"plus\", \"minus\", \"times\", \"divided-by\"]    want_invoke = True    while want_invoke:        print(f\"Let's invoke {lambda_name}. You can invoke these actions:\")        for index, action in enumerate(actions):            print(f\"{index + 1}: {action}\")        action_params = {}        action_index = q.ask(            \"Enter the number of the action you want to take: \",            q.is_int,            q.in_range(1, len(actions)),        )        action_params[\"action\"] = actions[action_index - 1]        print(f\"You've chosen to invoke 'x {action_params['action']} y'.\")        action_params[\"x\"] = q.ask(\"Enter a value for x: \", q.is_int)        action_params[\"y\"] = q.ask(\"Enter a value for y: \", q.is_int)        print(f\"Invoking {lambda_name}...\")        response = wrapper.invoke_function(lambda_name, action_params, True)        print(            f\"Calculating {action_params['x']} {action_params['action']} {action_params['y']} \"            f\"resulted in {json.load(response['Payload'])}\"        )        q.ask(\"Press Enter to see the logs from the call.\")        print(base64.b64decode(response[\"LogResult\"]).decode())        want_invoke = q.ask(\"That was fun. Shall we do it again? (y/n) \", q.is_yesno)    print(\"-\" * 88)    if q.ask(        \"Do you want to list all of the functions in your account? (y/n) \", q.is_yesno    ):        wrapper.list_functions()    print(\"-\" * 88)    if q.ask(\"Ready to delete the function and role? (y/n) \", q.is_yesno):        for policy in iam_role.attached_policies.all():            policy.detach_role(RoleName=iam_role.name)        iam_role.delete()        print(f\"Deleted role {lambda_name}.\")        wrapper.delete_function(lambda_name)        print(f\"Deleted function {lambda_name}.\")    print(\"\\nThanks for watching!\")    print(\"-\" * 88)if __name__ == \"__main__\":    try:        run_scenario(            boto3.client(\"lambda\"),            boto3.resource(\"iam\"),            \"lambda_handler_basic.py\",            \"lambda_handler_calculator.py\",            \"doc_example_lambda_calculator\",        )    except Exception:        logging.exception(\"Something went wrong with the demo!\")For API details, see the following topics in AWS SDK for Python (Boto3) API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Set up pre-requisite IAM permissions for a Lambda function capable of writing logs.  # Get an AWS Identity and Access Management (IAM) role.  #  # @param iam_role_name: The name of the role to retrieve.  # @param action: Whether to create or destroy the IAM apparatus.  # @return: The IAM role.  def manage_iam(iam_role_name, action)    case action    when 'create'      create_iam_role(iam_role_name)    when 'destroy'      destroy_iam_role(iam_role_name)    else      raise \"Incorrect action provided. Must provide 'create' or 'destroy'\"    end  end  private  def create_iam_role(iam_role_name)    role_policy = {      'Version': '2012-10-17',      'Statement': [        {          'Effect': 'Allow',          'Principal': { 'Service': 'lambda.amazonaws.com' },          'Action': 'sts:AssumeRole'        }      ]    }    role = @iam_client.create_role(      role_name: iam_role_name,      assume_role_policy_document: role_policy.to_json    )    @iam_client.attach_role_policy(      {        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',        role_name: iam_role_name      }    )    wait_for_role_to_exist(iam_role_name)    @logger.debug(\"Successfully created IAM role: #{role['role']['arn']}\")    sleep(10)    [role, role_policy.to_json]  end  def destroy_iam_role(iam_role_name)    @iam_client.detach_role_policy(      {        policy_arn: 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',        role_name: iam_role_name      }    )    @iam_client.delete_role(role_name: iam_role_name)    @logger.debug(\"Detached policy & deleted IAM role: #{iam_role_name}\")  end  def wait_for_role_to_exist(iam_role_name)    @iam_client.wait_until(:role_exists, { role_name: iam_role_name }) do |w|      w.max_attempts = 5      w.delay = 5    end  endDefine a Lambda handler that increments a number provided as an invocation parameter.require 'logger'# A function that increments a whole number by one (1) and logs the result.# Requires a manually-provided runtime parameter, 'number', which must be Int## @param event [Hash] Parameters sent when the function is invoked# @param context [Hash] Methods and properties that provide information# about the invocation, function, and execution environment.# @return incremented_number [String] The incremented number.def lambda_handler(event:, context:)  logger = Logger.new($stdout)  log_level = ENV['LOG_LEVEL']  logger.level = case log_level                 when 'debug'                   Logger::DEBUG                 when 'info'                   Logger::INFO                 else                   Logger::ERROR                 end  logger.debug('This is a debug log message.')  logger.info('This is an info log message. Code executed successfully!')  number = event['number'].to_i  incremented_number = number + 1  logger.info(\"You provided #{number.round} and it was incremented to #{incremented_number.round}\")  incremented_number.round.to_sendZip your Lambda function into a deployment package.  # Creates a Lambda deployment package in .zip format.  #  # @param source_file: The name of the object, without suffix, for the Lambda file and zip.  # @return: The deployment package.  def create_deployment_package(source_file)    Dir.chdir(File.dirname(__FILE__))    if File.exist?('lambda_function.zip')      File.delete('lambda_function.zip')      @logger.debug('Deleting old zip: lambda_function.zip')    end    Zip::File.open('lambda_function.zip', create: true) do |zipfile|      zipfile.add('lambda_function.rb', \"#{source_file}.rb\")    end    @logger.debug(\"Zipping #{source_file}.rb into: lambda_function.zip.\")    File.read('lambda_function.zip').to_s  rescue StandardError => e    @logger.error(\"There was an error creating deployment package:\\n #{e.message}\")  endCreate a new Lambda function.  # Deploys a Lambda function.  #  # @param function_name: The name of the Lambda function.  # @param handler_name: The fully qualified name of the handler function.  # @param role_arn: The IAM role to use for the function.  # @param deployment_package: The deployment package that contains the function code in .zip format.  # @return: The Amazon Resource Name (ARN) of the newly created function.  def create_function(function_name, handler_name, role_arn, deployment_package)    response = @lambda_client.create_function({                                                role: role_arn.to_s,                                                function_name: function_name,                                                handler: handler_name,                                                runtime: 'ruby2.7',                                                code: {                                                  zip_file: deployment_package                                                },                                                environment: {                                                  variables: {                                                    'LOG_LEVEL' => 'info'                                                  }                                                }                                              })    @lambda_client.wait_until(:function_active_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end    response  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error creating #{function_name}:\\n #{e.message}\")  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")  endInvoke your Lambda function with optional runtime parameters.  # Invokes a Lambda function.  # @param function_name [String] The name of the function to invoke.  # @param payload [nil] Payload containing runtime parameters.  # @return [Object] The response from the function invocation.  def invoke_function(function_name, payload = nil)    params = { function_name: function_name }    params[:payload] = payload unless payload.nil?    @lambda_client.invoke(params)  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error executing #{function_name}:\\n #{e.message}\")  endUpdate your Lambda function's configuration to inject a new environment variable.  # Updates the environment variables for a Lambda function.  # @param function_name: The name of the function to update.  # @param log_level: The log level of the function.  # @return: Data about the update, including the status.  def update_function_configuration(function_name, log_level)    @lambda_client.update_function_configuration({                                                   function_name: function_name,                                                   environment: {                                                     variables: {                                                       'LOG_LEVEL' => log_level                                                     }                                                   }                                                 })    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error updating configurations for #{function_name}:\\n #{e.message}\")  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")  endUpdate your Lambda function's code with a different deployment package containing different code.  # Updates the code for a Lambda function by submitting a .zip archive that contains  # the code for the function.  #  # @param function_name: The name of the function to update.  # @param deployment_package: The function code to update, packaged as bytes in  #                            .zip format.  # @return: Data about the update, including the status.  def update_function_code(function_name, deployment_package)    @lambda_client.update_function_code(      function_name: function_name,      zip_file: deployment_package    )    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error updating function code for: #{function_name}:\\n #{e.message}\")    nil  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to update:\\n #{e.message}\")  endList all existing Lambda functions using the built-in paginator.  # Lists the Lambda functions for the current account.  def list_functions    functions = []    @lambda_client.list_functions.each do |response|      response['functions'].each do |function|        functions.append(function['function_name'])      end    end    functions  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error listing functions:\\n #{e.message}\")  endDelete a specific Lambda function.  # Deletes a Lambda function.  # @param function_name: The name of the function to delete.  def delete_function(function_name)    print \"Deleting function: #{function_name}...\"    @lambda_client.delete_function(      function_name: function_name    )    print 'Done!'.green  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error deleting #{function_name}:\\n #{e.message}\")  endFor API details, see the following topics in AWS SDK for Ruby API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    The Cargo.toml with dependencies used in this scenario.[package]name = \"lambda-code-examples\"version = \"0.1.0\"edition = \"2021\"# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html[dependencies]aws-config = { version = \"1.0.1\", features = [\"behavior-version-latest\"] }aws-sdk-ec2 = { version = \"1.3.0\" }aws-sdk-iam = { version = \"1.3.0\" }aws-sdk-lambda = { version = \"1.3.0\" }aws-sdk-s3 = { version = \"1.4.0\" }aws-smithy-types = { version = \"1.0.1\" }aws-types = { version = \"1.0.1\" }clap = { version = \"4.4\", features = [\"derive\"] }tokio = { version = \"1.20.1\", features = [\"full\"] }tracing-subscriber = { version = \"0.3.15\", features = [\"env-filter\"] }tracing = \"0.1.37\"serde_json = \"1.0.94\"anyhow = \"1.0.71\"uuid = { version = \"1.3.3\", features = [\"v4\"] }lambda_runtime = \"0.8.0\"serde = \"1.0.164\"A collection of utilities that streamline calling Lambda for this scenario. This file is src/ations.rs in the crate.use anyhow::anyhow;use aws_sdk_iam::operation::{create_role::CreateRoleError, delete_role::DeleteRoleOutput};use aws_sdk_lambda::{    operation::{        delete_function::DeleteFunctionOutput, get_function::GetFunctionOutput,        invoke::InvokeOutput, list_functions::ListFunctionsOutput,        update_function_code::UpdateFunctionCodeOutput,        update_function_configuration::UpdateFunctionConfigurationOutput,    },    primitives::ByteStream,    types::{Environment, FunctionCode, LastUpdateStatus, State},};use aws_sdk_s3::{    error::ErrorMetadata,    operation::{delete_bucket::DeleteBucketOutput, delete_object::DeleteObjectOutput},    types::CreateBucketConfiguration,};use aws_smithy_types::Blob;use serde::{ser::SerializeMap, Serialize};use std::{fmt::Display, path::PathBuf, str::FromStr, time::Duration};use tracing::{debug, info, warn};/* Operation describes  */#[derive(Clone, Copy, Debug, Serialize)]pub enum Operation {    #[serde(rename = \"plus\")]    Plus,    #[serde(rename = \"minus\")]    Minus,    #[serde(rename = \"times\")]    Times,    #[serde(rename = \"divided-by\")]    DividedBy,}impl FromStr for Operation {    type Err = anyhow::Error;    fn from_str(s: &str) -> Result<Self, Self::Err> {        match s {            \"plus\" => Ok(Operation::Plus),            \"minus\" => Ok(Operation::Minus),            \"times\" => Ok(Operation::Times),            \"divided-by\" => Ok(Operation::DividedBy),            _ => Err(anyhow!(\"Unknown operation {s}\")),        }    }}impl Display for Operation {    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {        match self {            Operation::Plus => write!(f, \"plus\"),            Operation::Minus => write!(f, \"minus\"),            Operation::Times => write!(f, \"times\"),            Operation::DividedBy => write!(f, \"divided-by\"),        }    }}/** * InvokeArgs will be serialized as JSON and sent to the AWS Lambda handler. */#[derive(Debug)]pub enum InvokeArgs {    Increment(i32),    Arithmetic(Operation, i32, i32),}impl Serialize for InvokeArgs {    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>    where        S: serde::Serializer,    {        match self {            InvokeArgs::Increment(i) => serializer.serialize_i32(*i),            InvokeArgs::Arithmetic(o, i, j) => {                let mut map: S::SerializeMap = serializer.serialize_map(Some(3))?;                map.serialize_key(&\"op\".to_string())?;                map.serialize_value(&o.to_string())?;                map.serialize_key(&\"i\".to_string())?;                map.serialize_value(&i)?;                map.serialize_key(&\"j\".to_string())?;                map.serialize_value(&j)?;                map.end()            }        }    }}/** A policy document allowing Lambda to execute this function on the account's behalf. */const ROLE_POLICY_DOCUMENT: &str = r#\"{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Principal\": { \"Service\": \"lambda.amazonaws.com\" },            \"Action\": \"sts:AssumeRole\"        }    ]}\"#;/** * A LambdaManager gathers all the resources necessary to run the Lambda example scenario. * This includes instantiated aws_sdk clients and details of resource names. */pub struct LambdaManager {    iam_client: aws_sdk_iam::Client,    lambda_client: aws_sdk_lambda::Client,    s3_client: aws_sdk_s3::Client,    lambda_name: String,    role_name: String,    bucket: String,    own_bucket: bool,}// These unit type structs provide nominal typing on top of String parameters for LambdaManager::newpub struct LambdaName(pub String);pub struct RoleName(pub String);pub struct Bucket(pub String);pub struct OwnBucket(pub bool);impl LambdaManager {    pub fn new(        iam_client: aws_sdk_iam::Client,        lambda_client: aws_sdk_lambda::Client,        s3_client: aws_sdk_s3::Client,        lambda_name: LambdaName,        role_name: RoleName,        bucket: Bucket,        own_bucket: OwnBucket,    ) -> Self {        Self {            iam_client,            lambda_client,            s3_client,            lambda_name: lambda_name.0,            role_name: role_name.0,            bucket: bucket.0,            own_bucket: own_bucket.0,        }    }    /**     * Load the AWS configuration from the environment.     * Look up lambda_name and bucket if none are given, or generate a random name if not present in the environment.     * If the bucket name is provided, the caller needs to have created the bucket.     * If the bucket name is generated, it will be created.     */    pub async fn load_from_env(lambda_name: Option<String>, bucket: Option<String>) -> Self {        let sdk_config = aws_config::load_from_env().await;        let lambda_name = LambdaName(lambda_name.unwrap_or_else(|| {            std::env::var(\"LAMBDA_NAME\").unwrap_or_else(|_| \"rust_lambda_example\".to_string())        }));        let role_name = RoleName(format!(\"{}_role\", lambda_name.0));        let (bucket, own_bucket) =            match bucket {                Some(bucket) => (Bucket(bucket), false),                None => (                    Bucket(std::env::var(\"LAMBDA_BUCKET\").unwrap_or_else(|_| {                        format!(\"rust-lambda-example-{}\", uuid::Uuid::new_v4())                    })),                    true,                ),            };        let s3_client = aws_sdk_s3::Client::new(&sdk_config);        if own_bucket {            info!(\"Creating bucket for demo: {}\", bucket.0);            s3_client                .create_bucket()                .bucket(bucket.0.clone())                .create_bucket_configuration(                    CreateBucketConfiguration::builder()                        .location_constraint(aws_sdk_s3::types::BucketLocationConstraint::from(                            sdk_config.region().unwrap().as_ref(),                        ))                        .build(),                )                .send()                .await                .unwrap();        }        Self::new(            aws_sdk_iam::Client::new(&sdk_config),            aws_sdk_lambda::Client::new(&sdk_config),            s3_client,            lambda_name,            role_name,            bucket,            OwnBucket(own_bucket),        )    }    /**     * Upload function code from a path to a zip file.     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.     */    async fn prepare_function(        &self,        zip_file: PathBuf,        key: Option<String>,    ) -> Result<FunctionCode, anyhow::Error> {        let body = ByteStream::from_path(zip_file).await?;        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);        let _ = self            .s3_client            .put_object()            .bucket(self.bucket.clone())            .key(key.clone())            .body(body)            .send()            .await?;        Ok(FunctionCode::builder()            .s3_bucket(self.bucket.clone())            .s3_key(key)            .build())    }    /**     * Create a function, uploading from a zip file.     */    pub async fn create_function(&self, zip_file: PathBuf) -> Result<String, anyhow::Error> {        let code = self.prepare_function(zip_file, None).await?;        let key = code.s3_key().unwrap().to_string();        let role = self.create_role().await.map_err(|e| anyhow!(e))?;        info!(\"Created iam role, waiting 15s for it to become active\");        tokio::time::sleep(Duration::from_secs(15)).await;        info!(\"Creating lambda function {}\", self.lambda_name);        let _ = self            .lambda_client            .create_function()            .function_name(self.lambda_name.clone())            .code(code)            .role(role.arn())            .runtime(aws_sdk_lambda::types::Runtime::Providedal2)            .handler(\"_unused\")            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        self.lambda_client            .publish_version()            .function_name(self.lambda_name.clone())            .send()            .await?;        Ok(key)    }    /**     * Create an IAM execution role for the managed Lambda function.     * If the role already exists, use that instead.     */    async fn create_role(&self) -> Result<aws_sdk_iam::types::Role, CreateRoleError> {        info!(\"Creating execution role for function\");        let get_role = self            .iam_client            .get_role()            .role_name(self.role_name.clone())            .send()            .await;        if let Ok(get_role) = get_role {            if let Some(role) = get_role.role {                return Ok(role);            }        }        let create_role = self            .iam_client            .create_role()            .role_name(self.role_name.clone())            .assume_role_policy_document(ROLE_POLICY_DOCUMENT)            .send()            .await;        match create_role {            Ok(create_role) => match create_role.role {                Some(role) => Ok(role),                None => Err(CreateRoleError::generic(                    ErrorMetadata::builder()                        .message(\"CreateRole returned empty success\")                        .build(),                )),            },            Err(err) => Err(err.into_service_error()),        }    }    /**     * Poll `is_function_ready` with a 1-second delay. It returns when the function is ready or when there's an error checking the function's state.     */    pub async fn wait_for_function_ready(&self) -> Result<(), anyhow::Error> {        info!(\"Waiting for function\");        while !self.is_function_ready(None).await? {            info!(\"Function is not ready, sleeping 1s\");            tokio::time::sleep(Duration::from_secs(1)).await;        }        Ok(())    }    /**     * Check if a Lambda function is ready to be invoked.     * A Lambda function is ready for this scenario when its state is active and its LastUpdateStatus is Successful.     * Additionally, if a sha256 is provided, the function must have that as its current code hash.     * Any missing properties or failed requests will be reported as an Err.     */    async fn is_function_ready(        &self,        expected_code_sha256: Option<&str>,    ) -> Result<bool, anyhow::Error> {        match self.get_function().await {            Ok(func) => {                if let Some(config) = func.configuration() {                    if let Some(state) = config.state() {                        info!(?state, \"Checking if function is active\");                        if !matches!(state, State::Active) {                            return Ok(false);                        }                    }                    match config.last_update_status() {                        Some(last_update_status) => {                            info!(?last_update_status, \"Checking if function is ready\");                            match last_update_status {                                LastUpdateStatus::Successful => {                                    // continue                                }                                LastUpdateStatus::Failed | LastUpdateStatus::InProgress => {                                    return Ok(false);                                }                                unknown => {                                    warn!(                                        status_variant = unknown.as_str(),                                        \"LastUpdateStatus unknown\"                                    );                                    return Err(anyhow!(                                        \"Unknown LastUpdateStatus, fn config is {config:?}\"                                    ));                                }                            }                        }                        None => {                            warn!(\"Missing last update status\");                            return Ok(false);                        }                    };                    if expected_code_sha256.is_none() {                        return Ok(true);                    }                    if let Some(code_sha256) = config.code_sha256() {                        return Ok(code_sha256 == expected_code_sha256.unwrap_or_default());                    }                }            }            Err(e) => {                warn!(?e, \"Could not get function while waiting\");            }        }        Ok(false)    }    /** Get the Lambda function with this Manager's name. */    pub async fn get_function(&self) -> Result<GetFunctionOutput, anyhow::Error> {        info!(\"Getting lambda function\");        self.lambda_client            .get_function()            .function_name(self.lambda_name.clone())            .send()            .await            .map_err(anyhow::Error::from)    }    /** List all Lambda functions in the current Region. */    pub async fn list_functions(&self) -> Result<ListFunctionsOutput, anyhow::Error> {        info!(\"Listing lambda functions\");        self.lambda_client            .list_functions()            .send()            .await            .map_err(anyhow::Error::from)    }    /** Invoke the lambda function using calculator InvokeArgs. */    pub async fn invoke(&self, args: InvokeArgs) -> Result<InvokeOutput, anyhow::Error> {        info!(?args, \"Invoking {}\", self.lambda_name);        let payload = serde_json::to_string(&args)?;        debug!(?payload, \"Sending payload\");        self.lambda_client            .invoke()            .function_name(self.lambda_name.clone())            .payload(Blob::new(payload))            .send()            .await            .map_err(anyhow::Error::from)    }    /** Given a Path to a zip file, update the function's code and wait for the update to finish. */    pub async fn update_function_code(        &self,        zip_file: PathBuf,        key: String,    ) -> Result<UpdateFunctionCodeOutput, anyhow::Error> {        let function_code = self.prepare_function(zip_file, Some(key)).await?;        info!(\"Updating code for {}\", self.lambda_name);        let update = self            .lambda_client            .update_function_code()            .function_name(self.lambda_name.clone())            .s3_bucket(self.bucket.clone())            .s3_key(function_code.s3_key().unwrap().to_string())            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        Ok(update)    }    /** Update the environment for a function. */    pub async fn update_function_configuration(        &self,        environment: Environment,    ) -> Result<UpdateFunctionConfigurationOutput, anyhow::Error> {        info!(            ?environment,            \"Updating environment for {}\", self.lambda_name        );        let updated = self            .lambda_client            .update_function_configuration()            .function_name(self.lambda_name.clone())            .environment(environment)            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        Ok(updated)    }    /** Delete a function and its role, and if possible or necessary, its associated code object and bucket. */    pub async fn delete_function(        &self,        location: Option<String>,    ) -> (        Result<DeleteFunctionOutput, anyhow::Error>,        Result<DeleteRoleOutput, anyhow::Error>,        Option<Result<DeleteObjectOutput, anyhow::Error>>,    ) {        info!(\"Deleting lambda function {}\", self.lambda_name);        let delete_function = self            .lambda_client            .delete_function()            .function_name(self.lambda_name.clone())            .send()            .await            .map_err(anyhow::Error::from);        info!(\"Deleting iam role {}\", self.role_name);        let delete_role = self            .iam_client            .delete_role()            .role_name(self.role_name.clone())            .send()            .await            .map_err(anyhow::Error::from);        let delete_object: Option<Result<DeleteObjectOutput, anyhow::Error>> =            if let Some(location) = location {                info!(\"Deleting object {location}\");                Some(                    self.s3_client                        .delete_object()                        .bucket(self.bucket.clone())                        .key(location)                        .send()                        .await                        .map_err(anyhow::Error::from),                )            } else {                info!(?location, \"Skipping delete object\");                None            };        (delete_function, delete_role, delete_object)    }    pub async fn cleanup(        &self,        location: Option<String>,    ) -> (        (            Result<DeleteFunctionOutput, anyhow::Error>,            Result<DeleteRoleOutput, anyhow::Error>,            Option<Result<DeleteObjectOutput, anyhow::Error>>,        ),        Option<Result<DeleteBucketOutput, anyhow::Error>>,    ) {        let delete_function = self.delete_function(location).await;        let delete_bucket = if self.own_bucket {            info!(\"Deleting bucket {}\", self.bucket);            if delete_function.2.is_none() || delete_function.2.as_ref().unwrap().is_ok() {                Some(                    self.s3_client                        .delete_bucket()                        .bucket(self.bucket.clone())                        .send()                        .await                        .map_err(anyhow::Error::from),                )            } else {                None            }        } else {            info!(\"No bucket to clean up\");            None        };        (delete_function, delete_bucket)    }}/** * Testing occurs primarily as an integration test running the `scenario` bin successfully. * Each action relies deeply on the internal workings and state of Amazon Simple Storage Service (Amazon S3), Lambda, and IAM working together. * It is therefore infeasible to mock the clients to test the individual actions. */#[cfg(test)]mod test {    use super::{InvokeArgs, Operation};    use serde_json::json;    /** Make sure that the JSON output of serializing InvokeArgs is what's expected by the calculator. */    #[test]    fn test_serialize() {        assert_eq!(json!(InvokeArgs::Increment(5)), 5);        assert_eq!(            json!(InvokeArgs::Arithmetic(Operation::Plus, 5, 7)).to_string(),            r#\"{\"op\":\"plus\",\"i\":5,\"j\":7}\"#.to_string(),        );    }}A binary to run the scenario from front to end, using command line flags to control some behavior. This file is src/bin/scenario.rs in the crate./*## Service actionsService actions wrap the SDK call, taking a client and any specific parameters necessary for the call.* CreateFunction* GetFunction* ListFunctions* Invoke* UpdateFunctionCode* UpdateFunctionConfiguration* DeleteFunction## ScenarioA scenario runs at a command prompt and prints output to the user on the result of each service action. A scenario can run in one of two ways: straight through, printing out progress as it goes, or as an interactive question/answer script.## Getting started with functionsUse an SDK to manage AWS Lambda functions: create a function, invoke it, update its code, invoke it again, view its output and logs, and delete it.This scenario uses two Lambda handlers:_Note: Handlers don't use AWS SDK API calls._The increment handler is straightforward:1. It accepts a number, increments it, and returns the new value.2. It performs simple logging of the result.The arithmetic handler is more complex:1. It accepts a set of actions ['plus', 'minus', 'times', 'divided-by'] and two numbers, and returns the result of the calculation.2. It uses an environment variable to control log level (such as DEBUG, INFO, WARNING, ERROR).It logs a few things at different levels, such as:    * DEBUG: Full event data.    * INFO: The calculation result.    * WARN~ING~: When a divide by zero error occurs.    * This will be the typical `RUST_LOG` variable.The steps of the scenario are:1. Create an AWS Identity and Access Management (IAM) role that meets the following requirements:    * Has an assume_role policy that grants 'lambda.amazonaws.com' the 'sts:AssumeRole' action.    * Attaches the 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole' managed role.    * _You must wait for ~10 seconds after the role is created before you can use it!_2. Create a function (CreateFunction) for the increment handler by packaging it as a zip and doing one of the following:    * Adding it with CreateFunction Code.ZipFile.    * --or--    * Uploading it to Amazon Simple Storage Service (Amazon S3) and adding it with CreateFunction Code.S3Bucket/S3Key.    * _Note: Zipping the file does not have to be done in code._    * If you have a waiter, use it to wait until the function is active. Otherwise, call GetFunction until State is Active.3. Invoke the function with a number and print the result.4. Update the function (UpdateFunctionCode) to the arithmetic handler by packaging it as a zip and doing one of the following:    * Adding it with UpdateFunctionCode ZipFile.    * --or--    * Uploading it to Amazon S3 and adding it with UpdateFunctionCode S3Bucket/S3Key.5. Call GetFunction until Configuration.LastUpdateStatus is 'Successful' (or 'Failed').6. Update the environment variable by calling UpdateFunctionConfiguration and pass it a log level, such as:    * Environment={'Variables': {'RUST_LOG': 'TRACE'}}7. Invoke the function with an action from the list and a couple of values. Include LogType='Tail' to get logs in the result. Print the result of the calculation and the log.8. [Optional] Invoke the function to provoke a divide-by-zero error and show the log result.9. List all functions for the account, using pagination (ListFunctions).10. Delete the function (DeleteFunction).11. Delete the role.Each step should use the function created in Service Actions to abstract calling the SDK. */use aws_sdk_lambda::{operation::invoke::InvokeOutput, types::Environment};use clap::Parser;use std::{collections::HashMap, path::PathBuf};use tracing::{debug, info, warn};use tracing_subscriber::EnvFilter;use lambda_code_examples::actions::{    InvokeArgs::{Arithmetic, Increment},    LambdaManager, Operation,};#[derive(Debug, Parser)]pub struct Opt {    /// The AWS Region.    #[structopt(short, long)]    pub region: Option<String>,    // The bucket to use for the FunctionCode.    #[structopt(short, long)]    pub bucket: Option<String>,    // The name of the Lambda function.    #[structopt(short, long)]    pub lambda_name: Option<String>,    // The number to increment.    #[structopt(short, long, default_value = \"12\")]    pub inc: i32,    // The left operand.    #[structopt(long, default_value = \"19\")]    pub num_a: i32,    // The right operand.    #[structopt(long, default_value = \"23\")]    pub num_b: i32,    // The arithmetic operation.    #[structopt(short, long, default_value = \"plus\")]    pub operation: Operation,    #[structopt(long)]    pub cleanup: Option<bool>,    #[structopt(long)]    pub no_cleanup: Option<bool>,}fn code_path(lambda: &str) -> PathBuf {    PathBuf::from(format!(\"../target/lambda/{lambda}/bootstrap.zip\"))}fn log_invoke_output(invoke: &InvokeOutput, message: &str) {    if let Some(payload) = invoke.payload().cloned() {        let payload = String::from_utf8(payload.into_inner());        info!(?payload, message);    } else {        info!(\"Could not extract payload\")    }    if let Some(logs) = invoke.log_result() {        debug!(?logs, \"Invoked function logs\")    } else {        debug!(\"Invoked function had no logs\")    }}async fn main_block(    opt: &Opt,    manager: &LambdaManager,    code_location: String,) -> Result<(), anyhow::Error> {    let invoke = manager.invoke(Increment(opt.inc)).await?;    log_invoke_output(&invoke, \"Invoked function configured as increment\");    let update_code = manager        .update_function_code(code_path(\"arithmetic\"), code_location.clone())        .await?;    let code_sha256 = update_code.code_sha256().unwrap_or(\"Unknown SHA\");    info!(?code_sha256, \"Updated function code with arithmetic.zip\");    let arithmetic_args = Arithmetic(opt.operation, opt.num_a, opt.num_b);    let invoke = manager.invoke(arithmetic_args).await?;    log_invoke_output(&invoke, \"Invoked function configured as arithmetic\");    let update = manager        .update_function_configuration(            Environment::builder()                .set_variables(Some(HashMap::from([(                    \"RUST_LOG\".to_string(),                    \"trace\".to_string(),                )])))                .build(),        )        .await?;    let updated_environment = update.environment();    info!(?updated_environment, \"Updated function configuration\");    let invoke = manager        .invoke(Arithmetic(opt.operation, opt.num_a, opt.num_b))        .await?;    log_invoke_output(        &invoke,        \"Invoked function configured as arithmetic with increased logging\",    );    let invoke = manager        .invoke(Arithmetic(Operation::DividedBy, opt.num_a, 0))        .await?;    log_invoke_output(        &invoke,        \"Invoked function configured as arithmetic with divide by zero\",    );    Ok::<(), anyhow::Error>(())}#[tokio::main]async fn main() {    tracing_subscriber::fmt()        .without_time()        .with_file(true)        .with_line_number(true)        .with_env_filter(EnvFilter::from_default_env())        .init();    let opt = Opt::parse();    let manager = LambdaManager::load_from_env(opt.lambda_name.clone(), opt.bucket.clone()).await;    let key = match manager.create_function(code_path(\"increment\")).await {        Ok(init) => {            info!(?init, \"Created function, initially with increment.zip\");            let run_block = main_block(&opt, &manager, init.clone()).await;            info!(?run_block, \"Finished running example, cleaning up\");            Some(init)        }        Err(err) => {            warn!(?err, \"Error happened when initializing function\");            None        }    };    if Some(false) == opt.cleanup || Some(true) == opt.no_cleanup {        info!(\"Skipping cleanup\")    } else {        let delete = manager.cleanup(key).await;        info!(?delete, \"Deleted function & cleaned up resources\");    }}For API details, see the following topics in AWS SDK for Rust API reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfigurationSAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        \"Create an AWS Identity and Access Management (IAM) role that grants AWS Lambda permission to write to logs.\"        DATA(lv_policy_document) = `{` &&            `\"Version\":\"2012-10-17\",` &&                  `\"Statement\": [` &&                    `{` &&                      `\"Effect\": \"Allow\",` &&                      `\"Action\": [` &&                        `\"sts:AssumeRole\"` &&                      `],` &&                      `\"Principal\": {` &&                        `\"Service\": [` &&                          `\"lambda.amazonaws.com\"` &&                        `]` &&                      `}` &&                    `}` &&                  `]` &&                `}`.        TRY.            DATA(lo_create_role_output) =  lo_iam->createrole(                    iv_rolename = iv_role_name                    iv_assumerolepolicydocument = lv_policy_document                    iv_description = 'Grant lambda permission to write to logs'                ).            MESSAGE 'IAM role created.' TYPE 'I'.            WAIT UP TO 10 SECONDS.            \" Make sure that the IAM role is ready for use. \"          CATCH /aws1/cx_iamentityalrdyexex.            MESSAGE 'IAM role already exists.' TYPE 'E'.          CATCH /aws1/cx_iaminvalidinputex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_iammalformedplydocex.            MESSAGE 'Policy document in the request is malformed.' TYPE 'E'.        ENDTRY.        TRY.            lo_iam->attachrolepolicy(                iv_rolename  = iv_role_name                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'            ).            MESSAGE 'Attached policy to the IAM role.' TYPE 'I'.          CATCH /aws1/cx_iaminvalidinputex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_iamnosuchentityex.            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.          CATCH /aws1/cx_iamplynotattachableex.            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.          CATCH /aws1/cx_iamunmodableentityex.            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.        ENDTRY.        \" Create a Lambda function and upload handler code. \"        \" Lambda function performs 'increment' action on a number. \"        TRY.            lo_lmd->createfunction(                 iv_functionname = iv_function_name                 iv_runtime = `python3.9`                 iv_role = lo_create_role_output->get_role( )->get_arn( )                 iv_handler = iv_handler                 io_code = io_initial_zip_file                 iv_description = 'AWS Lambda code example'             ).            MESSAGE 'Lambda function created.' TYPE 'I'.          CATCH /aws1/cx_lmdcodestorageexcdex.            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.        ENDTRY.        \" Verify the function is in Active state \"        WHILE lo_lmd->getfunction( iv_functionname = iv_function_name )->get_configuration( )->ask_state( ) <> 'Active'.          IF sy-index = 10.            EXIT.               \" Maximum 10 seconds. \"          ENDIF.          WAIT UP TO 1 SECONDS.        ENDWHILE.        \"Invoke the function with a single parameter and get results.\"        TRY.            DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(              `{`  &&                `\"action\": \"increment\",`  &&                `\"number\": 10` &&              `}`            ).            DATA(lo_initial_invoke_output) =  lo_lmd->invoke(                       iv_functionname = iv_function_name                       iv_payload = lv_json                   ).            ov_initial_invoke_payload = lo_initial_invoke_output->get_payload( ).           \" ov_initial_invoke_payload is returned for testing purposes. \"            DATA(lo_writer_json) = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).            CALL TRANSFORMATION id SOURCE XML ov_initial_invoke_payload RESULT XML lo_writer_json.            DATA(lv_result) = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).            MESSAGE 'Lambda function invoked.' TYPE 'I'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdinvrequestcontex.            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.          CATCH /aws1/cx_lmdunsuppedmediatyp00.            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.        ENDTRY.        \" Update the function code and configure its Lambda environment with an environment variable. \"        \" Lambda function is updated to perform 'decrement' action also. \"        TRY.            lo_lmd->updatefunctioncode(                  iv_functionname = iv_function_name                  iv_zipfile = io_updated_zip_file              ).            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"            MESSAGE 'Lambda function code updated.' TYPE 'I'.          CATCH /aws1/cx_lmdcodestorageexcdex.            MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.        ENDTRY.        TRY.            DATA lt_variables TYPE /aws1/cl_lmdenvironmentvaria00=>tt_environmentvariables.            DATA ls_variable LIKE LINE OF lt_variables.            ls_variable-key = 'LOG_LEVEL'.            ls_variable-value = NEW /aws1/cl_lmdenvironmentvaria00( iv_value = 'info' ).            INSERT ls_variable INTO TABLE lt_variables.            lo_lmd->updatefunctionconfiguration(                  iv_functionname = iv_function_name                  io_environment = NEW /aws1/cl_lmdenvironment( it_variables = lt_variables )              ).            WAIT UP TO 10 SECONDS.            \" Make sure that the update is completed. \"            MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdresourceconflictex.            MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.        ENDTRY.        \"Invoke the function with new parameters and get results. Display the execution log that's returned from the invocation.\"        TRY.            lv_json = /aws1/cl_rt_util=>string_to_xstring(              `{`  &&                `\"action\": \"decrement\",`  &&                `\"number\": 10` &&              `}`            ).            DATA(lo_updated_invoke_output) =  lo_lmd->invoke(                       iv_functionname = iv_function_name                       iv_payload = lv_json                   ).            ov_updated_invoke_payload = lo_updated_invoke_output->get_payload( ).           \" ov_updated_invoke_payload is returned for testing purposes. \"            lo_writer_json = cl_sxml_string_writer=>create( type = if_sxml=>co_xt_json ).            CALL TRANSFORMATION id SOURCE XML ov_updated_invoke_payload RESULT XML lo_writer_json.            lv_result = cl_abap_codepage=>convert_from( lo_writer_json->get_output( ) ).            MESSAGE 'Lambda function invoked.' TYPE 'I'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdinvrequestcontex.            MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.          CATCH /aws1/cx_lmdunsuppedmediatyp00.            MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.        ENDTRY.        \" List the functions for your account. \"        TRY.            DATA(lo_list_output) = lo_lmd->listfunctions( ).            DATA(lt_functions) = lo_list_output->get_functions( ).            MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.        ENDTRY.        \" Delete the Lambda function. \"        TRY.            lo_lmd->deletefunction( iv_functionname = iv_function_name ).            MESSAGE 'Lambda function deleted.' TYPE 'I'.          CATCH /aws1/cx_lmdinvparamvalueex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_lmdresourcenotfoundex.            MESSAGE 'The requested resource does not exist.' TYPE 'E'.        ENDTRY.        \" Detach role policy. \"        TRY.            lo_iam->detachrolepolicy(                iv_rolename  = iv_role_name                iv_policyarn = 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'            ).            MESSAGE 'Detached policy from the IAM role.' TYPE 'I'.          CATCH /aws1/cx_iaminvalidinputex.            MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.          CATCH /aws1/cx_iamnosuchentityex.            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.          CATCH /aws1/cx_iamplynotattachableex.            MESSAGE 'Service role policies can only be attached to the service-linked role for their service.' TYPE 'E'.          CATCH /aws1/cx_iamunmodableentityex.            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.        ENDTRY.        \" Delete the IAM role. \"        TRY.            lo_iam->deleterole( iv_rolename = iv_role_name ).            MESSAGE 'IAM role deleted.' TYPE 'I'.          CATCH /aws1/cx_iamnosuchentityex.            MESSAGE 'The requested resource entity does not exist.' TYPE 'E'.          CATCH /aws1/cx_iamunmodableentityex.            MESSAGE 'Service that depends on the service-linked role is not modifiable.' TYPE 'E'.        ENDTRY.      CATCH /aws1/cx_rt_service_generic INTO lo_exception.        DATA(lv_error) = lo_exception->get_longtext( ).        MESSAGE lv_error TYPE 'E'.    ENDTRY.For API details, see the following topics in AWS SDK for SAP ABAP API reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfiguration",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\nusing Amazon.Lambda.Model;\n\n/// <summary>\n/// A class that implements AWS Lambda methods.\n/// </summary>\npublic class LambdaWrapper\n{\n    private readonly IAmazonLambda _lambdaService;\n\n    /// <summary>\n    /// Constructor for the LambdaWrapper class.\n    /// </summary>\n    /// <param name=\"lambdaService\">An initialized Lambda service client.</param>\n    public LambdaWrapper(IAmazonLambda lambdaService)\n    {\n        _lambdaService = lambdaService;\n    }\n\n    /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n    /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n    /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n    /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n    /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n    /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n    /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n}\n\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Create methods that perform Lambda actions.namespace LambdaActions;using Amazon.Lambda;using Amazon.Lambda.Model;/// <summary>/// A class that implements AWS Lambda methods./// </summary>public class LambdaWrapper{    private readonly IAmazonLambda _lambdaService;    /// <summary>    /// Constructor for the LambdaWrapper class.    /// </summary>    /// <param name=\"lambdaService\">An initialized Lambda service client.</param>    public LambdaWrapper(IAmazonLambda lambdaService)    {        _lambdaService = lambdaService;    }    /// <summary>    /// Creates a new Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function.</param>    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)    /// bucket where the zip file containing the code is located.</param>    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the    /// appropriate Lambda permissions.</param>    /// <param name=\"handler\">The name of the handler function.</param>    /// <returns>The Amazon Resource Name (ARN) of the newly created    /// Lambda function.</returns>    public async Task<string> CreateLambdaFunctionAsync(        string functionName,        string s3Bucket,        string s3Key,        string role,        string handler)    {        // Defines the location for the function code.        // S3Bucket - The S3 bucket where the file containing        //            the source code is stored.        // S3Key    - The name of the file containing the code.        var functionCode = new FunctionCode        {            S3Bucket = s3Bucket,            S3Key = s3Key,        };        var createFunctionRequest = new CreateFunctionRequest        {            FunctionName = functionName,            Description = \"Created by the Lambda .NET API\",            Code = functionCode,            Handler = handler,            Runtime = Runtime.Dotnet6,            Role = role,        };        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);        return reponse.FunctionArn;    }    /// <summary>    /// Delete an AWS Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// delete.</param>    /// <returns>A Boolean value that indicates the success of the action.</returns>    public async Task<bool> DeleteFunctionAsync(string functionName)    {        var request = new DeleteFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.DeleteFunctionAsync(request);        // A return value of NoContent means that the request was processed.        // In this case, the function was deleted, and the return value        // is intentionally blank.        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;    }    /// <summary>    /// Gets information about a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function for    /// which to retrieve information.</param>    /// <returns>Async Task.</returns>    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)    {        var functionRequest = new GetFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.GetFunctionAsync(functionRequest);        return response.Configuration;    }    /// <summary>    /// Invoke a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// invoke.</param    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>    /// <returns>A System Threading Task.</returns>    public async Task<string> InvokeFunctionAsync(        string functionName,        string parameters)    {        var payload = parameters;        var request = new InvokeRequest        {            FunctionName = functionName,            Payload = payload,        };        var response = await _lambdaService.InvokeAsync(request);        MemoryStream stream = response.Payload;        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());        return returnValue;    }    /// <summary>    /// Get a list of Lambda functions.    /// </summary>    /// <returns>A list of FunctionConfiguration objects.</returns>    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()    {        var functionList = new List<FunctionConfiguration>();        var functionPaginator =            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());        await foreach (var function in functionPaginator.Functions)        {            functionList.Add(function);        }        return functionList;    }    /// <summary>    /// Update an existing Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to update.</param>    /// <param name=\"bucketName\">The bucket where the zip file containing    /// the Lambda function code is stored.</param>    /// <param name=\"key\">The key name of the source code file.</param>    /// <returns>Async Task.</returns>    public async Task UpdateFunctionCodeAsync(        string functionName,        string bucketName,        string key)    {        var functionCodeRequest = new UpdateFunctionCodeRequest        {            FunctionName = functionName,            Publish = true,            S3Bucket = bucketName,            S3Key = key,        };        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");    }    /// <summary>    /// Update the code of a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function to update.</param>    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> UpdateFunctionConfigurationAsync(        string functionName,        string functionHandler,        Dictionary<string, string> environmentVariables)    {        var request = new UpdateFunctionConfigurationRequest        {            Handler = functionHandler,            FunctionName = functionName,            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },        };        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);        Console.WriteLine(response.LastModified);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }}Create a function that runs the scenario.global using System.Threading.Tasks;global using Amazon.IdentityManagement;global using Amazon.Lambda;global using LambdaActions;global using LambdaScenarioCommon;global using Microsoft.Extensions.DependencyInjection;global using Microsoft.Extensions.Hosting;global using Microsoft.Extensions.Logging;global using Microsoft.Extensions.Logging.Console;global using Microsoft.Extensions.Logging.Debug;using Amazon.Lambda.Model;using Microsoft.Extensions.Configuration;namespace LambdaBasics;public class LambdaBasics{    private static ILogger logger = null!;    static async Task Main(string[] args)    {        // Set up dependency injection for the Amazon service.        using var host = Host.CreateDefaultBuilder(args)            .ConfigureLogging(logging =>                logging.AddFilter(\"System\", LogLevel.Debug)                    .AddFilter<DebugLoggerProvider>(\"Microsoft\", LogLevel.Information)                    .AddFilter<ConsoleLoggerProvider>(\"Microsoft\", LogLevel.Trace))            .ConfigureServices((_, services) =>            services.AddAWSService<IAmazonLambda>()            .AddAWSService<IAmazonIdentityManagementService>()            .AddTransient<LambdaWrapper>()            .AddTransient<LambdaRoleWrapper>()            .AddTransient<UIWrapper>()        )        .Build();        var configuration = new ConfigurationBuilder()            .SetBasePath(Directory.GetCurrentDirectory())            .AddJsonFile(\"settings.json\") // Load test settings from .json file.            .AddJsonFile(\"settings.local.json\",            true) // Optionally load local settings.        .Build();        logger = LoggerFactory.Create(builder => { builder.AddConsole(); })            .CreateLogger<LambdaBasics>();        var lambdaWrapper = host.Services.GetRequiredService<LambdaWrapper>();        var lambdaRoleWrapper = host.Services.GetRequiredService<LambdaRoleWrapper>();        var uiWrapper = host.Services.GetRequiredService<UIWrapper>();        string functionName = configuration[\"FunctionName\"]!;        string roleName = configuration[\"RoleName\"]!;        string policyDocument = \"{\" +            \" \\\"Version\\\": \\\"2012-10-17\\\",\" +            \" \\\"Statement\\\": [ \" +            \"    {\" +            \"        \\\"Effect\\\": \\\"Allow\\\",\" +            \"        \\\"Principal\\\": {\" +            \"            \\\"Service\\\": \\\"lambda.amazonaws.com\\\" \" +            \"    },\" +            \"        \\\"Action\\\": \\\"sts:AssumeRole\\\" \" +            \"    }\" +            \"]\" +        \"}\";        var incrementHandler = configuration[\"IncrementHandler\"];        var calculatorHandler = configuration[\"CalculatorHandler\"];        var bucketName = configuration[\"BucketName\"];        var incrementKey = configuration[\"IncrementKey\"];        var calculatorKey = configuration[\"CalculatorKey\"];        var policyArn = configuration[\"PolicyArn\"];        uiWrapper.DisplayLambdaBasicsOverview();        // Create the policy to use with the AWS Lambda functions and then attach the        // policy to a new role.        var roleArn = await lambdaRoleWrapper.CreateLambdaRoleAsync(roleName, policyDocument);        Console.WriteLine(\"Waiting for role to become active.\");        uiWrapper.WaitABit(15, \"Wait until the role is active before trying to use it.\");        // Attach the appropriate AWS Identity and Access Management (IAM) role policy to the new role.        var success = await lambdaRoleWrapper.AttachLambdaRolePolicyAsync(policyArn, roleName);        uiWrapper.WaitABit(10, \"Allow time for the IAM policy to be attached to the role.\");        // Create the Lambda function using a zip file stored in an Amazon Simple Storage Service        // (Amazon S3) bucket.        uiWrapper.DisplayTitle(\"Create Lambda Function\");        Console.WriteLine($\"Creating the AWS Lambda function: {functionName}.\");        var lambdaArn = await lambdaWrapper.CreateLambdaFunctionAsync(            functionName,            bucketName,            incrementKey,            roleArn,            incrementHandler);        Console.WriteLine(\"Waiting for the new function to be available.\");        Console.WriteLine($\"The AWS Lambda ARN is {lambdaArn}\");        // Get the Lambda function.        Console.WriteLine($\"Getting the {functionName} AWS Lambda function.\");        FunctionConfiguration config;        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.State != State.Active);        Console.WriteLine($\"\\nThe function, {functionName} has been created.\");        Console.WriteLine($\"The runtime of this Lambda function is {config.Runtime}.\");        uiWrapper.PressEnter();        // List the Lambda functions.        uiWrapper.DisplayTitle(\"Listing all Lambda functions.\");        var functions = await lambdaWrapper.ListFunctionsAsync();        DisplayFunctionList(functions);        uiWrapper.DisplayTitle(\"Invoke increment function\");        Console.WriteLine(\"Now that it has been created, invoke the Lambda increment function.\");        string? value;        do        {            Console.Write(\"Enter a value to increment: \");            value = Console.ReadLine();        }        while (string.IsNullOrEmpty(value));        string functionParameters = \"{\" +            \"\\\"action\\\": \\\"increment\\\", \" +            \"\\\"x\\\": \\\"\" + value + \"\\\"\" +        \"}\";        var answer = await lambdaWrapper.InvokeFunctionAsync(functionName, functionParameters);        Console.WriteLine($\"{value} + 1 = {answer}.\");        uiWrapper.DisplayTitle(\"Update function\");        Console.WriteLine(\"Now update the Lambda function code.\");        await lambdaWrapper.UpdateFunctionCodeAsync(functionName, bucketName, calculatorKey);        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.LastUpdateStatus == LastUpdateStatus.InProgress);        await lambdaWrapper.UpdateFunctionConfigurationAsync(            functionName,            calculatorHandler,            new Dictionary<string, string> { { \"LOG_LEVEL\", \"DEBUG\" } });        do        {            config = await lambdaWrapper.GetFunctionAsync(functionName);            Console.Write(\".\");        }        while (config.LastUpdateStatus == LastUpdateStatus.InProgress);        uiWrapper.DisplayTitle(\"Call updated function\");        Console.WriteLine(\"Now call the updated function...\");        bool done = false;        do        {            string? opSelected;            Console.WriteLine(\"Select the operation to perform:\");            Console.WriteLine(\"\\t1. add\");            Console.WriteLine(\"\\t2. subtract\");            Console.WriteLine(\"\\t3. multiply\");            Console.WriteLine(\"\\t4. divide\");            Console.WriteLine(\"\\tOr enter \\\"q\\\" to quit.\");            Console.WriteLine(\"Enter the number (1, 2, 3, 4, or q) of the operation you want to perform: \");            do            {                Console.Write(\"Your choice? \");                opSelected = Console.ReadLine();            }            while (opSelected == string.Empty);            var operation = (opSelected) switch            {                \"1\" => \"add\",                \"2\" => \"subtract\",                \"3\" => \"multiply\",                \"4\" => \"divide\",                \"q\" => \"quit\",                _ => \"add\",            };            if (operation == \"quit\")            {                done = true;            }            else            {                // Get two numbers and an action from the user.                value = string.Empty;                do                {                    Console.Write(\"Enter the first value: \");                    value = Console.ReadLine();                }                while (value == string.Empty);                string? value2;                do                {                    Console.Write(\"Enter a second value: \");                    value2 = Console.ReadLine();                }                while (value2 == string.Empty);                functionParameters = \"{\" +                    \"\\\"action\\\": \\\"\" + operation + \"\\\", \" +                    \"\\\"x\\\": \\\"\" + value + \"\\\",\" +                    \"\\\"y\\\": \\\"\" + value2 + \"\\\"\" +                \"}\";                answer = await lambdaWrapper.InvokeFunctionAsync(functionName, functionParameters);                Console.WriteLine($\"The answer when we {operation} the two numbers is: {answer}.\");            }            uiWrapper.PressEnter();        } while (!done);        // Delete the function created earlier.        uiWrapper.DisplayTitle(\"Clean up resources\");        // Detach the IAM policy from the IAM role.        Console.WriteLine(\"First detach the IAM policy from the role.\");        success = await lambdaRoleWrapper.DetachLambdaRolePolicyAsync(policyArn, roleName);        uiWrapper.WaitABit(15, \"Let's wait for the policy to be fully detached from the role.\");        Console.WriteLine(\"Delete the AWS Lambda function.\");        success = await lambdaWrapper.DeleteFunctionAsync(functionName);        if (success)        {            Console.WriteLine($\"The {functionName} function was deleted.\");        }        else        {            Console.WriteLine($\"Could not remove the function {functionName}\");        }        // Now delete the IAM role created for use with the functions        // created by the application.        Console.WriteLine(\"Now we can delete the role that we created.\");        success = await lambdaRoleWrapper.DeleteLambdaRoleAsync(roleName);        if (success)        {            Console.WriteLine(\"The role has been successfully removed.\");        }        else        {            Console.WriteLine(\"Couldn't delete the role.\");        }        Console.WriteLine(\"The Lambda Scenario is now complete.\");        uiWrapper.PressEnter();        // Displays a formatted list of existing functions returned by the        // LambdaMethods.ListFunctions.        void DisplayFunctionList(List<FunctionConfiguration> functions)        {            functions.ForEach(functionConfig =>            {                Console.WriteLine($\"{functionConfig.FunctionName}\\t{functionConfig.Description}\");            });        }    }}namespace LambdaActions;using Amazon.IdentityManagement;using Amazon.IdentityManagement.Model;public class LambdaRoleWrapper{    private readonly IAmazonIdentityManagementService _lambdaRoleService;    public LambdaRoleWrapper(IAmazonIdentityManagementService lambdaRoleService)    {        _lambdaRoleService = lambdaRoleService;    }    /// <summary>    /// Attach an AWS Identity and Access Management (IAM) role policy to the    /// IAM role to be assumed by the AWS Lambda functions created for the scenario.    /// </summary>    /// <param name=\"policyArn\">The Amazon Resource Name (ARN) of the IAM policy.</param>    /// <param name=\"roleName\">The name of the IAM role to attach the IAM policy to.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> AttachLambdaRolePolicyAsync(string policyArn, string roleName)    {        var response = await _lambdaRoleService.AttachRolePolicyAsync(new AttachRolePolicyRequest { PolicyArn = policyArn, RoleName = roleName });        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }    /// <summary>    /// Create a new IAM role.    /// </summary>    /// <param name=\"roleName\">The name of the IAM role to create.</param>    /// <param name=\"policyDocument\">The policy document for the new IAM role.</param>    /// <returns>A string representing the ARN for newly created role.</returns>    public async Task<string> CreateLambdaRoleAsync(string roleName, string policyDocument)    {        var request = new CreateRoleRequest        {            AssumeRolePolicyDocument = policyDocument,            RoleName = roleName,        };        var response = await _lambdaRoleService.CreateRoleAsync(request);        return response.Role.Arn;    }    /// <summary>    /// Deletes an IAM role.    /// </summary>    /// <param name=\"roleName\">The name of the role to delete.</param>    /// <returns>A Boolean value indicating the success of the operation.</returns>    public async Task<bool> DeleteLambdaRoleAsync(string roleName)    {        var request = new DeleteRoleRequest        {            RoleName = roleName,        };        var response = await _lambdaRoleService.DeleteRoleAsync(request);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }    public async Task<bool> DetachLambdaRolePolicyAsync(string policyArn, string roleName)    {        var response = await _lambdaRoleService.DetachRolePolicyAsync(new DetachRolePolicyRequest { PolicyArn = policyArn, RoleName = roleName });        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }}namespace LambdaScenarioCommon;public class UIWrapper{    public readonly string SepBar = new('-', Console.WindowWidth);    /// <summary>    /// Show information about the AWS Lambda Basics scenario.    /// </summary>    public void DisplayLambdaBasicsOverview()    {        Console.Clear();        DisplayTitle(\"Welcome to AWS Lambda Basics\");        Console.WriteLine(\"This example application does the following:\");        Console.WriteLine(\"\\t1. Creates an AWS Identity and Access Management (IAM) role that will be assumed by the functions we create.\");        Console.WriteLine(\"\\t2. Attaches an IAM role policy that has Lambda permissions.\");        Console.WriteLine(\"\\t3. Creates a Lambda function that increments the value passed to it.\");        Console.WriteLine(\"\\t4. Calls the increment function and passes a value.\");        Console.WriteLine(\"\\t5. Updates the code so that the function is a simple calculator.\");        Console.WriteLine(\"\\t6. Calls the calculator function with the values entered.\");        Console.WriteLine(\"\\t7. Deletes the Lambda function.\");        Console.WriteLine(\"\\t7. Detaches the IAM role policy.\");        Console.WriteLine(\"\\t8. Deletes the IAM role.\");        PressEnter();    }    /// <summary>    /// Display a message and wait until the user presses enter.    /// </summary>    public void PressEnter()    {        Console.Write(\"\\nPress <Enter> to continue. \");        _ = Console.ReadLine();        Console.WriteLine();    }    /// <summary>    /// Pad a string with spaces to center it on the console display.    /// </summary>    /// <param name=\"strToCenter\">The string to be centered.</param>    /// <returns>The padded string.</returns>    public string CenterString(string strToCenter)    {        var padAmount = (Console.WindowWidth - strToCenter.Length) / 2;        var leftPad = new string(' ', padAmount);        return $\"{leftPad}{strToCenter}\";    }    /// <summary>    /// Display a line of hyphens, the centered text of the title and another    /// line of hyphens.    /// </summary>    /// <param name=\"strTitle\">The string to be displayed.</param>    public void DisplayTitle(string strTitle)    {        Console.WriteLine(SepBar);        Console.WriteLine(CenterString(strTitle));        Console.WriteLine(SepBar);    }    /// <summary>    /// Display a countdown and wait for a number of seconds.    /// </summary>    /// <param name=\"numSeconds\">The number of seconds to wait.</param>    public void WaitABit(int numSeconds, string msg)    {        Console.WriteLine(msg);        // Wait for the requested number of seconds.        for (int i = numSeconds; i > 0; i--)        {            System.Threading.Thread.Sleep(1000);            Console.Write($\"{i}...\");        }        PressEnter();    }}Define a Lambda handler that increments a number.using Amazon.Lambda.Core;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaIncrement;public class Function{    /// <summary>    /// A simple function increments the integer parameter.    /// </summary>    /// <param name=\"input\">A JSON string containing an action, which must be    /// \"increment\" and a string representing the value to increment.</param>    /// <param name=\"context\">The context object passed by Lambda containing    /// information about invocation, function, and execution environment.</param>    /// <returns>A string representing the incremented value of the parameter.</returns>    public int FunctionHandler(Dictionary<string, string> input, ILambdaContext context)    {        if (input[\"action\"] == \"increment\")        {            int inputValue = Convert.ToInt32(input[\"x\"]);            return inputValue + 1;        }        else        {            return 0;        }    }}Define a second Lambda handler that performs arithmetic operations.using Amazon.Lambda.Core;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaCalculator;public class Function{    /// <summary>    /// A simple function that takes two number in string format and performs    /// the requested arithmetic function.    /// </summary>    /// <param name=\"input\">JSON data containing an action, and x and y values.    /// Valid actions include: add, subtract, multiply, and divide.</param>    /// <param name=\"context\">The context object passed by Lambda containing    /// information about invocation, function, and execution environment.</param>    /// <returns>A string representing the results of the calculation.</returns>    public int FunctionHandler(Dictionary<string, string> input, ILambdaContext context)    {        var action = input[\"action\"];        int x = Convert.ToInt32(input[\"x\"]);        int y = Convert.ToInt32(input[\"y\"]);        int result;        switch (action)        {            case \"add\":                result = x + y;                break;            case \"subtract\":                result = x - y;                break;            case \"multiply\":                result = x * y;                break;            case \"divide\":                if (y == 0)                {                    Console.Error.WriteLine(\"Divide by zero error.\");                    result = 0;                }                else                    result = x / y;                break;            default:                Console.Error.WriteLine($\"{action} is not a valid operation.\");                result = 0;                break;        }        return result;    }}For API details, see the following topics in AWS SDK for .NET API Reference.CreateFunctionDeleteFunctionGetFunctionInvokeListFunctionsUpdateFunctionCodeUpdateFunctionConfiguration",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Actions",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/service_code_examples_actions.html",
                        "contents": [
                            {
                                "title": "CreateAlias",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_CreateAlias_section.html",
                                "sections": [
                                    "The following code examples show how to use CreateAlias.",
                                    "  1.CLI : create-alias",
                                    "  2.AWS CLI : create-alias",
                                    "  3.PowerShell : New-LMAlias -FunctionName \"MylambdaFunction123\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6} -Description \"Alias for version 4\" -FunctionVersion 4 -Name \"PowershellAlias\"\n",
                                    "  4.Tools for PowerShell : New-LMAlias -FunctionName \"MylambdaFunction123\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6} -Description \"Alias for version 4\" -FunctionVersion 4 -Name \"PowershellAlias\"\n",
                                    "CLIAWS CLITo create an alias for a Lambda functionThe following create-alias example creates an alias named LIVE that points to version 1 of the my-function Lambda function.aws lambda create-alias \\    --function-name my-function \\    --description \"alias for live version of function\" \\    --function-version 1 \\    --name LIVEOutput:{    \"FunctionVersion\": \"1\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"873282ed-4cd3-4dc8-a069-d0c647e470c6\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        CreateAlias                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example creates a New Lambda Alias for specified version and routing configuration to specify the percentage of invocation requests that it receives.New-LMAlias -FunctionName \"MylambdaFunction123\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6} -Description \"Alias for version 4\" -FunctionVersion 4 -Name \"PowershellAlias\"                        For API details, see                        CreateAlias                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : create-alias",
                                    "AWS CLITo create an alias for a Lambda functionThe following create-alias example creates an alias named LIVE that points to version 1 of the my-function Lambda function.aws lambda create-alias \\    --function-name my-function \\    --description \"alias for live version of function\" \\    --function-version 1 \\    --name LIVEOutput:{    \"FunctionVersion\": \"1\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"873282ed-4cd3-4dc8-a069-d0c647e470c6\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        CreateAlias                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "CreateFunction",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_CreateFunction_section.html",
                                "sections": [
                                    "The following code examples show how to use CreateFunction.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::CreateFunctionRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.\n#if USE_CPP_LAMBDA_FUNCTION\n        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);\n        request.SetTimeout(15);\n        request.SetMemorySize(128);\n\n        // Assume the AWS Lambda function was built in Docker with same architecture\n        // as this code.\n#if  defined(__x86_64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});\n#elif defined(__aarch64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});\n#else\n#error \"Unimplemented architecture\"\n#endif // defined(architecture)\n#else\n        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);\n#endif\n        request.SetRole(roleArn);\n        request.SetHandler(LAMBDA_HANDLER_NAME);\n        request.SetPublish(true);\n        Aws::Lambda::Model::FunctionCode code;\n        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n\n        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                               buffer.str().length()));\n        request.SetCode(code);\n\n        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda function was successfully created. \" << seconds\n                      << \" seconds elapsed.\" << std::endl;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with CreateFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::CreateFunctionRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.\n#if USE_CPP_LAMBDA_FUNCTION\n        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);\n        request.SetTimeout(15);\n        request.SetMemorySize(128);\n\n        // Assume the AWS Lambda function was built in Docker with same architecture\n        // as this code.\n#if  defined(__x86_64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});\n#elif defined(__aarch64__)\n        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});\n#else\n#error \"Unimplemented architecture\"\n#endif // defined(architecture)\n#else\n        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);\n#endif\n        request.SetRole(roleArn);\n        request.SetHandler(LAMBDA_HANDLER_NAME);\n        request.SetPublish(true);\n        Aws::Lambda::Model::FunctionCode code;\n        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n\n        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                               buffer.str().length()));\n        request.SetCode(code);\n\n        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda function was successfully created. \" << seconds\n                      << \" seconds elapsed.\" << std::endl;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with CreateFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n",
                                    "  5.CLI : create-function",
                                    "  6.AWS CLI : create-function",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// CreateFunction creates a new Lambda function from code contained in the zipPackage\n// buffer. The specified handlerName must match the name of the file and function\n// contained in the uploaded code. The role specified by iamRoleArn is assumed by\n// Lambda and grants specific permissions.\n// When the function already exists, types.StateActive is returned.\n// When the function is created, a lambda.FunctionActiveV2Waiter is used to wait until the\n// function is active.\nfunc (wrapper FunctionWrapper) CreateFunction(ctx context.Context, functionName string, handlerName string,\n\tiamRoleArn *string, zipPackage *bytes.Buffer) types.State {\n\tvar state types.State\n\t_, err := wrapper.LambdaClient.CreateFunction(ctx, &lambda.CreateFunctionInput{\n\t\tCode:         &types.FunctionCode{ZipFile: zipPackage.Bytes()},\n\t\tFunctionName: aws.String(functionName),\n\t\tRole:         iamRoleArn,\n\t\tHandler:      aws.String(handlerName),\n\t\tPublish:      true,\n\t\tRuntime:      types.RuntimePython39,\n\t})\n\tif err != nil {\n\t\tvar resConflict *types.ResourceConflictException\n\t\tif errors.As(err, &resConflict) {\n\t\t\tlog.Printf(\"Function %v already exists.\\n\", functionName)\n\t\t\tstate = types.StateActive\n\t\t} else {\n\t\t\tlog.Panicf(\"Couldn't create function %v. Here's why: %v\\n\", functionName, err)\n\t\t}\n\t} else {\n\t\twaiter := lambda.NewFunctionActiveV2Waiter(wrapper.LambdaClient)\n\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\n\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\n\t\t} else {\n\t\t\tstate = funcOutput.Configuration.State\n\t\t}\n\t}\n\treturn state\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// CreateFunction creates a new Lambda function from code contained in the zipPackage\n// buffer. The specified handlerName must match the name of the file and function\n// contained in the uploaded code. The role specified by iamRoleArn is assumed by\n// Lambda and grants specific permissions.\n// When the function already exists, types.StateActive is returned.\n// When the function is created, a lambda.FunctionActiveV2Waiter is used to wait until the\n// function is active.\nfunc (wrapper FunctionWrapper) CreateFunction(ctx context.Context, functionName string, handlerName string,\n\tiamRoleArn *string, zipPackage *bytes.Buffer) types.State {\n\tvar state types.State\n\t_, err := wrapper.LambdaClient.CreateFunction(ctx, &lambda.CreateFunctionInput{\n\t\tCode:         &types.FunctionCode{ZipFile: zipPackage.Bytes()},\n\t\tFunctionName: aws.String(functionName),\n\t\tRole:         iamRoleArn,\n\t\tHandler:      aws.String(handlerName),\n\t\tPublish:      true,\n\t\tRuntime:      types.RuntimePython39,\n\t})\n\tif err != nil {\n\t\tvar resConflict *types.ResourceConflictException\n\t\tif errors.As(err, &resConflict) {\n\t\t\tlog.Printf(\"Function %v already exists.\\n\", functionName)\n\t\t\tstate = types.StateActive\n\t\t} else {\n\t\t\tlog.Panicf(\"Couldn't create function %v. Here's why: %v\\n\", functionName, err)\n\t\t}\n\t} else {\n\t\twaiter := lambda.NewFunctionActiveV2Waiter(wrapper.LambdaClient)\n\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\n\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\n\t\t} else {\n\t\t\tstate = funcOutput.Configuration.State\n\t\t}\n\t}\n\treturn state\n}\n\n\n",
                                    "  9.Java :     /**\n     * Creates a new Lambda function in AWS using the AWS Lambda Java API.\n     *\n     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service\n     * @param functionName the name of the Lambda function to create\n     * @param key          the S3 key of the function code\n     * @param bucketName   the name of the S3 bucket containing the function code\n     * @param role         the IAM role to assign to the Lambda function\n     * @param handler      the fully qualified class name of the function handler\n     * @return the Amazon Resource Name (ARN) of the created Lambda function\n     */\n    public static String createLambdaFunction(LambdaClient awsLambda,\n                                              String functionName,\n                                              String key,\n                                              String bucketName,\n                                              String role,\n                                              String handler) {\n\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            FunctionCode code = FunctionCode.builder()\n                .s3Key(key)\n                .s3Bucket(bucketName)\n                .build();\n\n            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()\n                .functionName(functionName)\n                .description(\"Created by the Lambda Java API\")\n                .code(code)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .role(role)\n                .build();\n\n            // Create a Lambda function using a waiter\n            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);\n            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            return functionResponse.functionArn();\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n        return \"\";\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Creates a new Lambda function in AWS using the AWS Lambda Java API.\n     *\n     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service\n     * @param functionName the name of the Lambda function to create\n     * @param key          the S3 key of the function code\n     * @param bucketName   the name of the S3 bucket containing the function code\n     * @param role         the IAM role to assign to the Lambda function\n     * @param handler      the fully qualified class name of the function handler\n     * @return the Amazon Resource Name (ARN) of the created Lambda function\n     */\n    public static String createLambdaFunction(LambdaClient awsLambda,\n                                              String functionName,\n                                              String key,\n                                              String bucketName,\n                                              String role,\n                                              String handler) {\n\n        try {\n            LambdaWaiter waiter = awsLambda.waiter();\n            FunctionCode code = FunctionCode.builder()\n                .s3Key(key)\n                .s3Bucket(bucketName)\n                .build();\n\n            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()\n                .functionName(functionName)\n                .description(\"Created by the Lambda Java API\")\n                .code(code)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .role(role)\n                .build();\n\n            // Create a Lambda function using a waiter\n            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);\n            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);\n            waiterResponse.matched().response().ifPresent(System.out::println);\n            return functionResponse.functionArn();\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n        return \"\";\n    }\n\n",
                                    "  11.JavaScript : const createFunction = async (funcName, roleArn) => {\n  const client = new LambdaClient({});\n  const code = await readFile(`${dirname}../functions/${funcName}.zip`);\n\n  const command = new CreateFunctionCommand({\n    Code: { ZipFile: code },\n    FunctionName: funcName,\n    Role: roleArn,\n    Architectures: [Architecture.arm64],\n    Handler: \"index.handler\", // Required when sending a .zip file\n    PackageType: PackageType.Zip, // Required when sending a .zip file\n    Runtime: Runtime.nodejs16x, // Required when sending a .zip file\n  });\n\n  return client.send(command);\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : const createFunction = async (funcName, roleArn) => {\n  const client = new LambdaClient({});\n  const code = await readFile(`${dirname}../functions/${funcName}.zip`);\n\n  const command = new CreateFunctionCommand({\n    Code: { ZipFile: code },\n    FunctionName: funcName,\n    Role: roleArn,\n    Architectures: [Architecture.arm64],\n    Handler: \"index.handler\", // Required when sending a .zip file\n    PackageType: PackageType.Zip, // Required when sending a .zip file\n    Runtime: Runtime.nodejs16x, // Required when sending a .zip file\n  });\n\n  return client.send(command);\n};\n\n",
                                    "  13.Kotlin : suspend fun createNewFunction(\n    myFunctionName: String,\n    s3BucketName: String,\n    myS3Key: String,\n    myHandler: String,\n    myRole: String,\n): String? {\n    val functionCode =\n        FunctionCode {\n            s3Bucket = s3BucketName\n            s3Key = myS3Key\n        }\n\n    val request =\n        CreateFunctionRequest {\n            functionName = myFunctionName\n            code = functionCode\n            description = \"Created by the Lambda Kotlin API\"\n            handler = myHandler\n            role = myRole\n            runtime = Runtime.Java8\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val functionResponse = awsLambda.createFunction(request)\n        awsLambda.waitUntilFunctionActive {\n            functionName = myFunctionName\n        }\n        return functionResponse.functionArn\n    }\n}\n\n",
                                    "  14.SDK for Kotlin : suspend fun createNewFunction(\n    myFunctionName: String,\n    s3BucketName: String,\n    myS3Key: String,\n    myHandler: String,\n    myRole: String,\n): String? {\n    val functionCode =\n        FunctionCode {\n            s3Bucket = s3BucketName\n            s3Key = myS3Key\n        }\n\n    val request =\n        CreateFunctionRequest {\n            functionName = myFunctionName\n            code = functionCode\n            description = \"Created by the Lambda Kotlin API\"\n            handler = myHandler\n            role = myRole\n            runtime = Runtime.Java8\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val functionResponse = awsLambda.createFunction(request)\n        awsLambda.waitUntilFunctionActive {\n            functionName = myFunctionName\n        }\n        return functionResponse.functionArn\n    }\n}\n\n",
                                    "  15.PHP :     public function createFunction($functionName, $role, $bucketName, $handler)\n    {\n        //This assumes the Lambda function is in an S3 bucket.\n        return $this->customWaiter(function () use ($functionName, $role, $bucketName, $handler) {\n            return $this->lambdaClient->createFunction([\n                'Code' => [\n                    'S3Bucket' => $bucketName,\n                    'S3Key' => $functionName,\n                ],\n                'FunctionName' => $functionName,\n                'Role' => $role['Arn'],\n                'Runtime' => 'python3.9',\n                'Handler' => \"$handler.lambda_handler\",\n            ]);\n        });\n    }\n\n",
                                    "  16.SDK for PHP :     public function createFunction($functionName, $role, $bucketName, $handler)\n    {\n        //This assumes the Lambda function is in an S3 bucket.\n        return $this->customWaiter(function () use ($functionName, $role, $bucketName, $handler) {\n            return $this->lambdaClient->createFunction([\n                'Code' => [\n                    'S3Bucket' => $bucketName,\n                    'S3Key' => $functionName,\n                ],\n                'FunctionName' => $functionName,\n                'Role' => $role['Arn'],\n                'Runtime' => 'python3.9',\n                'Handler' => \"$handler.lambda_handler\",\n            ]);\n        });\n    }\n\n",
                                    "  17.PowerShell : Publish-LMFunction -Description \"My C# Lambda Function\" `\n        -FunctionName MyFunction `\n        -ZipFilename .\\MyFunctionBinaries.zip `\n        -Handler \"AssemblyName::Namespace.ClassName::MethodName\" `\n        -Role \"arn:aws:iam::123456789012:role/LambdaFullExecRole\" `\n        -Runtime dotnetcore1.0 `\n        -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" }\n",
                                    "  18.Tools for PowerShell : Publish-LMFunction -Description \"My C# Lambda Function\" `\n        -FunctionName MyFunction `\n        -ZipFilename .\\MyFunctionBinaries.zip `\n        -Handler \"AssemblyName::Namespace.ClassName::MethodName\" `\n        -Role \"arn:aws:iam::123456789012:role/LambdaFullExecRole\" `\n        -Runtime dotnetcore1.0 `\n        -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" }\n",
                                    "  19.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def create_function(\n        self, function_name, handler_name, iam_role, deployment_package\n    ):\n        \"\"\"\n        Deploys a Lambda function.\n\n        :param function_name: The name of the Lambda function.\n        :param handler_name: The fully qualified name of the handler function. This\n                             must include the file name and the function name.\n        :param iam_role: The IAM role to use for the function.\n        :param deployment_package: The deployment package that contains the function\n                                   code in .zip format.\n        :return: The Amazon Resource Name (ARN) of the newly created function.\n        \"\"\"\n        try:\n            response = self.lambda_client.create_function(\n                FunctionName=function_name,\n                Description=\"AWS Lambda doc example\",\n                Runtime=\"python3.9\",\n                Role=iam_role.arn,\n                Handler=handler_name,\n                Code={\"ZipFile\": deployment_package},\n                Publish=True,\n            )\n            function_arn = response[\"FunctionArn\"]\n            waiter = self.lambda_client.get_waiter(\"function_active_v2\")\n            waiter.wait(FunctionName=function_name)\n            logger.info(\n                \"Created function '%s' with ARN: '%s'.\",\n                function_name,\n                response[\"FunctionArn\"],\n            )\n        except ClientError:\n            logger.error(\"Couldn't create function %s.\", function_name)\n            raise\n        else:\n            return function_arn\n\n\n",
                                    "  20.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def create_function(\n        self, function_name, handler_name, iam_role, deployment_package\n    ):\n        \"\"\"\n        Deploys a Lambda function.\n\n        :param function_name: The name of the Lambda function.\n        :param handler_name: The fully qualified name of the handler function. This\n                             must include the file name and the function name.\n        :param iam_role: The IAM role to use for the function.\n        :param deployment_package: The deployment package that contains the function\n                                   code in .zip format.\n        :return: The Amazon Resource Name (ARN) of the newly created function.\n        \"\"\"\n        try:\n            response = self.lambda_client.create_function(\n                FunctionName=function_name,\n                Description=\"AWS Lambda doc example\",\n                Runtime=\"python3.9\",\n                Role=iam_role.arn,\n                Handler=handler_name,\n                Code={\"ZipFile\": deployment_package},\n                Publish=True,\n            )\n            function_arn = response[\"FunctionArn\"]\n            waiter = self.lambda_client.get_waiter(\"function_active_v2\")\n            waiter.wait(FunctionName=function_name)\n            logger.info(\n                \"Created function '%s' with ARN: '%s'.\",\n                function_name,\n                response[\"FunctionArn\"],\n            )\n        except ClientError:\n            logger.error(\"Couldn't create function %s.\", function_name)\n            raise\n        else:\n            return function_arn\n\n\n",
                                    "  21.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Deploys a Lambda function.\n  #\n  # @param function_name: The name of the Lambda function.\n  # @param handler_name: The fully qualified name of the handler function.\n  # @param role_arn: The IAM role to use for the function.\n  # @param deployment_package: The deployment package that contains the function code in .zip format.\n  # @return: The Amazon Resource Name (ARN) of the newly created function.\n  def create_function(function_name, handler_name, role_arn, deployment_package)\n    response = @lambda_client.create_function({\n                                                role: role_arn.to_s,\n                                                function_name: function_name,\n                                                handler: handler_name,\n                                                runtime: 'ruby2.7',\n                                                code: {\n                                                  zip_file: deployment_package\n                                                },\n                                                environment: {\n                                                  variables: {\n                                                    'LOG_LEVEL' => 'info'\n                                                  }\n                                                }\n                                              })\n    @lambda_client.wait_until(:function_active_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n    response\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error creating #{function_name}:\\n #{e.message}\")\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")\n  end\n\n",
                                    "  22.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Deploys a Lambda function.\n  #\n  # @param function_name: The name of the Lambda function.\n  # @param handler_name: The fully qualified name of the handler function.\n  # @param role_arn: The IAM role to use for the function.\n  # @param deployment_package: The deployment package that contains the function code in .zip format.\n  # @return: The Amazon Resource Name (ARN) of the newly created function.\n  def create_function(function_name, handler_name, role_arn, deployment_package)\n    response = @lambda_client.create_function({\n                                                role: role_arn.to_s,\n                                                function_name: function_name,\n                                                handler: handler_name,\n                                                runtime: 'ruby2.7',\n                                                code: {\n                                                  zip_file: deployment_package\n                                                },\n                                                environment: {\n                                                  variables: {\n                                                    'LOG_LEVEL' => 'info'\n                                                  }\n                                                }\n                                              })\n    @lambda_client.wait_until(:function_active_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n    response\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error creating #{function_name}:\\n #{e.message}\")\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")\n  end\n\n",
                                    "  23.Rust :     /**\n     * Create a function, uploading from a zip file.\n     */\n    pub async fn create_function(&self, zip_file: PathBuf) -> Result<String, anyhow::Error> {\n        let code = self.prepare_function(zip_file, None).await?;\n\n        let key = code.s3_key().unwrap().to_string();\n\n        let role = self.create_role().await.map_err(|e| anyhow!(e))?;\n\n        info!(\"Created iam role, waiting 15s for it to become active\");\n        tokio::time::sleep(Duration::from_secs(15)).await;\n\n        info!(\"Creating lambda function {}\", self.lambda_name);\n        let _ = self\n            .lambda_client\n            .create_function()\n            .function_name(self.lambda_name.clone())\n            .code(code)\n            .role(role.arn())\n            .runtime(aws_sdk_lambda::types::Runtime::Providedal2)\n            .handler(\"_unused\")\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        self.lambda_client\n            .publish_version()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await?;\n\n        Ok(key)\n    }\n\n    /**\n     * Upload function code from a path to a zip file.\n     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.\n     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.\n     */\n    async fn prepare_function(\n        &self,\n        zip_file: PathBuf,\n        key: Option<String>,\n    ) -> Result<FunctionCode, anyhow::Error> {\n        let body = ByteStream::from_path(zip_file).await?;\n\n        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));\n\n        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);\n        let _ = self\n            .s3_client\n            .put_object()\n            .bucket(self.bucket.clone())\n            .key(key.clone())\n            .body(body)\n            .send()\n            .await?;\n\n        Ok(FunctionCode::builder()\n            .s3_bucket(self.bucket.clone())\n            .s3_key(key)\n            .build())\n    }\n\n",
                                    "  24.SDK for Rust :     /**\n     * Create a function, uploading from a zip file.\n     */\n    pub async fn create_function(&self, zip_file: PathBuf) -> Result<String, anyhow::Error> {\n        let code = self.prepare_function(zip_file, None).await?;\n\n        let key = code.s3_key().unwrap().to_string();\n\n        let role = self.create_role().await.map_err(|e| anyhow!(e))?;\n\n        info!(\"Created iam role, waiting 15s for it to become active\");\n        tokio::time::sleep(Duration::from_secs(15)).await;\n\n        info!(\"Creating lambda function {}\", self.lambda_name);\n        let _ = self\n            .lambda_client\n            .create_function()\n            .function_name(self.lambda_name.clone())\n            .code(code)\n            .role(role.arn())\n            .runtime(aws_sdk_lambda::types::Runtime::Providedal2)\n            .handler(\"_unused\")\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        self.lambda_client\n            .publish_version()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await?;\n\n        Ok(key)\n    }\n\n    /**\n     * Upload function code from a path to a zip file.\n     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.\n     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.\n     */\n    async fn prepare_function(\n        &self,\n        zip_file: PathBuf,\n        key: Option<String>,\n    ) -> Result<FunctionCode, anyhow::Error> {\n        let body = ByteStream::from_path(zip_file).await?;\n\n        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));\n\n        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);\n        let _ = self\n            .s3_client\n            .put_object()\n            .bucket(self.bucket.clone())\n            .key(key.clone())\n            .body(body)\n            .send()\n            .await?;\n\n        Ok(FunctionCode::builder()\n            .s3_bucket(self.bucket.clone())\n            .s3_key(key)\n            .build())\n    }\n\n",
                                    "  25.SAP ABAP :     TRY.\n        lo_lmd->createfunction(\n            iv_functionname = iv_function_name\n            iv_runtime = `python3.9`\n            iv_role = iv_role_arn\n            iv_handler = iv_handler\n            io_code = io_zip_file\n            iv_description = 'AWS Lambda code example'\n        ).\n        MESSAGE 'Lambda function created.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodestorageexcdex.\n        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  26.SDK for SAP ABAP :     TRY.\n        lo_lmd->createfunction(\n            iv_functionname = iv_function_name\n            iv_runtime = `python3.9`\n            iv_role = iv_role_arn\n            iv_handler = iv_handler\n            io_code = io_zip_file\n            iv_description = 'AWS Lambda code example'\n        ).\n        MESSAGE 'Lambda function created.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodestorageexcdex.\n        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Creates a new Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function.</param>    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)    /// bucket where the zip file containing the code is located.</param>    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the    /// appropriate Lambda permissions.</param>    /// <param name=\"handler\">The name of the handler function.</param>    /// <returns>The Amazon Resource Name (ARN) of the newly created    /// Lambda function.</returns>    public async Task<string> CreateLambdaFunctionAsync(        string functionName,        string s3Bucket,        string s3Key,        string role,        string handler)    {        // Defines the location for the function code.        // S3Bucket - The S3 bucket where the file containing        //            the source code is stored.        // S3Key    - The name of the file containing the code.        var functionCode = new FunctionCode        {            S3Bucket = s3Bucket,            S3Key = s3Key,        };        var createFunctionRequest = new CreateFunctionRequest        {            FunctionName = functionName,            Description = \"Created by the Lambda .NET API\",            Code = functionCode,            Handler = handler,            Runtime = Runtime.Dotnet6,            Role = role,        };        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);        return reponse.FunctionArn;    }                        For API details, see                        CreateFunction                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);        Aws::Lambda::Model::CreateFunctionRequest request;        request.SetFunctionName(LAMBDA_NAME);        request.SetDescription(LAMBDA_DESCRIPTION); // Optional.#if USE_CPP_LAMBDA_FUNCTION        request.SetRuntime(Aws::Lambda::Model::Runtime::provided_al2);        request.SetTimeout(15);        request.SetMemorySize(128);        // Assume the AWS Lambda function was built in Docker with same architecture        // as this code.#if  defined(__x86_64__)        request.SetArchitectures({Aws::Lambda::Model::Architecture::x86_64});#elif defined(__aarch64__)        request.SetArchitectures({Aws::Lambda::Model::Architecture::arm64});#else#error \"Unimplemented architecture\"#endif // defined(architecture)#else        request.SetRuntime(Aws::Lambda::Model::Runtime::python3_9);#endif        request.SetRole(roleArn);        request.SetHandler(LAMBDA_HANDLER_NAME);        request.SetPublish(true);        Aws::Lambda::Model::FunctionCode code;        std::ifstream ifstream(INCREMENT_LAMBDA_CODE.c_str(),                               std::ios_base::in | std::ios_base::binary);        if (!ifstream.is_open()) {            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;#if USE_CPP_LAMBDA_FUNCTION            std::cerr                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"                    << std::endl;#endif            deleteIamRole(clientConfig);            return false;        }        Aws::StringStream buffer;        buffer << ifstream.rdbuf();        code.SetZipFile(Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),                                               buffer.str().length()));        request.SetCode(code);        Aws::Lambda::Model::CreateFunctionOutcome outcome = client.CreateFunction(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda function was successfully created. \" << seconds                      << \" seconds elapsed.\" << std::endl;            break;        }        else {            std::cerr << \"Error with CreateFunction. \"                      << outcome.GetError().GetMessage()                      << std::endl;            deleteIamRole(clientConfig);            return false;        }                        For API details, see                        CreateFunction                        in AWS SDK for C++ API Reference.                    CLIAWS CLITo create a Lambda functionThe following create-function example creates a Lambda function named my-function.aws lambda create-function \\    --function-name my-function \\    --runtime nodejs18.x \\    --zip-file fileb://my-function.zip \\    --handler my-function.handler \\    --role arn:aws:iam::123456789012:role/service-role/MyTestFunction-role-tges6bf4Contents of my-function.zip:This file is a deployment package that contains your function code and any dependencies.Output:{    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"PFn4S+er27qk+UuZSTKEQfNKG/XNn7QJs90mJgq6oH8=\",    \"FunctionName\": \"my-function\",    \"CodeSize\": 308,    \"RevisionId\": \"873282ed-4cd3-4dc8-a069-d0c647e470c6\",    \"MemorySize\": 128,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"Version\": \"$LATEST\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/MyTestFunction-role-zgur6bf4\",    \"Timeout\": 3,    \"LastModified\": \"2023-10-14T22:26:11.234+0000\",    \"Handler\": \"my-function.handler\",    \"Runtime\": \"nodejs18.x\",    \"Description\": \"\"}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        CreateFunction                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// CreateFunction creates a new Lambda function from code contained in the zipPackage// buffer. The specified handlerName must match the name of the file and function// contained in the uploaded code. The role specified by iamRoleArn is assumed by// Lambda and grants specific permissions.// When the function already exists, types.StateActive is returned.// When the function is created, a lambda.FunctionActiveV2Waiter is used to wait until the// function is active.func (wrapper FunctionWrapper) CreateFunction(ctx context.Context, functionName string, handlerName string,\tiamRoleArn *string, zipPackage *bytes.Buffer) types.State {\tvar state types.State\t_, err := wrapper.LambdaClient.CreateFunction(ctx, &lambda.CreateFunctionInput{\t\tCode:         &types.FunctionCode{ZipFile: zipPackage.Bytes()},\t\tFunctionName: aws.String(functionName),\t\tRole:         iamRoleArn,\t\tHandler:      aws.String(handlerName),\t\tPublish:      true,\t\tRuntime:      types.RuntimePython39,\t})\tif err != nil {\t\tvar resConflict *types.ResourceConflictException\t\tif errors.As(err, &resConflict) {\t\t\tlog.Printf(\"Function %v already exists.\\n\", functionName)\t\t\tstate = types.StateActive\t\t} else {\t\t\tlog.Panicf(\"Couldn't create function %v. Here's why: %v\\n\", functionName, err)\t\t}\t} else {\t\twaiter := lambda.NewFunctionActiveV2Waiter(wrapper.LambdaClient)\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\t\t} else {\t\t\tstate = funcOutput.Configuration.State\t\t}\t}\treturn state}                        For API details, see                        CreateFunction                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Creates a new Lambda function in AWS using the AWS Lambda Java API.     *     * @param awsLambda    the AWS Lambda client used to interact with the AWS Lambda service     * @param functionName the name of the Lambda function to create     * @param key          the S3 key of the function code     * @param bucketName   the name of the S3 bucket containing the function code     * @param role         the IAM role to assign to the Lambda function     * @param handler      the fully qualified class name of the function handler     * @return the Amazon Resource Name (ARN) of the created Lambda function     */    public static String createLambdaFunction(LambdaClient awsLambda,                                              String functionName,                                              String key,                                              String bucketName,                                              String role,                                              String handler) {        try {            LambdaWaiter waiter = awsLambda.waiter();            FunctionCode code = FunctionCode.builder()                .s3Key(key)                .s3Bucket(bucketName)                .build();            CreateFunctionRequest functionRequest = CreateFunctionRequest.builder()                .functionName(functionName)                .description(\"Created by the Lambda Java API\")                .code(code)                .handler(handler)                .runtime(Runtime.JAVA17)                .role(role)                .build();            // Create a Lambda function using a waiter            CreateFunctionResponse functionResponse = awsLambda.createFunction(functionRequest);            GetFunctionRequest getFunctionRequest = GetFunctionRequest.builder()                .functionName(functionName)                .build();            WaiterResponse<GetFunctionResponse> waiterResponse = waiter.waitUntilFunctionExists(getFunctionRequest);            waiterResponse.matched().response().ifPresent(System.out::println);            return functionResponse.functionArn();        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }        return \"\";    }                        For API details, see                        CreateFunction                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const createFunction = async (funcName, roleArn) => {  const client = new LambdaClient({});  const code = await readFile(`${dirname}../functions/${funcName}.zip`);  const command = new CreateFunctionCommand({    Code: { ZipFile: code },    FunctionName: funcName,    Role: roleArn,    Architectures: [Architecture.arm64],    Handler: \"index.handler\", // Required when sending a .zip file    PackageType: PackageType.Zip, // Required when sending a .zip file    Runtime: Runtime.nodejs16x, // Required when sending a .zip file  });  return client.send(command);};                        For API details, see                        CreateFunction                        in AWS SDK for JavaScript API Reference.                    KotlinSDK for KotlinNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    suspend fun createNewFunction(    myFunctionName: String,    s3BucketName: String,    myS3Key: String,    myHandler: String,    myRole: String,): String? {    val functionCode =        FunctionCode {            s3Bucket = s3BucketName            s3Key = myS3Key        }    val request =        CreateFunctionRequest {            functionName = myFunctionName            code = functionCode            description = \"Created by the Lambda Kotlin API\"            handler = myHandler            role = myRole            runtime = Runtime.Java8        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val functionResponse = awsLambda.createFunction(request)        awsLambda.waitUntilFunctionActive {            functionName = myFunctionName        }        return functionResponse.functionArn    }}                        For API details, see                        CreateFunction                        in AWS SDK for Kotlin API reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function createFunction($functionName, $role, $bucketName, $handler)    {        //This assumes the Lambda function is in an S3 bucket.        return $this->customWaiter(function () use ($functionName, $role, $bucketName, $handler) {            return $this->lambdaClient->createFunction([                'Code' => [                    'S3Bucket' => $bucketName,                    'S3Key' => $functionName,                ],                'FunctionName' => $functionName,                'Role' => $role['Arn'],                'Runtime' => 'python3.9',                'Handler' => \"$handler.lambda_handler\",            ]);        });    }                        For API details, see                        CreateFunction                        in AWS SDK for PHP API Reference.                    PowerShellTools for PowerShellExample 1: This example creates a new C# (dotnetcore1.0 runtime) function named MyFunction in AWS Lambda, providing the compiled binaries for the function from a zip file on the local file system (relative or absolute paths may be used). C# Lambda functions specify the handler for the function using the designation AssemblyName::Namespace.ClassName::MethodName. You should replace the assembly name (without .dll suffix), namespace, class name and method name parts of the handler spec appropriately. The new function will have environment variables 'envvar1' and 'envvar2' set up from the provided values.Publish-LMFunction -Description \"My C# Lambda Function\" `        -FunctionName MyFunction `        -ZipFilename .\\MyFunctionBinaries.zip `        -Handler \"AssemblyName::Namespace.ClassName::MethodName\" `        -Role \"arn:aws:iam::123456789012:role/LambdaFullExecRole\" `        -Runtime dotnetcore1.0 `        -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" }Output:CodeSha256       : /NgBMd...gq71I=CodeSize         : 214784DeadLetterConfig :Description      : My C# Lambda FunctionEnvironment      : Amazon.Lambda.Model.EnvironmentResponseFunctionArn      : arn:aws:lambda:us-west-2:123456789012:function:ToUpperFunctionName     : MyFunctionHandler          : AssemblyName::Namespace.ClassName::MethodNameKMSKeyArn        :LastModified     : 2016-12-29T23:50:14.207+0000MemorySize       : 128Role             : arn:aws:iam::123456789012:role/LambdaFullExecRoleRuntime          : dotnetcore1.0Timeout          : 3Version          : $LATESTVpcConfig        :Example 2: This example is similar to the previous one except the function binaries are first uploaded to an Amazon S3 bucket (which must be in the same region as the intended Lambda function) and the resulting S3 object is then referenced when creating the function.Write-S3Object -BucketName amzn-s3-demo-bucket -Key MyFunctionBinaries.zip -File .\\MyFunctionBinaries.zip    Publish-LMFunction -Description \"My C# Lambda Function\" `        -FunctionName MyFunction `        -BucketName amzn-s3-demo-bucket `        -Key MyFunctionBinaries.zip `        -Handler \"AssemblyName::Namespace.ClassName::MethodName\" `        -Role \"arn:aws:iam::123456789012:role/LambdaFullExecRole\" `        -Runtime dotnetcore1.0 `        -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" }                        For API details, see                        CreateFunction                        in AWS Tools for PowerShell Cmdlet Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def create_function(        self, function_name, handler_name, iam_role, deployment_package    ):        \"\"\"        Deploys a Lambda function.        :param function_name: The name of the Lambda function.        :param handler_name: The fully qualified name of the handler function. This                             must include the file name and the function name.        :param iam_role: The IAM role to use for the function.        :param deployment_package: The deployment package that contains the function                                   code in .zip format.        :return: The Amazon Resource Name (ARN) of the newly created function.        \"\"\"        try:            response = self.lambda_client.create_function(                FunctionName=function_name,                Description=\"AWS Lambda doc example\",                Runtime=\"python3.9\",                Role=iam_role.arn,                Handler=handler_name,                Code={\"ZipFile\": deployment_package},                Publish=True,            )            function_arn = response[\"FunctionArn\"]            waiter = self.lambda_client.get_waiter(\"function_active_v2\")            waiter.wait(FunctionName=function_name)            logger.info(                \"Created function '%s' with ARN: '%s'.\",                function_name,                response[\"FunctionArn\"],            )        except ClientError:            logger.error(\"Couldn't create function %s.\", function_name)            raise        else:            return function_arn                        For API details, see                        CreateFunction                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Deploys a Lambda function.  #  # @param function_name: The name of the Lambda function.  # @param handler_name: The fully qualified name of the handler function.  # @param role_arn: The IAM role to use for the function.  # @param deployment_package: The deployment package that contains the function code in .zip format.  # @return: The Amazon Resource Name (ARN) of the newly created function.  def create_function(function_name, handler_name, role_arn, deployment_package)    response = @lambda_client.create_function({                                                role: role_arn.to_s,                                                function_name: function_name,                                                handler: handler_name,                                                runtime: 'ruby2.7',                                                code: {                                                  zip_file: deployment_package                                                },                                                environment: {                                                  variables: {                                                    'LOG_LEVEL' => 'info'                                                  }                                                }                                              })    @lambda_client.wait_until(:function_active_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end    response  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error creating #{function_name}:\\n #{e.message}\")  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")  end                        For API details, see                        CreateFunction                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Create a function, uploading from a zip file.     */    pub async fn create_function(&self, zip_file: PathBuf) -> Result<String, anyhow::Error> {        let code = self.prepare_function(zip_file, None).await?;        let key = code.s3_key().unwrap().to_string();        let role = self.create_role().await.map_err(|e| anyhow!(e))?;        info!(\"Created iam role, waiting 15s for it to become active\");        tokio::time::sleep(Duration::from_secs(15)).await;        info!(\"Creating lambda function {}\", self.lambda_name);        let _ = self            .lambda_client            .create_function()            .function_name(self.lambda_name.clone())            .code(code)            .role(role.arn())            .runtime(aws_sdk_lambda::types::Runtime::Providedal2)            .handler(\"_unused\")            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        self.lambda_client            .publish_version()            .function_name(self.lambda_name.clone())            .send()            .await?;        Ok(key)    }    /**     * Upload function code from a path to a zip file.     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.     */    async fn prepare_function(        &self,        zip_file: PathBuf,        key: Option<String>,    ) -> Result<FunctionCode, anyhow::Error> {        let body = ByteStream::from_path(zip_file).await?;        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);        let _ = self            .s3_client            .put_object()            .bucket(self.bucket.clone())            .key(key.clone())            .body(body)            .send()            .await?;        Ok(FunctionCode::builder()            .s3_bucket(self.bucket.clone())            .s3_key(key)            .build())    }                        For API details, see                        CreateFunction                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        lo_lmd->createfunction(            iv_functionname = iv_function_name            iv_runtime = `python3.9`            iv_role = iv_role_arn            iv_handler = iv_handler            io_code = io_zip_file            iv_description = 'AWS Lambda code example'        ).        MESSAGE 'Lambda function created.' TYPE 'I'.      CATCH /aws1/cx_lmdcodesigningcfgno00.        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdcodestorageexcdex.        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.      CATCH /aws1/cx_lmdcodeverification00.        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.      CATCH /aws1/cx_lmdinvalidcodesigex.        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdresourceconflictex.        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.      CATCH /aws1/cx_lmdresourcenotfoundex.        MESSAGE 'The requested resource does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        CreateFunction                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Creates a new Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function.</param>\n    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)\n    /// bucket where the zip file containing the code is located.</param>\n    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>\n    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the\n    /// appropriate Lambda permissions.</param>\n    /// <param name=\"handler\">The name of the handler function.</param>\n    /// <returns>The Amazon Resource Name (ARN) of the newly created\n    /// Lambda function.</returns>\n    public async Task<string> CreateLambdaFunctionAsync(\n        string functionName,\n        string s3Bucket,\n        string s3Key,\n        string role,\n        string handler)\n    {\n        // Defines the location for the function code.\n        // S3Bucket - The S3 bucket where the file containing\n        //            the source code is stored.\n        // S3Key    - The name of the file containing the code.\n        var functionCode = new FunctionCode\n        {\n            S3Bucket = s3Bucket,\n            S3Key = s3Key,\n        };\n\n        var createFunctionRequest = new CreateFunctionRequest\n        {\n            FunctionName = functionName,\n            Description = \"Created by the Lambda .NET API\",\n            Code = functionCode,\n            Handler = handler,\n            Runtime = Runtime.Dotnet6,\n            Role = role,\n        };\n\n        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);\n        return reponse.FunctionArn;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Creates a new Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function.</param>    /// <param name=\"s3Bucket\">The Amazon Simple Storage Service (Amazon S3)    /// bucket where the zip file containing the code is located.</param>    /// <param name=\"s3Key\">The Amazon S3 key of the zip file.</param>    /// <param name=\"role\">The Amazon Resource Name (ARN) of a role with the    /// appropriate Lambda permissions.</param>    /// <param name=\"handler\">The name of the handler function.</param>    /// <returns>The Amazon Resource Name (ARN) of the newly created    /// Lambda function.</returns>    public async Task<string> CreateLambdaFunctionAsync(        string functionName,        string s3Bucket,        string s3Key,        string role,        string handler)    {        // Defines the location for the function code.        // S3Bucket - The S3 bucket where the file containing        //            the source code is stored.        // S3Key    - The name of the file containing the code.        var functionCode = new FunctionCode        {            S3Bucket = s3Bucket,            S3Key = s3Key,        };        var createFunctionRequest = new CreateFunctionRequest        {            FunctionName = functionName,            Description = \"Created by the Lambda .NET API\",            Code = functionCode,            Handler = handler,            Runtime = Runtime.Dotnet6,            Role = role,        };        var reponse = await _lambdaService.CreateFunctionAsync(createFunctionRequest);        return reponse.FunctionArn;    }                        For API details, see                        CreateFunction                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "DeleteAlias",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_DeleteAlias_section.html",
                                "sections": [
                                    "The following code examples show how to use DeleteAlias.",
                                    "  1.CLI : delete-alias",
                                    "  2.AWS CLI : delete-alias",
                                    "  3.PowerShell : Remove-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"NewAlias\"\n",
                                    "  4.Tools for PowerShell : Remove-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"NewAlias\"\n",
                                    "CLIAWS CLITo delete an alias of a Lambda functionThe following delete-alias example deletes the alias named LIVE from the my-function Lambda function.aws lambda delete-alias \\    --function-name my-function \\    --name LIVEThis command produces no output.For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        DeleteAlias                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example deletes the Lambda function Alias mentioned in the command.Remove-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"NewAlias\"                        For API details, see                        DeleteAlias                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : delete-alias",
                                    "AWS CLITo delete an alias of a Lambda functionThe following delete-alias example deletes the alias named LIVE from the my-function Lambda function.aws lambda delete-alias \\    --function-name my-function \\    --name LIVEThis command produces no output.For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        DeleteAlias                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "DeleteFunction",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_DeleteFunction_section.html",
                                "sections": [
                                    "The following code examples show how to use DeleteFunction.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    Aws::Lambda::Model::DeleteFunctionRequest request;\n    request.SetFunctionName(LAMBDA_NAME);\n\n    Aws::Lambda::Model::DeleteFunctionOutcome outcome = client.DeleteFunction(\n            request);\n\n    if (outcome.IsSuccess()) {\n        std::cout << \"The lambda function was successfully deleted.\" << std::endl;\n    }\n    else {\n        std::cerr << \"Error with Lambda::DeleteFunction. \"\n                  << outcome.GetError().GetMessage()\n                  << std::endl;\n    }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    Aws::Lambda::Model::DeleteFunctionRequest request;\n    request.SetFunctionName(LAMBDA_NAME);\n\n    Aws::Lambda::Model::DeleteFunctionOutcome outcome = client.DeleteFunction(\n            request);\n\n    if (outcome.IsSuccess()) {\n        std::cout << \"The lambda function was successfully deleted.\" << std::endl;\n    }\n    else {\n        std::cerr << \"Error with Lambda::DeleteFunction. \"\n                  << outcome.GetError().GetMessage()\n                  << std::endl;\n    }\n\n",
                                    "  5.CLI : delete-function",
                                    "  6.AWS CLI : delete-function",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// DeleteFunction deletes the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) DeleteFunction(ctx context.Context, functionName string) {\n\t_, err := wrapper.LambdaClient.DeleteFunction(ctx, &lambda.DeleteFunctionInput{\n\t\tFunctionName: aws.String(functionName),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't delete function %v. Here's why: %v\\n\", functionName, err)\n\t}\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// DeleteFunction deletes the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) DeleteFunction(ctx context.Context, functionName string) {\n\t_, err := wrapper.LambdaClient.DeleteFunction(ctx, &lambda.DeleteFunctionInput{\n\t\tFunctionName: aws.String(functionName),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't delete function %v. Here's why: %v\\n\", functionName, err)\n\t}\n}\n\n\n",
                                    "  9.Java :     /**\n     * Deletes an AWS Lambda function.\n     *\n     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName  the name of the Lambda function to be deleted\n     *\n     * @throws LambdaException if an error occurs while deleting the Lambda function\n     */\n    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            DeleteFunctionRequest request = DeleteFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            awsLambda.deleteFunction(request);\n            System.out.println(\"The \" + functionName + \" function was deleted\");\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Deletes an AWS Lambda function.\n     *\n     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName  the name of the Lambda function to be deleted\n     *\n     * @throws LambdaException if an error occurs while deleting the Lambda function\n     */\n    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            DeleteFunctionRequest request = DeleteFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            awsLambda.deleteFunction(request);\n            System.out.println(\"The \" + functionName + \" function was deleted\");\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  11.JavaScript : /**\n * @param {string} funcName\n */\nconst deleteFunction = (funcName) => {\n  const client = new LambdaClient({});\n  const command = new DeleteFunctionCommand({ FunctionName: funcName });\n  return client.send(command);\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : /**\n * @param {string} funcName\n */\nconst deleteFunction = (funcName) => {\n  const client = new LambdaClient({});\n  const command = new DeleteFunctionCommand({ FunctionName: funcName });\n  return client.send(command);\n};\n\n",
                                    "  13.Kotlin : suspend fun delLambdaFunction(myFunctionName: String) {\n    val request =\n        DeleteFunctionRequest {\n            functionName = myFunctionName\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.deleteFunction(request)\n        println(\"$myFunctionName was deleted\")\n    }\n}\n\n",
                                    "  14.SDK for Kotlin : suspend fun delLambdaFunction(myFunctionName: String) {\n    val request =\n        DeleteFunctionRequest {\n            functionName = myFunctionName\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        awsLambda.deleteFunction(request)\n        println(\"$myFunctionName was deleted\")\n    }\n}\n\n",
                                    "  15.PHP :     public function deleteFunction($functionName)\n    {\n        return $this->lambdaClient->deleteFunction([\n            'FunctionName' => $functionName,\n        ]);\n    }\n\n",
                                    "  16.SDK for PHP :     public function deleteFunction($functionName)\n    {\n        return $this->lambdaClient->deleteFunction([\n            'FunctionName' => $functionName,\n        ]);\n    }\n\n",
                                    "  17.PowerShell : Remove-LMFunction -FunctionName \"MylambdaFunction123\" -Qualifier '3'\n",
                                    "  18.Tools for PowerShell : Remove-LMFunction -FunctionName \"MylambdaFunction123\" -Qualifier '3'\n",
                                    "  19.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def delete_function(self, function_name):\n        \"\"\"\n        Deletes a Lambda function.\n\n        :param function_name: The name of the function to delete.\n        \"\"\"\n        try:\n            self.lambda_client.delete_function(FunctionName=function_name)\n        except ClientError:\n            logger.exception(\"Couldn't delete function %s.\", function_name)\n            raise\n\n\n",
                                    "  20.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def delete_function(self, function_name):\n        \"\"\"\n        Deletes a Lambda function.\n\n        :param function_name: The name of the function to delete.\n        \"\"\"\n        try:\n            self.lambda_client.delete_function(FunctionName=function_name)\n        except ClientError:\n            logger.exception(\"Couldn't delete function %s.\", function_name)\n            raise\n\n\n",
                                    "  21.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Deletes a Lambda function.\n  # @param function_name: The name of the function to delete.\n  def delete_function(function_name)\n    print \"Deleting function: #{function_name}...\"\n    @lambda_client.delete_function(\n      function_name: function_name\n    )\n    print 'Done!'.green\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error deleting #{function_name}:\\n #{e.message}\")\n  end\n\n",
                                    "  22.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Deletes a Lambda function.\n  # @param function_name: The name of the function to delete.\n  def delete_function(function_name)\n    print \"Deleting function: #{function_name}...\"\n    @lambda_client.delete_function(\n      function_name: function_name\n    )\n    print 'Done!'.green\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error deleting #{function_name}:\\n #{e.message}\")\n  end\n\n",
                                    "  23.Rust :     /** Delete a function and its role, and if possible or necessary, its associated code object and bucket. */\n    pub async fn delete_function(\n        &self,\n        location: Option<String>,\n    ) -> (\n        Result<DeleteFunctionOutput, anyhow::Error>,\n        Result<DeleteRoleOutput, anyhow::Error>,\n        Option<Result<DeleteObjectOutput, anyhow::Error>>,\n    ) {\n        info!(\"Deleting lambda function {}\", self.lambda_name);\n        let delete_function = self\n            .lambda_client\n            .delete_function()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from);\n\n        info!(\"Deleting iam role {}\", self.role_name);\n        let delete_role = self\n            .iam_client\n            .delete_role()\n            .role_name(self.role_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from);\n\n        let delete_object: Option<Result<DeleteObjectOutput, anyhow::Error>> =\n            if let Some(location) = location {\n                info!(\"Deleting object {location}\");\n                Some(\n                    self.s3_client\n                        .delete_object()\n                        .bucket(self.bucket.clone())\n                        .key(location)\n                        .send()\n                        .await\n                        .map_err(anyhow::Error::from),\n                )\n            } else {\n                info!(?location, \"Skipping delete object\");\n                None\n            };\n\n        (delete_function, delete_role, delete_object)\n    }\n\n",
                                    "  24.SDK for Rust :     /** Delete a function and its role, and if possible or necessary, its associated code object and bucket. */\n    pub async fn delete_function(\n        &self,\n        location: Option<String>,\n    ) -> (\n        Result<DeleteFunctionOutput, anyhow::Error>,\n        Result<DeleteRoleOutput, anyhow::Error>,\n        Option<Result<DeleteObjectOutput, anyhow::Error>>,\n    ) {\n        info!(\"Deleting lambda function {}\", self.lambda_name);\n        let delete_function = self\n            .lambda_client\n            .delete_function()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from);\n\n        info!(\"Deleting iam role {}\", self.role_name);\n        let delete_role = self\n            .iam_client\n            .delete_role()\n            .role_name(self.role_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from);\n\n        let delete_object: Option<Result<DeleteObjectOutput, anyhow::Error>> =\n            if let Some(location) = location {\n                info!(\"Deleting object {location}\");\n                Some(\n                    self.s3_client\n                        .delete_object()\n                        .bucket(self.bucket.clone())\n                        .key(location)\n                        .send()\n                        .await\n                        .map_err(anyhow::Error::from),\n                )\n            } else {\n                info!(?location, \"Skipping delete object\");\n                None\n            };\n\n        (delete_function, delete_role, delete_object)\n    }\n\n",
                                    "  25.SAP ABAP :     TRY.\n        lo_lmd->deletefunction( iv_functionname = iv_function_name ).\n        MESSAGE 'Lambda function deleted.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  26.SDK for SAP ABAP :     TRY.\n        lo_lmd->deletefunction( iv_functionname = iv_function_name ).\n        MESSAGE 'Lambda function deleted.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Delete an AWS Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// delete.</param>    /// <returns>A Boolean value that indicates the success of the action.</returns>    public async Task<bool> DeleteFunctionAsync(string functionName)    {        var request = new DeleteFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.DeleteFunctionAsync(request);        // A return value of NoContent means that the request was processed.        // In this case, the function was deleted, and the return value        // is intentionally blank.        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;    }                        For API details, see                        DeleteFunction                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);    Aws::Lambda::Model::DeleteFunctionRequest request;    request.SetFunctionName(LAMBDA_NAME);    Aws::Lambda::Model::DeleteFunctionOutcome outcome = client.DeleteFunction(            request);    if (outcome.IsSuccess()) {        std::cout << \"The lambda function was successfully deleted.\" << std::endl;    }    else {        std::cerr << \"Error with Lambda::DeleteFunction. \"                  << outcome.GetError().GetMessage()                  << std::endl;    }                        For API details, see                        DeleteFunction                        in AWS SDK for C++ API Reference.                    CLIAWS CLIExample 1: To delete a Lambda function by function nameThe following delete-function example deletes the Lambda function named my-function by specifying the function's name.aws lambda delete-function \\    --function-name my-functionThis command produces no output.Example 2: To delete a Lambda function by function ARNThe following delete-function example deletes the Lambda function named my-function by specifying the function's ARN.aws lambda delete-function \\    --function-name arn:aws:lambda:us-west-2:123456789012:function:my-functionThis command produces no output.Example 3: To delete a Lambda function by partial function ARNThe following delete-function example deletes the Lambda function named my-function by specifying the function's partial ARN.aws lambda delete-function \\    --function-name 123456789012:function:my-functionThis command produces no output.For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        DeleteFunction                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// DeleteFunction deletes the Lambda function specified by functionName.func (wrapper FunctionWrapper) DeleteFunction(ctx context.Context, functionName string) {\t_, err := wrapper.LambdaClient.DeleteFunction(ctx, &lambda.DeleteFunctionInput{\t\tFunctionName: aws.String(functionName),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't delete function %v. Here's why: %v\\n\", functionName, err)\t}}                        For API details, see                        DeleteFunction                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Deletes an AWS Lambda function.     *     * @param awsLambda     an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     * @param functionName  the name of the Lambda function to be deleted     *     * @throws LambdaException if an error occurs while deleting the Lambda function     */    public static void deleteLambdaFunction(LambdaClient awsLambda, String functionName) {        try {            DeleteFunctionRequest request = DeleteFunctionRequest.builder()                .functionName(functionName)                .build();            awsLambda.deleteFunction(request);            System.out.println(\"The \" + functionName + \" function was deleted\");        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        DeleteFunction                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    /** * @param {string} funcName */const deleteFunction = (funcName) => {  const client = new LambdaClient({});  const command = new DeleteFunctionCommand({ FunctionName: funcName });  return client.send(command);};                        For API details, see                        DeleteFunction                        in AWS SDK for JavaScript API Reference.                    KotlinSDK for KotlinNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    suspend fun delLambdaFunction(myFunctionName: String) {    val request =        DeleteFunctionRequest {            functionName = myFunctionName        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        awsLambda.deleteFunction(request)        println(\"$myFunctionName was deleted\")    }}                        For API details, see                        DeleteFunction                        in AWS SDK for Kotlin API reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function deleteFunction($functionName)    {        return $this->lambdaClient->deleteFunction([            'FunctionName' => $functionName,        ]);    }                        For API details, see                        DeleteFunction                        in AWS SDK for PHP API Reference.                    PowerShellTools for PowerShellExample 1: This example deletes a specific version of a Lambda functionRemove-LMFunction -FunctionName \"MylambdaFunction123\" -Qualifier '3'                        For API details, see                        DeleteFunction                        in AWS Tools for PowerShell Cmdlet Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def delete_function(self, function_name):        \"\"\"        Deletes a Lambda function.        :param function_name: The name of the function to delete.        \"\"\"        try:            self.lambda_client.delete_function(FunctionName=function_name)        except ClientError:            logger.exception(\"Couldn't delete function %s.\", function_name)            raise                        For API details, see                        DeleteFunction                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Deletes a Lambda function.  # @param function_name: The name of the function to delete.  def delete_function(function_name)    print \"Deleting function: #{function_name}...\"    @lambda_client.delete_function(      function_name: function_name    )    print 'Done!'.green  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error deleting #{function_name}:\\n #{e.message}\")  end                        For API details, see                        DeleteFunction                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** Delete a function and its role, and if possible or necessary, its associated code object and bucket. */    pub async fn delete_function(        &self,        location: Option<String>,    ) -> (        Result<DeleteFunctionOutput, anyhow::Error>,        Result<DeleteRoleOutput, anyhow::Error>,        Option<Result<DeleteObjectOutput, anyhow::Error>>,    ) {        info!(\"Deleting lambda function {}\", self.lambda_name);        let delete_function = self            .lambda_client            .delete_function()            .function_name(self.lambda_name.clone())            .send()            .await            .map_err(anyhow::Error::from);        info!(\"Deleting iam role {}\", self.role_name);        let delete_role = self            .iam_client            .delete_role()            .role_name(self.role_name.clone())            .send()            .await            .map_err(anyhow::Error::from);        let delete_object: Option<Result<DeleteObjectOutput, anyhow::Error>> =            if let Some(location) = location {                info!(\"Deleting object {location}\");                Some(                    self.s3_client                        .delete_object()                        .bucket(self.bucket.clone())                        .key(location)                        .send()                        .await                        .map_err(anyhow::Error::from),                )            } else {                info!(?location, \"Skipping delete object\");                None            };        (delete_function, delete_role, delete_object)    }                        For API details, see                        DeleteFunction                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        lo_lmd->deletefunction( iv_functionname = iv_function_name ).        MESSAGE 'Lambda function deleted.' TYPE 'I'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdresourceconflictex.        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.      CATCH /aws1/cx_lmdresourcenotfoundex.        MESSAGE 'The requested resource does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        DeleteFunction                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Delete an AWS Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// delete.</param>\n    /// <returns>A Boolean value that indicates the success of the action.</returns>\n    public async Task<bool> DeleteFunctionAsync(string functionName)\n    {\n        var request = new DeleteFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.DeleteFunctionAsync(request);\n\n        // A return value of NoContent means that the request was processed.\n        // In this case, the function was deleted, and the return value\n        // is intentionally blank.\n        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Delete an AWS Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// delete.</param>    /// <returns>A Boolean value that indicates the success of the action.</returns>    public async Task<bool> DeleteFunctionAsync(string functionName)    {        var request = new DeleteFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.DeleteFunctionAsync(request);        // A return value of NoContent means that the request was processed.        // In this case, the function was deleted, and the return value        // is intentionally blank.        return response.HttpStatusCode == System.Net.HttpStatusCode.NoContent;    }                        For API details, see                        DeleteFunction                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "DeleteFunctionConcurrency",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_DeleteFunctionConcurrency_section.html",
                                "sections": [
                                    "The following code examples show how to use DeleteFunctionConcurrency.",
                                    "  1.CLI : delete-function-concurrency",
                                    "  2.AWS CLI : delete-function-concurrency",
                                    "  3.PowerShell : Remove-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\"\n",
                                    "  4.Tools for PowerShell : Remove-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\"\n",
                                    "CLIAWS CLITo remove the reserved concurrent execution limit from a functionThe following delete-function-concurrency example deletes the reserved concurrent execution limit from the my-function function.aws lambda delete-function-concurrency \\    --function-name  my-functionThis command produces no output.For more information, see Reserving Concurrency for a Lambda Function in the AWS Lambda Developer Guide.                        For API details, see                        DeleteFunctionConcurrency                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This examples removes the Function Concurrency of the Lambda Function.Remove-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\"                        For API details, see                        DeleteFunctionConcurrency                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : delete-function-concurrency",
                                    "AWS CLITo remove the reserved concurrent execution limit from a functionThe following delete-function-concurrency example deletes the reserved concurrent execution limit from the my-function function.aws lambda delete-function-concurrency \\    --function-name  my-functionThis command produces no output.For more information, see Reserving Concurrency for a Lambda Function in the AWS Lambda Developer Guide.                        For API details, see                        DeleteFunctionConcurrency                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "DeleteProvisionedConcurrencyConfig",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_DeleteProvisionedConcurrencyConfig_section.html",
                                "sections": [
                                    "The following code examples show how to use DeleteProvisionedConcurrencyConfig.",
                                    "  1.CLI : delete-provisioned-concurrency-config",
                                    "  2.AWS CLI : delete-provisioned-concurrency-config",
                                    "  3.PowerShell : Remove-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"\n",
                                    "  4.Tools for PowerShell : Remove-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"\n",
                                    "CLIAWS CLITo delete a provisioned concurrency configurationThe following delete-provisioned-concurrency-config example deletes the provisioned concurrency configuration for the GREEN alias of the specified function.aws lambda delete-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier GREEN                        For API details, see                        DeleteProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example removes the Provisioned Concurrency Configuration for a specific Alias.Remove-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"                        For API details, see                        DeleteProvisionedConcurrencyConfig                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : delete-provisioned-concurrency-config",
                                    "AWS CLITo delete a provisioned concurrency configurationThe following delete-provisioned-concurrency-config example deletes the provisioned concurrency configuration for the GREEN alias of the specified function.aws lambda delete-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier GREEN                        For API details, see                        DeleteProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetAccountSettings",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetAccountSettings_section.html",
                                "sections": [
                                    "The following code examples show how to use GetAccountSettings.",
                                    "  1.CLI : get-account-settings",
                                    "  2.AWS CLI : get-account-settings",
                                    "  3.PowerShell : Get-LMAccountSetting | Select-Object @{Name=\"TotalCodeSizeLimit\";Expression={$_.AccountLimit.TotalCodeSize}}, @{Name=\"TotalCodeSizeUsed\";Expression={$_.AccountUsage.TotalCodeSize}}\n",
                                    "  4.Tools for PowerShell : Get-LMAccountSetting | Select-Object @{Name=\"TotalCodeSizeLimit\";Expression={$_.AccountLimit.TotalCodeSize}}, @{Name=\"TotalCodeSizeUsed\";Expression={$_.AccountUsage.TotalCodeSize}}\n",
                                    "CLIAWS CLITo retrieve details about your account in an AWS RegionThe following get-account-settings example displays the Lambda limits and usage information for your account.aws lambda get-account-settingsOutput:{    \"AccountLimit\": {       \"CodeSizeUnzipped\": 262144000,       \"UnreservedConcurrentExecutions\": 1000,       \"ConcurrentExecutions\": 1000,       \"CodeSizeZipped\": 52428800,       \"TotalCodeSize\": 80530636800    },    \"AccountUsage\": {       \"FunctionCount\": 4,       \"TotalCodeSize\": 9426    }}For more information, see AWS Lambda Limits in the AWS Lambda Developer Guide.                        For API details, see                        GetAccountSettings                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This sample displays to compare the Account Limit and Account UsageGet-LMAccountSetting | Select-Object @{Name=\"TotalCodeSizeLimit\";Expression={$_.AccountLimit.TotalCodeSize}}, @{Name=\"TotalCodeSizeUsed\";Expression={$_.AccountUsage.TotalCodeSize}}Output:TotalCodeSizeLimit TotalCodeSizeUsed------------------ -----------------       80530636800          15078795                        For API details, see                        GetAccountSettings                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-account-settings",
                                    "AWS CLITo retrieve details about your account in an AWS RegionThe following get-account-settings example displays the Lambda limits and usage information for your account.aws lambda get-account-settingsOutput:{    \"AccountLimit\": {       \"CodeSizeUnzipped\": 262144000,       \"UnreservedConcurrentExecutions\": 1000,       \"ConcurrentExecutions\": 1000,       \"CodeSizeZipped\": 52428800,       \"TotalCodeSize\": 80530636800    },    \"AccountUsage\": {       \"FunctionCount\": 4,       \"TotalCodeSize\": 9426    }}For more information, see AWS Lambda Limits in the AWS Lambda Developer Guide.                        For API details, see                        GetAccountSettings                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetAlias",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetAlias_section.html",
                                "sections": [
                                    "The following code examples show how to use GetAlias.",
                                    "  1.CLI : get-alias",
                                    "  2.AWS CLI : get-alias",
                                    "  3.PowerShell : Get-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"newlabel1\" -Select RoutingConfig\n",
                                    "  4.Tools for PowerShell : Get-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"newlabel1\" -Select RoutingConfig\n",
                                    "CLIAWS CLITo retrieve details about a function aliasThe following get-alias example displays details for the alias named LIVE on the my-function Lambda function.aws lambda get-alias \\    --function-name my-function \\    --name LIVEOutput:{    \"FunctionVersion\": \"3\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"594f41fb-b85f-4c20-95c7-6ca5f2a92c93\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        GetAlias                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example retrieves the Routing Config weights for a specific Lambda Function Alias.Get-LMAlias -FunctionName \"MylambdaFunction123\" -Name \"newlabel1\" -Select RoutingConfigOutput:AdditionalVersionWeights------------------------{[1, 0.6]}                        For API details, see                        GetAlias                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-alias",
                                    "AWS CLITo retrieve details about a function aliasThe following get-alias example displays details for the alias named LIVE on the my-function Lambda function.aws lambda get-alias \\    --function-name my-function \\    --name LIVEOutput:{    \"FunctionVersion\": \"3\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"594f41fb-b85f-4c20-95c7-6ca5f2a92c93\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        GetAlias                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetFunction",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetFunction_section.html",
                                "sections": [
                                    "The following code examples show how to use GetFunction.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::GetFunctionRequest request;\n        request.SetFunctionName(functionName);\n\n        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"Function retrieve.\\n\" <<\n                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()\n                      << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::GetFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::GetFunctionRequest request;\n        request.SetFunctionName(functionName);\n\n        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"Function retrieve.\\n\" <<\n                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()\n                      << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::GetFunction. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  5.CLI : get-function",
                                    "  6.AWS CLI : get-function",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// GetFunction gets data about the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) GetFunction(ctx context.Context, functionName string) types.State {\n\tvar state types.State\n\tfuncOutput, err := wrapper.LambdaClient.GetFunction(ctx, &lambda.GetFunctionInput{\n\t\tFunctionName: aws.String(functionName),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't get function %v. Here's why: %v\\n\", functionName, err)\n\t} else {\n\t\tstate = funcOutput.Configuration.State\n\t}\n\treturn state\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// GetFunction gets data about the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) GetFunction(ctx context.Context, functionName string) types.State {\n\tvar state types.State\n\tfuncOutput, err := wrapper.LambdaClient.GetFunction(ctx, &lambda.GetFunctionInput{\n\t\tFunctionName: aws.String(functionName),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't get function %v. Here's why: %v\\n\", functionName, err)\n\t} else {\n\t\tstate = funcOutput.Configuration.State\n\t}\n\treturn state\n}\n\n\n",
                                    "  9.Java :     /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  11.JavaScript : const getFunction = (funcName) => {\n  const client = new LambdaClient({});\n  const command = new GetFunctionCommand({ FunctionName: funcName });\n  return client.send(command);\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : const getFunction = (funcName) => {\n  const client = new LambdaClient({});\n  const command = new GetFunctionCommand({ FunctionName: funcName });\n  return client.send(command);\n};\n\n",
                                    "  13.PHP :     public function getFunction($functionName)\n    {\n        return $this->lambdaClient->getFunction([\n            'FunctionName' => $functionName,\n        ]);\n    }\n\n",
                                    "  14.SDK for PHP :     public function getFunction($functionName)\n    {\n        return $this->lambdaClient->getFunction([\n            'FunctionName' => $functionName,\n        ]);\n    }\n\n",
                                    "  15.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def get_function(self, function_name):\n        \"\"\"\n        Gets data about a Lambda function.\n\n        :param function_name: The name of the function.\n        :return: The function data.\n        \"\"\"\n        response = None\n        try:\n            response = self.lambda_client.get_function(FunctionName=function_name)\n        except ClientError as err:\n            if err.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":\n                logger.info(\"Function %s does not exist.\", function_name)\n            else:\n                logger.error(\n                    \"Couldn't get function %s. Here's why: %s: %s\",\n                    function_name,\n                    err.response[\"Error\"][\"Code\"],\n                    err.response[\"Error\"][\"Message\"],\n                )\n                raise\n        return response\n\n\n",
                                    "  16.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def get_function(self, function_name):\n        \"\"\"\n        Gets data about a Lambda function.\n\n        :param function_name: The name of the function.\n        :return: The function data.\n        \"\"\"\n        response = None\n        try:\n            response = self.lambda_client.get_function(FunctionName=function_name)\n        except ClientError as err:\n            if err.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":\n                logger.info(\"Function %s does not exist.\", function_name)\n            else:\n                logger.error(\n                    \"Couldn't get function %s. Here's why: %s: %s\",\n                    function_name,\n                    err.response[\"Error\"][\"Code\"],\n                    err.response[\"Error\"][\"Message\"],\n                )\n                raise\n        return response\n\n\n",
                                    "  17.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Gets data about a Lambda function.\n  #\n  # @param function_name: The name of the function.\n  # @return response: The function data, or nil if no such function exists.\n  def get_function(function_name)\n    @lambda_client.get_function(\n      {\n        function_name: function_name\n      }\n    )\n  rescue Aws::Lambda::Errors::ResourceNotFoundException => e\n    @logger.debug(\"Could not find function: #{function_name}:\\n #{e.message}\")\n    nil\n  end\n\n",
                                    "  18.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Gets data about a Lambda function.\n  #\n  # @param function_name: The name of the function.\n  # @return response: The function data, or nil if no such function exists.\n  def get_function(function_name)\n    @lambda_client.get_function(\n      {\n        function_name: function_name\n      }\n    )\n  rescue Aws::Lambda::Errors::ResourceNotFoundException => e\n    @logger.debug(\"Could not find function: #{function_name}:\\n #{e.message}\")\n    nil\n  end\n\n",
                                    "  19.Rust :     /** Get the Lambda function with this Manager's name. */\n    pub async fn get_function(&self) -> Result<GetFunctionOutput, anyhow::Error> {\n        info!(\"Getting lambda function\");\n        self.lambda_client\n            .get_function()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\n",
                                    "  20.SDK for Rust :     /** Get the Lambda function with this Manager's name. */\n    pub async fn get_function(&self) -> Result<GetFunctionOutput, anyhow::Error> {\n        info!(\"Getting lambda function\");\n        self.lambda_client\n            .get_function()\n            .function_name(self.lambda_name.clone())\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\n",
                                    "  21.SAP ABAP :     TRY.\n        oo_result =  lo_lmd->getfunction( iv_functionname = iv_function_name ).       \" oo_result is returned for testing purposes. \"\n        MESSAGE 'Lambda function information retrieved.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  22.SDK for SAP ABAP :     TRY.\n        oo_result =  lo_lmd->getfunction( iv_functionname = iv_function_name ).       \" oo_result is returned for testing purposes. \"\n        MESSAGE 'Lambda function information retrieved.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Gets information about a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function for    /// which to retrieve information.</param>    /// <returns>Async Task.</returns>    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)    {        var functionRequest = new GetFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.GetFunctionAsync(functionRequest);        return response.Configuration;    }                        For API details, see                        GetFunction                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);        Aws::Lambda::Model::GetFunctionRequest request;        request.SetFunctionName(functionName);        Aws::Lambda::Model::GetFunctionOutcome outcome = client.GetFunction(request);        if (outcome.IsSuccess()) {            std::cout << \"Function retrieve.\\n\" <<                      outcome.GetResult().GetConfiguration().Jsonize().View().WriteReadable()                      << std::endl;        }        else {            std::cerr << \"Error with Lambda::GetFunction. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }                        For API details, see                        GetFunction                        in AWS SDK for C++ API Reference.                    CLIAWS CLITo retrieve information about a functionThe following get-function example displays information about the my-function function.aws lambda get-function \\    --function-name  my-functionOutput:{    \"Concurrency\": {        \"ReservedConcurrentExecutions\": 100    },    \"Code\": {        \"RepositoryType\": \"S3\",        \"Location\": \"https://awslambda-us-west-2-tasks.s3.us-west-2.amazonaws.com/snapshots/123456789012/my-function...\"    },    \"Configuration\": {        \"TracingConfig\": {            \"Mode\": \"PassThrough\"        },        \"Version\": \"$LATEST\",        \"CodeSha256\": \"5tT2qgzYUHoqwR616pZ2dpkn/0J1FrzJmlKidWaaCgk=\",        \"FunctionName\": \"my-function\",        \"VpcConfig\": {            \"SubnetIds\": [],            \"VpcId\": \"\",            \"SecurityGroupIds\": []        },        \"MemorySize\": 128,        \"RevisionId\": \"28f0fb31-5c5c-43d3-8955-03e76c5c1075\",        \"CodeSize\": 304,        \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",        \"Handler\": \"index.handler\",        \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",        \"Timeout\": 3,        \"LastModified\": \"2019-09-24T18:20:35.054+0000\",        \"Runtime\": \"nodejs10.x\",        \"Description\": \"\"    }}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        GetFunction                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// GetFunction gets data about the Lambda function specified by functionName.func (wrapper FunctionWrapper) GetFunction(ctx context.Context, functionName string) types.State {\tvar state types.State\tfuncOutput, err := wrapper.LambdaClient.GetFunction(ctx, &lambda.GetFunctionInput{\t\tFunctionName: aws.String(functionName),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't get function %v. Here's why: %v\\n\", functionName, err)\t} else {\t\tstate = funcOutput.Configuration.State\t}\treturn state}                        For API details, see                        GetFunction                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Retrieves information about an AWS Lambda function.     *     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     * @param functionName the name of the AWS Lambda function to retrieve information about     */    public static void getFunction(LambdaClient awsLambda, String functionName) {        try {            GetFunctionRequest functionRequest = GetFunctionRequest.builder()                .functionName(functionName)                .build();            GetFunctionResponse response = awsLambda.getFunction(functionRequest);            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        GetFunction                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const getFunction = (funcName) => {  const client = new LambdaClient({});  const command = new GetFunctionCommand({ FunctionName: funcName });  return client.send(command);};                        For API details, see                        GetFunction                        in AWS SDK for JavaScript API Reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function getFunction($functionName)    {        return $this->lambdaClient->getFunction([            'FunctionName' => $functionName,        ]);    }                        For API details, see                        GetFunction                        in AWS SDK for PHP API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def get_function(self, function_name):        \"\"\"        Gets data about a Lambda function.        :param function_name: The name of the function.        :return: The function data.        \"\"\"        response = None        try:            response = self.lambda_client.get_function(FunctionName=function_name)        except ClientError as err:            if err.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":                logger.info(\"Function %s does not exist.\", function_name)            else:                logger.error(                    \"Couldn't get function %s. Here's why: %s: %s\",                    function_name,                    err.response[\"Error\"][\"Code\"],                    err.response[\"Error\"][\"Message\"],                )                raise        return response                        For API details, see                        GetFunction                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Gets data about a Lambda function.  #  # @param function_name: The name of the function.  # @return response: The function data, or nil if no such function exists.  def get_function(function_name)    @lambda_client.get_function(      {        function_name: function_name      }    )  rescue Aws::Lambda::Errors::ResourceNotFoundException => e    @logger.debug(\"Could not find function: #{function_name}:\\n #{e.message}\")    nil  end                        For API details, see                        GetFunction                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** Get the Lambda function with this Manager's name. */    pub async fn get_function(&self) -> Result<GetFunctionOutput, anyhow::Error> {        info!(\"Getting lambda function\");        self.lambda_client            .get_function()            .function_name(self.lambda_name.clone())            .send()            .await            .map_err(anyhow::Error::from)    }                        For API details, see                        GetFunction                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        oo_result =  lo_lmd->getfunction( iv_functionname = iv_function_name ).       \" oo_result is returned for testing purposes. \"        MESSAGE 'Lambda function information retrieved.' TYPE 'I'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        GetFunction                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Gets information about a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function for\n    /// which to retrieve information.</param>\n    /// <returns>Async Task.</returns>\n    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)\n    {\n        var functionRequest = new GetFunctionRequest\n        {\n            FunctionName = functionName,\n        };\n\n        var response = await _lambdaService.GetFunctionAsync(functionRequest);\n        return response.Configuration;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Gets information about a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function for    /// which to retrieve information.</param>    /// <returns>Async Task.</returns>    public async Task<FunctionConfiguration> GetFunctionAsync(string functionName)    {        var functionRequest = new GetFunctionRequest        {            FunctionName = functionName,        };        var response = await _lambdaService.GetFunctionAsync(functionRequest);        return response.Configuration;    }                        For API details, see                        GetFunction                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetFunctionConcurrency",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetFunctionConcurrency_section.html",
                                "sections": [
                                    "The following code examples show how to use GetFunctionConcurrency.",
                                    "  1.CLI : get-function-concurrency",
                                    "  2.AWS CLI : get-function-concurrency",
                                    "  3.PowerShell : Get-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -Select *\n",
                                    "  4.Tools for PowerShell : Get-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -Select *\n",
                                    "CLIAWS CLITo view the reserved concurrency setting for a functionThe following get-function-concurrency example retrieves the reserved concurrency setting for the specified function.aws lambda get-function-concurrency \\    --function-name my-functionOutput:{    \"ReservedConcurrentExecutions\": 250}                        For API details, see                        GetFunctionConcurrency                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This examples gets the Reserved concurrency for the Lambda FunctionGet-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -Select *Output:ReservedConcurrentExecutions----------------------------100                        For API details, see                        GetFunctionConcurrency                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-function-concurrency",
                                    "AWS CLITo view the reserved concurrency setting for a functionThe following get-function-concurrency example retrieves the reserved concurrency setting for the specified function.aws lambda get-function-concurrency \\    --function-name my-functionOutput:{    \"ReservedConcurrentExecutions\": 250}                        For API details, see                        GetFunctionConcurrency                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetFunctionConfiguration",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetFunctionConfiguration_section.html",
                                "sections": [
                                    "The following code examples show how to use GetFunctionConfiguration.",
                                    "  1.CLI : get-function-configuration",
                                    "  2.AWS CLI : get-function-configuration",
                                    "  3.PowerShell : Get-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Qualifier \"PowershellAlias\"\n",
                                    "  4.Tools for PowerShell : Get-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Qualifier \"PowershellAlias\"\n",
                                    "CLIAWS CLITo retrieve the version-specific settings of a Lambda functionThe following get-function-configuration example displays the settings for version 2 of the my-function function.aws lambda get-function-configuration \\    --function-name  my-function:2Output:{    \"FunctionName\": \"my-function\",    \"LastModified\": \"2019-09-26T20:28:40.438+0000\",    \"RevisionId\": \"e52502d4-9320-4688-9cd6-152a6ab7490d\",    \"MemorySize\": 256,    \"Version\": \"2\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/my-function-role-uy3l9qyq\",    \"Timeout\": 3,    \"Runtime\": \"nodejs10.x\",    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"5tT2qgzYUHaqwR716pZ2dpkn/0J1FrzJmlKidWoaCgk=\",    \"Description\": \"\",    \"VpcConfig\": {        \"SubnetIds\": [],        \"VpcId\": \"\",        \"SecurityGroupIds\": []    },    \"CodeSize\": 304,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:2\",    \"Handler\": \"index.handler\"}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        GetFunctionConfiguration                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example returns the version specific configuration of a Lambda Function.Get-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Qualifier \"PowershellAlias\"Output:CodeSha256                 : uWOW0R7z+f0VyLuUg7+/D08hkMFsq0SF4seuyUZJ/R8=CodeSize                   : 1426DeadLetterConfig           : Amazon.Lambda.Model.DeadLetterConfigDescription                : Verson 3 to test AliasesEnvironment                : Amazon.Lambda.Model.EnvironmentResponseFunctionArn                : arn:aws:lambda:us-east-1:123456789012:function:MylambdaFunction123                             :PowershellAliasFunctionName               : MylambdaFunction123Handler                    : lambda_function.launch_instanceKMSKeyArn                  : LastModified               : 2019-12-25T09:52:59.872+0000LastUpdateStatus           : SuccessfulLastUpdateStatusReason     : LastUpdateStatusReasonCode : Layers                     : {}MasterArn                  : MemorySize                 : 128RevisionId                 : 5d7de38b-87f2-4260-8f8a-e87280e10c33Role                       : arn:aws:iam::123456789012:role/service-role/lambdaRuntime                    : python3.8State                      : ActiveStateReason                : StateReasonCode            : Timeout                    : 600TracingConfig              : Amazon.Lambda.Model.TracingConfigResponseVersion                    : 4VpcConfig                  : Amazon.Lambda.Model.VpcConfigDetail                        For API details, see                        GetFunctionConfiguration                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-function-configuration",
                                    "AWS CLITo retrieve the version-specific settings of a Lambda functionThe following get-function-configuration example displays the settings for version 2 of the my-function function.aws lambda get-function-configuration \\    --function-name  my-function:2Output:{    \"FunctionName\": \"my-function\",    \"LastModified\": \"2019-09-26T20:28:40.438+0000\",    \"RevisionId\": \"e52502d4-9320-4688-9cd6-152a6ab7490d\",    \"MemorySize\": 256,    \"Version\": \"2\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/my-function-role-uy3l9qyq\",    \"Timeout\": 3,    \"Runtime\": \"nodejs10.x\",    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"5tT2qgzYUHaqwR716pZ2dpkn/0J1FrzJmlKidWoaCgk=\",    \"Description\": \"\",    \"VpcConfig\": {        \"SubnetIds\": [],        \"VpcId\": \"\",        \"SecurityGroupIds\": []    },    \"CodeSize\": 304,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:2\",    \"Handler\": \"index.handler\"}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        GetFunctionConfiguration                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetPolicy",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetPolicy_section.html",
                                "sections": [
                                    "The following code examples show how to use GetPolicy.",
                                    "  1.CLI : get-policy",
                                    "  2.AWS CLI : get-policy",
                                    "  3.PowerShell : Get-LMPolicy -FunctionName test -Select Policy\n",
                                    "  4.Tools for PowerShell : Get-LMPolicy -FunctionName test -Select Policy\n",
                                    "CLIAWS CLITo retrieve the resource-based IAM policy for a function, version, or aliasThe following get-policy example displays policy information about the my-function Lambda function.aws lambda get-policy \\    --function-name my-functionOutput:{    \"Policy\": {        \"Version\":\"2012-10-17\",        \"Id\":\"default\",        \"Statement\":        [            {                \"Sid\":\"iot-events\",                \"Effect\":\"Allow\",                \"Principal\": {\"Service\":\"iotevents.amazonaws.com\"},                \"Action\":\"lambda:InvokeFunction\",                \"Resource\":\"arn:aws:lambda:us-west-2:123456789012:function:my-function\"            }        ]    },    \"RevisionId\": \"93017fc9-59cb-41dc-901b-4845ce4bf668\"}For more information, see Using Resource-based Policies for AWS Lambda in the AWS Lambda Developer Guide.                        For API details, see                        GetPolicy                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This sample displays the Function policy of the Lambda functionGet-LMPolicy -FunctionName test -Select PolicyOutput:{\"Version\":\"2012-10-17\",\"Id\":\"default\",\"Statement\":[{\"Sid\":\"xxxx\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"sns.amazonaws.com\"},\"Action\":\"lambda:InvokeFunction\",\"Resource\":\"arn:aws:lambda:us-east-1:123456789102:function:test\"}]}                        For API details, see                        GetPolicy                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-policy",
                                    "AWS CLITo retrieve the resource-based IAM policy for a function, version, or aliasThe following get-policy example displays policy information about the my-function Lambda function.aws lambda get-policy \\    --function-name my-functionOutput:{    \"Policy\": {        \"Version\":\"2012-10-17\",        \"Id\":\"default\",        \"Statement\":        [            {                \"Sid\":\"iot-events\",                \"Effect\":\"Allow\",                \"Principal\": {\"Service\":\"iotevents.amazonaws.com\"},                \"Action\":\"lambda:InvokeFunction\",                \"Resource\":\"arn:aws:lambda:us-west-2:123456789012:function:my-function\"            }        ]    },    \"RevisionId\": \"93017fc9-59cb-41dc-901b-4845ce4bf668\"}For more information, see Using Resource-based Policies for AWS Lambda in the AWS Lambda Developer Guide.                        For API details, see                        GetPolicy                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "GetProvisionedConcurrencyConfig",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_GetProvisionedConcurrencyConfig_section.html",
                                "sections": [
                                    "The following code examples show how to use GetProvisionedConcurrencyConfig.",
                                    "  1.CLI : get-provisioned-concurrency-config",
                                    "  2.AWS CLI : get-provisioned-concurrency-config",
                                    "  3.PowerShell : C:\\>Get-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"\n",
                                    "  4.Tools for PowerShell : C:\\>Get-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"\n",
                                    "CLIAWS CLITo view a provisioned concurrency configurationThe following get-provisioned-concurrency-config example displays details for the provisioned concurrency configuration for the BLUE alias of the specified function.aws lambda get-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier BLUEOutput:{    \"RequestedProvisionedConcurrentExecutions\": 100,    \"AvailableProvisionedConcurrentExecutions\": 100,    \"AllocatedProvisionedConcurrentExecutions\": 100,    \"Status\": \"READY\",    \"LastModified\": \"2019-12-31T20:28:49+0000\"}                        For API details, see                        GetProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example gets the provisioned Concurrency Configuration for the specified Alias of the Lambda Function.C:\\>Get-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -Qualifier \"NewAlias1\"Output:AllocatedProvisionedConcurrentExecutions : 0AvailableProvisionedConcurrentExecutions : 0LastModified                             : 2020-01-15T03:21:26+0000RequestedProvisionedConcurrentExecutions : 70Status                                   : IN_PROGRESSStatusReason                             :                        For API details, see                        GetProvisionedConcurrencyConfig                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : get-provisioned-concurrency-config",
                                    "AWS CLITo view a provisioned concurrency configurationThe following get-provisioned-concurrency-config example displays details for the provisioned concurrency configuration for the BLUE alias of the specified function.aws lambda get-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier BLUEOutput:{    \"RequestedProvisionedConcurrentExecutions\": 100,    \"AvailableProvisionedConcurrentExecutions\": 100,    \"AllocatedProvisionedConcurrentExecutions\": 100,    \"Status\": \"READY\",    \"LastModified\": \"2019-12-31T20:28:49+0000\"}                        For API details, see                        GetProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "Invoke",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_Invoke_section.html",
                                "sections": [
                                    "The following code examples show how to use Invoke.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::InvokeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetLogType(logType);\n        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(\n                \"FunctionTest\");\n        *payload << jsonPayload.View().WriteReadable();\n        request.SetBody(payload);\n        request.SetContentType(\"application/json\");\n        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);\n\n        if (outcome.IsSuccess()) {\n            invokeResult = std::move(outcome.GetResult());\n            result = true;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with Lambda::InvokeRequest. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            break;\n        }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::InvokeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        request.SetLogType(logType);\n        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(\n                \"FunctionTest\");\n        *payload << jsonPayload.View().WriteReadable();\n        request.SetBody(payload);\n        request.SetContentType(\"application/json\");\n        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);\n\n        if (outcome.IsSuccess()) {\n            invokeResult = std::move(outcome.GetResult());\n            result = true;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with Lambda::InvokeRequest. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n            break;\n        }\n\n",
                                    "  5.CLI : invoke",
                                    "  6.AWS CLI : invoke",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// Invoke invokes the Lambda function specified by functionName, passing the parameters\n// as a JSON payload. When getLog is true, types.LogTypeTail is specified, which tells\n// Lambda to include the last few log lines in the returned result.\nfunc (wrapper FunctionWrapper) Invoke(ctx context.Context, functionName string, parameters any, getLog bool) *lambda.InvokeOutput {\n\tlogType := types.LogTypeNone\n\tif getLog {\n\t\tlogType = types.LogTypeTail\n\t}\n\tpayload, err := json.Marshal(parameters)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't marshal parameters to JSON. Here's why %v\\n\", err)\n\t}\n\tinvokeOutput, err := wrapper.LambdaClient.Invoke(ctx, &lambda.InvokeInput{\n\t\tFunctionName: aws.String(functionName),\n\t\tLogType:      logType,\n\t\tPayload:      payload,\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't invoke function %v. Here's why: %v\\n\", functionName, err)\n\t}\n\treturn invokeOutput\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// Invoke invokes the Lambda function specified by functionName, passing the parameters\n// as a JSON payload. When getLog is true, types.LogTypeTail is specified, which tells\n// Lambda to include the last few log lines in the returned result.\nfunc (wrapper FunctionWrapper) Invoke(ctx context.Context, functionName string, parameters any, getLog bool) *lambda.InvokeOutput {\n\tlogType := types.LogTypeNone\n\tif getLog {\n\t\tlogType = types.LogTypeTail\n\t}\n\tpayload, err := json.Marshal(parameters)\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't marshal parameters to JSON. Here's why %v\\n\", err)\n\t}\n\tinvokeOutput, err := wrapper.LambdaClient.Invoke(ctx, &lambda.InvokeInput{\n\t\tFunctionName: aws.String(functionName),\n\t\tLogType:      logType,\n\t\tPayload:      payload,\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't invoke function %v. Here's why: %v\\n\", functionName, err)\n\t}\n\treturn invokeOutput\n}\n\n\n",
                                    "  9.Java :     /**\n     * Invokes a specific AWS Lambda function.\n     *\n     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to be invoked\n     */\n    public static void invokeFunction(LambdaClient awsLambda, String functionName) {\n        InvokeResponse res;\n        try {\n            // Need a SdkBytes instance for the payload.\n            JSONObject jsonObj = new JSONObject();\n            jsonObj.put(\"inputValue\", \"2000\");\n            String json = jsonObj.toString();\n            SdkBytes payload = SdkBytes.fromUtf8String(json);\n\n            InvokeRequest request = InvokeRequest.builder()\n                .functionName(functionName)\n                .payload(payload)\n                .build();\n\n            res = awsLambda.invoke(request);\n            String value = res.payload().asUtf8String();\n            System.out.println(value);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Invokes a specific AWS Lambda function.\n     *\n     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to be invoked\n     */\n    public static void invokeFunction(LambdaClient awsLambda, String functionName) {\n        InvokeResponse res;\n        try {\n            // Need a SdkBytes instance for the payload.\n            JSONObject jsonObj = new JSONObject();\n            jsonObj.put(\"inputValue\", \"2000\");\n            String json = jsonObj.toString();\n            SdkBytes payload = SdkBytes.fromUtf8String(json);\n\n            InvokeRequest request = InvokeRequest.builder()\n                .functionName(functionName)\n                .payload(payload)\n                .build();\n\n            res = awsLambda.invoke(request);\n            String value = res.payload().asUtf8String();\n            System.out.println(value);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  11.JavaScript : const invoke = async (funcName, payload) => {\n  const client = new LambdaClient({});\n  const command = new InvokeCommand({\n    FunctionName: funcName,\n    Payload: JSON.stringify(payload),\n    LogType: LogType.Tail,\n  });\n\n  const { Payload, LogResult } = await client.send(command);\n  const result = Buffer.from(Payload).toString();\n  const logs = Buffer.from(LogResult, \"base64\").toString();\n  return { logs, result };\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : const invoke = async (funcName, payload) => {\n  const client = new LambdaClient({});\n  const command = new InvokeCommand({\n    FunctionName: funcName,\n    Payload: JSON.stringify(payload),\n    LogType: LogType.Tail,\n  });\n\n  const { Payload, LogResult } = await client.send(command);\n  const result = Buffer.from(Payload).toString();\n  const logs = Buffer.from(LogResult, \"base64\").toString();\n  return { logs, result };\n};\n\n",
                                    "  13.Kotlin : suspend fun invokeFunction(functionNameVal: String) {\n    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"\n    val byteArray = json.trimIndent().encodeToByteArray()\n    val request =\n        InvokeRequest {\n            functionName = functionNameVal\n            logType = LogType.Tail\n            payload = byteArray\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val res = awsLambda.invoke(request)\n        println(\"${res.payload?.toString(Charsets.UTF_8)}\")\n        println(\"The log result is ${res.logResult}\")\n    }\n}\n\n",
                                    "  14.SDK for Kotlin : suspend fun invokeFunction(functionNameVal: String) {\n    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"\n    val byteArray = json.trimIndent().encodeToByteArray()\n    val request =\n        InvokeRequest {\n            functionName = functionNameVal\n            logType = LogType.Tail\n            payload = byteArray\n        }\n\n    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->\n        val res = awsLambda.invoke(request)\n        println(\"${res.payload?.toString(Charsets.UTF_8)}\")\n        println(\"The log result is ${res.logResult}\")\n    }\n}\n\n",
                                    "  15.PHP :     public function invoke($functionName, $params, $logType = 'None')\n    {\n        return $this->lambdaClient->invoke([\n            'FunctionName' => $functionName,\n            'Payload' => json_encode($params),\n            'LogType' => $logType,\n        ]);\n    }\n\n",
                                    "  16.SDK for PHP :     public function invoke($functionName, $params, $logType = 'None')\n    {\n        return $this->lambdaClient->invoke([\n            'FunctionName' => $functionName,\n            'Payload' => json_encode($params),\n            'LogType' => $logType,\n        ]);\n    }\n\n",
                                    "  17.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def invoke_function(self, function_name, function_params, get_log=False):\n        \"\"\"\n        Invokes a Lambda function.\n\n        :param function_name: The name of the function to invoke.\n        :param function_params: The parameters of the function as a dict. This dict\n                                is serialized to JSON before it is sent to Lambda.\n        :param get_log: When true, the last 4 KB of the execution log are included in\n                        the response.\n        :return: The response from the function invocation.\n        \"\"\"\n        try:\n            response = self.lambda_client.invoke(\n                FunctionName=function_name,\n                Payload=json.dumps(function_params),\n                LogType=\"Tail\" if get_log else \"None\",\n            )\n            logger.info(\"Invoked function %s.\", function_name)\n        except ClientError:\n            logger.exception(\"Couldn't invoke function %s.\", function_name)\n            raise\n        return response\n\n\n",
                                    "  18.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def invoke_function(self, function_name, function_params, get_log=False):\n        \"\"\"\n        Invokes a Lambda function.\n\n        :param function_name: The name of the function to invoke.\n        :param function_params: The parameters of the function as a dict. This dict\n                                is serialized to JSON before it is sent to Lambda.\n        :param get_log: When true, the last 4 KB of the execution log are included in\n                        the response.\n        :return: The response from the function invocation.\n        \"\"\"\n        try:\n            response = self.lambda_client.invoke(\n                FunctionName=function_name,\n                Payload=json.dumps(function_params),\n                LogType=\"Tail\" if get_log else \"None\",\n            )\n            logger.info(\"Invoked function %s.\", function_name)\n        except ClientError:\n            logger.exception(\"Couldn't invoke function %s.\", function_name)\n            raise\n        return response\n\n\n",
                                    "  19.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Invokes a Lambda function.\n  # @param function_name [String] The name of the function to invoke.\n  # @param payload [nil] Payload containing runtime parameters.\n  # @return [Object] The response from the function invocation.\n  def invoke_function(function_name, payload = nil)\n    params = { function_name: function_name }\n    params[:payload] = payload unless payload.nil?\n    @lambda_client.invoke(params)\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error executing #{function_name}:\\n #{e.message}\")\n  end\n\n",
                                    "  20.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Invokes a Lambda function.\n  # @param function_name [String] The name of the function to invoke.\n  # @param payload [nil] Payload containing runtime parameters.\n  # @return [Object] The response from the function invocation.\n  def invoke_function(function_name, payload = nil)\n    params = { function_name: function_name }\n    params[:payload] = payload unless payload.nil?\n    @lambda_client.invoke(params)\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error executing #{function_name}:\\n #{e.message}\")\n  end\n\n",
                                    "  21.Rust :     /** Invoke the lambda function using calculator InvokeArgs. */\n    pub async fn invoke(&self, args: InvokeArgs) -> Result<InvokeOutput, anyhow::Error> {\n        info!(?args, \"Invoking {}\", self.lambda_name);\n        let payload = serde_json::to_string(&args)?;\n        debug!(?payload, \"Sending payload\");\n        self.lambda_client\n            .invoke()\n            .function_name(self.lambda_name.clone())\n            .payload(Blob::new(payload))\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\nfn log_invoke_output(invoke: &InvokeOutput, message: &str) {\n    if let Some(payload) = invoke.payload().cloned() {\n        let payload = String::from_utf8(payload.into_inner());\n        info!(?payload, message);\n    } else {\n        info!(\"Could not extract payload\")\n    }\n    if let Some(logs) = invoke.log_result() {\n        debug!(?logs, \"Invoked function logs\")\n    } else {\n        debug!(\"Invoked function had no logs\")\n    }\n}\n\n",
                                    "  22.SDK for Rust :     /** Invoke the lambda function using calculator InvokeArgs. */\n    pub async fn invoke(&self, args: InvokeArgs) -> Result<InvokeOutput, anyhow::Error> {\n        info!(?args, \"Invoking {}\", self.lambda_name);\n        let payload = serde_json::to_string(&args)?;\n        debug!(?payload, \"Sending payload\");\n        self.lambda_client\n            .invoke()\n            .function_name(self.lambda_name.clone())\n            .payload(Blob::new(payload))\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\nfn log_invoke_output(invoke: &InvokeOutput, message: &str) {\n    if let Some(payload) = invoke.payload().cloned() {\n        let payload = String::from_utf8(payload.into_inner());\n        info!(?payload, message);\n    } else {\n        info!(\"Could not extract payload\")\n    }\n    if let Some(logs) = invoke.log_result() {\n        debug!(?logs, \"Invoked function logs\")\n    } else {\n        debug!(\"Invoked function had no logs\")\n    }\n}\n\n",
                                    "  23.SAP ABAP :     TRY.\n        DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(\n          `{`  &&\n            `\"action\": \"increment\",`  &&\n            `\"number\": 10` &&\n          `}`\n        ).\n        oo_result =  lo_lmd->invoke(                  \" oo_result is returned for testing purposes. \"\n                 iv_functionname = iv_function_name\n                 iv_payload = lv_json\n             ).\n        MESSAGE 'Lambda function invoked.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvrequestcontex.\n        MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidzipfileex.\n        MESSAGE 'The deployment package could not be unzipped.' TYPE 'E'.\n      CATCH /aws1/cx_lmdrequesttoolargeex.\n        MESSAGE 'Invoke request body JSON input limit was exceeded by the request payload.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n      CATCH /aws1/cx_lmdunsuppedmediatyp00.\n        MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  24.SDK for SAP ABAP :     TRY.\n        DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(\n          `{`  &&\n            `\"action\": \"increment\",`  &&\n            `\"number\": 10` &&\n          `}`\n        ).\n        oo_result =  lo_lmd->invoke(                  \" oo_result is returned for testing purposes. \"\n                 iv_functionname = iv_function_name\n                 iv_payload = lv_json\n             ).\n        MESSAGE 'Lambda function invoked.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvrequestcontex.\n        MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidzipfileex.\n        MESSAGE 'The deployment package could not be unzipped.' TYPE 'E'.\n      CATCH /aws1/cx_lmdrequesttoolargeex.\n        MESSAGE 'Invoke request body JSON input limit was exceeded by the request payload.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n      CATCH /aws1/cx_lmdunsuppedmediatyp00.\n        MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Invoke a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// invoke.</param    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>    /// <returns>A System Threading Task.</returns>    public async Task<string> InvokeFunctionAsync(        string functionName,        string parameters)    {        var payload = parameters;        var request = new InvokeRequest        {            FunctionName = functionName,            Payload = payload,        };        var response = await _lambdaService.InvokeAsync(request);        MemoryStream stream = response.Payload;        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());        return returnValue;    }                        For API details, see                        Invoke                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);        Aws::Lambda::Model::InvokeRequest request;        request.SetFunctionName(LAMBDA_NAME);        request.SetLogType(logType);        std::shared_ptr<Aws::IOStream> payload = Aws::MakeShared<Aws::StringStream>(                \"FunctionTest\");        *payload << jsonPayload.View().WriteReadable();        request.SetBody(payload);        request.SetContentType(\"application/json\");        Aws::Lambda::Model::InvokeOutcome outcome = client.Invoke(request);        if (outcome.IsSuccess()) {            invokeResult = std::move(outcome.GetResult());            result = true;            break;        }        else {            std::cerr << \"Error with Lambda::InvokeRequest. \"                      << outcome.GetError().GetMessage()                      << std::endl;            break;        }                        For API details, see                        Invoke                        in AWS SDK for C++ API Reference.                    CLIAWS CLIExample 1: To invoke a Lambda function synchronouslyThe following invoke example invokes the my-function function synchronously. The cli-binary-format option is required if you're using AWS CLI version 2. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide.aws lambda invoke \\    --function-name my-function \\    --cli-binary-format raw-in-base64-out \\    --payload '{ \"name\": \"Bob\" }' \\    response.jsonOutput:{    \"ExecutedVersion\": \"$LATEST\",    \"StatusCode\": 200}For more information, see Synchronous Invocation in the AWS Lambda Developer Guide.Example 2: To invoke a Lambda function asynchronouslyThe following invoke example invokes the my-function function asynchronously. The cli-binary-format option is required if you're using AWS CLI version 2. For more information, see AWS CLI supported global command line options in the AWS Command Line Interface User Guide.aws lambda invoke \\    --function-name my-function \\    --invocation-type Event \\    --cli-binary-format raw-in-base64-out \\    --payload '{ \"name\": \"Bob\" }' \\    response.jsonOutput:{    \"StatusCode\": 202}For more information, see Asynchronous Invocation in the AWS Lambda Developer Guide.                        For API details, see                        Invoke                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// Invoke invokes the Lambda function specified by functionName, passing the parameters// as a JSON payload. When getLog is true, types.LogTypeTail is specified, which tells// Lambda to include the last few log lines in the returned result.func (wrapper FunctionWrapper) Invoke(ctx context.Context, functionName string, parameters any, getLog bool) *lambda.InvokeOutput {\tlogType := types.LogTypeNone\tif getLog {\t\tlogType = types.LogTypeTail\t}\tpayload, err := json.Marshal(parameters)\tif err != nil {\t\tlog.Panicf(\"Couldn't marshal parameters to JSON. Here's why %v\\n\", err)\t}\tinvokeOutput, err := wrapper.LambdaClient.Invoke(ctx, &lambda.InvokeInput{\t\tFunctionName: aws.String(functionName),\t\tLogType:      logType,\t\tPayload:      payload,\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't invoke function %v. Here's why: %v\\n\", functionName, err)\t}\treturn invokeOutput}                        For API details, see                        Invoke                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Invokes a specific AWS Lambda function.     *     * @param awsLambda    an instance of {@link LambdaClient} to interact with the AWS Lambda service     * @param functionName the name of the AWS Lambda function to be invoked     */    public static void invokeFunction(LambdaClient awsLambda, String functionName) {        InvokeResponse res;        try {            // Need a SdkBytes instance for the payload.            JSONObject jsonObj = new JSONObject();            jsonObj.put(\"inputValue\", \"2000\");            String json = jsonObj.toString();            SdkBytes payload = SdkBytes.fromUtf8String(json);            InvokeRequest request = InvokeRequest.builder()                .functionName(functionName)                .payload(payload)                .build();            res = awsLambda.invoke(request);            String value = res.payload().asUtf8String();            System.out.println(value);        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        Invoke                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const invoke = async (funcName, payload) => {  const client = new LambdaClient({});  const command = new InvokeCommand({    FunctionName: funcName,    Payload: JSON.stringify(payload),    LogType: LogType.Tail,  });  const { Payload, LogResult } = await client.send(command);  const result = Buffer.from(Payload).toString();  const logs = Buffer.from(LogResult, \"base64\").toString();  return { logs, result };};                        For API details, see                        Invoke                        in AWS SDK for JavaScript API Reference.                    KotlinSDK for KotlinNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    suspend fun invokeFunction(functionNameVal: String) {    val json = \"\"\"{\"inputValue\":\"1000\"}\"\"\"    val byteArray = json.trimIndent().encodeToByteArray()    val request =        InvokeRequest {            functionName = functionNameVal            logType = LogType.Tail            payload = byteArray        }    LambdaClient { region = \"us-west-2\" }.use { awsLambda ->        val res = awsLambda.invoke(request)        println(\"${res.payload?.toString(Charsets.UTF_8)}\")        println(\"The log result is ${res.logResult}\")    }}                        For API details, see                        Invoke                        in AWS SDK for Kotlin API reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function invoke($functionName, $params, $logType = 'None')    {        return $this->lambdaClient->invoke([            'FunctionName' => $functionName,            'Payload' => json_encode($params),            'LogType' => $logType,        ]);    }                        For API details, see                        Invoke                        in AWS SDK for PHP API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def invoke_function(self, function_name, function_params, get_log=False):        \"\"\"        Invokes a Lambda function.        :param function_name: The name of the function to invoke.        :param function_params: The parameters of the function as a dict. This dict                                is serialized to JSON before it is sent to Lambda.        :param get_log: When true, the last 4 KB of the execution log are included in                        the response.        :return: The response from the function invocation.        \"\"\"        try:            response = self.lambda_client.invoke(                FunctionName=function_name,                Payload=json.dumps(function_params),                LogType=\"Tail\" if get_log else \"None\",            )            logger.info(\"Invoked function %s.\", function_name)        except ClientError:            logger.exception(\"Couldn't invoke function %s.\", function_name)            raise        return response                        For API details, see                        Invoke                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Invokes a Lambda function.  # @param function_name [String] The name of the function to invoke.  # @param payload [nil] Payload containing runtime parameters.  # @return [Object] The response from the function invocation.  def invoke_function(function_name, payload = nil)    params = { function_name: function_name }    params[:payload] = payload unless payload.nil?    @lambda_client.invoke(params)  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error executing #{function_name}:\\n #{e.message}\")  end                        For API details, see                        Invoke                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** Invoke the lambda function using calculator InvokeArgs. */    pub async fn invoke(&self, args: InvokeArgs) -> Result<InvokeOutput, anyhow::Error> {        info!(?args, \"Invoking {}\", self.lambda_name);        let payload = serde_json::to_string(&args)?;        debug!(?payload, \"Sending payload\");        self.lambda_client            .invoke()            .function_name(self.lambda_name.clone())            .payload(Blob::new(payload))            .send()            .await            .map_err(anyhow::Error::from)    }fn log_invoke_output(invoke: &InvokeOutput, message: &str) {    if let Some(payload) = invoke.payload().cloned() {        let payload = String::from_utf8(payload.into_inner());        info!(?payload, message);    } else {        info!(\"Could not extract payload\")    }    if let Some(logs) = invoke.log_result() {        debug!(?logs, \"Invoked function logs\")    } else {        debug!(\"Invoked function had no logs\")    }}                        For API details, see                        Invoke                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        DATA(lv_json) = /aws1/cl_rt_util=>string_to_xstring(          `{`  &&            `\"action\": \"increment\",`  &&            `\"number\": 10` &&          `}`        ).        oo_result =  lo_lmd->invoke(                  \" oo_result is returned for testing purposes. \"                 iv_functionname = iv_function_name                 iv_payload = lv_json             ).        MESSAGE 'Lambda function invoked.' TYPE 'I'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdinvrequestcontex.        MESSAGE 'Unable to parse request body as JSON.' TYPE 'E'.      CATCH /aws1/cx_lmdinvalidzipfileex.        MESSAGE 'The deployment package could not be unzipped.' TYPE 'E'.      CATCH /aws1/cx_lmdrequesttoolargeex.        MESSAGE 'Invoke request body JSON input limit was exceeded by the request payload.' TYPE 'E'.      CATCH /aws1/cx_lmdresourceconflictex.        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.      CATCH /aws1/cx_lmdresourcenotfoundex.        MESSAGE 'The requested resource does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.      CATCH /aws1/cx_lmdunsuppedmediatyp00.        MESSAGE 'Invoke request body does not have JSON as its content type.' TYPE 'E'.    ENDTRY.                        For API details, see                        Invoke                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Invoke a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to\n    /// invoke.</param\n    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>\n    /// <returns>A System Threading Task.</returns>\n    public async Task<string> InvokeFunctionAsync(\n        string functionName,\n        string parameters)\n    {\n        var payload = parameters;\n        var request = new InvokeRequest\n        {\n            FunctionName = functionName,\n            Payload = payload,\n        };\n\n        var response = await _lambdaService.InvokeAsync(request);\n        MemoryStream stream = response.Payload;\n        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());\n        return returnValue;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Invoke a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to    /// invoke.</param    /// <param name=\"parameters\">The parameter values that will be passed to the function.</param>    /// <returns>A System Threading Task.</returns>    public async Task<string> InvokeFunctionAsync(        string functionName,        string parameters)    {        var payload = parameters;        var request = new InvokeRequest        {            FunctionName = functionName,            Payload = payload,        };        var response = await _lambdaService.InvokeAsync(request);        MemoryStream stream = response.Payload;        string returnValue = System.Text.Encoding.UTF8.GetString(stream.ToArray());        return returnValue;    }                        For API details, see                        Invoke                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "ListFunctions",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_ListFunctions_section.html",
                                "sections": [
                                    "The following code examples show how to use ListFunctions.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    std::vector<Aws::String> functions;\n    Aws::String marker;\n\n    do {\n        Aws::Lambda::Model::ListFunctionsRequest request;\n        if (!marker.empty()) {\n            request.SetMarker(marker);\n        }\n\n        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(\n                request);\n\n        if (outcome.IsSuccess()) {\n            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();\n            std::cout << result.GetFunctions().size()\n                      << \" lambda functions were retrieved.\" << std::endl;\n\n            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {\n                functions.push_back(functionConfiguration.GetFunctionName());\n                std::cout << functions.size() << \"  \"\n                          << functionConfiguration.GetDescription() << std::endl;\n                std::cout << \"   \"\n                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(\n                                  functionConfiguration.GetRuntime()) << \": \"\n                          << functionConfiguration.GetHandler()\n                          << std::endl;\n            }\n            marker = result.GetNextMarker();\n        }\n        else {\n            std::cerr << \"Error with Lambda::ListFunctions. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    } while (!marker.empty());\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n    std::vector<Aws::String> functions;\n    Aws::String marker;\n\n    do {\n        Aws::Lambda::Model::ListFunctionsRequest request;\n        if (!marker.empty()) {\n            request.SetMarker(marker);\n        }\n\n        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(\n                request);\n\n        if (outcome.IsSuccess()) {\n            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();\n            std::cout << result.GetFunctions().size()\n                      << \" lambda functions were retrieved.\" << std::endl;\n\n            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {\n                functions.push_back(functionConfiguration.GetFunctionName());\n                std::cout << functions.size() << \"  \"\n                          << functionConfiguration.GetDescription() << std::endl;\n                std::cout << \"   \"\n                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(\n                                  functionConfiguration.GetRuntime()) << \": \"\n                          << functionConfiguration.GetHandler()\n                          << std::endl;\n            }\n            marker = result.GetNextMarker();\n        }\n        else {\n            std::cerr << \"Error with Lambda::ListFunctions. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n    } while (!marker.empty());\n\n",
                                    "  5.CLI : list-functions",
                                    "  6.AWS CLI : list-functions",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// ListFunctions lists up to maxItems functions for the account. This function uses a\n// lambda.ListFunctionsPaginator to paginate the results.\nfunc (wrapper FunctionWrapper) ListFunctions(ctx context.Context, maxItems int) []types.FunctionConfiguration {\n\tvar functions []types.FunctionConfiguration\n\tpaginator := lambda.NewListFunctionsPaginator(wrapper.LambdaClient, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tfor paginator.HasMorePages() && len(functions) < maxItems {\n\t\tpageOutput, err := paginator.NextPage(ctx)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\t}\n\t\tfunctions = append(functions, pageOutput.Functions...)\n\t}\n\treturn functions\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// ListFunctions lists up to maxItems functions for the account. This function uses a\n// lambda.ListFunctionsPaginator to paginate the results.\nfunc (wrapper FunctionWrapper) ListFunctions(ctx context.Context, maxItems int) []types.FunctionConfiguration {\n\tvar functions []types.FunctionConfiguration\n\tpaginator := lambda.NewListFunctionsPaginator(wrapper.LambdaClient, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tfor paginator.HasMorePages() && len(functions) < maxItems {\n\t\tpageOutput, err := paginator.NextPage(ctx)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\t}\n\t\tfunctions = append(functions, pageOutput.Functions...)\n\t}\n\treturn functions\n}\n\n\n",
                                    "  9.JavaScript : const listFunctions = () => {\n  const client = new LambdaClient({});\n  const command = new ListFunctionsCommand({});\n\n  return client.send(command);\n};\n\n",
                                    "  10.SDK for JavaScript (v3) : const listFunctions = () => {\n  const client = new LambdaClient({});\n  const command = new ListFunctionsCommand({});\n\n  return client.send(command);\n};\n\n",
                                    "  11.PHP :     public function listFunctions($maxItems = 50, $marker = null)\n    {\n        if (is_null($marker)) {\n            return $this->lambdaClient->listFunctions([\n                'MaxItems' => $maxItems,\n            ]);\n        }\n\n        return $this->lambdaClient->listFunctions([\n            'Marker' => $marker,\n            'MaxItems' => $maxItems,\n        ]);\n    }\n\n",
                                    "  12.SDK for PHP :     public function listFunctions($maxItems = 50, $marker = null)\n    {\n        if (is_null($marker)) {\n            return $this->lambdaClient->listFunctions([\n                'MaxItems' => $maxItems,\n            ]);\n        }\n\n        return $this->lambdaClient->listFunctions([\n            'Marker' => $marker,\n            'MaxItems' => $maxItems,\n        ]);\n    }\n\n",
                                    "  13.PowerShell : Get-LMFunctionList | Sort-Object -Property CodeSize | Select-Object FunctionName, RunTime, Timeout, CodeSize\n",
                                    "  14.Tools for PowerShell : Get-LMFunctionList | Sort-Object -Property CodeSize | Select-Object FunctionName, RunTime, Timeout, CodeSize\n",
                                    "  15.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def list_functions(self):\n        \"\"\"\n        Lists the Lambda functions for the current account.\n        \"\"\"\n        try:\n            func_paginator = self.lambda_client.get_paginator(\"list_functions\")\n            for func_page in func_paginator.paginate():\n                for func in func_page[\"Functions\"]:\n                    print(func[\"FunctionName\"])\n                    desc = func.get(\"Description\")\n                    if desc:\n                        print(f\"\\t{desc}\")\n                    print(f\"\\t{func['Runtime']}: {func['Handler']}\")\n        except ClientError as err:\n            logger.error(\n                \"Couldn't list functions. Here's why: %s: %s\",\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n\n\n",
                                    "  16.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def list_functions(self):\n        \"\"\"\n        Lists the Lambda functions for the current account.\n        \"\"\"\n        try:\n            func_paginator = self.lambda_client.get_paginator(\"list_functions\")\n            for func_page in func_paginator.paginate():\n                for func in func_page[\"Functions\"]:\n                    print(func[\"FunctionName\"])\n                    desc = func.get(\"Description\")\n                    if desc:\n                        print(f\"\\t{desc}\")\n                    print(f\"\\t{func['Runtime']}: {func['Handler']}\")\n        except ClientError as err:\n            logger.error(\n                \"Couldn't list functions. Here's why: %s: %s\",\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n\n\n",
                                    "  17.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Lists the Lambda functions for the current account.\n  def list_functions\n    functions = []\n    @lambda_client.list_functions.each do |response|\n      response['functions'].each do |function|\n        functions.append(function['function_name'])\n      end\n    end\n    functions\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error listing functions:\\n #{e.message}\")\n  end\n\n",
                                    "  18.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Lists the Lambda functions for the current account.\n  def list_functions\n    functions = []\n    @lambda_client.list_functions.each do |response|\n      response['functions'].each do |function|\n        functions.append(function['function_name'])\n      end\n    end\n    functions\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error listing functions:\\n #{e.message}\")\n  end\n\n",
                                    "  19.Rust :     /** List all Lambda functions in the current Region. */\n    pub async fn list_functions(&self) -> Result<ListFunctionsOutput, anyhow::Error> {\n        info!(\"Listing lambda functions\");\n        self.lambda_client\n            .list_functions()\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\n",
                                    "  20.SDK for Rust :     /** List all Lambda functions in the current Region. */\n    pub async fn list_functions(&self) -> Result<ListFunctionsOutput, anyhow::Error> {\n        info!(\"Listing lambda functions\");\n        self.lambda_client\n            .list_functions()\n            .send()\n            .await\n            .map_err(anyhow::Error::from)\n    }\n\n",
                                    "  21.SAP ABAP :     TRY.\n        oo_result =  lo_lmd->listfunctions( ).       \" oo_result is returned for testing purposes. \"\n        DATA(lt_functions) = oo_result->get_functions( ).\n        MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  22.SDK for SAP ABAP :     TRY.\n        oo_result =  lo_lmd->listfunctions( ).       \" oo_result is returned for testing purposes. \"\n        DATA(lt_functions) = oo_result->get_functions( ).\n        MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Get a list of Lambda functions.    /// </summary>    /// <returns>A list of FunctionConfiguration objects.</returns>    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()    {        var functionList = new List<FunctionConfiguration>();        var functionPaginator =            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());        await foreach (var function in functionPaginator.Functions)        {            functionList.Add(function);        }        return functionList;    }                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);    std::vector<Aws::String> functions;    Aws::String marker;    do {        Aws::Lambda::Model::ListFunctionsRequest request;        if (!marker.empty()) {            request.SetMarker(marker);        }        Aws::Lambda::Model::ListFunctionsOutcome outcome = client.ListFunctions(                request);        if (outcome.IsSuccess()) {            const Aws::Lambda::Model::ListFunctionsResult &result = outcome.GetResult();            std::cout << result.GetFunctions().size()                      << \" lambda functions were retrieved.\" << std::endl;            for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: result.GetFunctions()) {                functions.push_back(functionConfiguration.GetFunctionName());                std::cout << functions.size() << \"  \"                          << functionConfiguration.GetDescription() << std::endl;                std::cout << \"   \"                          << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                  functionConfiguration.GetRuntime()) << \": \"                          << functionConfiguration.GetHandler()                          << std::endl;            }            marker = result.GetNextMarker();        }        else {            std::cerr << \"Error with Lambda::ListFunctions. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }    } while (!marker.empty());                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    CLIAWS CLITo retrieve a list of Lambda functionsThe following list-functions example displays a list of all of the functions for the current user.aws lambda list-functionsOutput:{    \"Functions\": [        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"$LATEST\",            \"CodeSha256\": \"dBG9m8SGdmlEjw/JYXlhhvCrAv5TxvXsbL/RMr0fT/I=\",            \"FunctionName\": \"helloworld\",            \"MemorySize\": 128,            \"RevisionId\": \"1718e831-badf-4253-9518-d0644210af7b\",            \"CodeSize\": 294,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:helloworld\",            \"Handler\": \"helloworld.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/MyTestFunction-role-zgur6bf4\",            \"Timeout\": 3,            \"LastModified\": \"2023-09-23T18:32:33.857+0000\",            \"Runtime\": \"nodejs18.x\",            \"Description\": \"\"        },        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"$LATEST\",            \"CodeSha256\": \"sU0cJ2/hOZevwV/lTxCuQqK3gDZP3i8gUoqUUVRmY6E=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"93017fc9-59cb-41dc-901b-4845ce4bf668\",            \"CodeSize\": 266,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2023-10-01T16:47:28.490+0000\",            \"Runtime\": \"nodejs18.x\",            \"Description\": \"\"        },        {            \"Layers\": [                {                    \"CodeSize\": 41784542,                    \"Arn\": \"arn:aws:lambda:us-west-2:420165488524:layer:AWSLambda-Python37-SciPy1x:2\"                },                {                    \"CodeSize\": 4121,                    \"Arn\": \"arn:aws:lambda:us-west-2:123456789012:layer:pythonLayer:1\"                }            ],            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"$LATEST\",            \"CodeSha256\": \"ZQukCqxtkqFgyF2cU41Avj99TKQ/hNihPtDtRcc08mI=\",            \"FunctionName\": \"my-python-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 128,            \"RevisionId\": \"80b4eabc-acf7-4ea8-919a-e874c213707d\",            \"CodeSize\": 299,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-python-function\",            \"Handler\": \"lambda_function.lambda_handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/my-python-function-role-z5g7dr6n\",            \"Timeout\": 3,            \"LastModified\": \"2023-10-01T19:40:41.643+0000\",            \"Runtime\": \"python3.11\",            \"Description\": \"\"        }    ]}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        ListFunctions                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// ListFunctions lists up to maxItems functions for the account. This function uses a// lambda.ListFunctionsPaginator to paginate the results.func (wrapper FunctionWrapper) ListFunctions(ctx context.Context, maxItems int) []types.FunctionConfiguration {\tvar functions []types.FunctionConfiguration\tpaginator := lambda.NewListFunctionsPaginator(wrapper.LambdaClient, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tfor paginator.HasMorePages() && len(functions) < maxItems {\t\tpageOutput, err := paginator.NextPage(ctx)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\t}\t\tfunctions = append(functions, pageOutput.Functions...)\t}\treturn functions}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const listFunctions = () => {  const client = new LambdaClient({});  const command = new ListFunctionsCommand({});  return client.send(command);};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function listFunctions($maxItems = 50, $marker = null)    {        if (is_null($marker)) {            return $this->lambdaClient->listFunctions([                'MaxItems' => $maxItems,            ]);        }        return $this->lambdaClient->listFunctions([            'Marker' => $marker,            'MaxItems' => $maxItems,        ]);    }                        For API details, see                        ListFunctions                        in AWS SDK for PHP API Reference.                    PowerShellTools for PowerShellExample 1: This sample displays all the Lambda functions with sorted code sizeGet-LMFunctionList | Sort-Object -Property CodeSize | Select-Object FunctionName, RunTime, Timeout, CodeSizeOutput:FunctionName                                                 Runtime   Timeout CodeSize------------                                                 -------   ------- --------test                                                         python2.7       3      243MylambdaFunction123                                          python3.8     600      659myfuncpython1                                                python3.8     303      675                        For API details, see                        ListFunctions                        in AWS Tools for PowerShell Cmdlet Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def list_functions(self):        \"\"\"        Lists the Lambda functions for the current account.        \"\"\"        try:            func_paginator = self.lambda_client.get_paginator(\"list_functions\")            for func_page in func_paginator.paginate():                for func in func_page[\"Functions\"]:                    print(func[\"FunctionName\"])                    desc = func.get(\"Description\")                    if desc:                        print(f\"\\t{desc}\")                    print(f\"\\t{func['Runtime']}: {func['Handler']}\")        except ClientError as err:            logger.error(                \"Couldn't list functions. Here's why: %s: %s\",                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raise                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Lists the Lambda functions for the current account.  def list_functions    functions = []    @lambda_client.list_functions.each do |response|      response['functions'].each do |function|        functions.append(function['function_name'])      end    end    functions  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error listing functions:\\n #{e.message}\")  end                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** List all Lambda functions in the current Region. */    pub async fn list_functions(&self) -> Result<ListFunctionsOutput, anyhow::Error> {        info!(\"Listing lambda functions\");        self.lambda_client            .list_functions()            .send()            .await            .map_err(anyhow::Error::from)    }                        For API details, see                        ListFunctions                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        oo_result =  lo_lmd->listfunctions( ).       \" oo_result is returned for testing purposes. \"        DATA(lt_functions) = oo_result->get_functions( ).        MESSAGE 'Retrieved list of Lambda functions.' TYPE 'I'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        ListFunctions                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Get a list of Lambda functions.\n    /// </summary>\n    /// <returns>A list of FunctionConfiguration objects.</returns>\n    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()\n    {\n        var functionList = new List<FunctionConfiguration>();\n\n        var functionPaginator =\n            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());\n        await foreach (var function in functionPaginator.Functions)\n        {\n            functionList.Add(function);\n        }\n\n        return functionList;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Get a list of Lambda functions.    /// </summary>    /// <returns>A list of FunctionConfiguration objects.</returns>    public async Task<List<FunctionConfiguration>> ListFunctionsAsync()    {        var functionList = new List<FunctionConfiguration>();        var functionPaginator =            _lambdaService.Paginators.ListFunctions(new ListFunctionsRequest());        await foreach (var function in functionPaginator.Functions)        {            functionList.Add(function);        }        return functionList;    }                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "ListProvisionedConcurrencyConfigs",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_ListProvisionedConcurrencyConfigs_section.html",
                                "sections": [
                                    "The following code examples show how to use ListProvisionedConcurrencyConfigs.",
                                    "  1.CLI : list-provisioned-concurrency-configs",
                                    "  2.AWS CLI : list-provisioned-concurrency-configs",
                                    "  3.PowerShell : Get-LMProvisionedConcurrencyConfigList -FunctionName \"MylambdaFunction123\"\n",
                                    "  4.Tools for PowerShell : Get-LMProvisionedConcurrencyConfigList -FunctionName \"MylambdaFunction123\"\n",
                                    "CLIAWS CLITo get a list of provisioned concurrency configurationsThe following list-provisioned-concurrency-configs example lists the provisioned concurrency configurations for the specified function.aws lambda list-provisioned-concurrency-configs \\    --function-name my-functionOutput:{    \"ProvisionedConcurrencyConfigs\": [        {            \"FunctionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:my-function:GREEN\",            \"RequestedProvisionedConcurrentExecutions\": 100,            \"AvailableProvisionedConcurrentExecutions\": 100,            \"AllocatedProvisionedConcurrentExecutions\": 100,            \"Status\": \"READY\",            \"LastModified\": \"2019-12-31T20:29:00+0000\"        },        {            \"FunctionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:my-function:BLUE\",            \"RequestedProvisionedConcurrentExecutions\": 100,            \"AvailableProvisionedConcurrentExecutions\": 100,            \"AllocatedProvisionedConcurrentExecutions\": 100,            \"Status\": \"READY\",            \"LastModified\": \"2019-12-31T20:28:49+0000\"        }    ]}                        For API details, see                        ListProvisionedConcurrencyConfigs                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example retrieves the list of provisioned concurrency configurations for a Lambda function.Get-LMProvisionedConcurrencyConfigList -FunctionName \"MylambdaFunction123\"                        For API details, see                        ListProvisionedConcurrencyConfigs                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : list-provisioned-concurrency-configs",
                                    "AWS CLITo get a list of provisioned concurrency configurationsThe following list-provisioned-concurrency-configs example lists the provisioned concurrency configurations for the specified function.aws lambda list-provisioned-concurrency-configs \\    --function-name my-functionOutput:{    \"ProvisionedConcurrencyConfigs\": [        {            \"FunctionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:my-function:GREEN\",            \"RequestedProvisionedConcurrentExecutions\": 100,            \"AvailableProvisionedConcurrentExecutions\": 100,            \"AllocatedProvisionedConcurrentExecutions\": 100,            \"Status\": \"READY\",            \"LastModified\": \"2019-12-31T20:29:00+0000\"        },        {            \"FunctionArn\": \"arn:aws:lambda:us-east-2:123456789012:function:my-function:BLUE\",            \"RequestedProvisionedConcurrentExecutions\": 100,            \"AvailableProvisionedConcurrentExecutions\": 100,            \"AllocatedProvisionedConcurrentExecutions\": 100,            \"Status\": \"READY\",            \"LastModified\": \"2019-12-31T20:28:49+0000\"        }    ]}                        For API details, see                        ListProvisionedConcurrencyConfigs                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "ListTags",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_ListTags_section.html",
                                "sections": [
                                    "The following code examples show how to use ListTags.",
                                    "  1.CLI : list-tags",
                                    "  2.AWS CLI : list-tags",
                                    "  3.PowerShell : Get-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\"\n",
                                    "  4.Tools for PowerShell : Get-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\"\n",
                                    "CLIAWS CLITo retrieve the list of tags for a Lambda functionThe following list-tags example displays the tags attached to the my-function Lambda function.aws lambda list-tags \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-functionOutput:{    \"Tags\": {        \"Category\": \"Web Tools\",        \"Department\": \"Sales\"    }}For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        ListTags                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: Retrieves the tags and their values currently set on the specified function.Get-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\"Output:Key        Value---        -----California SacramentoOregon     SalemWashington Olympia                        For API details, see                        ListTags                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : list-tags",
                                    "AWS CLITo retrieve the list of tags for a Lambda functionThe following list-tags example displays the tags attached to the my-function Lambda function.aws lambda list-tags \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-functionOutput:{    \"Tags\": {        \"Category\": \"Web Tools\",        \"Department\": \"Sales\"    }}For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        ListTags                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "ListVersionsByFunction",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_ListVersionsByFunction_section.html",
                                "sections": [
                                    "The following code examples show how to use ListVersionsByFunction.",
                                    "  1.CLI : list-versions-by-function",
                                    "  2.AWS CLI : list-versions-by-function",
                                    "  3.PowerShell : Get-LMVersionsByFunction -FunctionName \"MylambdaFunction123\"\n",
                                    "  4.Tools for PowerShell : Get-LMVersionsByFunction -FunctionName \"MylambdaFunction123\"\n",
                                    "CLIAWS CLITo retrieve a list of versions of a functionThe following list-versions-by-function example displays the list of versions for the my-function Lambda function.aws lambda list-versions-by-function \\    --function-name my-functionOutput:{    \"Versions\": [        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"$LATEST\",            \"CodeSha256\": \"sU0cJ2/hOZevwV/lTxCuQqK3gDZP3i8gUoqUUVRmY6E=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"93017fc9-59cb-41dc-901b-4845ce4bf668\",            \"CodeSize\": 266,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:$LATEST\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-10-01T16:47:28.490+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"\"        },        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"1\",            \"CodeSha256\": \"5tT2qgzYUHoqwR616pZ2dpkn/0J1FrzJmlKidWaaCgk=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"949c8914-012e-4795-998c-e467121951b1\",            \"CodeSize\": 304,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:1\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-09-26T20:28:40.438+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"new version\"        },        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"2\",            \"CodeSha256\": \"sU0cJ2/hOZevwV/lTxCuQqK3gDZP3i8gUoqUUVRmY6E=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"cd669f21-0f3d-4e1c-9566-948837f2e2ea\",            \"CodeSize\": 266,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:2\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-10-01T16:47:28.490+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"newer version\"        }    ]}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        ListVersionsByFunction                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example returns the list of version specific configurations for each version of the Lambda Function.Get-LMVersionsByFunction -FunctionName \"MylambdaFunction123\"Output:FunctionName        Runtime   MemorySize Timeout CodeSize LastModified                 RoleName------------        -------   ---------- ------- -------- ------------                 --------MylambdaFunction123 python3.8        128     600      659 2020-01-10T03:20:56.390+0000 lambdaMylambdaFunction123 python3.8        128       5     1426 2019-12-25T09:19:02.238+0000 lambdaMylambdaFunction123 python3.8        128       5     1426 2019-12-25T09:39:36.779+0000 lambdaMylambdaFunction123 python3.8        128     600     1426 2019-12-25T09:52:59.872+0000 lambda                        For API details, see                        ListVersionsByFunction                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : list-versions-by-function",
                                    "AWS CLITo retrieve a list of versions of a functionThe following list-versions-by-function example displays the list of versions for the my-function Lambda function.aws lambda list-versions-by-function \\    --function-name my-functionOutput:{    \"Versions\": [        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"$LATEST\",            \"CodeSha256\": \"sU0cJ2/hOZevwV/lTxCuQqK3gDZP3i8gUoqUUVRmY6E=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"93017fc9-59cb-41dc-901b-4845ce4bf668\",            \"CodeSize\": 266,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:$LATEST\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-10-01T16:47:28.490+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"\"        },        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"1\",            \"CodeSha256\": \"5tT2qgzYUHoqwR616pZ2dpkn/0J1FrzJmlKidWaaCgk=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"949c8914-012e-4795-998c-e467121951b1\",            \"CodeSize\": 304,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:1\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-09-26T20:28:40.438+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"new version\"        },        {            \"TracingConfig\": {                \"Mode\": \"PassThrough\"            },            \"Version\": \"2\",            \"CodeSha256\": \"sU0cJ2/hOZevwV/lTxCuQqK3gDZP3i8gUoqUUVRmY6E=\",            \"FunctionName\": \"my-function\",            \"VpcConfig\": {                \"SubnetIds\": [],                \"VpcId\": \"\",                \"SecurityGroupIds\": []            },            \"MemorySize\": 256,            \"RevisionId\": \"cd669f21-0f3d-4e1c-9566-948837f2e2ea\",            \"CodeSize\": 266,            \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:2\",            \"Handler\": \"index.handler\",            \"Role\": \"arn:aws:iam::123456789012:role/service-role/helloWorldPython-role-uy3l9qyq\",            \"Timeout\": 3,            \"LastModified\": \"2019-10-01T16:47:28.490+0000\",            \"Runtime\": \"nodejs10.x\",            \"Description\": \"newer version\"        }    ]}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        ListVersionsByFunction                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "PublishVersion",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_PublishVersion_section.html",
                                "sections": [
                                    "The following code examples show how to use PublishVersion.",
                                    "  1.CLI : publish-version",
                                    "  2.AWS CLI : publish-version",
                                    "  3.PowerShell : Publish-LMVersion -FunctionName \"MylambdaFunction123\" -Description \"Publishing Existing Snapshot of function code as a  new version through Powershell\"\n",
                                    "  4.Tools for PowerShell : Publish-LMVersion -FunctionName \"MylambdaFunction123\" -Description \"Publishing Existing Snapshot of function code as a  new version through Powershell\"\n",
                                    "CLIAWS CLITo publish a new version of a functionThe following publish-version example publishes a new version of the my-function Lambda function.aws lambda publish-version \\    --function-name my-functionOutput:{    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"dBG9m8SGdmlEjw/JYXlhhvCrAv5TxvXsbL/RMr0fT/I=\",    \"FunctionName\": \"my-function\",    \"CodeSize\": 294,    \"RevisionId\": \"f31d3d39-cc63-4520-97d4-43cd44c94c20\",    \"MemorySize\": 128,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:3\",    \"Version\": \"2\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/MyTestFunction-role-zgur6bf4\",    \"Timeout\": 3,    \"LastModified\": \"2019-09-23T18:32:33.857+0000\",    \"Handler\": \"my-function.handler\",    \"Runtime\": \"nodejs10.x\",    \"Description\": \"\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        PublishVersion                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example creates a version for the existing snapshot of Lambda Function CodePublish-LMVersion -FunctionName \"MylambdaFunction123\" -Description \"Publishing Existing Snapshot of function code as a  new version through Powershell\"                        For API details, see                        PublishVersion                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : publish-version",
                                    "AWS CLITo publish a new version of a functionThe following publish-version example publishes a new version of the my-function Lambda function.aws lambda publish-version \\    --function-name my-functionOutput:{    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"dBG9m8SGdmlEjw/JYXlhhvCrAv5TxvXsbL/RMr0fT/I=\",    \"FunctionName\": \"my-function\",    \"CodeSize\": 294,    \"RevisionId\": \"f31d3d39-cc63-4520-97d4-43cd44c94c20\",    \"MemorySize\": 128,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:3\",    \"Version\": \"2\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/MyTestFunction-role-zgur6bf4\",    \"Timeout\": 3,    \"LastModified\": \"2019-09-23T18:32:33.857+0000\",    \"Handler\": \"my-function.handler\",    \"Runtime\": \"nodejs10.x\",    \"Description\": \"\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        PublishVersion                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "PutFunctionConcurrency",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_PutFunctionConcurrency_section.html",
                                "sections": [
                                    "The following code examples show how to use PutFunctionConcurrency.",
                                    "  1.CLI : put-function-concurrency",
                                    "  2.AWS CLI : put-function-concurrency",
                                    "  3.PowerShell : Write-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -ReservedConcurrentExecution 100\n",
                                    "  4.Tools for PowerShell : Write-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -ReservedConcurrentExecution 100\n",
                                    "CLIAWS CLITo configure a reserved concurrency limit for a functionThe following put-function-concurrency example configures 100 reserved concurrent executions for the my-function function.aws lambda put-function-concurrency \\    --function-name  my-function  \\    --reserved-concurrent-executions 100Output:{    \"ReservedConcurrentExecutions\": 100}For more information, see Reserving Concurrency for a Lambda Function in the AWS Lambda Developer Guide.                        For API details, see                        PutFunctionConcurrency                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example applies the concurrency settings for the Function as a whole.Write-LMFunctionConcurrency -FunctionName \"MylambdaFunction123\" -ReservedConcurrentExecution 100                        For API details, see                        PutFunctionConcurrency                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : put-function-concurrency",
                                    "AWS CLITo configure a reserved concurrency limit for a functionThe following put-function-concurrency example configures 100 reserved concurrent executions for the my-function function.aws lambda put-function-concurrency \\    --function-name  my-function  \\    --reserved-concurrent-executions 100Output:{    \"ReservedConcurrentExecutions\": 100}For more information, see Reserving Concurrency for a Lambda Function in the AWS Lambda Developer Guide.                        For API details, see                        PutFunctionConcurrency                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "PutProvisionedConcurrencyConfig",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_PutProvisionedConcurrencyConfig_section.html",
                                "sections": [
                                    "The following code examples show how to use PutProvisionedConcurrencyConfig.",
                                    "  1.CLI : put-provisioned-concurrency-config",
                                    "  2.AWS CLI : put-provisioned-concurrency-config",
                                    "  3.PowerShell : Write-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -ProvisionedConcurrentExecution 20 -Qualifier \"NewAlias1\"\n",
                                    "  4.Tools for PowerShell : Write-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -ProvisionedConcurrentExecution 20 -Qualifier \"NewAlias1\"\n",
                                    "CLIAWS CLITo allocate provisioned concurrencyThe following put-provisioned-concurrency-config example allocates 100 provisioned concurrency for the BLUE alias of the specified function.aws lambda put-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier BLUE \\    --provisioned-concurrent-executions 100Output:{    \"Requested ProvisionedConcurrentExecutions\": 100,    \"Allocated ProvisionedConcurrentExecutions\": 0,    \"Status\": \"IN_PROGRESS\",    \"LastModified\": \"2019-11-21T19:32:12+0000\"}                        For API details, see                        PutProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example adds a provisioned concurrency configuration to a Function's AliasWrite-LMProvisionedConcurrencyConfig -FunctionName \"MylambdaFunction123\" -ProvisionedConcurrentExecution 20 -Qualifier \"NewAlias1\"                        For API details, see                        PutProvisionedConcurrencyConfig                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : put-provisioned-concurrency-config",
                                    "AWS CLITo allocate provisioned concurrencyThe following put-provisioned-concurrency-config example allocates 100 provisioned concurrency for the BLUE alias of the specified function.aws lambda put-provisioned-concurrency-config \\    --function-name my-function \\    --qualifier BLUE \\    --provisioned-concurrent-executions 100Output:{    \"Requested ProvisionedConcurrentExecutions\": 100,    \"Allocated ProvisionedConcurrentExecutions\": 0,    \"Status\": \"IN_PROGRESS\",    \"LastModified\": \"2019-11-21T19:32:12+0000\"}                        For API details, see                        PutProvisionedConcurrencyConfig                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "RemovePermission",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_RemovePermission_section.html",
                                "sections": [
                                    "The following code examples show how to use RemovePermission.",
                                    "  1.CLI : remove-permission",
                                    "  2.AWS CLI : remove-permission",
                                    "  3.PowerShell : $policy =  Get-LMPolicy -FunctionName \"MylambdaFunction123\" -Select Policy | ConvertFrom-Json| Select-Object -ExpandProperty Statement\nRemove-LMPermission -FunctionName \"MylambdaFunction123\" -StatementId $policy[0].Sid\n",
                                    "  4.Tools for PowerShell : $policy =  Get-LMPolicy -FunctionName \"MylambdaFunction123\" -Select Policy | ConvertFrom-Json| Select-Object -ExpandProperty Statement\nRemove-LMPermission -FunctionName \"MylambdaFunction123\" -StatementId $policy[0].Sid\n",
                                    "CLIAWS CLITo remove permissions from an existing Lambda functionThe following remove-permission example removes permission to invoke a function named my-function.aws lambda remove-permission \\    --function-name my-function \\    --statement-id snsThis command produces no output.For more information, see Using Resource-based Policies for AWS Lambda in the AWS Lambda Developer Guide.                        For API details, see                        RemovePermission                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example removes the function policy for the specified StatementId of a Lambda Function.$policy =  Get-LMPolicy -FunctionName \"MylambdaFunction123\" -Select Policy | ConvertFrom-Json| Select-Object -ExpandProperty StatementRemove-LMPermission -FunctionName \"MylambdaFunction123\" -StatementId $policy[0].Sid                        For API details, see                        RemovePermission                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : remove-permission",
                                    "AWS CLITo remove permissions from an existing Lambda functionThe following remove-permission example removes permission to invoke a function named my-function.aws lambda remove-permission \\    --function-name my-function \\    --statement-id snsThis command produces no output.For more information, see Using Resource-based Policies for AWS Lambda in the AWS Lambda Developer Guide.                        For API details, see                        RemovePermission                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "TagResource",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_TagResource_section.html",
                                "sections": [
                                    "The following code examples show how to use TagResource.",
                                    "  1.CLI : tag-resource",
                                    "  2.AWS CLI : tag-resource",
                                    "  3.PowerShell : Add-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -Tag @{ \"Washington\" = \"Olympia\"; \"Oregon\" = \"Salem\"; \"California\" = \"Sacramento\" }\n",
                                    "  4.Tools for PowerShell : Add-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -Tag @{ \"Washington\" = \"Olympia\"; \"Oregon\" = \"Salem\"; \"California\" = \"Sacramento\" }\n",
                                    "CLIAWS CLITo add tags to an existing Lambda functionThe following tag-resource example adds a tag with the key name DEPARTMENT and a value of Department A to the specified Lambda function.aws lambda tag-resource \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-function \\    --tags \"DEPARTMENT=Department A\"This command produces no output.For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        TagResource                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: Adds the three tags (Washington, Oregon and California) and their associated values to the specified function identified by its ARN.Add-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -Tag @{ \"Washington\" = \"Olympia\"; \"Oregon\" = \"Salem\"; \"California\" = \"Sacramento\" }                        For API details, see                        TagResource                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : tag-resource",
                                    "AWS CLITo add tags to an existing Lambda functionThe following tag-resource example adds a tag with the key name DEPARTMENT and a value of Department A to the specified Lambda function.aws lambda tag-resource \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-function \\    --tags \"DEPARTMENT=Department A\"This command produces no output.For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        TagResource                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "UntagResource",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_UntagResource_section.html",
                                "sections": [
                                    "The following code examples show how to use UntagResource.",
                                    "  1.CLI : untag-resource",
                                    "  2.AWS CLI : untag-resource",
                                    "  3.PowerShell : Remove-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -TagKey \"Washington\",\"Oregon\",\"California\"\n",
                                    "  4.Tools for PowerShell : Remove-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -TagKey \"Washington\",\"Oregon\",\"California\"\n",
                                    "CLIAWS CLITo remove tags from an existing Lambda functionThe following untag-resource example removes the tag with the key name DEPARTMENT tag from the my-function Lambda function.aws lambda untag-resource \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-function \\    --tag-keys DEPARTMENTThis command produces no output.For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        UntagResource                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: Removes the supplied tags from a function. The cmdlet will prompt for confirmation before proceeding unless the -Force switch is specified. A single call is made to the service to remove the tags.Remove-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\" -TagKey \"Washington\",\"Oregon\",\"California\"Example 2: Removes the supplied tags from a function. The cmdlet will prompt for confirmation before proceeding unless the -Force switch is specified. Once call to the service is made per supplied tag.\"Washington\",\"Oregon\",\"California\" | Remove-LMResourceTag -Resource \"arn:aws:lambda:us-west-2:123456789012:function:MyFunction\"                        For API details, see                        UntagResource                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : untag-resource",
                                    "AWS CLITo remove tags from an existing Lambda functionThe following untag-resource example removes the tag with the key name DEPARTMENT tag from the my-function Lambda function.aws lambda untag-resource \\    --resource arn:aws:lambda:us-west-2:123456789012:function:my-function \\    --tag-keys DEPARTMENTThis command produces no output.For more information, see Tagging Lambda Functions in the AWS Lambda Developer Guide.                        For API details, see                        UntagResource                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "UpdateAlias",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_UpdateAlias_section.html",
                                "sections": [
                                    "The following code examples show how to use UpdateAlias.",
                                    "  1.CLI : update-alias",
                                    "  2.AWS CLI : update-alias",
                                    "  3.PowerShell : Update-LMAlias -FunctionName \"MylambdaFunction123\" -Description \" Alias for version 2\" -FunctionVersion 2 -Name \"newlabel1\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6}\n",
                                    "  4.Tools for PowerShell : Update-LMAlias -FunctionName \"MylambdaFunction123\" -Description \" Alias for version 2\" -FunctionVersion 2 -Name \"newlabel1\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6}\n",
                                    "CLIAWS CLITo update a function aliasThe following update-alias example updates the alias named LIVE to point to version 3 of the my-function Lambda function.aws lambda update-alias \\    --function-name my-function \\    --function-version 3 \\    --name LIVEOutput:{    \"FunctionVersion\": \"3\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"594f41fb-b85f-4c20-95c7-6ca5f2a92c93\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        UpdateAlias                        in AWS CLI Command Reference.                    PowerShellTools for PowerShellExample 1: This example updates the Configuration of an existing Lambda function Alias. It updates the RoutingConfiguration value to shift 60% (0.6) of traffic to version 1Update-LMAlias -FunctionName \"MylambdaFunction123\" -Description \" Alias for version 2\" -FunctionVersion 2 -Name \"newlabel1\" -RoutingConfig_AdditionalVersionWeight @{Name=\"1\";Value=\"0.6}                        For API details, see                        UpdateAlias                        in AWS Tools for PowerShell Cmdlet Reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS CLI : update-alias",
                                    "AWS CLITo update a function aliasThe following update-alias example updates the alias named LIVE to point to version 3 of the my-function Lambda function.aws lambda update-alias \\    --function-name my-function \\    --function-version 3 \\    --name LIVEOutput:{    \"FunctionVersion\": \"3\",    \"Name\": \"LIVE\",    \"AliasArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function:LIVE\",    \"RevisionId\": \"594f41fb-b85f-4c20-95c7-6ca5f2a92c93\",    \"Description\": \"alias for live version of function\"}For more information, see Configuring AWS Lambda Function Aliases in the AWS Lambda Developer Guide.                        For API details, see                        UpdateAlias                        in AWS CLI Command Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "UpdateFunctionCode",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_UpdateFunctionCode_section.html",
                                "sections": [
                                    "The following code examples show how to use UpdateFunctionCode.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::UpdateFunctionCodeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteLambdaFunction(client);\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n        request.SetZipFile(\n                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                       buffer.str().length()));\n        request.SetPublish(true);\n\n        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda code was successfully updated.\" << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::UpdateFunctionCodeRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),\n                               std::ios_base::in | std::ios_base::binary);\n        if (!ifstream.is_open()) {\n            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;\n\n#if USE_CPP_LAMBDA_FUNCTION\n            std::cerr\n                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"\n                    << std::endl;\n#endif\n            deleteLambdaFunction(client);\n            deleteIamRole(clientConfig);\n            return false;\n        }\n\n        Aws::StringStream buffer;\n        buffer << ifstream.rdbuf();\n        request.SetZipFile(\n                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),\n                                       buffer.str().length()));\n        request.SetPublish(true);\n\n        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda code was successfully updated.\" << std::endl;\n        }\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  5.CLI : update-function-code",
                                    "  6.AWS CLI : update-function-code",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// UpdateFunctionCode updates the code for the Lambda function specified by functionName.\n// The existing code for the Lambda function is entirely replaced by the code in the\n// zipPackage buffer. After the update action is called, a lambda.FunctionUpdatedV2Waiter\n// is used to wait until the update is successful.\nfunc (wrapper FunctionWrapper) UpdateFunctionCode(ctx context.Context, functionName string, zipPackage *bytes.Buffer) types.State {\n\tvar state types.State\n\t_, err := wrapper.LambdaClient.UpdateFunctionCode(ctx, &lambda.UpdateFunctionCodeInput{\n\t\tFunctionName: aws.String(functionName), ZipFile: zipPackage.Bytes(),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't update code for function %v. Here's why: %v\\n\", functionName, err)\n\t} else {\n\t\twaiter := lambda.NewFunctionUpdatedV2Waiter(wrapper.LambdaClient)\n\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\n\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\n\t\t} else {\n\t\t\tstate = funcOutput.Configuration.State\n\t\t}\n\t}\n\treturn state\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// UpdateFunctionCode updates the code for the Lambda function specified by functionName.\n// The existing code for the Lambda function is entirely replaced by the code in the\n// zipPackage buffer. After the update action is called, a lambda.FunctionUpdatedV2Waiter\n// is used to wait until the update is successful.\nfunc (wrapper FunctionWrapper) UpdateFunctionCode(ctx context.Context, functionName string, zipPackage *bytes.Buffer) types.State {\n\tvar state types.State\n\t_, err := wrapper.LambdaClient.UpdateFunctionCode(ctx, &lambda.UpdateFunctionCodeInput{\n\t\tFunctionName: aws.String(functionName), ZipFile: zipPackage.Bytes(),\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't update code for function %v. Here's why: %v\\n\", functionName, err)\n\t} else {\n\t\twaiter := lambda.NewFunctionUpdatedV2Waiter(wrapper.LambdaClient)\n\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\n\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\n\t\tif err != nil {\n\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\n\t\t} else {\n\t\t\tstate = funcOutput.Configuration.State\n\t\t}\n\t}\n\treturn state\n}\n\n\n",
                                    "  9.Java :     /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Retrieves information about an AWS Lambda function.\n     *\n     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     * @param functionName the name of the AWS Lambda function to retrieve information about\n     */\n    public static void getFunction(LambdaClient awsLambda, String functionName) {\n        try {\n            GetFunctionRequest functionRequest = GetFunctionRequest.builder()\n                .functionName(functionName)\n                .build();\n\n            GetFunctionResponse response = awsLambda.getFunction(functionRequest);\n            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  11.JavaScript : const updateFunctionCode = async (funcName, newFunc) => {\n  const client = new LambdaClient({});\n  const code = await readFile(`${dirname}../functions/${newFunc}.zip`);\n  const command = new UpdateFunctionCodeCommand({\n    ZipFile: code,\n    FunctionName: funcName,\n    Architectures: [Architecture.arm64],\n    Handler: \"index.handler\", // Required when sending a .zip file\n    PackageType: PackageType.Zip, // Required when sending a .zip file\n    Runtime: Runtime.nodejs16x, // Required when sending a .zip file\n  });\n\n  return client.send(command);\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : const updateFunctionCode = async (funcName, newFunc) => {\n  const client = new LambdaClient({});\n  const code = await readFile(`${dirname}../functions/${newFunc}.zip`);\n  const command = new UpdateFunctionCodeCommand({\n    ZipFile: code,\n    FunctionName: funcName,\n    Architectures: [Architecture.arm64],\n    Handler: \"index.handler\", // Required when sending a .zip file\n    PackageType: PackageType.Zip, // Required when sending a .zip file\n    Runtime: Runtime.nodejs16x, // Required when sending a .zip file\n  });\n\n  return client.send(command);\n};\n\n",
                                    "  13.PHP :     public function updateFunctionCode($functionName, $s3Bucket, $s3Key)\n    {\n        return $this->lambdaClient->updateFunctionCode([\n            'FunctionName' => $functionName,\n            'S3Bucket' => $s3Bucket,\n            'S3Key' => $s3Key,\n        ]);\n    }\n\n",
                                    "  14.SDK for PHP :     public function updateFunctionCode($functionName, $s3Bucket, $s3Key)\n    {\n        return $this->lambdaClient->updateFunctionCode([\n            'FunctionName' => $functionName,\n            'S3Bucket' => $s3Bucket,\n            'S3Key' => $s3Key,\n        ]);\n    }\n\n",
                                    "  15.PowerShell : Update-LMFunctionCode -FunctionName MyFunction -ZipFilename .\\UpdatedCode.zip\n",
                                    "  16.Tools for PowerShell : Update-LMFunctionCode -FunctionName MyFunction -ZipFilename .\\UpdatedCode.zip\n",
                                    "  17.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def update_function_code(self, function_name, deployment_package):\n        \"\"\"\n        Updates the code for a Lambda function by submitting a .zip archive that contains\n        the code for the function.\n\n        :param function_name: The name of the function to update.\n        :param deployment_package: The function code to update, packaged as bytes in\n                                   .zip format.\n        :return: Data about the update, including the status.\n        \"\"\"\n        try:\n            response = self.lambda_client.update_function_code(\n                FunctionName=function_name, ZipFile=deployment_package\n            )\n        except ClientError as err:\n            logger.error(\n                \"Couldn't update function %s. Here's why: %s: %s\",\n                function_name,\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n        else:\n            return response\n\n\n",
                                    "  18.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def update_function_code(self, function_name, deployment_package):\n        \"\"\"\n        Updates the code for a Lambda function by submitting a .zip archive that contains\n        the code for the function.\n\n        :param function_name: The name of the function to update.\n        :param deployment_package: The function code to update, packaged as bytes in\n                                   .zip format.\n        :return: Data about the update, including the status.\n        \"\"\"\n        try:\n            response = self.lambda_client.update_function_code(\n                FunctionName=function_name, ZipFile=deployment_package\n            )\n        except ClientError as err:\n            logger.error(\n                \"Couldn't update function %s. Here's why: %s: %s\",\n                function_name,\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n        else:\n            return response\n\n\n",
                                    "  19.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Updates the code for a Lambda function by submitting a .zip archive that contains\n  # the code for the function.\n  #\n  # @param function_name: The name of the function to update.\n  # @param deployment_package: The function code to update, packaged as bytes in\n  #                            .zip format.\n  # @return: Data about the update, including the status.\n  def update_function_code(function_name, deployment_package)\n    @lambda_client.update_function_code(\n      function_name: function_name,\n      zip_file: deployment_package\n    )\n    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error updating function code for: #{function_name}:\\n #{e.message}\")\n    nil\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to update:\\n #{e.message}\")\n  end\n\n",
                                    "  20.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Updates the code for a Lambda function by submitting a .zip archive that contains\n  # the code for the function.\n  #\n  # @param function_name: The name of the function to update.\n  # @param deployment_package: The function code to update, packaged as bytes in\n  #                            .zip format.\n  # @return: Data about the update, including the status.\n  def update_function_code(function_name, deployment_package)\n    @lambda_client.update_function_code(\n      function_name: function_name,\n      zip_file: deployment_package\n    )\n    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error updating function code for: #{function_name}:\\n #{e.message}\")\n    nil\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to update:\\n #{e.message}\")\n  end\n\n",
                                    "  21.Rust :     /** Given a Path to a zip file, update the function's code and wait for the update to finish. */\n    pub async fn update_function_code(\n        &self,\n        zip_file: PathBuf,\n        key: String,\n    ) -> Result<UpdateFunctionCodeOutput, anyhow::Error> {\n        let function_code = self.prepare_function(zip_file, Some(key)).await?;\n\n        info!(\"Updating code for {}\", self.lambda_name);\n        let update = self\n            .lambda_client\n            .update_function_code()\n            .function_name(self.lambda_name.clone())\n            .s3_bucket(self.bucket.clone())\n            .s3_key(function_code.s3_key().unwrap().to_string())\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        Ok(update)\n    }\n\n    /**\n     * Upload function code from a path to a zip file.\n     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.\n     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.\n     */\n    async fn prepare_function(\n        &self,\n        zip_file: PathBuf,\n        key: Option<String>,\n    ) -> Result<FunctionCode, anyhow::Error> {\n        let body = ByteStream::from_path(zip_file).await?;\n\n        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));\n\n        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);\n        let _ = self\n            .s3_client\n            .put_object()\n            .bucket(self.bucket.clone())\n            .key(key.clone())\n            .body(body)\n            .send()\n            .await?;\n\n        Ok(FunctionCode::builder()\n            .s3_bucket(self.bucket.clone())\n            .s3_key(key)\n            .build())\n    }\n\n",
                                    "  22.SDK for Rust :     /** Given a Path to a zip file, update the function's code and wait for the update to finish. */\n    pub async fn update_function_code(\n        &self,\n        zip_file: PathBuf,\n        key: String,\n    ) -> Result<UpdateFunctionCodeOutput, anyhow::Error> {\n        let function_code = self.prepare_function(zip_file, Some(key)).await?;\n\n        info!(\"Updating code for {}\", self.lambda_name);\n        let update = self\n            .lambda_client\n            .update_function_code()\n            .function_name(self.lambda_name.clone())\n            .s3_bucket(self.bucket.clone())\n            .s3_key(function_code.s3_key().unwrap().to_string())\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        Ok(update)\n    }\n\n    /**\n     * Upload function code from a path to a zip file.\n     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.\n     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.\n     */\n    async fn prepare_function(\n        &self,\n        zip_file: PathBuf,\n        key: Option<String>,\n    ) -> Result<FunctionCode, anyhow::Error> {\n        let body = ByteStream::from_path(zip_file).await?;\n\n        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));\n\n        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);\n        let _ = self\n            .s3_client\n            .put_object()\n            .bucket(self.bucket.clone())\n            .key(key.clone())\n            .body(body)\n            .send()\n            .await?;\n\n        Ok(FunctionCode::builder()\n            .s3_bucket(self.bucket.clone())\n            .s3_key(key)\n            .build())\n    }\n\n",
                                    "  23.SAP ABAP :     TRY.\n        oo_result = lo_lmd->updatefunctioncode(     \" oo_result is returned for testing purposes. \"\n              iv_functionname = iv_function_name\n              iv_zipfile = io_zip_file\n          ).\n\n        MESSAGE 'Lambda function code updated.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodestorageexcdex.\n        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  24.SDK for SAP ABAP :     TRY.\n        oo_result = lo_lmd->updatefunctioncode(     \" oo_result is returned for testing purposes. \"\n              iv_functionname = iv_function_name\n              iv_zipfile = io_zip_file\n          ).\n\n        MESSAGE 'Lambda function code updated.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodestorageexcdex.\n        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Update an existing Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to update.</param>    /// <param name=\"bucketName\">The bucket where the zip file containing    /// the Lambda function code is stored.</param>    /// <param name=\"key\">The key name of the source code file.</param>    /// <returns>Async Task.</returns>    public async Task UpdateFunctionCodeAsync(        string functionName,        string bucketName,        string key)    {        var functionCodeRequest = new UpdateFunctionCodeRequest        {            FunctionName = functionName,            Publish = true,            S3Bucket = bucketName,            S3Key = key,        };        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");    }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);        Aws::Lambda::Model::UpdateFunctionCodeRequest request;        request.SetFunctionName(LAMBDA_NAME);        std::ifstream ifstream(CALCULATOR_LAMBDA_CODE.c_str(),                               std::ios_base::in | std::ios_base::binary);        if (!ifstream.is_open()) {            std::cerr << \"Error opening file \" << INCREMENT_LAMBDA_CODE << \".\" << std::endl;#if USE_CPP_LAMBDA_FUNCTION            std::cerr                    << \"The cpp Lambda function must be built following the instructions in the cpp_lambda/README.md file. \"                    << std::endl;#endif            deleteLambdaFunction(client);            deleteIamRole(clientConfig);            return false;        }        Aws::StringStream buffer;        buffer << ifstream.rdbuf();        request.SetZipFile(                Aws::Utils::ByteBuffer((unsigned char *) buffer.str().c_str(),                                       buffer.str().length()));        request.SetPublish(true);        Aws::Lambda::Model::UpdateFunctionCodeOutcome outcome = client.UpdateFunctionCode(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda code was successfully updated.\" << std::endl;        }        else {            std::cerr << \"Error with Lambda::UpdateFunctionCode. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for C++ API Reference.                    CLIAWS CLITo update the code of a Lambda functionThe following update-function-code example replaces the code of the unpublished ($LATEST) version of the my-function function with the contents of the specified zip file.aws lambda update-function-code \\    --function-name  my-function \\    --zip-file fileb://my-function.zipOutput:{    \"FunctionName\": \"my-function\",    \"LastModified\": \"2019-09-26T20:28:40.438+0000\",    \"RevisionId\": \"e52502d4-9320-4688-9cd6-152a6ab7490d\",    \"MemorySize\": 256,    \"Version\": \"$LATEST\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/my-function-role-uy3l9qyq\",    \"Timeout\": 3,    \"Runtime\": \"nodejs10.x\",    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"5tT2qgzYUHaqwR716pZ2dpkn/0J1FrzJmlKidWoaCgk=\",    \"Description\": \"\",    \"VpcConfig\": {        \"SubnetIds\": [],        \"VpcId\": \"\",        \"SecurityGroupIds\": []    },    \"CodeSize\": 304,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"Handler\": \"index.handler\"}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        UpdateFunctionCode                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// UpdateFunctionCode updates the code for the Lambda function specified by functionName.// The existing code for the Lambda function is entirely replaced by the code in the// zipPackage buffer. After the update action is called, a lambda.FunctionUpdatedV2Waiter// is used to wait until the update is successful.func (wrapper FunctionWrapper) UpdateFunctionCode(ctx context.Context, functionName string, zipPackage *bytes.Buffer) types.State {\tvar state types.State\t_, err := wrapper.LambdaClient.UpdateFunctionCode(ctx, &lambda.UpdateFunctionCodeInput{\t\tFunctionName: aws.String(functionName), ZipFile: zipPackage.Bytes(),\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't update code for function %v. Here's why: %v\\n\", functionName, err)\t} else {\t\twaiter := lambda.NewFunctionUpdatedV2Waiter(wrapper.LambdaClient)\t\tfuncOutput, err := waiter.WaitForOutput(ctx, &lambda.GetFunctionInput{\t\t\tFunctionName: aws.String(functionName)}, 1*time.Minute)\t\tif err != nil {\t\t\tlog.Panicf(\"Couldn't wait for function %v to be active. Here's why: %v\\n\", functionName, err)\t\t} else {\t\t\tstate = funcOutput.Configuration.State\t\t}\t}\treturn state}                        For API details, see                        UpdateFunctionCode                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Retrieves information about an AWS Lambda function.     *     * @param awsLambda    an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     * @param functionName the name of the AWS Lambda function to retrieve information about     */    public static void getFunction(LambdaClient awsLambda, String functionName) {        try {            GetFunctionRequest functionRequest = GetFunctionRequest.builder()                .functionName(functionName)                .build();            GetFunctionResponse response = awsLambda.getFunction(functionRequest);            System.out.println(\"The runtime of this Lambda function is \" + response.configuration().runtime());        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const updateFunctionCode = async (funcName, newFunc) => {  const client = new LambdaClient({});  const code = await readFile(`${dirname}../functions/${newFunc}.zip`);  const command = new UpdateFunctionCodeCommand({    ZipFile: code,    FunctionName: funcName,    Architectures: [Architecture.arm64],    Handler: \"index.handler\", // Required when sending a .zip file    PackageType: PackageType.Zip, // Required when sending a .zip file    Runtime: Runtime.nodejs16x, // Required when sending a .zip file  });  return client.send(command);};                        For API details, see                        UpdateFunctionCode                        in AWS SDK for JavaScript API Reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function updateFunctionCode($functionName, $s3Bucket, $s3Key)    {        return $this->lambdaClient->updateFunctionCode([            'FunctionName' => $functionName,            'S3Bucket' => $s3Bucket,            'S3Key' => $s3Key,        ]);    }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for PHP API Reference.                    PowerShellTools for PowerShellExample 1: Updates the function named 'MyFunction' with new content contained in the specified zip file. For a C# .NET Core Lambda function the zip file should contain the compiled assembly.Update-LMFunctionCode -FunctionName MyFunction -ZipFilename .\\UpdatedCode.zipExample 2: This example is similar to the previous one but uses an Amazon S3 object containing the updated code to update the function.Update-LMFunctionCode -FunctionName MyFunction -BucketName amzn-s3-demo-bucket -Key UpdatedCode.zip                        For API details, see                        UpdateFunctionCode                        in AWS Tools for PowerShell Cmdlet Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def update_function_code(self, function_name, deployment_package):        \"\"\"        Updates the code for a Lambda function by submitting a .zip archive that contains        the code for the function.        :param function_name: The name of the function to update.        :param deployment_package: The function code to update, packaged as bytes in                                   .zip format.        :return: Data about the update, including the status.        \"\"\"        try:            response = self.lambda_client.update_function_code(                FunctionName=function_name, ZipFile=deployment_package            )        except ClientError as err:            logger.error(                \"Couldn't update function %s. Here's why: %s: %s\",                function_name,                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raise        else:            return response                        For API details, see                        UpdateFunctionCode                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Updates the code for a Lambda function by submitting a .zip archive that contains  # the code for the function.  #  # @param function_name: The name of the function to update.  # @param deployment_package: The function code to update, packaged as bytes in  #                            .zip format.  # @return: Data about the update, including the status.  def update_function_code(function_name, deployment_package)    @lambda_client.update_function_code(      function_name: function_name,      zip_file: deployment_package    )    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error updating function code for: #{function_name}:\\n #{e.message}\")    nil  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to update:\\n #{e.message}\")  end                        For API details, see                        UpdateFunctionCode                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** Given a Path to a zip file, update the function's code and wait for the update to finish. */    pub async fn update_function_code(        &self,        zip_file: PathBuf,        key: String,    ) -> Result<UpdateFunctionCodeOutput, anyhow::Error> {        let function_code = self.prepare_function(zip_file, Some(key)).await?;        info!(\"Updating code for {}\", self.lambda_name);        let update = self            .lambda_client            .update_function_code()            .function_name(self.lambda_name.clone())            .s3_bucket(self.bucket.clone())            .s3_key(function_code.s3_key().unwrap().to_string())            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        Ok(update)    }    /**     * Upload function code from a path to a zip file.     * The zip file must have an AL2 Linux-compatible binary called `bootstrap`.     * The easiest way to create such a zip is to use `cargo lambda build --output-format Zip`.     */    async fn prepare_function(        &self,        zip_file: PathBuf,        key: Option<String>,    ) -> Result<FunctionCode, anyhow::Error> {        let body = ByteStream::from_path(zip_file).await?;        let key = key.unwrap_or_else(|| format!(\"{}_code\", self.lambda_name));        info!(\"Uploading function code to s3://{}/{}\", self.bucket, key);        let _ = self            .s3_client            .put_object()            .bucket(self.bucket.clone())            .key(key.clone())            .body(body)            .send()            .await?;        Ok(FunctionCode::builder()            .s3_bucket(self.bucket.clone())            .s3_key(key)            .build())    }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        oo_result = lo_lmd->updatefunctioncode(     \" oo_result is returned for testing purposes. \"              iv_functionname = iv_function_name              iv_zipfile = io_zip_file          ).        MESSAGE 'Lambda function code updated.' TYPE 'I'.      CATCH /aws1/cx_lmdcodesigningcfgno00.        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdcodestorageexcdex.        MESSAGE 'Maximum total code size per account exceeded.' TYPE 'E'.      CATCH /aws1/cx_lmdcodeverification00.        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.      CATCH /aws1/cx_lmdinvalidcodesigex.        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdresourceconflictex.        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.      CATCH /aws1/cx_lmdresourcenotfoundex.        MESSAGE 'The requested resource does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        UpdateFunctionCode                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Update an existing Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the Lambda function to update.</param>\n    /// <param name=\"bucketName\">The bucket where the zip file containing\n    /// the Lambda function code is stored.</param>\n    /// <param name=\"key\">The key name of the source code file.</param>\n    /// <returns>Async Task.</returns>\n    public async Task UpdateFunctionCodeAsync(\n        string functionName,\n        string bucketName,\n        string key)\n    {\n        var functionCodeRequest = new UpdateFunctionCodeRequest\n        {\n            FunctionName = functionName,\n            Publish = true,\n            S3Bucket = bucketName,\n            S3Key = key,\n        };\n\n        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);\n        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Update an existing Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the Lambda function to update.</param>    /// <param name=\"bucketName\">The bucket where the zip file containing    /// the Lambda function code is stored.</param>    /// <param name=\"key\">The key name of the source code file.</param>    /// <returns>Async Task.</returns>    public async Task UpdateFunctionCodeAsync(        string functionName,        string bucketName,        string key)    {        var functionCodeRequest = new UpdateFunctionCodeRequest        {            FunctionName = functionName,            Publish = true,            S3Bucket = bucketName,            S3Key = key,        };        var response = await _lambdaService.UpdateFunctionCodeAsync(functionCodeRequest);        Console.WriteLine($\"The Function was last modified at {response.LastModified}.\");    }                        For API details, see                        UpdateFunctionCode                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            },
                            {
                                "title": "UpdateFunctionConfiguration",
                                "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_lambda_UpdateFunctionConfiguration_section.html",
                                "sections": [
                                    "The following code examples show how to use UpdateFunctionConfiguration.",
                                    "Action examples are code excerpts from larger programs and must be run in context. You can see this action in            context in the following code example:            ",
                                    "  1.Learn the basics",
                                    "  1..NET :     /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n",
                                    "  2.AWS SDK for .NET :     /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n",
                                    "  3.C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        Aws::Lambda::Model::Environment environment;\n        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");\n        request.SetEnvironment(environment);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda configuration was successfully updated.\"\n                      << std::endl;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  4.SDK for C++ :         Aws::Client::ClientConfiguration clientConfig;\n        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).\n        // clientConfig.region = \"us-east-1\";\n\n    Aws::Lambda::LambdaClient client(clientConfig);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;\n        request.SetFunctionName(LAMBDA_NAME);\n        Aws::Lambda::Model::Environment environment;\n        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");\n        request.SetEnvironment(environment);\n\n        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(\n                request);\n\n        if (outcome.IsSuccess()) {\n            std::cout << \"The lambda configuration was successfully updated.\"\n                      << std::endl;\n            break;\n        }\n\n        else {\n            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"\n                      << outcome.GetError().GetMessage()\n                      << std::endl;\n        }\n\n",
                                    "  5.CLI : update-function-configuration",
                                    "  6.AWS CLI : update-function-configuration",
                                    "  7.Go : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// UpdateFunctionConfiguration updates a map of environment variables configured for\n// the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) UpdateFunctionConfiguration(ctx context.Context, functionName string, envVars map[string]string) {\n\t_, err := wrapper.LambdaClient.UpdateFunctionConfiguration(ctx, &lambda.UpdateFunctionConfigurationInput{\n\t\tFunctionName: aws.String(functionName),\n\t\tEnvironment:  &types.Environment{Variables: envVars},\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't update configuration for %v. Here's why: %v\", functionName, err)\n\t}\n}\n\n\n",
                                    "  8.SDK for Go V2 : \nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\"\n)\n\n// FunctionWrapper encapsulates function actions used in the examples.\n// It contains an AWS Lambda service client that is used to perform user actions.\ntype FunctionWrapper struct {\n\tLambdaClient *lambda.Client\n}\n\n\n\n// UpdateFunctionConfiguration updates a map of environment variables configured for\n// the Lambda function specified by functionName.\nfunc (wrapper FunctionWrapper) UpdateFunctionConfiguration(ctx context.Context, functionName string, envVars map[string]string) {\n\t_, err := wrapper.LambdaClient.UpdateFunctionConfiguration(ctx, &lambda.UpdateFunctionConfigurationInput{\n\t\tFunctionName: aws.String(functionName),\n\t\tEnvironment:  &types.Environment{Variables: envVars},\n\t})\n\tif err != nil {\n\t\tlog.Panicf(\"Couldn't update configuration for %v. Here's why: %v\", functionName, err)\n\t}\n}\n\n\n",
                                    "  9.Java :     /**\n     * Updates the configuration of an AWS Lambda function.\n     *\n     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation\n     * @param functionName  the name of the AWS Lambda function to update\n     * @param handler       the new handler for the AWS Lambda function\n     *\n     * @throws LambdaException if there is an error while updating the function configuration\n     */\n    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {\n        try {\n            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .build();\n\n            awsLambda.updateFunctionConfiguration(configurationRequest);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  10.SDK for Java 2.x :     /**\n     * Updates the configuration of an AWS Lambda function.\n     *\n     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation\n     * @param functionName  the name of the AWS Lambda function to update\n     * @param handler       the new handler for the AWS Lambda function\n     *\n     * @throws LambdaException if there is an error while updating the function configuration\n     */\n    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {\n        try {\n            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()\n                .functionName(functionName)\n                .handler(handler)\n                .runtime(Runtime.JAVA17)\n                .build();\n\n            awsLambda.updateFunctionConfiguration(configurationRequest);\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
                                    "  11.JavaScript : const updateFunctionConfiguration = (funcName) => {\n  const client = new LambdaClient({});\n  const config = readFileSync(`${dirname}../functions/config.json`).toString();\n  const command = new UpdateFunctionConfigurationCommand({\n    ...JSON.parse(config),\n    FunctionName: funcName,\n  });\n  const result = client.send(command);\n  waitForFunctionUpdated({ FunctionName: funcName });\n  return result;\n};\n\n",
                                    "  12.SDK for JavaScript (v3) : const updateFunctionConfiguration = (funcName) => {\n  const client = new LambdaClient({});\n  const config = readFileSync(`${dirname}../functions/config.json`).toString();\n  const command = new UpdateFunctionConfigurationCommand({\n    ...JSON.parse(config),\n    FunctionName: funcName,\n  });\n  const result = client.send(command);\n  waitForFunctionUpdated({ FunctionName: funcName });\n  return result;\n};\n\n",
                                    "  13.PHP :     public function updateFunctionConfiguration($functionName, $handler, $environment = '')\n    {\n        return $this->lambdaClient->updateFunctionConfiguration([\n            'FunctionName' => $functionName,\n            'Handler' => \"$handler.lambda_handler\",\n            'Environment' => $environment,\n        ]);\n    }\n\n",
                                    "  14.SDK for PHP :     public function updateFunctionConfiguration($functionName, $handler, $environment = '')\n    {\n        return $this->lambdaClient->updateFunctionConfiguration([\n            'FunctionName' => $functionName,\n            'Handler' => \"$handler.lambda_handler\",\n            'Environment' => $environment,\n        ]);\n    }\n\n",
                                    "  15.PowerShell : Update-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Handler \"lambda_function.launch_instance\" -Timeout 600 -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" } -Role arn:aws:iam::123456789101:role/service-role/lambda -DeadLetterConfig_TargetArn arn:aws:sns:us-east-1: 123456789101:MyfirstTopic\n",
                                    "  16.Tools for PowerShell : Update-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Handler \"lambda_function.launch_instance\" -Timeout 600 -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" } -Role arn:aws:iam::123456789101:role/service-role/lambda -DeadLetterConfig_TargetArn arn:aws:sns:us-east-1: 123456789101:MyfirstTopic\n",
                                    "  17.Python : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def update_function_configuration(self, function_name, env_vars):\n        \"\"\"\n        Updates the environment variables for a Lambda function.\n\n        :param function_name: The name of the function to update.\n        :param env_vars: A dict of environment variables to update.\n        :return: Data about the update, including the status.\n        \"\"\"\n        try:\n            response = self.lambda_client.update_function_configuration(\n                FunctionName=function_name, Environment={\"Variables\": env_vars}\n            )\n        except ClientError as err:\n            logger.error(\n                \"Couldn't update function configuration %s. Here's why: %s: %s\",\n                function_name,\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n        else:\n            return response\n\n\n",
                                    "  18.SDK for Python (Boto3) : class LambdaWrapper:\n    def __init__(self, lambda_client, iam_resource):\n        self.lambda_client = lambda_client\n        self.iam_resource = iam_resource\n\n\n    def update_function_configuration(self, function_name, env_vars):\n        \"\"\"\n        Updates the environment variables for a Lambda function.\n\n        :param function_name: The name of the function to update.\n        :param env_vars: A dict of environment variables to update.\n        :return: Data about the update, including the status.\n        \"\"\"\n        try:\n            response = self.lambda_client.update_function_configuration(\n                FunctionName=function_name, Environment={\"Variables\": env_vars}\n            )\n        except ClientError as err:\n            logger.error(\n                \"Couldn't update function configuration %s. Here's why: %s: %s\",\n                function_name,\n                err.response[\"Error\"][\"Code\"],\n                err.response[\"Error\"][\"Message\"],\n            )\n            raise\n        else:\n            return response\n\n\n",
                                    "  19.Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Updates the environment variables for a Lambda function.\n  # @param function_name: The name of the function to update.\n  # @param log_level: The log level of the function.\n  # @return: Data about the update, including the status.\n  def update_function_configuration(function_name, log_level)\n    @lambda_client.update_function_configuration({\n                                                   function_name: function_name,\n                                                   environment: {\n                                                     variables: {\n                                                       'LOG_LEVEL' => log_level\n                                                     }\n                                                   }\n                                                 })\n    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error updating configurations for #{function_name}:\\n #{e.message}\")\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")\n  end\n\n",
                                    "  20.SDK for Ruby : class LambdaWrapper\n  attr_accessor :lambda_client, :cloudwatch_client, :iam_client\n\n  def initialize\n    @lambda_client = Aws::Lambda::Client.new\n    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')\n    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')\n    @logger = Logger.new($stdout)\n    @logger.level = Logger::WARN\n  end\n\n  # Updates the environment variables for a Lambda function.\n  # @param function_name: The name of the function to update.\n  # @param log_level: The log level of the function.\n  # @return: Data about the update, including the status.\n  def update_function_configuration(function_name, log_level)\n    @lambda_client.update_function_configuration({\n                                                   function_name: function_name,\n                                                   environment: {\n                                                     variables: {\n                                                       'LOG_LEVEL' => log_level\n                                                     }\n                                                   }\n                                                 })\n    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|\n      w.max_attempts = 5\n      w.delay = 5\n    end\n  rescue Aws::Lambda::Errors::ServiceException => e\n    @logger.error(\"There was an error updating configurations for #{function_name}:\\n #{e.message}\")\n  rescue Aws::Waiters::Errors::WaiterFailed => e\n    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")\n  end\n\n",
                                    "  21.Rust :     /** Update the environment for a function. */\n    pub async fn update_function_configuration(\n        &self,\n        environment: Environment,\n    ) -> Result<UpdateFunctionConfigurationOutput, anyhow::Error> {\n        info!(\n            ?environment,\n            \"Updating environment for {}\", self.lambda_name\n        );\n        let updated = self\n            .lambda_client\n            .update_function_configuration()\n            .function_name(self.lambda_name.clone())\n            .environment(environment)\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        Ok(updated)\n    }\n\n",
                                    "  22.SDK for Rust :     /** Update the environment for a function. */\n    pub async fn update_function_configuration(\n        &self,\n        environment: Environment,\n    ) -> Result<UpdateFunctionConfigurationOutput, anyhow::Error> {\n        info!(\n            ?environment,\n            \"Updating environment for {}\", self.lambda_name\n        );\n        let updated = self\n            .lambda_client\n            .update_function_configuration()\n            .function_name(self.lambda_name.clone())\n            .environment(environment)\n            .send()\n            .await\n            .map_err(anyhow::Error::from)?;\n\n        self.wait_for_function_ready().await?;\n\n        Ok(updated)\n    }\n\n",
                                    "  23.SAP ABAP :     TRY.\n        oo_result = lo_lmd->updatefunctionconfiguration(     \" oo_result is returned for testing purposes. \"\n              iv_functionname = iv_function_name\n              iv_runtime = iv_runtime\n              iv_description  = 'Updated Lambda function'\n              iv_memorysize  = iv_memory_size\n          ).\n\n        MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    "  24.SDK for SAP ABAP :     TRY.\n        oo_result = lo_lmd->updatefunctionconfiguration(     \" oo_result is returned for testing purposes. \"\n              iv_functionname = iv_function_name\n              iv_runtime = iv_runtime\n              iv_description  = 'Updated Lambda function'\n              iv_memorysize  = iv_memory_size\n          ).\n\n        MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.\n      CATCH /aws1/cx_lmdcodesigningcfgno00.\n        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdcodeverification00.\n        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvalidcodesigex.\n        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.\n      CATCH /aws1/cx_lmdinvparamvalueex.\n        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourceconflictex.\n        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.\n      CATCH /aws1/cx_lmdresourcenotfoundex.\n        MESSAGE 'The requested resource does not exist.' TYPE 'E'.\n      CATCH /aws1/cx_lmdserviceexception.\n        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.\n      CATCH /aws1/cx_lmdtoomanyrequestsex.\n        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.\n    ENDTRY.\n\n",
                                    ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Update the code of a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function to update.</param>    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> UpdateFunctionConfigurationAsync(        string functionName,        string functionHandler,        Dictionary<string, string> environmentVariables)    {        var request = new UpdateFunctionConfigurationRequest        {            Handler = functionHandler,            FunctionName = functionName,            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },        };        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);        Console.WriteLine(response.LastModified);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.            Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region in which the bucket was created (overrides config file).        // clientConfig.region = \"us-east-1\";    Aws::Lambda::LambdaClient client(clientConfig);        Aws::Lambda::Model::UpdateFunctionConfigurationRequest request;        request.SetFunctionName(LAMBDA_NAME);        Aws::Lambda::Model::Environment environment;        environment.AddVariables(\"LOG_LEVEL\", \"DEBUG\");        request.SetEnvironment(environment);        Aws::Lambda::Model::UpdateFunctionConfigurationOutcome outcome = client.UpdateFunctionConfiguration(                request);        if (outcome.IsSuccess()) {            std::cout << \"The lambda configuration was successfully updated.\"                      << std::endl;            break;        }        else {            std::cerr << \"Error with Lambda::UpdateFunctionConfiguration. \"                      << outcome.GetError().GetMessage()                      << std::endl;        }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for C++ API Reference.                    CLIAWS CLITo modify the configuration of a functionThe following update-function-configuration example modifies the memory size to be 256 MB for the unpublished ($LATEST) version of the my-function function.aws lambda update-function-configuration \\    --function-name  my-function \\    --memory-size 256Output:{    \"FunctionName\": \"my-function\",    \"LastModified\": \"2019-09-26T20:28:40.438+0000\",    \"RevisionId\": \"e52502d4-9320-4688-9cd6-152a6ab7490d\",    \"MemorySize\": 256,    \"Version\": \"$LATEST\",    \"Role\": \"arn:aws:iam::123456789012:role/service-role/my-function-role-uy3l9qyq\",    \"Timeout\": 3,    \"Runtime\": \"nodejs10.x\",    \"TracingConfig\": {        \"Mode\": \"PassThrough\"    },    \"CodeSha256\": \"5tT2qgzYUHaqwR716pZ2dpkn/0J1FrzJmlKidWoaCgk=\",    \"Description\": \"\",    \"VpcConfig\": {        \"SubnetIds\": [],        \"VpcId\": \"\",        \"SecurityGroupIds\": []    },    \"CodeSize\": 304,    \"FunctionArn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-function\",    \"Handler\": \"index.handler\"}For more information, see AWS Lambda Function Configuration in the AWS Lambda Developer Guide.                        For API details, see                        UpdateFunctionConfiguration                        in AWS CLI Command Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import (\t\"bytes\"\t\"context\"\t\"encoding/json\"\t\"errors\"\t\"log\"\t\"time\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda/types\")// FunctionWrapper encapsulates function actions used in the examples.// It contains an AWS Lambda service client that is used to perform user actions.type FunctionWrapper struct {\tLambdaClient *lambda.Client}// UpdateFunctionConfiguration updates a map of environment variables configured for// the Lambda function specified by functionName.func (wrapper FunctionWrapper) UpdateFunctionConfiguration(ctx context.Context, functionName string, envVars map[string]string) {\t_, err := wrapper.LambdaClient.UpdateFunctionConfiguration(ctx, &lambda.UpdateFunctionConfigurationInput{\t\tFunctionName: aws.String(functionName),\t\tEnvironment:  &types.Environment{Variables: envVars},\t})\tif err != nil {\t\tlog.Panicf(\"Couldn't update configuration for %v. Here's why: %v\", functionName, err)\t}}                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Updates the configuration of an AWS Lambda function.     *     * @param awsLambda     the {@link LambdaClient} instance to use for the AWS Lambda operation     * @param functionName  the name of the AWS Lambda function to update     * @param handler       the new handler for the AWS Lambda function     *     * @throws LambdaException if there is an error while updating the function configuration     */    public static void updateFunctionConfiguration(LambdaClient awsLambda, String functionName, String handler) {        try {            UpdateFunctionConfigurationRequest configurationRequest = UpdateFunctionConfigurationRequest.builder()                .functionName(functionName)                .handler(handler)                .runtime(Runtime.JAVA17)                .build();            awsLambda.updateFunctionConfiguration(configurationRequest);        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    const updateFunctionConfiguration = (funcName) => {  const client = new LambdaClient({});  const config = readFileSync(`${dirname}../functions/config.json`).toString();  const command = new UpdateFunctionConfigurationCommand({    ...JSON.parse(config),    FunctionName: funcName,  });  const result = client.send(command);  waitForFunctionUpdated({ FunctionName: funcName });  return result;};                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for JavaScript API Reference.                    PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        public function updateFunctionConfiguration($functionName, $handler, $environment = '')    {        return $this->lambdaClient->updateFunctionConfiguration([            'FunctionName' => $functionName,            'Handler' => \"$handler.lambda_handler\",            'Environment' => $environment,        ]);    }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for PHP API Reference.                    PowerShellTools for PowerShellExample 1: This example updates the existing Lambda Function ConfigurationUpdate-LMFunctionConfiguration -FunctionName \"MylambdaFunction123\" -Handler \"lambda_function.launch_instance\" -Timeout 600 -Environment_Variable @{ \"envvar1\"=\"value\";\"envvar2\"=\"value\" } -Role arn:aws:iam::123456789101:role/service-role/lambda -DeadLetterConfig_TargetArn arn:aws:sns:us-east-1: 123456789101:MyfirstTopic                        For API details, see                        UpdateFunctionConfiguration                        in AWS Tools for PowerShell Cmdlet Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper:    def __init__(self, lambda_client, iam_resource):        self.lambda_client = lambda_client        self.iam_resource = iam_resource    def update_function_configuration(self, function_name, env_vars):        \"\"\"        Updates the environment variables for a Lambda function.        :param function_name: The name of the function to update.        :param env_vars: A dict of environment variables to update.        :return: Data about the update, including the status.        \"\"\"        try:            response = self.lambda_client.update_function_configuration(                FunctionName=function_name, Environment={\"Variables\": env_vars}            )        except ClientError as err:            logger.error(                \"Couldn't update function configuration %s. Here's why: %s: %s\",                function_name,                err.response[\"Error\"][\"Code\"],                err.response[\"Error\"][\"Message\"],            )            raise        else:            return response                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    class LambdaWrapper  attr_accessor :lambda_client, :cloudwatch_client, :iam_client  def initialize    @lambda_client = Aws::Lambda::Client.new    @cloudwatch_client = Aws::CloudWatchLogs::Client.new(region: 'us-east-1')    @iam_client = Aws::IAM::Client.new(region: 'us-east-1')    @logger = Logger.new($stdout)    @logger.level = Logger::WARN  end  # Updates the environment variables for a Lambda function.  # @param function_name: The name of the function to update.  # @param log_level: The log level of the function.  # @return: Data about the update, including the status.  def update_function_configuration(function_name, log_level)    @lambda_client.update_function_configuration({                                                   function_name: function_name,                                                   environment: {                                                     variables: {                                                       'LOG_LEVEL' => log_level                                                     }                                                   }                                                 })    @lambda_client.wait_until(:function_updated_v2, { function_name: function_name }) do |w|      w.max_attempts = 5      w.delay = 5    end  rescue Aws::Lambda::Errors::ServiceException => e    @logger.error(\"There was an error updating configurations for #{function_name}:\\n #{e.message}\")  rescue Aws::Waiters::Errors::WaiterFailed => e    @logger.error(\"Failed waiting for #{function_name} to activate:\\n #{e.message}\")  end                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for Ruby API Reference.                    RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /** Update the environment for a function. */    pub async fn update_function_configuration(        &self,        environment: Environment,    ) -> Result<UpdateFunctionConfigurationOutput, anyhow::Error> {        info!(            ?environment,            \"Updating environment for {}\", self.lambda_name        );        let updated = self            .lambda_client            .update_function_configuration()            .function_name(self.lambda_name.clone())            .environment(environment)            .send()            .await            .map_err(anyhow::Error::from)?;        self.wait_for_function_ready().await?;        Ok(updated)    }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for Rust API reference.                    SAP ABAPSDK for SAP ABAPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        TRY.        oo_result = lo_lmd->updatefunctionconfiguration(     \" oo_result is returned for testing purposes. \"              iv_functionname = iv_function_name              iv_runtime = iv_runtime              iv_description  = 'Updated Lambda function'              iv_memorysize  = iv_memory_size          ).        MESSAGE 'Lambda function configuration/settings updated.' TYPE 'I'.      CATCH /aws1/cx_lmdcodesigningcfgno00.        MESSAGE 'Code signing configuration does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdcodeverification00.        MESSAGE 'Code signature failed one or more validation checks for signature mismatch or expiration.' TYPE 'E'.      CATCH /aws1/cx_lmdinvalidcodesigex.        MESSAGE 'Code signature failed the integrity check.' TYPE 'E'.      CATCH /aws1/cx_lmdinvparamvalueex.        MESSAGE 'The request contains a non-valid parameter.' TYPE 'E'.      CATCH /aws1/cx_lmdresourceconflictex.        MESSAGE 'Resource already exists or another operation is in progress.' TYPE 'E'.      CATCH /aws1/cx_lmdresourcenotfoundex.        MESSAGE 'The requested resource does not exist.' TYPE 'E'.      CATCH /aws1/cx_lmdserviceexception.        MESSAGE 'An internal problem was encountered by the AWS Lambda service.' TYPE 'E'.      CATCH /aws1/cx_lmdtoomanyrequestsex.        MESSAGE 'The maximum request throughput was reached.' TYPE 'E'.    ENDTRY.                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for SAP ABAP API reference.                    ",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "anchor",
                                    "  1.AWS SDK for .NET :     /// <summary>\n    /// Update the code of a Lambda function.\n    /// </summary>\n    /// <param name=\"functionName\">The name of the function to update.</param>\n    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>\n    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>\n    /// <returns>A Boolean value indicating the success of the action.</returns>\n    public async Task<bool> UpdateFunctionConfigurationAsync(\n        string functionName,\n        string functionHandler,\n        Dictionary<string, string> environmentVariables)\n    {\n        var request = new UpdateFunctionConfigurationRequest\n        {\n            Handler = functionHandler,\n            FunctionName = functionName,\n            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },\n        };\n\n        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);\n\n        Console.WriteLine(response.LastModified);\n\n        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n    }\n\n\n",
                                    "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /// <summary>    /// Update the code of a Lambda function.    /// </summary>    /// <param name=\"functionName\">The name of the function to update.</param>    /// <param name=\"functionHandler\">The code that performs the function's actions.</param>    /// <param name=\"environmentVariables\">A dictionary of environment variables.</param>    /// <returns>A Boolean value indicating the success of the action.</returns>    public async Task<bool> UpdateFunctionConfigurationAsync(        string functionName,        string functionHandler,        Dictionary<string, string> environmentVariables)    {        var request = new UpdateFunctionConfigurationRequest        {            Handler = functionHandler,            FunctionName = functionName,            Environment = new Amazon.Lambda.Model.Environment { Variables = environmentVariables },        };        var response = await _lambdaService.UpdateFunctionConfigurationAsync(request);        Console.WriteLine(response.LastModified);        return response.HttpStatusCode == System.Net.HttpStatusCode.OK;    }                        For API details, see                        UpdateFunctionConfiguration                        in AWS SDK for .NET API Reference.                    ",
                                    "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                                ]
                            }
                        ],
                        "source": "Aws",
                        "sections": [
                            "The following code examples demonstrate how to perform individual Lambda        actions with AWS SDKs. Each example includes        a link to GitHub, where you can find instructions for setting up and running the code.    ",
                            "These excerpts call the Lambda API and        are code excerpts from larger programs that must be run in context.        You can see actions in context in        Scenarios for            Lambda using AWS SDKs        .    ",
                            "        The following examples include only the most commonly used actions.        For a complete list, see the        AWS Lambda API Reference.    ",
                            "Examples"
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "The following code examples show how to use the basics of AWS Lambda with AWS    SDKs.",
                    "Examples"
                ]
            },
            {
                "title": "Scenarios",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/service_code_examples_scenarios.html",
                "contents": [
                    {
                        "title": "Automatically confirm known users with a Lambda function",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_CognitoAutoConfirmUser_section.html",
                        "sections": [
                            "The following code examples show how to automatically confirm known Amazon Cognito users with a Lambda function.",
                            "  1.Configure a user pool to call a Lambda function for the PreSignUp trigger.",
                            "  2.Sign up a user with Amazon Cognito.",
                            "  3.The Lambda function scans a DynamoDB table and automatically confirms known users.",
                            "  4.Sign in as the new user, then clean up resources.",
                            "  1.Go : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// AutoConfirm separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype AutoConfirm struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewAutoConfirm constructs a new auto confirm runner.\nfunc NewAutoConfirm(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) AutoConfirm {\n\tscenario := AutoConfirm{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddPreSignUpTrigger adds a Lambda handler as an invocation target for the PreSignUp trigger.\nfunc (runner *AutoConfirm) AddPreSignUpTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the PreSignUp trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when a user signs up, and lets your function take action before the main Cognito\\n\" +\n\t\t\"sign up processing occurs.\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PreSignUp, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the PreSignUp trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n}\n\n// SignUpUser signs up a user from the known user table with a password you specify.\nfunc (runner *AutoConfirm) SignUpUser(ctx context.Context, clientId string, usersTable string) (string, string) {\n\tlog.Println(\"Let's sign up a user to your Cognito user pool. When the user's email matches an email in the\\n\" +\n\t\t\"DynamoDB known users table, it is automatically verified and the user is confirmed.\")\n\n\tknownUsers, err := runner.helper.GetKnownUsers(ctx, usersTable)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuserChoice := runner.questioner.AskChoice(\"Which user do you want to use?\\n\", knownUsers.UserNameList())\n\tuser := knownUsers.Users[userChoice]\n\n\tvar signedUp bool\n\tvar userConfirmed bool\n\tpassword := runner.questioner.AskPassword(\"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !signedUp {\n\t\tlog.Printf(\"Signing up user '%v' with email '%v' to Cognito.\\n\", user.UserName, user.UserEmail)\n\t\tuserConfirmed, err = runner.cognitoActor.SignUp(ctx, clientId, user.UserName, password, user.UserEmail)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"Enter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tsignedUp = true\n\t\t}\n\t}\n\tlog.Printf(\"User %v signed up, confirmed = %v.\\n\", user.UserName, userConfirmed)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// SignInUser signs in a user.\nfunc (runner *AutoConfirm) SignInUser(ctx context.Context, clientId string, userName string, password string) string {\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tlog.Printf(\"Let's sign in as %v...\\n\", userName)\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn *authResult.AccessToken\n}\n\n// Run runs the scenario.\nfunc (runner *AutoConfirm) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\n\trunner.AddPreSignUpTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"AutoConfirmFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PreSignUp)\n\tuserName, password := runner.SignUpUser(ctx, stackOutputs[\"UserPoolClientId\"], stackOutputs[\"TableName\"])\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"AutoConfirmFunction\"])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens,\n\t\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password))\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "  2.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// AutoConfirm separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype AutoConfirm struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewAutoConfirm constructs a new auto confirm runner.\nfunc NewAutoConfirm(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) AutoConfirm {\n\tscenario := AutoConfirm{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddPreSignUpTrigger adds a Lambda handler as an invocation target for the PreSignUp trigger.\nfunc (runner *AutoConfirm) AddPreSignUpTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the PreSignUp trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when a user signs up, and lets your function take action before the main Cognito\\n\" +\n\t\t\"sign up processing occurs.\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PreSignUp, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the PreSignUp trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n}\n\n// SignUpUser signs up a user from the known user table with a password you specify.\nfunc (runner *AutoConfirm) SignUpUser(ctx context.Context, clientId string, usersTable string) (string, string) {\n\tlog.Println(\"Let's sign up a user to your Cognito user pool. When the user's email matches an email in the\\n\" +\n\t\t\"DynamoDB known users table, it is automatically verified and the user is confirmed.\")\n\n\tknownUsers, err := runner.helper.GetKnownUsers(ctx, usersTable)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuserChoice := runner.questioner.AskChoice(\"Which user do you want to use?\\n\", knownUsers.UserNameList())\n\tuser := knownUsers.Users[userChoice]\n\n\tvar signedUp bool\n\tvar userConfirmed bool\n\tpassword := runner.questioner.AskPassword(\"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !signedUp {\n\t\tlog.Printf(\"Signing up user '%v' with email '%v' to Cognito.\\n\", user.UserName, user.UserEmail)\n\t\tuserConfirmed, err = runner.cognitoActor.SignUp(ctx, clientId, user.UserName, password, user.UserEmail)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"Enter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tsignedUp = true\n\t\t}\n\t}\n\tlog.Printf(\"User %v signed up, confirmed = %v.\\n\", user.UserName, userConfirmed)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// SignInUser signs in a user.\nfunc (runner *AutoConfirm) SignInUser(ctx context.Context, clientId string, userName string, password string) string {\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tlog.Printf(\"Let's sign in as %v...\\n\", userName)\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn *authResult.AccessToken\n}\n\n// Run runs the scenario.\nfunc (runner *AutoConfirm) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\n\trunner.AddPreSignUpTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"AutoConfirmFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PreSignUp)\n\tuserName, password := runner.SignUpUser(ctx, stackOutputs[\"UserPoolClientId\"], stackOutputs[\"TableName\"])\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"AutoConfirmFunction\"])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens,\n\t\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password))\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "  3.JavaScript : import { AutoConfirm } from \"./scenario-auto-confirm.js\";\n\n/**\n * The context is passed to every scenario. Scenario steps\n * will modify the context.\n */\nconst context = {\n  errors: [],\n  users: [\n    {\n      UserName: \"test_user_1\",\n      UserEmail: \"test_email_1@example.com\",\n    },\n    {\n      UserName: \"test_user_2\",\n      UserEmail: \"test_email_2@example.com\",\n    },\n    {\n      UserName: \"test_user_3\",\n      UserEmail: \"test_email_3@example.com\",\n    },\n  ],\n};\n\n/**\n * Three Scenarios are created for the workflow. A Scenario is an orchestration class\n * that simplifies running a series of steps.\n */\nexport const scenarios = {\n  // Demonstrate automatically confirming known users in a database.\n  \"auto-confirm\": AutoConfirm(context),\n};\n\n// Call function if run directly\nimport { fileURLToPath } from \"node:url\";\nimport { parseScenarioArgs } from \"@aws-doc-sdk-examples/lib/scenario/index.js\";\n\nif (process.argv[1] === fileURLToPath(import.meta.url)) {\n  parseScenarioArgs(scenarios, {\n    name: \"Cognito user pools and triggers\",\n    description:\n      \"Demonstrate how to use the AWS SDKs to customize Amazon Cognito authentication behavior.\",\n  });\n}\n\n",
                            "  4.SDK for JavaScript (v3) : import { AutoConfirm } from \"./scenario-auto-confirm.js\";\n\n/**\n * The context is passed to every scenario. Scenario steps\n * will modify the context.\n */\nconst context = {\n  errors: [],\n  users: [\n    {\n      UserName: \"test_user_1\",\n      UserEmail: \"test_email_1@example.com\",\n    },\n    {\n      UserName: \"test_user_2\",\n      UserEmail: \"test_email_2@example.com\",\n    },\n    {\n      UserName: \"test_user_3\",\n      UserEmail: \"test_email_3@example.com\",\n    },\n  ],\n};\n\n/**\n * Three Scenarios are created for the workflow. A Scenario is an orchestration class\n * that simplifies running a series of steps.\n */\nexport const scenarios = {\n  // Demonstrate automatically confirming known users in a database.\n  \"auto-confirm\": AutoConfirm(context),\n};\n\n// Call function if run directly\nimport { fileURLToPath } from \"node:url\";\nimport { parseScenarioArgs } from \"@aws-doc-sdk-examples/lib/scenario/index.js\";\n\nif (process.argv[1] === fileURLToPath(import.meta.url)) {\n  parseScenarioArgs(scenarios, {\n    name: \"Cognito user pools and triggers\",\n    description:\n      \"Demonstrate how to use the AWS SDKs to customize Amazon Cognito authentication behavior.\",\n  });\n}\n\n",
                            "GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// AutoConfirm separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type AutoConfirm struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewAutoConfirm constructs a new auto confirm runner.func NewAutoConfirm(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) AutoConfirm {\tscenario := AutoConfirm{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddPreSignUpTrigger adds a Lambda handler as an invocation target for the PreSignUp trigger.func (runner *AutoConfirm) AddPreSignUpTrigger(ctx context.Context, userPoolId string, functionArn string) {\tlog.Printf(\"Let's add a Lambda function to handle the PreSignUp trigger from Cognito.\\n\" +\t\t\"This trigger happens when a user signs up, and lets your function take action before the main Cognito\\n\" +\t\t\"sign up processing occurs.\\n\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.PreSignUp, HandlerArn: aws.String(functionArn)})\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Lambda function %v added to user pool %v to handle the PreSignUp trigger.\\n\",\t\tfunctionArn, userPoolId)}// SignUpUser signs up a user from the known user table with a password you specify.func (runner *AutoConfirm) SignUpUser(ctx context.Context, clientId string, usersTable string) (string, string) {\tlog.Println(\"Let's sign up a user to your Cognito user pool. When the user's email matches an email in the\\n\" +\t\t\"DynamoDB known users table, it is automatically verified and the user is confirmed.\")\tknownUsers, err := runner.helper.GetKnownUsers(ctx, usersTable)\tif err != nil {\t\tpanic(err)\t}\tuserChoice := runner.questioner.AskChoice(\"Which user do you want to use?\\n\", knownUsers.UserNameList())\tuser := knownUsers.Users[userChoice]\tvar signedUp bool\tvar userConfirmed bool\tpassword := runner.questioner.AskPassword(\"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !signedUp {\t\tlog.Printf(\"Signing up user '%v' with email '%v' to Cognito.\\n\", user.UserName, user.UserEmail)\t\tuserConfirmed, err = runner.cognitoActor.SignUp(ctx, clientId, user.UserName, password, user.UserEmail)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"Enter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tsignedUp = true\t\t}\t}\tlog.Printf(\"User %v signed up, confirmed = %v.\\n\", user.UserName, userConfirmed)\tlog.Println(strings.Repeat(\"-\", 88))\treturn user.UserName, password}// SignInUser signs in a user.func (runner *AutoConfirm) SignInUser(ctx context.Context, clientId string, userName string, password string) string {\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\tlog.Printf(\"Let's sign in as %v...\\n\", userName)\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\tlog.Println(strings.Repeat(\"-\", 88))\treturn *authResult.AccessToken}// Run runs the scenario.func (runner *AutoConfirm) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\trunner.AddPreSignUpTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"AutoConfirmFunctionArn\"])\trunner.resources.triggers = append(runner.resources.triggers, actions.PreSignUp)\tuserName, password := runner.SignUpUser(ctx, stackOutputs[\"UserPoolClientId\"], stackOutputs[\"TableName\"])\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"AutoConfirmFunction\"])\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens,\t\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password))\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the PreSignUp trigger with a Lambda function.import (\t\"context\"\t\"log\"\t\"os\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\tdynamodbtypes \"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")const TABLE_NAME = \"TABLE_NAME\"// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string `dynamodbav:\"UserName\"`\tUserEmail string `dynamodbav:\"UserEmail\"`}// GetKey marshals the user email value to a DynamoDB key format.func (user UserInfo) GetKey() map[string]dynamodbtypes.AttributeValue {\tuserEmail, err := attributevalue.Marshal(user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\treturn map[string]dynamodbtypes.AttributeValue{\"UserEmail\": userEmail}}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the PreSignUp event by looking up a user in an Amazon DynamoDB table and// specifying whether they should be confirmed and verified.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) {\tlog.Printf(\"Received presignup from %v for user '%v'\", event.TriggerSource, event.UserName)\tif event.TriggerSource != \"PreSignUp_SignUp\" {\t\t// Other trigger sources, such as PreSignUp_AdminInitiateAuth, ignore the response from this handler.\t\treturn event, nil\t}\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserEmail: event.Request.UserAttributes[\"email\"],\t}\tlog.Printf(\"Looking up email %v in table %v.\\n\", user.UserEmail, tableName)\toutput, err := h.dynamoClient.GetItem(ctx, &dynamodb.GetItemInput{\t\tKey:       user.GetKey(),\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Error looking up email %v.\\n\", user.UserEmail)\t\treturn event, err\t}\tif output.Item == nil {\t\tlog.Printf(\"Email %v not found. Email verification is required.\\n\", user.UserEmail)\t\treturn event, err\t}\terr = attributevalue.UnmarshalMap(output.Item, &user)\tif err != nil {\t\tlog.Printf(\"Couldn't unmarshal DynamoDB item. Here's why: %v\\n\", err)\t\treturn event, err\t}\tif user.UserName != event.UserName {\t\tlog.Printf(\"UserEmail %v found, but stored UserName '%v' does not match supplied UserName '%v'. Verification is required.\\n\",\t\t\tuser.UserEmail, user.UserName, event.UserName)\t} else {\t\tlog.Printf(\"UserEmail %v found with matching UserName %v. User is confirmed.\\n\", user.UserEmail, user.UserName)\t\tevent.Response.AutoConfirmUser = true\t\tevent.Response.AutoVerifyEmail = true\t}\treturn event, err}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.DeleteUserInitiateAuthSignUpUpdateUserPoolJavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Configure an interactive \"Scenario\" run. The JavaScript (v3) examplesshare a Scenario runner to streamline complex examples. The completesource code is on GitHub.import { AutoConfirm } from \"./scenario-auto-confirm.js\";/** * The context is passed to every scenario. Scenario steps * will modify the context. */const context = {  errors: [],  users: [    {      UserName: \"test_user_1\",      UserEmail: \"test_email_1@example.com\",    },    {      UserName: \"test_user_2\",      UserEmail: \"test_email_2@example.com\",    },    {      UserName: \"test_user_3\",      UserEmail: \"test_email_3@example.com\",    },  ],};/** * Three Scenarios are created for the workflow. A Scenario is an orchestration class * that simplifies running a series of steps. */export const scenarios = {  // Demonstrate automatically confirming known users in a database.  \"auto-confirm\": AutoConfirm(context),};// Call function if run directlyimport { fileURLToPath } from \"node:url\";import { parseScenarioArgs } from \"@aws-doc-sdk-examples/lib/scenario/index.js\";if (process.argv[1] === fileURLToPath(import.meta.url)) {  parseScenarioArgs(scenarios, {    name: \"Cognito user pools and triggers\",    description:      \"Demonstrate how to use the AWS SDKs to customize Amazon Cognito authentication behavior.\",  });}This Scenario demonstrates auto-confirming a known user.It orchestrates the example steps.import { wait } from \"@aws-doc-sdk-examples/lib/utils/util-timers.js\";import {  Scenario,  ScenarioAction,  ScenarioInput,  ScenarioOutput,} from \"@aws-doc-sdk-examples/lib/scenario/scenario.js\";import {  getStackOutputs,  logCleanUpReminder,  promptForStackName,  promptForStackRegion,  skipWhenErrors,} from \"./steps-common.js\";import { populateTable } from \"./actions/dynamodb-actions.js\";import {  addPreSignUpHandler,  deleteUser,  getUser,  signIn,  signUpUser,} from \"./actions/cognito-actions.js\";import {  getLatestLogStreamForLambda,  getLogEvents,} from \"./actions/cloudwatch-logs-actions.js\";/** * @typedef {{ *   errors: Error[], *   password: string, *   users: { UserName: string, UserEmail: string }[], *   selectedUser?: string, *   stackName?: string, *   stackRegion?: string, *   token?: string, *   confirmDeleteSignedInUser?: boolean, *   TableName?: string, *   UserPoolClientId?: string, *   UserPoolId?: string, *   UserPoolArn?: string, *   AutoConfirmHandlerArn?: string, *   AutoConfirmHandlerName?: string * }} State */const greeting = new ScenarioOutput(  \"greeting\",  (/** @type {State} */ state) => `This demo will populate some users into the \\database created as part of the \"${state.stackName}\" stack. \\Then the autoConfirmHandler will be linked to the PreSignUp \\trigger from Cognito. Finally, you will choose a user to sign up.`,  { skipWhen: skipWhenErrors },);const logPopulatingUsers = new ScenarioOutput(  \"logPopulatingUsers\",  \"Populating the DynamoDB table with some users.\",  { skipWhenErrors: skipWhenErrors },);const logPopulatingUsersComplete = new ScenarioOutput(  \"logPopulatingUsersComplete\",  \"Done populating users.\",  { skipWhen: skipWhenErrors },);const populateUsers = new ScenarioAction(  \"populateUsers\",  async (/** @type {State} */ state) => {    const [_, err] = await populateTable({      region: state.stackRegion,      tableName: state.TableName,      items: state.users,    });    if (err) {      state.errors.push(err);    }  },  {    skipWhen: skipWhenErrors,  },);const logSetupSignUpTrigger = new ScenarioOutput(  \"logSetupSignUpTrigger\",  \"Setting up the PreSignUp trigger for the Cognito User Pool.\",  { skipWhen: skipWhenErrors },);const setupSignUpTrigger = new ScenarioAction(  \"setupSignUpTrigger\",  async (/** @type {State} */ state) => {    const [_, err] = await addPreSignUpHandler({      region: state.stackRegion,      userPoolId: state.UserPoolId,      handlerArn: state.AutoConfirmHandlerArn,    });    if (err) {      state.errors.push(err);    }  },  {    skipWhen: skipWhenErrors,  },);const logSetupSignUpTriggerComplete = new ScenarioOutput(  \"logSetupSignUpTriggerComplete\",  (    /** @type {State} */ state,  ) => `The lambda function \"${state.AutoConfirmHandlerName}\" \\has been configured as the PreSignUp trigger handler for the user pool \"${state.UserPoolId}\".`,  { skipWhen: skipWhenErrors },);const selectUser = new ScenarioInput(  \"selectedUser\",  \"Select a user to sign up.\",  {    type: \"select\",    choices: (/** @type {State} */ state) => state.users.map((u) => u.UserName),    skipWhen: skipWhenErrors,    default: (/** @type {State} */ state) => state.users[0].UserName,  },);const checkIfUserAlreadyExists = new ScenarioAction(  \"checkIfUserAlreadyExists\",  async (/** @type {State} */ state) => {    const [user, err] = await getUser({      region: state.stackRegion,      userPoolId: state.UserPoolId,      username: state.selectedUser,    });    if (err?.name === \"UserNotFoundException\") {      // Do nothing. We're not expecting the user to exist before      // sign up is complete.      return;    }    if (err) {      state.errors.push(err);      return;    }    if (user) {      state.errors.push(        new Error(          `The user \"${state.selectedUser}\" already exists in the user pool \"${state.UserPoolId}\".`,        ),      );    }  },  {    skipWhen: skipWhenErrors,  },);const createPassword = new ScenarioInput(  \"password\",  \"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\",  { type: \"password\", skipWhen: skipWhenErrors, default: \"Abcd1234!\" },);const logSignUpExistingUser = new ScenarioOutput(  \"logSignUpExistingUser\",  (/** @type {State} */ state) => `Signing up user \"${state.selectedUser}\".`,  { skipWhen: skipWhenErrors },);const signUpExistingUser = new ScenarioAction(  \"signUpExistingUser\",  async (/** @type {State} */ state) => {    const signUp = (password) =>      signUpUser({        region: state.stackRegion,        userPoolClientId: state.UserPoolClientId,        username: state.selectedUser,        email: state.users.find((u) => u.UserName === state.selectedUser)          .UserEmail,        password,      });    let [_, err] = await signUp(state.password);    while (err?.name === \"InvalidPasswordException\") {      console.warn(\"The password you entered was invalid.\");      await createPassword.handle(state);      [_, err] = await signUp(state.password);    }    if (err) {      state.errors.push(err);    }  },  { skipWhen: skipWhenErrors },);const logSignUpExistingUserComplete = new ScenarioOutput(  \"logSignUpExistingUserComplete\",  (/** @type {State} */ state) =>    `\"${state.selectedUser} was signed up successfully.`,  { skipWhen: skipWhenErrors },);const logLambdaLogs = new ScenarioAction(  \"logLambdaLogs\",  async (/** @type {State} */ state) => {    console.log(      \"Waiting a few seconds to let Lambda write to CloudWatch Logs...\\n\",    );    await wait(10);    const [logStream, logStreamErr] = await getLatestLogStreamForLambda({      functionName: state.AutoConfirmHandlerName,      region: state.stackRegion,    });    if (logStreamErr) {      state.errors.push(logStreamErr);      return;    }    console.log(      `Getting some recent events from log stream \"${logStream.logStreamName}\"`,    );    const [logEvents, logEventsErr] = await getLogEvents({      functionName: state.AutoConfirmHandlerName,      region: state.stackRegion,      eventCount: 10,      logStreamName: logStream.logStreamName,    });    if (logEventsErr) {      state.errors.push(logEventsErr);      return;    }    console.log(logEvents.map((ev) => `\\t${ev.message}`).join(\"\"));  },  { skipWhen: skipWhenErrors },);const logSignInUser = new ScenarioOutput(  \"logSignInUser\",  (/** @type {State} */ state) => `Let's sign in as ${state.selectedUser}`,  { skipWhen: skipWhenErrors },);const signInUser = new ScenarioAction(  \"signInUser\",  async (/** @type {State} */ state) => {    const [response, err] = await signIn({      region: state.stackRegion,      clientId: state.UserPoolClientId,      username: state.selectedUser,      password: state.password,    });    if (err?.name === \"PasswordResetRequiredException\") {      state.errors.push(new Error(\"Please reset your password.\"));      return;    }    if (err) {      state.errors.push(err);      return;    }    state.token = response?.AuthenticationResult?.AccessToken;  },  { skipWhen: skipWhenErrors },);const logSignInUserComplete = new ScenarioOutput(  \"logSignInUserComplete\",  (/** @type {State} */ state) =>    `Successfully signed in. Your access token starts with: ${state.token.slice(0, 11)}`,  { skipWhen: skipWhenErrors },);const confirmDeleteSignedInUser = new ScenarioInput(  \"confirmDeleteSignedInUser\",  \"Do you want to delete the currently signed in user?\",  { type: \"confirm\", skipWhen: skipWhenErrors },);const deleteSignedInUser = new ScenarioAction(  \"deleteSignedInUser\",  async (/** @type {State} */ state) => {    const [_, err] = await deleteUser({      region: state.stackRegion,      accessToken: state.token,    });    if (err) {      state.errors.push(err);    }  },  {    skipWhen: (/** @type {State} */ state) =>      skipWhenErrors(state) || !state.confirmDeleteSignedInUser,  },);const logErrors = new ScenarioOutput(  \"logErrors\",  (/** @type {State}*/ state) => {    const errorList = state.errors      .map((err) => ` - ${err.name}: ${err.message}`)      .join(\"\\n\");    return `Scenario errors found:\\n${errorList}`;  },  {    // Don't log errors when there aren't any!    skipWhen: (/** @type {State} */ state) => state.errors.length === 0,  },);export const AutoConfirm = (context) =>  new Scenario(    \"AutoConfirm\",    [      promptForStackName,      promptForStackRegion,      getStackOutputs,      greeting,      logPopulatingUsers,      populateUsers,      logPopulatingUsersComplete,      logSetupSignUpTrigger,      setupSignUpTrigger,      logSetupSignUpTriggerComplete,      selectUser,      checkIfUserAlreadyExists,      createPassword,      logSignUpExistingUser,      signUpExistingUser,      logSignUpExistingUserComplete,      logLambdaLogs,      logSignInUser,      signInUser,      logSignInUserComplete,      confirmDeleteSignedInUser,      deleteSignedInUser,      logCleanUpReminder,      logErrors,    ],    context,  );These are steps that are shared with other Scenarios.import {  ScenarioAction,  ScenarioInput,  ScenarioOutput,} from \"@aws-doc-sdk-examples/lib/scenario/scenario.js\";import { getCfnOutputs } from \"@aws-doc-sdk-examples/lib/sdk/cfn-outputs.js\";export const skipWhenErrors = (state) => state.errors.length > 0;export const getStackOutputs = new ScenarioAction(  \"getStackOutputs\",  async (state) => {    if (!state.stackName || !state.stackRegion) {      state.errors.push(        new Error(          \"No stack name or region provided. The stack name and \\region are required to fetch CFN outputs relevant to this example.\",        ),      );      return;    }    const outputs = await getCfnOutputs(state.stackName, state.stackRegion);    Object.assign(state, outputs);  },);export const promptForStackName = new ScenarioInput(  \"stackName\",  \"Enter the name of the stack you deployed earlier.\",  { type: \"input\", default: \"PoolsAndTriggersStack\" },);export const promptForStackRegion = new ScenarioInput(  \"stackRegion\",  \"Enter the region of the stack you deployed earlier.\",  { type: \"input\", default: \"us-east-1\" },);export const logCleanUpReminder = new ScenarioOutput(  \"logCleanUpReminder\",  \"All done. Remember to run 'cdk destroy' to teardown the stack.\",  { skipWhen: skipWhenErrors },);A handler for the PreSignUp trigger with a Lambda function.import type { PreSignUpTriggerEvent, Handler } from \"aws-lambda\";import type { UserRepository } from \"./user-repository\";import { DynamoDBUserRepository } from \"./user-repository\";export class PreSignUpHandler {  private userRepository: UserRepository;  constructor(userRepository: UserRepository) {    this.userRepository = userRepository;  }  private isPreSignUpTriggerSource(event: PreSignUpTriggerEvent): boolean {    return event.triggerSource === \"PreSignUp_SignUp\";  }  private getEventUserEmail(event: PreSignUpTriggerEvent): string {    return event.request.userAttributes.email;  }  async handlePreSignUpTriggerEvent(    event: PreSignUpTriggerEvent,  ): Promise<PreSignUpTriggerEvent> {    console.log(      `Received presignup from ${event.triggerSource} for user '${event.userName}'`,    );    if (!this.isPreSignUpTriggerSource(event)) {      return event;    }    const eventEmail = this.getEventUserEmail(event);    console.log(`Looking up email ${eventEmail}.`);    const storedUserInfo =      await this.userRepository.getUserInfoByEmail(eventEmail);    if (!storedUserInfo) {      console.log(        `Email ${eventEmail} not found. Email verification is required.`,      );      return event;    }    if (storedUserInfo.UserName !== event.userName) {      console.log(        `UserEmail ${eventEmail} found, but stored UserName '${storedUserInfo.UserName}' does not match supplied UserName '${event.userName}'. Verification is required.`,      );    } else {      console.log(        `UserEmail ${eventEmail} found with matching UserName ${storedUserInfo.UserName}. User is confirmed.`,      );      event.response.autoConfirmUser = true;      event.response.autoVerifyEmail = true;    }    return event;  }}const createPreSignUpHandler = (): PreSignUpHandler => {  const tableName = process.env.TABLE_NAME;  if (!tableName) {    throw new Error(\"TABLE_NAME environment variable is not set\");  }  const userRepository = new DynamoDBUserRepository(tableName);  return new PreSignUpHandler(userRepository);};export const handler: Handler = async (event: PreSignUpTriggerEvent) => {  const preSignUpHandler = createPreSignUpHandler();  return preSignUpHandler.handlePreSignUpTriggerEvent(event);};Module of CloudWatch Logs actions.import {  CloudWatchLogsClient,  GetLogEventsCommand,  OrderBy,  paginateDescribeLogStreams,} from \"@aws-sdk/client-cloudwatch-logs\";/** * Get the latest log stream for a Lambda function. * @param {{ functionName: string, region: string }} config * @returns {Promise<[import(\"@aws-sdk/client-cloudwatch-logs\").LogStream | null, unknown]>} */export const getLatestLogStreamForLambda = async ({ functionName, region }) => {  try {    const logGroupName = `/aws/lambda/${functionName}`;    const cwlClient = new CloudWatchLogsClient({ region });    const paginator = paginateDescribeLogStreams(      { client: cwlClient },      {        descending: true,        limit: 1,        orderBy: OrderBy.LastEventTime,        logGroupName,      },    );    for await (const page of paginator) {      return [page.logStreams[0], null];    }  } catch (err) {    return [null, err];  }};/** * Get the log events for a Lambda function's log stream. * @param {{ *   functionName: string, *   logStreamName: string, *   eventCount: number, *   region: string * }} config * @returns {Promise<[import(\"@aws-sdk/client-cloudwatch-logs\").OutputLogEvent[] | null, unknown]>} */export const getLogEvents = async ({  functionName,  logStreamName,  eventCount,  region,}) => {  try {    const cwlClient = new CloudWatchLogsClient({ region });    const logGroupName = `/aws/lambda/${functionName}`;    const response = await cwlClient.send(      new GetLogEventsCommand({        logStreamName: logStreamName,        limit: eventCount,        logGroupName: logGroupName,      }),    );    return [response.events, null];  } catch (err) {    return [null, err];  }};Module of Amazon Cognito actions.import {  AdminGetUserCommand,  CognitoIdentityProviderClient,  DeleteUserCommand,  InitiateAuthCommand,  SignUpCommand,  UpdateUserPoolCommand,} from \"@aws-sdk/client-cognito-identity-provider\";/** * Connect a Lambda function to the PreSignUp trigger for a Cognito user pool * @param {{ region: string, userPoolId: string, handlerArn: string }} config * @returns {Promise<[import(\"@aws-sdk/client-cognito-identity-provider\").UpdateUserPoolCommandOutput | null, unknown]>} */export const addPreSignUpHandler = async ({  region,  userPoolId,  handlerArn,}) => {  try {    const cognitoClient = new CognitoIdentityProviderClient({      region,    });    const command = new UpdateUserPoolCommand({      UserPoolId: userPoolId,      LambdaConfig: {        PreSignUp: handlerArn,      },    });    const response = await cognitoClient.send(command);    return [response, null];  } catch (err) {    return [null, err];  }};/** * Attempt to register a user to a user pool with a given username and password. * @param {{ *   region: string, *   userPoolClientId: string, *   username: string, *   email: string, *   password: string * }} config * @returns {Promise<[import(\"@aws-sdk/client-cognito-identity-provider\").SignUpCommandOutput | null, unknown]>} */export const signUpUser = async ({  region,  userPoolClientId,  username,  email,  password,}) => {  try {    const cognitoClient = new CognitoIdentityProviderClient({      region,    });    const response = await cognitoClient.send(      new SignUpCommand({        ClientId: userPoolClientId,        Username: username,        Password: password,        UserAttributes: [{ Name: \"email\", Value: email }],      }),    );    return [response, null];  } catch (err) {    return [null, err];  }};/** * Sign in a user to Amazon Cognito using a username and password authentication flow. * @param {{ region: string, clientId: string, username: string, password: string }} config * @returns {Promise<[import(\"@aws-sdk/client-cognito-identity-provider\").InitiateAuthCommandOutput | null, unknown]>} */export const signIn = async ({ region, clientId, username, password }) => {  try {    const cognitoClient = new CognitoIdentityProviderClient({ region });    const response = await cognitoClient.send(      new InitiateAuthCommand({        AuthFlow: \"USER_PASSWORD_AUTH\",        ClientId: clientId,        AuthParameters: { USERNAME: username, PASSWORD: password },      }),    );    return [response, null];  } catch (err) {    return [null, err];  }};/** * Retrieve an existing user from a user pool. * @param {{ region: string, userPoolId: string, username: string }} config * @returns {Promise<[import(\"@aws-sdk/client-cognito-identity-provider\").AdminGetUserCommandOutput | null, unknown]>} */export const getUser = async ({ region, userPoolId, username }) => {  try {    const cognitoClient = new CognitoIdentityProviderClient({ region });    const response = await cognitoClient.send(      new AdminGetUserCommand({        UserPoolId: userPoolId,        Username: username,      }),    );    return [response, null];  } catch (err) {    return [null, err];  }};/** * Delete the signed-in user. Useful for allowing a user to delete their * own profile. * @param {{ region: string, accessToken: string }} config * @returns {Promise<[import(\"@aws-sdk/client-cognito-identity-provider\").DeleteUserCommandOutput | null, unknown]>} */export const deleteUser = async ({ region, accessToken }) => {  try {    const client = new CognitoIdentityProviderClient({ region });    const response = await client.send(      new DeleteUserCommand({ AccessToken: accessToken }),    );    return [response, null];  } catch (err) {    return [null, err];  }};Module of DynamoDB actions.import { DynamoDBClient } from \"@aws-sdk/client-dynamodb\";import {  BatchWriteCommand,  DynamoDBDocumentClient,} from \"@aws-sdk/lib-dynamodb\";/** * Populate a DynamoDB table with provide items. * @param {{ region: string, tableName: string, items: Record<string, unknown>[] }} config * @returns {Promise<[import(\"@aws-sdk/lib-dynamodb\").BatchWriteCommandOutput | null, unknown]>} */export const populateTable = async ({ region, tableName, items }) => {  try {    const ddbClient = new DynamoDBClient({ region });    const docClient = DynamoDBDocumentClient.from(ddbClient);    const response = await docClient.send(      new BatchWriteCommand({        RequestItems: {          [tableName]: items.map((item) => ({            PutRequest: {              Item: item,            },          })),        },      }),    );    return [response, null];  } catch (err) {    return [null, err];  }};For API details, see the following topics in AWS SDK for JavaScript API Reference.DeleteUserInitiateAuthSignUpUpdateUserPool",
                            "anchor",
                            "anchor",
                            "  1.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// AutoConfirm separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype AutoConfirm struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewAutoConfirm constructs a new auto confirm runner.\nfunc NewAutoConfirm(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) AutoConfirm {\n\tscenario := AutoConfirm{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddPreSignUpTrigger adds a Lambda handler as an invocation target for the PreSignUp trigger.\nfunc (runner *AutoConfirm) AddPreSignUpTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the PreSignUp trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when a user signs up, and lets your function take action before the main Cognito\\n\" +\n\t\t\"sign up processing occurs.\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PreSignUp, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the PreSignUp trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n}\n\n// SignUpUser signs up a user from the known user table with a password you specify.\nfunc (runner *AutoConfirm) SignUpUser(ctx context.Context, clientId string, usersTable string) (string, string) {\n\tlog.Println(\"Let's sign up a user to your Cognito user pool. When the user's email matches an email in the\\n\" +\n\t\t\"DynamoDB known users table, it is automatically verified and the user is confirmed.\")\n\n\tknownUsers, err := runner.helper.GetKnownUsers(ctx, usersTable)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuserChoice := runner.questioner.AskChoice(\"Which user do you want to use?\\n\", knownUsers.UserNameList())\n\tuser := knownUsers.Users[userChoice]\n\n\tvar signedUp bool\n\tvar userConfirmed bool\n\tpassword := runner.questioner.AskPassword(\"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !signedUp {\n\t\tlog.Printf(\"Signing up user '%v' with email '%v' to Cognito.\\n\", user.UserName, user.UserEmail)\n\t\tuserConfirmed, err = runner.cognitoActor.SignUp(ctx, clientId, user.UserName, password, user.UserEmail)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"Enter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tsignedUp = true\n\t\t}\n\t}\n\tlog.Printf(\"User %v signed up, confirmed = %v.\\n\", user.UserName, userConfirmed)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// SignInUser signs in a user.\nfunc (runner *AutoConfirm) SignInUser(ctx context.Context, clientId string, userName string, password string) string {\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tlog.Printf(\"Let's sign in as %v...\\n\", userName)\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn *authResult.AccessToken\n}\n\n// Run runs the scenario.\nfunc (runner *AutoConfirm) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\n\trunner.AddPreSignUpTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"AutoConfirmFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PreSignUp)\n\tuserName, password := runner.SignUpUser(ctx, stackOutputs[\"UserPoolClientId\"], stackOutputs[\"TableName\"])\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"AutoConfirmFunction\"])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens,\n\t\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password))\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "SDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// AutoConfirm separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type AutoConfirm struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewAutoConfirm constructs a new auto confirm runner.func NewAutoConfirm(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) AutoConfirm {\tscenario := AutoConfirm{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddPreSignUpTrigger adds a Lambda handler as an invocation target for the PreSignUp trigger.func (runner *AutoConfirm) AddPreSignUpTrigger(ctx context.Context, userPoolId string, functionArn string) {\tlog.Printf(\"Let's add a Lambda function to handle the PreSignUp trigger from Cognito.\\n\" +\t\t\"This trigger happens when a user signs up, and lets your function take action before the main Cognito\\n\" +\t\t\"sign up processing occurs.\\n\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.PreSignUp, HandlerArn: aws.String(functionArn)})\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Lambda function %v added to user pool %v to handle the PreSignUp trigger.\\n\",\t\tfunctionArn, userPoolId)}// SignUpUser signs up a user from the known user table with a password you specify.func (runner *AutoConfirm) SignUpUser(ctx context.Context, clientId string, usersTable string) (string, string) {\tlog.Println(\"Let's sign up a user to your Cognito user pool. When the user's email matches an email in the\\n\" +\t\t\"DynamoDB known users table, it is automatically verified and the user is confirmed.\")\tknownUsers, err := runner.helper.GetKnownUsers(ctx, usersTable)\tif err != nil {\t\tpanic(err)\t}\tuserChoice := runner.questioner.AskChoice(\"Which user do you want to use?\\n\", knownUsers.UserNameList())\tuser := knownUsers.Users[userChoice]\tvar signedUp bool\tvar userConfirmed bool\tpassword := runner.questioner.AskPassword(\"Enter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !signedUp {\t\tlog.Printf(\"Signing up user '%v' with email '%v' to Cognito.\\n\", user.UserName, user.UserEmail)\t\tuserConfirmed, err = runner.cognitoActor.SignUp(ctx, clientId, user.UserName, password, user.UserEmail)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"Enter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tsignedUp = true\t\t}\t}\tlog.Printf(\"User %v signed up, confirmed = %v.\\n\", user.UserName, userConfirmed)\tlog.Println(strings.Repeat(\"-\", 88))\treturn user.UserName, password}// SignInUser signs in a user.func (runner *AutoConfirm) SignInUser(ctx context.Context, clientId string, userName string, password string) string {\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\tlog.Printf(\"Let's sign in as %v...\\n\", userName)\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\tlog.Println(strings.Repeat(\"-\", 88))\treturn *authResult.AccessToken}// Run runs the scenario.func (runner *AutoConfirm) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\trunner.AddPreSignUpTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"AutoConfirmFunctionArn\"])\trunner.resources.triggers = append(runner.resources.triggers, actions.PreSignUp)\tuserName, password := runner.SignUpUser(ctx, stackOutputs[\"UserPoolClientId\"], stackOutputs[\"TableName\"])\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"AutoConfirmFunction\"])\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens,\t\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password))\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the PreSignUp trigger with a Lambda function.import (\t\"context\"\t\"log\"\t\"os\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\tdynamodbtypes \"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")const TABLE_NAME = \"TABLE_NAME\"// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string `dynamodbav:\"UserName\"`\tUserEmail string `dynamodbav:\"UserEmail\"`}// GetKey marshals the user email value to a DynamoDB key format.func (user UserInfo) GetKey() map[string]dynamodbtypes.AttributeValue {\tuserEmail, err := attributevalue.Marshal(user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\treturn map[string]dynamodbtypes.AttributeValue{\"UserEmail\": userEmail}}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the PreSignUp event by looking up a user in an Amazon DynamoDB table and// specifying whether they should be confirmed and verified.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) {\tlog.Printf(\"Received presignup from %v for user '%v'\", event.TriggerSource, event.UserName)\tif event.TriggerSource != \"PreSignUp_SignUp\" {\t\t// Other trigger sources, such as PreSignUp_AdminInitiateAuth, ignore the response from this handler.\t\treturn event, nil\t}\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserEmail: event.Request.UserAttributes[\"email\"],\t}\tlog.Printf(\"Looking up email %v in table %v.\\n\", user.UserEmail, tableName)\toutput, err := h.dynamoClient.GetItem(ctx, &dynamodb.GetItemInput{\t\tKey:       user.GetKey(),\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Error looking up email %v.\\n\", user.UserEmail)\t\treturn event, err\t}\tif output.Item == nil {\t\tlog.Printf(\"Email %v not found. Email verification is required.\\n\", user.UserEmail)\t\treturn event, err\t}\terr = attributevalue.UnmarshalMap(output.Item, &user)\tif err != nil {\t\tlog.Printf(\"Couldn't unmarshal DynamoDB item. Here's why: %v\\n\", err)\t\treturn event, err\t}\tif user.UserName != event.UserName {\t\tlog.Printf(\"UserEmail %v found, but stored UserName '%v' does not match supplied UserName '%v'. Verification is required.\\n\",\t\t\tuser.UserEmail, user.UserName, event.UserName)\t} else {\t\tlog.Printf(\"UserEmail %v found with matching UserName %v. User is confirmed.\\n\", user.UserEmail, user.UserName)\t\tevent.Response.AutoConfirmUser = true\t\tevent.Response.AutoVerifyEmail = true\t}\treturn event, err}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.DeleteUserInitiateAuthSignUpUpdateUserPool",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Automatically migrate known users with a Lambda function",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_CognitoAutoMigrateUser_section.html",
                        "sections": [
                            "The following code example shows how to automatically migrate known Amazon Cognito users with a Lambda function.",
                            "  1.Configure a user pool to call a Lambda function for the MigrateUser trigger.",
                            "  2.Sign in to Amazon Cognito with a username and email that is not in the user pool.",
                            "  3.The Lambda function scans a DynamoDB table and automatically migrates known users to the user pool.",
                            "  4.Perform the forgot password flow to reset the password for the migrated user.",
                            "  5.Sign in as the new user, then clean up resources.",
                            "  1.Go : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// MigrateUser separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype MigrateUser struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewMigrateUser constructs a new migrate user runner.\nfunc NewMigrateUser(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) MigrateUser {\n\tscenario := MigrateUser{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddMigrateUserTrigger adds a Lambda handler as an invocation target for the MigrateUser trigger.\nfunc (runner *MigrateUser) AddMigrateUserTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the MigrateUser trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when an unknown user signs in, and lets your function take action before Cognito\\n\" +\n\t\t\"rejects the user.\\n\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.UserMigration, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the MigrateUser trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser adds a new user to the known users table and signs that user in to Amazon Cognito.\nfunc (runner *MigrateUser) SignInUser(ctx context.Context, usersTable string, clientId string) (bool, actions.User) {\n\tlog.Println(\"Let's sign in a user to your Cognito user pool. When the username and email matches an entry in the\\n\" +\n\t\t\"DynamoDB known users table, the email is automatically verified and the user is migrated to the Cognito user pool.\")\n\n\tuser := actions.User{}\n\tuser.UserName = runner.questioner.Ask(\"\\nEnter a username:\")\n\tuser.UserEmail = runner.questioner.Ask(\"\\nEnter an email that you own. This email will be used to confirm user migration\\n\" +\n\t\t\"during this example:\")\n\n\trunner.helper.AddKnownUser(ctx, usersTable, user)\n\n\tvar err error\n\tvar resetRequired *types.PasswordResetRequiredException\n\tvar authResult *types.AuthenticationResultType\n\tsignedIn := false\n\tfor !signedIn && resetRequired == nil {\n\t\tlog.Printf(\"Signing in to Cognito as user '%v'. The expected result is a PasswordResetRequiredException.\\n\\n\", user.UserName)\n\t\tauthResult, err = runner.cognitoActor.SignIn(ctx, clientId, user.UserName, \"_\")\n\t\tif err != nil {\n\t\t\tif errors.As(err, &resetRequired) {\n\t\t\t\tlog.Printf(\"\\nUser '%v' is not in the Cognito user pool but was found in the DynamoDB known users table.\\n\"+\n\t\t\t\t\t\"User migration is started and a password reset is required.\", user.UserName)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tlog.Printf(\"User '%v' successfully signed in. This is unexpected and probably means you have not\\n\"+\n\t\t\t\t\"cleaned up a previous run of this scenario, so the user exist in the Cognito user pool.\\n\"+\n\t\t\t\t\"You can continue this example and select to clean up resources, or manually remove\\n\"+\n\t\t\t\t\"the user from your user pool and try again.\", user.UserName)\n\t\t\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\t\t\tsignedIn = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn resetRequired != nil, user\n}\n\n// ResetPassword starts a password recovery flow.\nfunc (runner *MigrateUser) ResetPassword(ctx context.Context, clientId string, user actions.User) {\n\twantCode := runner.questioner.AskBool(fmt.Sprintf(\"In order to migrate the user to Cognito, you must be able to receive a confirmation\\n\"+\n\t\t\"code by email at %v. Do you want to send a code (y/n)?\", user.UserEmail), \"y\")\n\tif !wantCode {\n\t\tlog.Println(\"To complete this example and successfully migrate a user to Cognito, you must enter an email\\n\" +\n\t\t\t\"you own that can receive a confirmation code.\")\n\t\treturn\n\t}\n\tcodeDelivery, err := runner.cognitoActor.ForgotPassword(ctx, clientId, user.UserName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"\\nA confirmation code has been sent to %v.\", *codeDelivery.Destination)\n\tcode := runner.questioner.Ask(\"Check your email and enter it here:\")\n\n\tconfirmed := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !confirmed {\n\t\tlog.Printf(\"\\nConfirming password reset for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.ConfirmForgotPassword(ctx, clientId, code, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tconfirmed = true\n\t\t}\n\t}\n\tlog.Printf(\"User '%v' successfully confirmed and migrated.\\n\", user.UserName)\n\tlog.Println(\"Signing in with your username and password...\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, user.UserName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *MigrateUser) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\n\trunner.AddMigrateUserTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"MigrateUserFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.UserMigration)\n\tresetNeeded, user := runner.SignInUser(ctx, stackOutputs[\"TableName\"], stackOutputs[\"UserPoolClientId\"])\n\tif resetNeeded {\n\t\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"MigrateUserFunction\"])\n\t\trunner.ResetPassword(ctx, stackOutputs[\"UserPoolClientId\"], user)\n\t}\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "  2.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// MigrateUser separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype MigrateUser struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewMigrateUser constructs a new migrate user runner.\nfunc NewMigrateUser(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) MigrateUser {\n\tscenario := MigrateUser{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddMigrateUserTrigger adds a Lambda handler as an invocation target for the MigrateUser trigger.\nfunc (runner *MigrateUser) AddMigrateUserTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the MigrateUser trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when an unknown user signs in, and lets your function take action before Cognito\\n\" +\n\t\t\"rejects the user.\\n\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.UserMigration, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the MigrateUser trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser adds a new user to the known users table and signs that user in to Amazon Cognito.\nfunc (runner *MigrateUser) SignInUser(ctx context.Context, usersTable string, clientId string) (bool, actions.User) {\n\tlog.Println(\"Let's sign in a user to your Cognito user pool. When the username and email matches an entry in the\\n\" +\n\t\t\"DynamoDB known users table, the email is automatically verified and the user is migrated to the Cognito user pool.\")\n\n\tuser := actions.User{}\n\tuser.UserName = runner.questioner.Ask(\"\\nEnter a username:\")\n\tuser.UserEmail = runner.questioner.Ask(\"\\nEnter an email that you own. This email will be used to confirm user migration\\n\" +\n\t\t\"during this example:\")\n\n\trunner.helper.AddKnownUser(ctx, usersTable, user)\n\n\tvar err error\n\tvar resetRequired *types.PasswordResetRequiredException\n\tvar authResult *types.AuthenticationResultType\n\tsignedIn := false\n\tfor !signedIn && resetRequired == nil {\n\t\tlog.Printf(\"Signing in to Cognito as user '%v'. The expected result is a PasswordResetRequiredException.\\n\\n\", user.UserName)\n\t\tauthResult, err = runner.cognitoActor.SignIn(ctx, clientId, user.UserName, \"_\")\n\t\tif err != nil {\n\t\t\tif errors.As(err, &resetRequired) {\n\t\t\t\tlog.Printf(\"\\nUser '%v' is not in the Cognito user pool but was found in the DynamoDB known users table.\\n\"+\n\t\t\t\t\t\"User migration is started and a password reset is required.\", user.UserName)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tlog.Printf(\"User '%v' successfully signed in. This is unexpected and probably means you have not\\n\"+\n\t\t\t\t\"cleaned up a previous run of this scenario, so the user exist in the Cognito user pool.\\n\"+\n\t\t\t\t\"You can continue this example and select to clean up resources, or manually remove\\n\"+\n\t\t\t\t\"the user from your user pool and try again.\", user.UserName)\n\t\t\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\t\t\tsignedIn = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn resetRequired != nil, user\n}\n\n// ResetPassword starts a password recovery flow.\nfunc (runner *MigrateUser) ResetPassword(ctx context.Context, clientId string, user actions.User) {\n\twantCode := runner.questioner.AskBool(fmt.Sprintf(\"In order to migrate the user to Cognito, you must be able to receive a confirmation\\n\"+\n\t\t\"code by email at %v. Do you want to send a code (y/n)?\", user.UserEmail), \"y\")\n\tif !wantCode {\n\t\tlog.Println(\"To complete this example and successfully migrate a user to Cognito, you must enter an email\\n\" +\n\t\t\t\"you own that can receive a confirmation code.\")\n\t\treturn\n\t}\n\tcodeDelivery, err := runner.cognitoActor.ForgotPassword(ctx, clientId, user.UserName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"\\nA confirmation code has been sent to %v.\", *codeDelivery.Destination)\n\tcode := runner.questioner.Ask(\"Check your email and enter it here:\")\n\n\tconfirmed := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !confirmed {\n\t\tlog.Printf(\"\\nConfirming password reset for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.ConfirmForgotPassword(ctx, clientId, code, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tconfirmed = true\n\t\t}\n\t}\n\tlog.Printf(\"User '%v' successfully confirmed and migrated.\\n\", user.UserName)\n\tlog.Println(\"Signing in with your username and password...\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, user.UserName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *MigrateUser) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\n\trunner.AddMigrateUserTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"MigrateUserFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.UserMigration)\n\tresetNeeded, user := runner.SignInUser(ctx, stackOutputs[\"TableName\"], stackOutputs[\"UserPoolClientId\"])\n\tif resetNeeded {\n\t\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"MigrateUserFunction\"])\n\t\trunner.ResetPassword(ctx, stackOutputs[\"UserPoolClientId\"], user)\n\t}\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"fmt\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// MigrateUser separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type MigrateUser struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewMigrateUser constructs a new migrate user runner.func NewMigrateUser(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) MigrateUser {\tscenario := MigrateUser{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddMigrateUserTrigger adds a Lambda handler as an invocation target for the MigrateUser trigger.func (runner *MigrateUser) AddMigrateUserTrigger(ctx context.Context, userPoolId string, functionArn string) {\tlog.Printf(\"Let's add a Lambda function to handle the MigrateUser trigger from Cognito.\\n\" +\t\t\"This trigger happens when an unknown user signs in, and lets your function take action before Cognito\\n\" +\t\t\"rejects the user.\\n\\n\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.UserMigration, HandlerArn: aws.String(functionArn)})\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Lambda function %v added to user pool %v to handle the MigrateUser trigger.\\n\",\t\tfunctionArn, userPoolId)\tlog.Println(strings.Repeat(\"-\", 88))}// SignInUser adds a new user to the known users table and signs that user in to Amazon Cognito.func (runner *MigrateUser) SignInUser(ctx context.Context, usersTable string, clientId string) (bool, actions.User) {\tlog.Println(\"Let's sign in a user to your Cognito user pool. When the username and email matches an entry in the\\n\" +\t\t\"DynamoDB known users table, the email is automatically verified and the user is migrated to the Cognito user pool.\")\tuser := actions.User{}\tuser.UserName = runner.questioner.Ask(\"\\nEnter a username:\")\tuser.UserEmail = runner.questioner.Ask(\"\\nEnter an email that you own. This email will be used to confirm user migration\\n\" +\t\t\"during this example:\")\trunner.helper.AddKnownUser(ctx, usersTable, user)\tvar err error\tvar resetRequired *types.PasswordResetRequiredException\tvar authResult *types.AuthenticationResultType\tsignedIn := false\tfor !signedIn && resetRequired == nil {\t\tlog.Printf(\"Signing in to Cognito as user '%v'. The expected result is a PasswordResetRequiredException.\\n\\n\", user.UserName)\t\tauthResult, err = runner.cognitoActor.SignIn(ctx, clientId, user.UserName, \"_\")\t\tif err != nil {\t\t\tif errors.As(err, &resetRequired) {\t\t\t\tlog.Printf(\"\\nUser '%v' is not in the Cognito user pool but was found in the DynamoDB known users table.\\n\"+\t\t\t\t\t\"User migration is started and a password reset is required.\", user.UserName)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tlog.Printf(\"User '%v' successfully signed in. This is unexpected and probably means you have not\\n\"+\t\t\t\t\"cleaned up a previous run of this scenario, so the user exist in the Cognito user pool.\\n\"+\t\t\t\t\"You can continue this example and select to clean up resources, or manually remove\\n\"+\t\t\t\t\"the user from your user pool and try again.\", user.UserName)\t\t\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\t\t\tsignedIn = true\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))\treturn resetRequired != nil, user}// ResetPassword starts a password recovery flow.func (runner *MigrateUser) ResetPassword(ctx context.Context, clientId string, user actions.User) {\twantCode := runner.questioner.AskBool(fmt.Sprintf(\"In order to migrate the user to Cognito, you must be able to receive a confirmation\\n\"+\t\t\"code by email at %v. Do you want to send a code (y/n)?\", user.UserEmail), \"y\")\tif !wantCode {\t\tlog.Println(\"To complete this example and successfully migrate a user to Cognito, you must enter an email\\n\" +\t\t\t\"you own that can receive a confirmation code.\")\t\treturn\t}\tcodeDelivery, err := runner.cognitoActor.ForgotPassword(ctx, clientId, user.UserName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"\\nA confirmation code has been sent to %v.\", *codeDelivery.Destination)\tcode := runner.questioner.Ask(\"Check your email and enter it here:\")\tconfirmed := false\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !confirmed {\t\tlog.Printf(\"\\nConfirming password reset for user '%v'.\\n\", user.UserName)\t\terr = runner.cognitoActor.ConfirmForgotPassword(ctx, clientId, code, user.UserName, password)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tconfirmed = true\t\t}\t}\tlog.Printf(\"User '%v' successfully confirmed and migrated.\\n\", user.UserName)\tlog.Println(\"Signing in with your username and password...\")\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, user.UserName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\tlog.Println(strings.Repeat(\"-\", 88))}// Run runs the scenario.func (runner *MigrateUser) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.AddMigrateUserTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"MigrateUserFunctionArn\"])\trunner.resources.triggers = append(runner.resources.triggers, actions.UserMigration)\tresetNeeded, user := runner.SignInUser(ctx, stackOutputs[\"TableName\"], stackOutputs[\"UserPoolClientId\"])\tif resetNeeded {\t\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"MigrateUserFunction\"])\t\trunner.ResetPassword(ctx, stackOutputs[\"UserPoolClientId\"], user)\t}\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the MigrateUser trigger with a Lambda function.import (\t\"context\"\t\"log\"\t\"os\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/expression\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\")const TABLE_NAME = \"TABLE_NAME\"// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string `dynamodbav:\"UserName\"`\tUserEmail string `dynamodbav:\"UserEmail\"`}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the MigrateUser event by looking up a user in an Amazon DynamoDB table and// specifying whether they should be migrated to the user pool.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsMigrateUser) (events.CognitoEventUserPoolsMigrateUser, error) {\tlog.Printf(\"Received migrate trigger from %v for user '%v'\", event.TriggerSource, event.UserName)\tif event.TriggerSource != \"UserMigration_Authentication\" {\t\treturn event, nil\t}\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserName: event.UserName,\t}\tlog.Printf(\"Looking up user '%v' in table %v.\\n\", user.UserName, tableName)\tfilterEx := expression.Name(\"UserName\").Equal(expression.Value(user.UserName))\texpr, err := expression.NewBuilder().WithFilter(filterEx).Build()\tif err != nil {\t\tlog.Printf(\"Error building expression to query for user '%v'.\\n\", user.UserName)\t\treturn event, err\t}\toutput, err := h.dynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName:                 aws.String(tableName),\t\tFilterExpression:          expr.Filter(),\t\tExpressionAttributeNames:  expr.Names(),\t\tExpressionAttributeValues: expr.Values(),\t})\tif err != nil {\t\tlog.Printf(\"Error looking up user '%v'.\\n\", user.UserName)\t\treturn event, err\t}\tif len(output.Items) == 0 {\t\tlog.Printf(\"User '%v' not found, not migrating user.\\n\", user.UserName)\t\treturn event, err\t}\tvar users []UserInfo\terr = attributevalue.UnmarshalListOfMaps(output.Items, &users)\tif err != nil {\t\tlog.Printf(\"Couldn't unmarshal DynamoDB items. Here's why: %v\\n\", err)\t\treturn event, err\t}\tuser = users[0]\tlog.Printf(\"UserName '%v' found with email %v. User is migrated and must reset password.\\n\", user.UserName, user.UserEmail)\tevent.CognitoEventUserPoolsMigrateUserResponse.UserAttributes = map[string]string{\t\t\"email\":          user.UserEmail,\t\t\"email_verified\": \"true\", // email_verified is required for the forgot password flow.\t}\tevent.CognitoEventUserPoolsMigrateUserResponse.FinalUserStatus = \"RESET_REQUIRED\"\tevent.CognitoEventUserPoolsMigrateUserResponse.MessageAction = \"SUPPRESS\"\treturn event, err}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.ConfirmForgotPasswordDeleteUserForgotPasswordInitiateAuthSignUpUpdateUserPool",
                            "anchor",
                            "  1.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// MigrateUser separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype MigrateUser struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewMigrateUser constructs a new migrate user runner.\nfunc NewMigrateUser(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) MigrateUser {\n\tscenario := MigrateUser{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddMigrateUserTrigger adds a Lambda handler as an invocation target for the MigrateUser trigger.\nfunc (runner *MigrateUser) AddMigrateUserTrigger(ctx context.Context, userPoolId string, functionArn string) {\n\tlog.Printf(\"Let's add a Lambda function to handle the MigrateUser trigger from Cognito.\\n\" +\n\t\t\"This trigger happens when an unknown user signs in, and lets your function take action before Cognito\\n\" +\n\t\t\"rejects the user.\\n\\n\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.UserMigration, HandlerArn: aws.String(functionArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle the MigrateUser trigger.\\n\",\n\t\tfunctionArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser adds a new user to the known users table and signs that user in to Amazon Cognito.\nfunc (runner *MigrateUser) SignInUser(ctx context.Context, usersTable string, clientId string) (bool, actions.User) {\n\tlog.Println(\"Let's sign in a user to your Cognito user pool. When the username and email matches an entry in the\\n\" +\n\t\t\"DynamoDB known users table, the email is automatically verified and the user is migrated to the Cognito user pool.\")\n\n\tuser := actions.User{}\n\tuser.UserName = runner.questioner.Ask(\"\\nEnter a username:\")\n\tuser.UserEmail = runner.questioner.Ask(\"\\nEnter an email that you own. This email will be used to confirm user migration\\n\" +\n\t\t\"during this example:\")\n\n\trunner.helper.AddKnownUser(ctx, usersTable, user)\n\n\tvar err error\n\tvar resetRequired *types.PasswordResetRequiredException\n\tvar authResult *types.AuthenticationResultType\n\tsignedIn := false\n\tfor !signedIn && resetRequired == nil {\n\t\tlog.Printf(\"Signing in to Cognito as user '%v'. The expected result is a PasswordResetRequiredException.\\n\\n\", user.UserName)\n\t\tauthResult, err = runner.cognitoActor.SignIn(ctx, clientId, user.UserName, \"_\")\n\t\tif err != nil {\n\t\t\tif errors.As(err, &resetRequired) {\n\t\t\t\tlog.Printf(\"\\nUser '%v' is not in the Cognito user pool but was found in the DynamoDB known users table.\\n\"+\n\t\t\t\t\t\"User migration is started and a password reset is required.\", user.UserName)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tlog.Printf(\"User '%v' successfully signed in. This is unexpected and probably means you have not\\n\"+\n\t\t\t\t\"cleaned up a previous run of this scenario, so the user exist in the Cognito user pool.\\n\"+\n\t\t\t\t\"You can continue this example and select to clean up resources, or manually remove\\n\"+\n\t\t\t\t\"the user from your user pool and try again.\", user.UserName)\n\t\t\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\t\t\tsignedIn = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\treturn resetRequired != nil, user\n}\n\n// ResetPassword starts a password recovery flow.\nfunc (runner *MigrateUser) ResetPassword(ctx context.Context, clientId string, user actions.User) {\n\twantCode := runner.questioner.AskBool(fmt.Sprintf(\"In order to migrate the user to Cognito, you must be able to receive a confirmation\\n\"+\n\t\t\"code by email at %v. Do you want to send a code (y/n)?\", user.UserEmail), \"y\")\n\tif !wantCode {\n\t\tlog.Println(\"To complete this example and successfully migrate a user to Cognito, you must enter an email\\n\" +\n\t\t\t\"you own that can receive a confirmation code.\")\n\t\treturn\n\t}\n\tcodeDelivery, err := runner.cognitoActor.ForgotPassword(ctx, clientId, user.UserName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"\\nA confirmation code has been sent to %v.\", *codeDelivery.Destination)\n\tcode := runner.questioner.Ask(\"Check your email and enter it here:\")\n\n\tconfirmed := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !confirmed {\n\t\tlog.Printf(\"\\nConfirming password reset for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.ConfirmForgotPassword(ctx, clientId, code, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tconfirmed = true\n\t\t}\n\t}\n\tlog.Printf(\"User '%v' successfully confirmed and migrated.\\n\", user.UserName)\n\tlog.Println(\"Signing in with your username and password...\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, user.UserName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *MigrateUser) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\n\trunner.AddMigrateUserTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"MigrateUserFunctionArn\"])\n\trunner.resources.triggers = append(runner.resources.triggers, actions.UserMigration)\n\tresetNeeded, user := runner.SignInUser(ctx, stackOutputs[\"TableName\"], stackOutputs[\"UserPoolClientId\"])\n\tif resetNeeded {\n\t\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"MigrateUserFunction\"])\n\t\trunner.ResetPassword(ctx, stackOutputs[\"UserPoolClientId\"], user)\n\t}\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "SDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"fmt\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// MigrateUser separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type MigrateUser struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewMigrateUser constructs a new migrate user runner.func NewMigrateUser(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) MigrateUser {\tscenario := MigrateUser{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddMigrateUserTrigger adds a Lambda handler as an invocation target for the MigrateUser trigger.func (runner *MigrateUser) AddMigrateUserTrigger(ctx context.Context, userPoolId string, functionArn string) {\tlog.Printf(\"Let's add a Lambda function to handle the MigrateUser trigger from Cognito.\\n\" +\t\t\"This trigger happens when an unknown user signs in, and lets your function take action before Cognito\\n\" +\t\t\"rejects the user.\\n\\n\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.UserMigration, HandlerArn: aws.String(functionArn)})\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Lambda function %v added to user pool %v to handle the MigrateUser trigger.\\n\",\t\tfunctionArn, userPoolId)\tlog.Println(strings.Repeat(\"-\", 88))}// SignInUser adds a new user to the known users table and signs that user in to Amazon Cognito.func (runner *MigrateUser) SignInUser(ctx context.Context, usersTable string, clientId string) (bool, actions.User) {\tlog.Println(\"Let's sign in a user to your Cognito user pool. When the username and email matches an entry in the\\n\" +\t\t\"DynamoDB known users table, the email is automatically verified and the user is migrated to the Cognito user pool.\")\tuser := actions.User{}\tuser.UserName = runner.questioner.Ask(\"\\nEnter a username:\")\tuser.UserEmail = runner.questioner.Ask(\"\\nEnter an email that you own. This email will be used to confirm user migration\\n\" +\t\t\"during this example:\")\trunner.helper.AddKnownUser(ctx, usersTable, user)\tvar err error\tvar resetRequired *types.PasswordResetRequiredException\tvar authResult *types.AuthenticationResultType\tsignedIn := false\tfor !signedIn && resetRequired == nil {\t\tlog.Printf(\"Signing in to Cognito as user '%v'. The expected result is a PasswordResetRequiredException.\\n\\n\", user.UserName)\t\tauthResult, err = runner.cognitoActor.SignIn(ctx, clientId, user.UserName, \"_\")\t\tif err != nil {\t\t\tif errors.As(err, &resetRequired) {\t\t\t\tlog.Printf(\"\\nUser '%v' is not in the Cognito user pool but was found in the DynamoDB known users table.\\n\"+\t\t\t\t\t\"User migration is started and a password reset is required.\", user.UserName)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tlog.Printf(\"User '%v' successfully signed in. This is unexpected and probably means you have not\\n\"+\t\t\t\t\"cleaned up a previous run of this scenario, so the user exist in the Cognito user pool.\\n\"+\t\t\t\t\"You can continue this example and select to clean up resources, or manually remove\\n\"+\t\t\t\t\"the user from your user pool and try again.\", user.UserName)\t\t\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\t\t\tsignedIn = true\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))\treturn resetRequired != nil, user}// ResetPassword starts a password recovery flow.func (runner *MigrateUser) ResetPassword(ctx context.Context, clientId string, user actions.User) {\twantCode := runner.questioner.AskBool(fmt.Sprintf(\"In order to migrate the user to Cognito, you must be able to receive a confirmation\\n\"+\t\t\"code by email at %v. Do you want to send a code (y/n)?\", user.UserEmail), \"y\")\tif !wantCode {\t\tlog.Println(\"To complete this example and successfully migrate a user to Cognito, you must enter an email\\n\" +\t\t\t\"you own that can receive a confirmation code.\")\t\treturn\t}\tcodeDelivery, err := runner.cognitoActor.ForgotPassword(ctx, clientId, user.UserName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"\\nA confirmation code has been sent to %v.\", *codeDelivery.Destination)\tcode := runner.questioner.Ask(\"Check your email and enter it here:\")\tconfirmed := false\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !confirmed {\t\tlog.Printf(\"\\nConfirming password reset for user '%v'.\\n\", user.UserName)\t\terr = runner.cognitoActor.ConfirmForgotPassword(ctx, clientId, code, user.UserName, password)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tconfirmed = true\t\t}\t}\tlog.Printf(\"User '%v' successfully confirmed and migrated.\\n\", user.UserName)\tlog.Println(\"Signing in with your username and password...\")\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, user.UserName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Successfully signed in. Your access token starts with: %v...\\n\", (*authResult.AccessToken)[:10])\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\tlog.Println(strings.Repeat(\"-\", 88))}// Run runs the scenario.func (runner *MigrateUser) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.AddMigrateUserTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"MigrateUserFunctionArn\"])\trunner.resources.triggers = append(runner.resources.triggers, actions.UserMigration)\tresetNeeded, user := runner.SignInUser(ctx, stackOutputs[\"TableName\"], stackOutputs[\"UserPoolClientId\"])\tif resetNeeded {\t\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"MigrateUserFunction\"])\t\trunner.ResetPassword(ctx, stackOutputs[\"UserPoolClientId\"], user)\t}\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the MigrateUser trigger with a Lambda function.import (\t\"context\"\t\"log\"\t\"os\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/expression\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\")const TABLE_NAME = \"TABLE_NAME\"// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string `dynamodbav:\"UserName\"`\tUserEmail string `dynamodbav:\"UserEmail\"`}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the MigrateUser event by looking up a user in an Amazon DynamoDB table and// specifying whether they should be migrated to the user pool.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsMigrateUser) (events.CognitoEventUserPoolsMigrateUser, error) {\tlog.Printf(\"Received migrate trigger from %v for user '%v'\", event.TriggerSource, event.UserName)\tif event.TriggerSource != \"UserMigration_Authentication\" {\t\treturn event, nil\t}\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserName: event.UserName,\t}\tlog.Printf(\"Looking up user '%v' in table %v.\\n\", user.UserName, tableName)\tfilterEx := expression.Name(\"UserName\").Equal(expression.Value(user.UserName))\texpr, err := expression.NewBuilder().WithFilter(filterEx).Build()\tif err != nil {\t\tlog.Printf(\"Error building expression to query for user '%v'.\\n\", user.UserName)\t\treturn event, err\t}\toutput, err := h.dynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName:                 aws.String(tableName),\t\tFilterExpression:          expr.Filter(),\t\tExpressionAttributeNames:  expr.Names(),\t\tExpressionAttributeValues: expr.Values(),\t})\tif err != nil {\t\tlog.Printf(\"Error looking up user '%v'.\\n\", user.UserName)\t\treturn event, err\t}\tif len(output.Items) == 0 {\t\tlog.Printf(\"User '%v' not found, not migrating user.\\n\", user.UserName)\t\treturn event, err\t}\tvar users []UserInfo\terr = attributevalue.UnmarshalListOfMaps(output.Items, &users)\tif err != nil {\t\tlog.Printf(\"Couldn't unmarshal DynamoDB items. Here's why: %v\\n\", err)\t\treturn event, err\t}\tuser = users[0]\tlog.Printf(\"UserName '%v' found with email %v. User is migrated and must reset password.\\n\", user.UserName, user.UserEmail)\tevent.CognitoEventUserPoolsMigrateUserResponse.UserAttributes = map[string]string{\t\t\"email\":          user.UserEmail,\t\t\"email_verified\": \"true\", // email_verified is required for the forgot password flow.\t}\tevent.CognitoEventUserPoolsMigrateUserResponse.FinalUserStatus = \"RESET_REQUIRED\"\tevent.CognitoEventUserPoolsMigrateUserResponse.MessageAction = \"SUPPRESS\"\treturn event, err}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.ConfirmForgotPasswordDeleteUserForgotPasswordInitiateAuthSignUpUpdateUserPool",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create a REST API to track COVID-19 data",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_ApiGatewayDataTracker_section.html",
                        "sections": [
                            "The following code example shows how to create a REST API that simulates a system to track daily cases of COVID-19 in the United States, using fictional data.",
                            "  1.Python : \n\n\nSDK for Python (Boto3)\n\n\n        Shows how to use AWS Chalice with the AWS SDK for Python (Boto3) to\n        create a serverless REST API that uses Amazon API Gateway, AWS Lambda, and\n        Amazon DynamoDB. The REST API simulates a system that tracks daily cases\n        of COVID-19 in the United States, using fictional data. Learn how to:\n    \n\nUse AWS Chalice to define routes in Lambda functions that\n        are called to handle REST requests that come through API Gateway.Use Lambda functions to retrieve and store data in a DynamoDB\n        table to serve REST requests.Define table structure and security role resources in an AWS CloudFormation template.Use AWS Chalice and CloudFormation to package and deploy all necessary resources.Use CloudFormation to clean up all created resources.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAWS CloudFormationDynamoDBLambda\n\n\n",
                            "  2.SDK for Python (Boto3) : \n\n        Shows how to use AWS Chalice with the AWS SDK for Python (Boto3) to\n        create a serverless REST API that uses Amazon API Gateway, AWS Lambda, and\n        Amazon DynamoDB. The REST API simulates a system that tracks daily cases\n        of COVID-19 in the United States, using fictional data. Learn how to:\n    \n\nUse AWS Chalice to define routes in Lambda functions that\n        are called to handle REST requests that come through API Gateway.Use Lambda functions to retrieve and store data in a DynamoDB\n        table to serve REST requests.Define table structure and security role resources in an AWS CloudFormation template.Use AWS Chalice and CloudFormation to package and deploy all necessary resources.Use CloudFormation to clean up all created resources.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAWS CloudFormationDynamoDBLambda\n",
                            "PythonSDK for Python (Boto3)        Shows how to use AWS Chalice with the AWS SDK for Python (Boto3) to        create a serverless REST API that uses Amazon API Gateway, AWS Lambda, and        Amazon DynamoDB. The REST API simulates a system that tracks daily cases        of COVID-19 in the United States, using fictional data. Learn how to:    Use AWS Chalice to define routes in Lambda functions that        are called to handle REST requests that come through API Gateway.Use Lambda functions to retrieve and store data in a DynamoDB        table to serve REST requests.Define table structure and security role resources in an AWS CloudFormation template.Use AWS Chalice and CloudFormation to package and deploy all necessary resources.Use CloudFormation to clean up all created resources.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayAWS CloudFormationDynamoDBLambda",
                            "anchor",
                            "  1.SDK for Python (Boto3) : \n\n        Shows how to use AWS Chalice with the AWS SDK for Python (Boto3) to\n        create a serverless REST API that uses Amazon API Gateway, AWS Lambda, and\n        Amazon DynamoDB. The REST API simulates a system that tracks daily cases\n        of COVID-19 in the United States, using fictional data. Learn how to:\n    \n\nUse AWS Chalice to define routes in Lambda functions that\n        are called to handle REST requests that come through API Gateway.Use Lambda functions to retrieve and store data in a DynamoDB\n        table to serve REST requests.Define table structure and security role resources in an AWS CloudFormation template.Use AWS Chalice and CloudFormation to package and deploy all necessary resources.Use CloudFormation to clean up all created resources.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAWS CloudFormationDynamoDBLambda\n",
                            "SDK for Python (Boto3)        Shows how to use AWS Chalice with the AWS SDK for Python (Boto3) to        create a serverless REST API that uses Amazon API Gateway, AWS Lambda, and        Amazon DynamoDB. The REST API simulates a system that tracks daily cases        of COVID-19 in the United States, using fictional data. Learn how to:    Use AWS Chalice to define routes in Lambda functions that        are called to handle REST requests that come through API Gateway.Use Lambda functions to retrieve and store data in a DynamoDB        table to serve REST requests.Define table structure and security role resources in an AWS CloudFormation template.Use AWS Chalice and CloudFormation to package and deploy all necessary resources.Use CloudFormation to clean up all created resources.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayAWS CloudFormationDynamoDBLambda",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create a lending library REST API",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_AuroraRestLendingLibrary_section.html",
                        "sections": [
                            "The following code example shows how to create a lending library where patrons can borrow and return books by using a REST API backed by an Amazon Aurora database.",
                            "  1.Python : \n\n\nSDK for Python (Boto3)\n\n\n        Shows how to use the AWS SDK for Python (Boto3) with the Amazon Relational Database Service (Amazon RDS) API and AWS Chalice to create a REST API\n        backed by an Amazon Aurora database. The web service is fully serverless and represents\n        a simple lending library where patrons can borrow and return books. Learn how to:\n    \n\nCreate and manage a serverless Aurora database cluster.Use AWS Secrets Manager to manage database credentials.Implement a data storage layer that uses Amazon RDS to move data into\n            and out of the database.Use AWS Chalice to deploy a serverless REST API to Amazon API Gateway and AWS Lambda.Use the Requests package to send requests to the web service.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAuroraLambdaSecrets Manager\n\n\n",
                            "  2.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with the Amazon Relational Database Service (Amazon RDS) API and AWS Chalice to create a REST API\n        backed by an Amazon Aurora database. The web service is fully serverless and represents\n        a simple lending library where patrons can borrow and return books. Learn how to:\n    \n\nCreate and manage a serverless Aurora database cluster.Use AWS Secrets Manager to manage database credentials.Implement a data storage layer that uses Amazon RDS to move data into\n            and out of the database.Use AWS Chalice to deploy a serverless REST API to Amazon API Gateway and AWS Lambda.Use the Requests package to send requests to the web service.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAuroraLambdaSecrets Manager\n",
                            "PythonSDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with the Amazon Relational Database Service (Amazon RDS) API and AWS Chalice to create a REST API        backed by an Amazon Aurora database. The web service is fully serverless and represents        a simple lending library where patrons can borrow and return books. Learn how to:    Create and manage a serverless Aurora database cluster.Use AWS Secrets Manager to manage database credentials.Implement a data storage layer that uses Amazon RDS to move data into            and out of the database.Use AWS Chalice to deploy a serverless REST API to Amazon API Gateway and AWS Lambda.Use the Requests package to send requests to the web service.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayAuroraLambdaSecrets Manager",
                            "anchor",
                            "  1.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with the Amazon Relational Database Service (Amazon RDS) API and AWS Chalice to create a REST API\n        backed by an Amazon Aurora database. The web service is fully serverless and represents\n        a simple lending library where patrons can borrow and return books. Learn how to:\n    \n\nCreate and manage a serverless Aurora database cluster.Use AWS Secrets Manager to manage database credentials.Implement a data storage layer that uses Amazon RDS to move data into\n            and out of the database.Use AWS Chalice to deploy a serverless REST API to Amazon API Gateway and AWS Lambda.Use the Requests package to send requests to the web service.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayAuroraLambdaSecrets Manager\n",
                            "SDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with the Amazon Relational Database Service (Amazon RDS) API and AWS Chalice to create a REST API        backed by an Amazon Aurora database. The web service is fully serverless and represents        a simple lending library where patrons can borrow and return books. Learn how to:    Create and manage a serverless Aurora database cluster.Use AWS Secrets Manager to manage database credentials.Implement a data storage layer that uses Amazon RDS to move data into            and out of the database.Use AWS Chalice to deploy a serverless REST API to Amazon API Gateway and AWS Lambda.Use the Requests package to send requests to the web service.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayAuroraLambdaSecrets Manager",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create a messenger application",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_StepFunctionsMessenger_section.html",
                        "sections": [
                            "The following code example shows how to create an AWS Step Functions messenger application that retrieves message records from a database table.",
                            "  1.Python : \n\n\nSDK for Python (Boto3)\n\n\n        Shows how to use the AWS SDK for Python (Boto3) with AWS Step Functions to create a messenger application that\n        retrieves message records from an Amazon DynamoDB table and sends them with Amazon Simple Queue Service (Amazon SQS).\n        The state machine integrates with an AWS Lambda function to scan the database for unsent messages.\n    \n\nCreate a state machine that retrieves and updates message records from an Amazon DynamoDB table.Update the state machine definition to also send messages to Amazon Simple Queue Service (Amazon SQS).Start and stop state machine runs.Connect to Lambda, DynamoDB, and Amazon SQS from a state machine by using service integrations.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SQSStep Functions\n\n\n",
                            "  2.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with AWS Step Functions to create a messenger application that\n        retrieves message records from an Amazon DynamoDB table and sends them with Amazon Simple Queue Service (Amazon SQS).\n        The state machine integrates with an AWS Lambda function to scan the database for unsent messages.\n    \n\nCreate a state machine that retrieves and updates message records from an Amazon DynamoDB table.Update the state machine definition to also send messages to Amazon Simple Queue Service (Amazon SQS).Start and stop state machine runs.Connect to Lambda, DynamoDB, and Amazon SQS from a state machine by using service integrations.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SQSStep Functions\n",
                            "PythonSDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with AWS Step Functions to create a messenger application that        retrieves message records from an Amazon DynamoDB table and sends them with Amazon Simple Queue Service (Amazon SQS).        The state machine integrates with an AWS Lambda function to scan the database for unsent messages.    Create a state machine that retrieves and updates message records from an Amazon DynamoDB table.Update the state machine definition to also send messages to Amazon Simple Queue Service (Amazon SQS).Start and stop state machine runs.Connect to Lambda, DynamoDB, and Amazon SQS from a state machine by using service integrations.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaAmazon SQSStep Functions",
                            "anchor",
                            "  1.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with AWS Step Functions to create a messenger application that\n        retrieves message records from an Amazon DynamoDB table and sends them with Amazon Simple Queue Service (Amazon SQS).\n        The state machine integrates with an AWS Lambda function to scan the database for unsent messages.\n    \n\nCreate a state machine that retrieves and updates message records from an Amazon DynamoDB table.Update the state machine definition to also send messages to Amazon Simple Queue Service (Amazon SQS).Start and stop state machine runs.Connect to Lambda, DynamoDB, and Amazon SQS from a state machine by using service integrations.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SQSStep Functions\n",
                            "SDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with AWS Step Functions to create a messenger application that        retrieves message records from an Amazon DynamoDB table and sends them with Amazon Simple Queue Service (Amazon SQS).        The state machine integrates with an AWS Lambda function to scan the database for unsent messages.    Create a state machine that retrieves and updates message records from an Amazon DynamoDB table.Update the state machine definition to also send messages to Amazon Simple Queue Service (Amazon SQS).Start and stop state machine runs.Connect to Lambda, DynamoDB, and Amazon SQS from a state machine by using service integrations.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaAmazon SQSStep Functions",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create a serverless application to manage photos",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_PAM_section.html",
                        "sections": [
                            "The following code examples show how to create a serverless application that lets users manage photos using labels.",
                            "  1..NET : \n\n\nAWS SDK for .NET\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  2.AWS SDK for .NET : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  3.C++ : \n\n\nSDK for C++\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  4.SDK for C++ : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  5.Java : \n\n\nSDK for Java 2.x\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  6.SDK for Java 2.x : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  7.JavaScript : \n\n\nSDK for JavaScript (v3)\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  8.SDK for JavaScript (v3) : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  9.Kotlin : \n\n\nSDK for Kotlin\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  10.SDK for Kotlin : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  11.PHP : \n\n\nSDK for PHP\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  12.SDK for PHP : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "  13.Rust : \n\n\nSDK for Rust\n\n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n\n\n",
                            "  14.SDK for Rust : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            ".NETAWS SDK for .NET        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSC++SDK for C++        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSJavaSDK for Java 2.x        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSJavaScriptSDK for JavaScript (v3)        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSKotlinSDK for Kotlin        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSPHPSDK for PHP        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNSRustSDK for Rust        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : \n\n        Shows how to develop a photo asset management application that detects labels in images\n        using Amazon Rekognition and stores them for later retrieval.\n    \nFor complete source code and instructions on how to set up and run, see the full example\n        on \n        GitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS\n",
                            "AWS SDK for .NET        Shows how to develop a photo asset management application that detects labels in images        using Amazon Rekognition and stores them for later retrieval.    For complete source code and instructions on how to set up and run, see the full example        on         GitHub.For a deep dive into the origin of this example see the post on AWS Community.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon RekognitionAmazon S3Amazon SNS",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create a websocket chat application",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_ApiGatewayWebsocketChat_section.html",
                        "sections": [
                            "The following code example shows how to create a chat application that is served by a websocket API built on Amazon API Gateway.",
                            "  1.Python : \n\n\nSDK for Python (Boto3)\n\n\n        Shows how to use the AWS SDK for Python (Boto3) with Amazon API Gateway V2 to\n        create a websocket API that integrates with AWS Lambda and Amazon DynamoDB.\n    \n\nCreate a websocket API served by API Gateway.Define a Lambda handler that stores connections in DynamoDB and posts messages to\n        other chat participants.Connect to the websocket chat application and send messages with the Websockets\n        package.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambda\n\n\n",
                            "  2.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with Amazon API Gateway V2 to\n        create a websocket API that integrates with AWS Lambda and Amazon DynamoDB.\n    \n\nCreate a websocket API served by API Gateway.Define a Lambda handler that stores connections in DynamoDB and posts messages to\n        other chat participants.Connect to the websocket chat application and send messages with the Websockets\n        package.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambda\n",
                            "PythonSDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with Amazon API Gateway V2 to        create a websocket API that integrates with AWS Lambda and Amazon DynamoDB.    Create a websocket API served by API Gateway.Define a Lambda handler that stores connections in DynamoDB and posts messages to        other chat participants.Connect to the websocket chat application and send messages with the Websockets        package.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayDynamoDBLambda",
                            "anchor",
                            "  1.SDK for Python (Boto3) : \n\n        Shows how to use the AWS SDK for Python (Boto3) with Amazon API Gateway V2 to\n        create a websocket API that integrates with AWS Lambda and Amazon DynamoDB.\n    \n\nCreate a websocket API served by API Gateway.Define a Lambda handler that stores connections in DynamoDB and posts messages to\n        other chat participants.Connect to the websocket chat application and send messages with the Websockets\n        package.\n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambda\n",
                            "SDK for Python (Boto3)        Shows how to use the AWS SDK for Python (Boto3) with Amazon API Gateway V2 to        create a websocket API that integrates with AWS Lambda and Amazon DynamoDB.    Create a websocket API served by API Gateway.Define a Lambda handler that stores connections in DynamoDB and posts messages to        other chat participants.Connect to the websocket chat application and send messages with the Websockets        package.        For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayDynamoDBLambda",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Create an application to analyze customer feedback",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_FSA_section.html",
                        "sections": [
                            "The following code examples show how to create an application that analyzes customer comment cards, translates them from their original language, determines their sentiment, and generates an audio file from the translated text.",
                            "  1..NET : \n\n\nAWS SDK for .NET\n\n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n\n\n",
                            "  2.AWS SDK for .NET : \n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n",
                            "  3.Java : \n\n\nSDK for Java 2.x\n\n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n\n\n",
                            "  4.SDK for Java 2.x : \n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n",
                            "  5.JavaScript : import {\n  ComprehendClient,\n  DetectDominantLanguageCommand,\n  DetectSentimentCommand,\n} from \"@aws-sdk/client-comprehend\";\n\n/**\n * Determine the language and sentiment of the extracted text.\n *\n * @param {{ source_text: string}} extractTextOutput\n */\nexport const handler = async (extractTextOutput) => {\n  const comprehendClient = new ComprehendClient({});\n\n  const detectDominantLanguageCommand = new DetectDominantLanguageCommand({\n    Text: extractTextOutput.source_text,\n  });\n\n  // The source language is required for sentiment analysis and\n  // translation in the next step.\n  const { Languages } = await comprehendClient.send(\n    detectDominantLanguageCommand,\n  );\n\n  const languageCode = Languages[0].LanguageCode;\n\n  const detectSentimentCommand = new DetectSentimentCommand({\n    Text: extractTextOutput.source_text,\n    LanguageCode: languageCode,\n  });\n\n  const { Sentiment } = await comprehendClient.send(detectSentimentCommand);\n\n  return {\n    sentiment: Sentiment,\n    language_code: languageCode,\n  };\n};\n",
                            "  6.SDK for JavaScript (v3) : import {\n  ComprehendClient,\n  DetectDominantLanguageCommand,\n  DetectSentimentCommand,\n} from \"@aws-sdk/client-comprehend\";\n\n/**\n * Determine the language and sentiment of the extracted text.\n *\n * @param {{ source_text: string}} extractTextOutput\n */\nexport const handler = async (extractTextOutput) => {\n  const comprehendClient = new ComprehendClient({});\n\n  const detectDominantLanguageCommand = new DetectDominantLanguageCommand({\n    Text: extractTextOutput.source_text,\n  });\n\n  // The source language is required for sentiment analysis and\n  // translation in the next step.\n  const { Languages } = await comprehendClient.send(\n    detectDominantLanguageCommand,\n  );\n\n  const languageCode = Languages[0].LanguageCode;\n\n  const detectSentimentCommand = new DetectSentimentCommand({\n    Text: extractTextOutput.source_text,\n    LanguageCode: languageCode,\n  });\n\n  const { Sentiment } = await comprehendClient.send(detectSentimentCommand);\n\n  return {\n    sentiment: Sentiment,\n    language_code: languageCode,\n  };\n};\n",
                            "  7.Ruby : \n\n\nSDK for Ruby\n\n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n\n\n",
                            "  8.SDK for Ruby : \n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n",
                            ".NETAWS SDK for .NET    This example application analyzes and stores customer feedback cards. Specifically,    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback    from guests in various languages in the form of physical comment cards. That feedback    is uploaded into the app through a web client.    After an image of a comment card is uploaded, the following steps occur:  Text is extracted from the image using Amazon Textract.Amazon Comprehend determines the sentiment of the extracted text and its language.The extracted text is translated to English using Amazon Translate.Amazon Polly synthesizes an audio file from the extracted text. The full app can be deployed with the AWS CDK. For source code and deployment    instructions, see the project in     GitHub. Services used in this exampleAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon TranslateJavaSDK for Java 2.x    This example application analyzes and stores customer feedback cards. Specifically,    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback    from guests in various languages in the form of physical comment cards. That feedback    is uploaded into the app through a web client.    After an image of a comment card is uploaded, the following steps occur:  Text is extracted from the image using Amazon Textract.Amazon Comprehend determines the sentiment of the extracted text and its language.The extracted text is translated to English using Amazon Translate.Amazon Polly synthesizes an audio file from the extracted text. The full app can be deployed with the AWS CDK. For source code and deployment    instructions, see the project in     GitHub. Services used in this exampleAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon TranslateJavaScriptSDK for JavaScript (v3)    This example application analyzes and stores customer feedback cards. Specifically,    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback    from guests in various languages in the form of physical comment cards. That feedback    is uploaded into the app through a web client.    After an image of a comment card is uploaded, the following steps occur:  Text is extracted from the image using Amazon Textract.Amazon Comprehend determines the sentiment of the extracted text and its language.The extracted text is translated to English using Amazon Translate.Amazon Polly synthesizes an audio file from the extracted text. The full app can be deployed with the AWS CDK. For source code and deployment    instructions, see the project in     GitHub. The following excerpts show how the AWS SDK for JavaScript is used inside of Lambda functions. import {  ComprehendClient,  DetectDominantLanguageCommand,  DetectSentimentCommand,} from \"@aws-sdk/client-comprehend\";/** * Determine the language and sentiment of the extracted text. * * @param {{ source_text: string}} extractTextOutput */export const handler = async (extractTextOutput) => {  const comprehendClient = new ComprehendClient({});  const detectDominantLanguageCommand = new DetectDominantLanguageCommand({    Text: extractTextOutput.source_text,  });  // The source language is required for sentiment analysis and  // translation in the next step.  const { Languages } = await comprehendClient.send(    detectDominantLanguageCommand,  );  const languageCode = Languages[0].LanguageCode;  const detectSentimentCommand = new DetectSentimentCommand({    Text: extractTextOutput.source_text,    LanguageCode: languageCode,  });  const { Sentiment } = await comprehendClient.send(detectSentimentCommand);  return {    sentiment: Sentiment,    language_code: languageCode,  };};import {  DetectDocumentTextCommand,  TextractClient,} from \"@aws-sdk/client-textract\";/** * Fetch the S3 object from the event and analyze it using Amazon Textract. * * @param {import(\"@types/aws-lambda\").EventBridgeEvent<\"Object Created\">} eventBridgeS3Event */export const handler = async (eventBridgeS3Event) => {  const textractClient = new TextractClient();  const detectDocumentTextCommand = new DetectDocumentTextCommand({    Document: {      S3Object: {        Bucket: eventBridgeS3Event.bucket,        Name: eventBridgeS3Event.object,      },    },  });  // Textract returns a list of blocks. A block can be a line, a page, word, etc.  // Each block also contains geometry of the detected text.  // For more information on the Block type, see https://docs.aws.amazon.com/textract/latest/dg/API_Block.html.  const { Blocks } = await textractClient.send(detectDocumentTextCommand);  // For the purpose of this example, we are only interested in words.  const extractedWords = Blocks.filter((b) => b.BlockType === \"WORD\").map(    (b) => b.Text,  );  return extractedWords.join(\" \");};import { PollyClient, SynthesizeSpeechCommand } from \"@aws-sdk/client-polly\";import { S3Client } from \"@aws-sdk/client-s3\";import { Upload } from \"@aws-sdk/lib-storage\";/** * Synthesize an audio file from text. * * @param {{ bucket: string, translated_text: string, object: string}} sourceDestinationConfig */export const handler = async (sourceDestinationConfig) => {  const pollyClient = new PollyClient({});  const synthesizeSpeechCommand = new SynthesizeSpeechCommand({    Engine: \"neural\",    Text: sourceDestinationConfig.translated_text,    VoiceId: \"Ruth\",    OutputFormat: \"mp3\",  });  const { AudioStream } = await pollyClient.send(synthesizeSpeechCommand);  const audioKey = `${sourceDestinationConfig.object}.mp3`;  // Store the audio file in S3.  const s3Client = new S3Client();  const upload = new Upload({    client: s3Client,    params: {      Bucket: sourceDestinationConfig.bucket,      Key: audioKey,      Body: AudioStream,      ContentType: \"audio/mp3\",    },  });  await upload.done();  return audioKey;};import {  TranslateClient,  TranslateTextCommand,} from \"@aws-sdk/client-translate\";/** * Translate the extracted text to English. * * @param {{ extracted_text: string, source_language_code: string}} textAndSourceLanguage */export const handler = async (textAndSourceLanguage) => {  const translateClient = new TranslateClient({});  const translateCommand = new TranslateTextCommand({    SourceLanguageCode: textAndSourceLanguage.source_language_code,    TargetLanguageCode: \"en\",    Text: textAndSourceLanguage.extracted_text,  });  const { TranslatedText } = await translateClient.send(translateCommand);  return { translated_text: TranslatedText };};Services used in this exampleAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon TranslateRubySDK for Ruby    This example application analyzes and stores customer feedback cards. Specifically,    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback    from guests in various languages in the form of physical comment cards. That feedback    is uploaded into the app through a web client.    After an image of a comment card is uploaded, the following steps occur:  Text is extracted from the image using Amazon Textract.Amazon Comprehend determines the sentiment of the extracted text and its language.The extracted text is translated to English using Amazon Translate.Amazon Polly synthesizes an audio file from the extracted text. The full app can be deployed with the AWS CDK. For source code and deployment    instructions, see the project in     GitHub. Services used in this exampleAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : \n\n    This example application analyzes and stores customer feedback cards. Specifically,\n    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback\n    from guests in various languages in the form of physical comment cards. That feedback\n    is uploaded into the app through a web client.\n\n    After an image of a comment card is uploaded, the following steps occur:\n  \n\n\nText is extracted from the image using Amazon Textract.\n\nAmazon Comprehend determines the sentiment of the extracted text and its language.\n\nThe extracted text is translated to English using Amazon Translate.\n\nAmazon Polly synthesizes an audio file from the extracted text.\n\n The full app can be deployed with the AWS CDK. For source code and deployment\n    instructions, see the project in \n    GitHub. \n\nServices used in this example\nAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate\n",
                            "AWS SDK for .NET    This example application analyzes and stores customer feedback cards. Specifically,    it fulfills the need of a fictitious hotel in New York City. The hotel receives feedback    from guests in various languages in the form of physical comment cards. That feedback    is uploaded into the app through a web client.    After an image of a comment card is uploaded, the following steps occur:  Text is extracted from the image using Amazon Textract.Amazon Comprehend determines the sentiment of the extracted text and its language.The extracted text is translated to English using Amazon Translate.Amazon Polly synthesizes an audio file from the extracted text. The full app can be deployed with the AWS CDK. For source code and deployment    instructions, see the project in     GitHub. Services used in this exampleAmazon ComprehendLambdaAmazon PollyAmazon TextractAmazon Translate",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from a browser",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_LambdaForBrowser_section.html",
                        "sections": [
                            "The following code example shows how to invoke an AWS Lambda function from a browser.",
                            "  1.JavaScript : \n\n\nSDK for JavaScript (v2)\n\n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambda\n\nSDK for JavaScript (v3)\n\n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections. This app uses AWS SDK for JavaScript v3.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n\n    \n\nServices used in this example\nDynamoDBLambda\n\n\n",
                            "  2.SDK for JavaScript (v2) : \n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambda\n",
                            "  3.SDK for JavaScript (v3) : \n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections. This app uses AWS SDK for JavaScript v3.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n\n    \n\nServices used in this example\nDynamoDBLambda\n",
                            "JavaScriptSDK for JavaScript (v2)        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB        table with user selections.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaSDK for JavaScript (v3)        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB        table with user selections. This app uses AWS SDK for JavaScript v3.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambda",
                            "anchor",
                            "  1.SDK for JavaScript (v2) : \n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambda\n",
                            "  2.SDK for JavaScript (v3) : \n\n        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB\n        table with user selections. This app uses AWS SDK for JavaScript v3.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n\n    \n\nServices used in this example\nDynamoDBLambda\n",
                            "SDK for JavaScript (v2)        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB        table with user selections.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaSDK for JavaScript (v3)        You can create a browser-based application that uses an AWS Lambda function to update an Amazon DynamoDB        table with user selections. This app uses AWS SDK for JavaScript v3.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambda",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Transform data with S3 Object Lambda",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_ServerlessS3DataTransformation_section.html",
                        "sections": [
                            "The following code example shows how to transform data for your application with S3 Object Lambda.",
                            "  1..NET : \n\n\nAWS SDK for .NET\n\n\n        Shows how to add custom code to standard S3 GET requests to modify the requested object retrieved from S3 so that the object suit the needs of the requesting client or application.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nLambdaAmazon S3\n\n\n",
                            "  2.AWS SDK for .NET : \n\n        Shows how to add custom code to standard S3 GET requests to modify the requested object retrieved from S3 so that the object suit the needs of the requesting client or application.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nLambdaAmazon S3\n",
                            ".NETAWS SDK for .NET        Shows how to add custom code to standard S3 GET requests to modify the requested object retrieved from S3 so that the object suit the needs of the requesting client or application.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleLambdaAmazon S3",
                            "anchor",
                            "  1.AWS SDK for .NET : \n\n        Shows how to add custom code to standard S3 GET requests to modify the requested object retrieved from S3 so that the object suit the needs of the requesting client or application.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nLambdaAmazon S3\n",
                            "AWS SDK for .NET        Shows how to add custom code to standard S3 GET requests to modify the requested object retrieved from S3 so that the object suit the needs of the requesting client or application.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleLambdaAmazon S3",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Use API Gateway to invoke a Lambda function",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_LambdaAPIGateway_section.html",
                        "sections": [
                            "The following code examples show how to create an AWS Lambda function invoked by Amazon API Gateway.",
                            "  1.Java : \n\n\nSDK for Java 2.x\n\n\n        Shows how to create an AWS Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries\n        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates\n        them at their one year anniversary date.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon SNS\n\n\n",
                            "  2.SDK for Java 2.x : \n\n        Shows how to create an AWS Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries\n        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates\n        them at their one year anniversary date.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon SNS\n",
                            "  3.JavaScript : \n\n\nSDK for JavaScript (v3)\n\n\n        Shows how to create an AWS Lambda function by using the Lambda JavaScript runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries\n        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates\n        them at their one year anniversary date.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \nThis example is also available in the\n        AWS SDK for JavaScript v3 developer guide.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon SNS\n\n\n",
                            "  4.SDK for JavaScript (v3) : \n\n        Shows how to create an AWS Lambda function by using the Lambda JavaScript runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries\n        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates\n        them at their one year anniversary date.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \nThis example is also available in the\n        AWS SDK for JavaScript v3 developer guide.\n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon SNS\n",
                            "  5.Python : \n\n\nSDK for Python (Boto3)\n\n\n        This example shows how to create and use an Amazon API Gateway REST API that targets an\n        AWS Lambda function. The Lambda handler demonstrates how to route based on HTTP\n        methods; how to get data from the query string, header, and body; and how to\n        return a JSON response.\n    \n\nDeploy a Lambda function.Create an API Gateway REST API.Create a REST resource that targets the Lambda function.Grant permission to let API Gateway invoke the Lambda function.Use the Requests package to send requests to the REST API.Clean up all resources created during the demo.\n\n        This example is best viewed on GitHub. For complete source code and\n        instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayLambda\n\n\n",
                            "  6.SDK for Python (Boto3) : \n\n        This example shows how to create and use an Amazon API Gateway REST API that targets an\n        AWS Lambda function. The Lambda handler demonstrates how to route based on HTTP\n        methods; how to get data from the query string, header, and body; and how to\n        return a JSON response.\n    \n\nDeploy a Lambda function.Create an API Gateway REST API.Create a REST resource that targets the Lambda function.Grant permission to let API Gateway invoke the Lambda function.Use the Requests package to send requests to the REST API.Clean up all resources created during the demo.\n\n        This example is best viewed on GitHub. For complete source code and\n        instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayLambda\n",
                            "JavaSDK for Java 2.x        Shows how to create an AWS Lambda function by using the Lambda Java runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates        them at their one year anniversary date.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayDynamoDBLambdaAmazon SNSJavaScriptSDK for JavaScript (v3)        Shows how to create an AWS Lambda function by using the Lambda JavaScript runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates        them at their one year anniversary date.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    This example is also available in the        AWS SDK for JavaScript v3 developer guide.Services used in this exampleAPI GatewayDynamoDBLambdaAmazon SNSPythonSDK for Python (Boto3)        This example shows how to create and use an Amazon API Gateway REST API that targets an        AWS Lambda function. The Lambda handler demonstrates how to route based on HTTP        methods; how to get data from the query string, header, and body; and how to        return a JSON response.    Deploy a Lambda function.Create an API Gateway REST API.Create a REST resource that targets the Lambda function.Grant permission to let API Gateway invoke the Lambda function.Use the Requests package to send requests to the REST API.Clean up all resources created during the demo.        This example is best viewed on GitHub. For complete source code and        instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayLambda",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.SDK for Java 2.x : \n\n        Shows how to create an AWS Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries\n        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates\n        them at their one year anniversary date.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nAPI GatewayDynamoDBLambdaAmazon SNS\n",
                            "SDK for Java 2.x        Shows how to create an AWS Lambda function by using the Lambda Java runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create a Lambda function invoked by Amazon API Gateway that scans an Amazon DynamoDB table for work anniversaries        and uses Amazon Simple Notification Service (Amazon SNS) to send a text message to your employees that congratulates        them at their one year anniversary date.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleAPI GatewayDynamoDBLambdaAmazon SNS",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Use Step Functions to invoke Lambda functions",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_ServerlessWorkflows_section.html",
                        "sections": [
                            "The following code example shows how to create an AWS Step Functions state machine that invokes AWS Lambda functions in sequence.",
                            "  1.Java : \n\n\nSDK for Java 2.x\n\n\n        Shows how to create an AWS serverless workflow by using AWS Step Functions and the AWS SDK for Java 2.x.\n        Each workflow step is implemented using an AWS Lambda function.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SESStep Functions\n\n\n",
                            "  2.SDK for Java 2.x : \n\n        Shows how to create an AWS serverless workflow by using AWS Step Functions and the AWS SDK for Java 2.x.\n        Each workflow step is implemented using an AWS Lambda function.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SESStep Functions\n",
                            "JavaSDK for Java 2.x        Shows how to create an AWS serverless workflow by using AWS Step Functions and the AWS SDK for Java 2.x.        Each workflow step is implemented using an AWS Lambda function.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaAmazon SESStep Functions",
                            "anchor",
                            "  1.SDK for Java 2.x : \n\n        Shows how to create an AWS serverless workflow by using AWS Step Functions and the AWS SDK for Java 2.x.\n        Each workflow step is implemented using an AWS Lambda function.\n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBLambdaAmazon SESStep Functions\n",
                            "SDK for Java 2.x        Shows how to create an AWS serverless workflow by using AWS Step Functions and the AWS SDK for Java 2.x.        Each workflow step is implemented using an AWS Lambda function.            For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBLambdaAmazon SESStep Functions",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Use scheduled events to invoke a Lambda function",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_LambdaScheduledEvents_section.html",
                        "sections": [
                            "The following code examples show how to create an AWS Lambda function invoked by an Amazon EventBridge scheduled event.",
                            "  1.Java : \n\n\nSDK for Java 2.x\n\n\n        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.\n        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.\n        In this example, you create a Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create an app that sends a mobile text message to your employees that congratulates \n        them at the one year anniversary date. \n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBEventBridgeLambdaAmazon SNS\n\n\n",
                            "  2.SDK for Java 2.x : \n\n        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.\n        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.\n        In this example, you create a Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create an app that sends a mobile text message to your employees that congratulates \n        them at the one year anniversary date. \n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBEventBridgeLambdaAmazon SNS\n",
                            "  3.JavaScript : \n\n\nSDK for JavaScript (v3)\n\n\n        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.\n        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.\n        In this example, you create a Lambda function by using the Lambda JavaScript runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create an app that sends a mobile text message to your employees that congratulates \n        them at the one year anniversary date. \n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \nThis example is also available in the\n        AWS SDK for JavaScript v3 developer guide.\n\nServices used in this example\nDynamoDBEventBridgeLambdaAmazon SNS\n\n\n",
                            "  4.SDK for JavaScript (v3) : \n\n        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.\n        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.\n        In this example, you create a Lambda function by using the Lambda JavaScript runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create an app that sends a mobile text message to your employees that congratulates \n        them at the one year anniversary date. \n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \nThis example is also available in the\n        AWS SDK for JavaScript v3 developer guide.\n\nServices used in this example\nDynamoDBEventBridgeLambdaAmazon SNS\n",
                            "  5.Python : \n\n\nSDK for Python (Boto3)\n\n\n        This example shows how to register an AWS Lambda function as the target of a\n        scheduled Amazon EventBridge event. The Lambda handler writes a friendly message and the\n        full event data to Amazon CloudWatch Logs for later retrieval.\n    \n\nDeploys a Lambda function.Creates an EventBridge scheduled event and makes the Lambda function the target.Grants permission to let EventBridge invoke the Lambda function.Prints the latest data from CloudWatch Logs to show the result of the scheduled invocations.Cleans up all resources created during the demo.\n\n        This example is best viewed on GitHub. For complete source code and\n        instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nCloudWatch LogsEventBridgeLambda\n\n\n",
                            "  6.SDK for Python (Boto3) : \n\n        This example shows how to register an AWS Lambda function as the target of a\n        scheduled Amazon EventBridge event. The Lambda handler writes a friendly message and the\n        full event data to Amazon CloudWatch Logs for later retrieval.\n    \n\nDeploys a Lambda function.Creates an EventBridge scheduled event and makes the Lambda function the target.Grants permission to let EventBridge invoke the Lambda function.Prints the latest data from CloudWatch Logs to show the result of the scheduled invocations.Cleans up all resources created during the demo.\n\n        This example is best viewed on GitHub. For complete source code and\n        instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nCloudWatch LogsEventBridgeLambda\n",
                            "JavaSDK for Java 2.x        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.        In this example, you create a Lambda function by using the Lambda Java runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create an app that sends a mobile text message to your employees that congratulates         them at the one year anniversary date.             For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBEventBridgeLambdaAmazon SNSJavaScriptSDK for JavaScript (v3)        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.        In this example, you create a Lambda function by using the Lambda JavaScript runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create an app that sends a mobile text message to your employees that congratulates         them at the one year anniversary date.             For complete source code and instructions on how to set up and run, see the full example on        GitHub.    This example is also available in the        AWS SDK for JavaScript v3 developer guide.Services used in this exampleDynamoDBEventBridgeLambdaAmazon SNSPythonSDK for Python (Boto3)        This example shows how to register an AWS Lambda function as the target of a        scheduled Amazon EventBridge event. The Lambda handler writes a friendly message and the        full event data to Amazon CloudWatch Logs for later retrieval.    Deploys a Lambda function.Creates an EventBridge scheduled event and makes the Lambda function the target.Grants permission to let EventBridge invoke the Lambda function.Prints the latest data from CloudWatch Logs to show the result of the scheduled invocations.Cleans up all resources created during the demo.        This example is best viewed on GitHub. For complete source code and        instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleCloudWatch LogsEventBridgeLambda",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.SDK for Java 2.x : \n\n        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.\n        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.\n        In this example, you create a Lambda function by using the Lambda Java runtime API.\n        This example invokes different AWS services to perform a specific use case. This example demonstrates how to\n        create an app that sends a mobile text message to your employees that congratulates \n        them at the one year anniversary date. \n    \n\n        For complete source code and instructions on how to set up and run, see the full example on\n        GitHub.\n    \n\nServices used in this example\nDynamoDBEventBridgeLambdaAmazon SNS\n",
                            "SDK for Java 2.x        Shows how to create an Amazon EventBridge scheduled event that invokes an AWS Lambda function.        Configure EventBridge to use a cron expression to schedule when the Lambda function is invoked.        In this example, you create a Lambda function by using the Lambda Java runtime API.        This example invokes different AWS services to perform a specific use case. This example demonstrates how to        create an app that sends a mobile text message to your employees that congratulates         them at the one year anniversary date.             For complete source code and instructions on how to set up and run, see the full example on        GitHub.    Services used in this exampleDynamoDBEventBridgeLambdaAmazon SNS",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Write custom activity data with a Lambda function after Amazon Cognito user authentication",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_cross_CognitoCustomActivityLog_section.html",
                        "sections": [
                            "The following code example shows how to write custom activity data with a Lambda function after Amazon Cognito user authentication.",
                            "  1.Use administrator functions to add a user to a user pool.",
                            "  2.Configure a user pool to call a Lambda function for the PostAuthentication trigger.",
                            "  3.Sign the new user in to Amazon Cognito.",
                            "  4.The Lambda function writes custom information to CloudWatch Logs and to an DynamoDB table.",
                            "  5.Get and display custom data from the DynamoDB table, then clean up resources.",
                            "  1.Go : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// ActivityLog separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype ActivityLog struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewActivityLog constructs a new activity log runner.\nfunc NewActivityLog(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) ActivityLog {\n\tscenario := ActivityLog{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddUserToPool selects a user from the known users table and uses administrator credentials to add the user to the user pool.\nfunc (runner *ActivityLog) AddUserToPool(ctx context.Context, userPoolId string, tableName string) (string, string) {\n\tlog.Println(\"To facilitate this example, let's add a user to the user pool using administrator privileges.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuser := users.Users[0]\n\tlog.Printf(\"Adding known user %v to the user pool.\\n\", user.UserName)\n\terr = runner.cognitoActor.AdminCreateUser(ctx, userPoolId, user.UserName, user.UserEmail)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tpwSet := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !pwSet {\n\t\tlog.Printf(\"\\nSetting password for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.AdminSetUserPassword(ctx, userPoolId, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tpwSet = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// AddActivityLogTrigger adds a Lambda handler as an invocation target for the PostAuthentication trigger.\nfunc (runner *ActivityLog) AddActivityLogTrigger(ctx context.Context, userPoolId string, activityLogArn string) {\n\tlog.Println(\"Let's add a Lambda function to handle the PostAuthentication trigger from Cognito.\\n\" +\n\t\t\"This trigger happens after a user is authenticated, and lets your function take action, such as logging\\n\" +\n\t\t\"the outcome.\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PostAuthentication, HandlerArn: aws.String(activityLogArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PostAuthentication)\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle PostAuthentication Cognito trigger.\\n\",\n\t\tactivityLogArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser signs in as the specified user.\nfunc (runner *ActivityLog) SignInUser(ctx context.Context, clientId string, userName string, password string) {\n\tlog.Printf(\"Now we'll sign in user %v and check the results in the logs and the DynamoDB table.\", userName)\n\trunner.questioner.Ask(\"Press Enter when you're ready.\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Println(\"Sign in successful.\",\n\t\t\"The PostAuthentication Lambda handler writes custom information to CloudWatch Logs.\")\n\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n}\n\n// GetKnownUserLastLogin gets the login info for a user from the Amazon DynamoDB table and displays it.\nfunc (runner *ActivityLog) GetKnownUserLastLogin(ctx context.Context, tableName string, userName string) {\n\tlog.Println(\"The PostAuthentication handler also writes login data to the DynamoDB table.\")\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfor _, user := range users.Users {\n\t\tif user.UserName == userName {\n\t\t\tlog.Println(\"The last login info for the user in the known users table is:\")\n\t\t\tlog.Printf(\"\\t%+v\", *user.LastLogin)\n\t\t}\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *ActivityLog) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\tuserName, password := runner.AddUserToPool(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"TableName\"])\n\n\trunner.AddActivityLogTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"ActivityLogFunctionArn\"])\n\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password)\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"ActivityLogFunction\"])\n\trunner.GetKnownUserLastLogin(ctx, stackOutputs[\"TableName\"], userName)\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "  2.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// ActivityLog separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype ActivityLog struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewActivityLog constructs a new activity log runner.\nfunc NewActivityLog(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) ActivityLog {\n\tscenario := ActivityLog{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddUserToPool selects a user from the known users table and uses administrator credentials to add the user to the user pool.\nfunc (runner *ActivityLog) AddUserToPool(ctx context.Context, userPoolId string, tableName string) (string, string) {\n\tlog.Println(\"To facilitate this example, let's add a user to the user pool using administrator privileges.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuser := users.Users[0]\n\tlog.Printf(\"Adding known user %v to the user pool.\\n\", user.UserName)\n\terr = runner.cognitoActor.AdminCreateUser(ctx, userPoolId, user.UserName, user.UserEmail)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tpwSet := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !pwSet {\n\t\tlog.Printf(\"\\nSetting password for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.AdminSetUserPassword(ctx, userPoolId, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tpwSet = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// AddActivityLogTrigger adds a Lambda handler as an invocation target for the PostAuthentication trigger.\nfunc (runner *ActivityLog) AddActivityLogTrigger(ctx context.Context, userPoolId string, activityLogArn string) {\n\tlog.Println(\"Let's add a Lambda function to handle the PostAuthentication trigger from Cognito.\\n\" +\n\t\t\"This trigger happens after a user is authenticated, and lets your function take action, such as logging\\n\" +\n\t\t\"the outcome.\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PostAuthentication, HandlerArn: aws.String(activityLogArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PostAuthentication)\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle PostAuthentication Cognito trigger.\\n\",\n\t\tactivityLogArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser signs in as the specified user.\nfunc (runner *ActivityLog) SignInUser(ctx context.Context, clientId string, userName string, password string) {\n\tlog.Printf(\"Now we'll sign in user %v and check the results in the logs and the DynamoDB table.\", userName)\n\trunner.questioner.Ask(\"Press Enter when you're ready.\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Println(\"Sign in successful.\",\n\t\t\"The PostAuthentication Lambda handler writes custom information to CloudWatch Logs.\")\n\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n}\n\n// GetKnownUserLastLogin gets the login info for a user from the Amazon DynamoDB table and displays it.\nfunc (runner *ActivityLog) GetKnownUserLastLogin(ctx context.Context, tableName string, userName string) {\n\tlog.Println(\"The PostAuthentication handler also writes login data to the DynamoDB table.\")\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfor _, user := range users.Users {\n\t\tif user.UserName == userName {\n\t\t\tlog.Println(\"The last login info for the user in the known users table is:\")\n\t\t\tlog.Printf(\"\\t%+v\", *user.LastLogin)\n\t\t}\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *ActivityLog) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\tuserName, password := runner.AddUserToPool(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"TableName\"])\n\n\trunner.AddActivityLogTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"ActivityLogFunctionArn\"])\n\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password)\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"ActivityLogFunction\"])\n\trunner.GetKnownUserLastLogin(ctx, stackOutputs[\"TableName\"], userName)\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// ActivityLog separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type ActivityLog struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewActivityLog constructs a new activity log runner.func NewActivityLog(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) ActivityLog {\tscenario := ActivityLog{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddUserToPool selects a user from the known users table and uses administrator credentials to add the user to the user pool.func (runner *ActivityLog) AddUserToPool(ctx context.Context, userPoolId string, tableName string) (string, string) {\tlog.Println(\"To facilitate this example, let's add a user to the user pool using administrator privileges.\")\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}\tuser := users.Users[0]\tlog.Printf(\"Adding known user %v to the user pool.\\n\", user.UserName)\terr = runner.cognitoActor.AdminCreateUser(ctx, userPoolId, user.UserName, user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\tpwSet := false\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !pwSet {\t\tlog.Printf(\"\\nSetting password for user '%v'.\\n\", user.UserName)\t\terr = runner.cognitoActor.AdminSetUserPassword(ctx, userPoolId, user.UserName, password)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tpwSet = true\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))\treturn user.UserName, password}// AddActivityLogTrigger adds a Lambda handler as an invocation target for the PostAuthentication trigger.func (runner *ActivityLog) AddActivityLogTrigger(ctx context.Context, userPoolId string, activityLogArn string) {\tlog.Println(\"Let's add a Lambda function to handle the PostAuthentication trigger from Cognito.\\n\" +\t\t\"This trigger happens after a user is authenticated, and lets your function take action, such as logging\\n\" +\t\t\"the outcome.\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.PostAuthentication, HandlerArn: aws.String(activityLogArn)})\tif err != nil {\t\tpanic(err)\t}\trunner.resources.triggers = append(runner.resources.triggers, actions.PostAuthentication)\tlog.Printf(\"Lambda function %v added to user pool %v to handle PostAuthentication Cognito trigger.\\n\",\t\tactivityLogArn, userPoolId)\tlog.Println(strings.Repeat(\"-\", 88))}// SignInUser signs in as the specified user.func (runner *ActivityLog) SignInUser(ctx context.Context, clientId string, userName string, password string) {\tlog.Printf(\"Now we'll sign in user %v and check the results in the logs and the DynamoDB table.\", userName)\trunner.questioner.Ask(\"Press Enter when you're ready.\")\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Println(\"Sign in successful.\",\t\t\"The PostAuthentication Lambda handler writes custom information to CloudWatch Logs.\")\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)}// GetKnownUserLastLogin gets the login info for a user from the Amazon DynamoDB table and displays it.func (runner *ActivityLog) GetKnownUserLastLogin(ctx context.Context, tableName string, userName string) {\tlog.Println(\"The PostAuthentication handler also writes login data to the DynamoDB table.\")\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}\tfor _, user := range users.Users {\t\tif user.UserName == userName {\t\t\tlog.Println(\"The last login info for the user in the known users table is:\")\t\t\tlog.Printf(\"\\t%+v\", *user.LastLogin)\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))}// Run runs the scenario.func (runner *ActivityLog) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\tuserName, password := runner.AddUserToPool(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"TableName\"])\trunner.AddActivityLogTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"ActivityLogFunctionArn\"])\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password)\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"ActivityLogFunction\"])\trunner.GetKnownUserLastLogin(ctx, stackOutputs[\"TableName\"], userName)\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the PostAuthentication trigger with a Lambda function.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"os\"\t\"time\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\tdynamodbtypes \"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")const TABLE_NAME = \"TABLE_NAME\"// LoginInfo defines structured login data that can be marshalled to a DynamoDB format.type LoginInfo struct {\tUserPoolId string `dynamodbav:\"UserPoolId\"`\tClientId   string `dynamodbav:\"ClientId\"`\tTime       string `dynamodbav:\"Time\"`}// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string    `dynamodbav:\"UserName\"`\tUserEmail string    `dynamodbav:\"UserEmail\"`\tLastLogin LoginInfo `dynamodbav:\"LastLogin\"`}// GetKey marshals the user email value to a DynamoDB key format.func (user UserInfo) GetKey() map[string]dynamodbtypes.AttributeValue {\tuserEmail, err := attributevalue.Marshal(user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\treturn map[string]dynamodbtypes.AttributeValue{\"UserEmail\": userEmail}}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the PostAuthentication event by writing custom data to the logs and// to an Amazon DynamoDB table.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsPostAuthentication) (events.CognitoEventUserPoolsPostAuthentication, error) {\tlog.Printf(\"Received post authentication trigger from %v for user '%v'\", event.TriggerSource, event.UserName)\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserName:  event.UserName,\t\tUserEmail: event.Request.UserAttributes[\"email\"],\t\tLastLogin: LoginInfo{\t\t\tUserPoolId: event.UserPoolID,\t\t\tClientId:   event.CallerContext.ClientID,\t\t\tTime:       time.Now().Format(time.UnixDate),\t\t},\t}\t// Write to CloudWatch Logs.\tfmt.Printf(\"%#v\", user)\t// Also write to an external system. This examples uses DynamoDB to demonstrate.\tuserMap, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshal to DynamoDB map. Here's why: %v\\n\", err)\t} else if len(userMap) == 0 {\t\tlog.Printf(\"User info marshaled to an empty map.\")\t} else {\t\t_, err := h.dynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\t\tItem:      userMap,\t\t\tTableName: aws.String(tableName),\t\t})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't write to DynamoDB. Here's why: %v\\n\", err)\t\t} else {\t\t\tlog.Printf(\"Wrote user info to DynamoDB table %v.\\n\", tableName)\t\t}\t}\treturn event, nil}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.AdminCreateUserAdminSetUserPasswordDeleteUserInitiateAuthUpdateUserPool",
                            "anchor",
                            "  1.SDK for Go V2 : \nimport (\n\t\"context\"\n\t\"errors\"\n\t\"log\"\n\t\"strings\"\n\t\"user_pools_and_lambda_triggers/actions\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\n\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\n\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\"\n)\n\n// ActivityLog separates the steps of this scenario into individual functions so that\n// they are simpler to read and understand.\ntype ActivityLog struct {\n\thelper       IScenarioHelper\n\tquestioner   demotools.IQuestioner\n\tresources    Resources\n\tcognitoActor *actions.CognitoActions\n}\n\n// NewActivityLog constructs a new activity log runner.\nfunc NewActivityLog(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) ActivityLog {\n\tscenario := ActivityLog{\n\t\thelper:       helper,\n\t\tquestioner:   questioner,\n\t\tresources:    Resources{},\n\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\n\t}\n\tscenario.resources.init(scenario.cognitoActor, questioner)\n\treturn scenario\n}\n\n// AddUserToPool selects a user from the known users table and uses administrator credentials to add the user to the user pool.\nfunc (runner *ActivityLog) AddUserToPool(ctx context.Context, userPoolId string, tableName string) (string, string) {\n\tlog.Println(\"To facilitate this example, let's add a user to the user pool using administrator privileges.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tuser := users.Users[0]\n\tlog.Printf(\"Adding known user %v to the user pool.\\n\", user.UserName)\n\terr = runner.cognitoActor.AdminCreateUser(ctx, userPoolId, user.UserName, user.UserEmail)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tpwSet := false\n\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\n\t\t\"(the password will not display as you type):\", 8)\n\tfor !pwSet {\n\t\tlog.Printf(\"\\nSetting password for user '%v'.\\n\", user.UserName)\n\t\terr = runner.cognitoActor.AdminSetUserPassword(ctx, userPoolId, user.UserName, password)\n\t\tif err != nil {\n\t\t\tvar invalidPassword *types.InvalidPasswordException\n\t\t\tif errors.As(err, &invalidPassword) {\n\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\n\t\t\t} else {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t} else {\n\t\t\tpwSet = true\n\t\t}\n\t}\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\treturn user.UserName, password\n}\n\n// AddActivityLogTrigger adds a Lambda handler as an invocation target for the PostAuthentication trigger.\nfunc (runner *ActivityLog) AddActivityLogTrigger(ctx context.Context, userPoolId string, activityLogArn string) {\n\tlog.Println(\"Let's add a Lambda function to handle the PostAuthentication trigger from Cognito.\\n\" +\n\t\t\"This trigger happens after a user is authenticated, and lets your function take action, such as logging\\n\" +\n\t\t\"the outcome.\")\n\terr := runner.cognitoActor.UpdateTriggers(\n\t\tctx, userPoolId,\n\t\tactions.TriggerInfo{Trigger: actions.PostAuthentication, HandlerArn: aws.String(activityLogArn)})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.triggers = append(runner.resources.triggers, actions.PostAuthentication)\n\tlog.Printf(\"Lambda function %v added to user pool %v to handle PostAuthentication Cognito trigger.\\n\",\n\t\tactivityLogArn, userPoolId)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// SignInUser signs in as the specified user.\nfunc (runner *ActivityLog) SignInUser(ctx context.Context, clientId string, userName string, password string) {\n\tlog.Printf(\"Now we'll sign in user %v and check the results in the logs and the DynamoDB table.\", userName)\n\trunner.questioner.Ask(\"Press Enter when you're ready.\")\n\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Println(\"Sign in successful.\",\n\t\t\"The PostAuthentication Lambda handler writes custom information to CloudWatch Logs.\")\n\n\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)\n}\n\n// GetKnownUserLastLogin gets the login info for a user from the Amazon DynamoDB table and displays it.\nfunc (runner *ActivityLog) GetKnownUserLastLogin(ctx context.Context, tableName string, userName string) {\n\tlog.Println(\"The PostAuthentication handler also writes login data to the DynamoDB table.\")\n\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\n\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfor _, user := range users.Users {\n\t\tif user.UserName == userName {\n\t\t\tlog.Println(\"The last login info for the user in the known users table is:\")\n\t\t\tlog.Printf(\"\\t%+v\", *user.LastLogin)\n\t\t}\n\t}\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n// Run runs the scenario.\nfunc (runner *ActivityLog) Run(ctx context.Context, stackName string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tlog.Println(\"Something went wrong with the demo.\")\n\t\t\trunner.resources.Cleanup(ctx)\n\t\t}\n\t}()\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Printf(\"Welcome\\n\")\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\n\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\n\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\n\tuserName, password := runner.AddUserToPool(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"TableName\"])\n\n\trunner.AddActivityLogTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"ActivityLogFunctionArn\"])\n\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password)\n\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"ActivityLogFunction\"])\n\trunner.GetKnownUserLastLogin(ctx, stackOutputs[\"TableName\"], userName)\n\n\trunner.resources.Cleanup(ctx)\n\n\tlog.Println(strings.Repeat(\"-\", 88))\n\tlog.Println(\"Thanks for watching!\")\n\tlog.Println(strings.Repeat(\"-\", 88))\n}\n\n\n",
                            "SDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Run an interactive scenario at a command prompt.import (\t\"context\"\t\"errors\"\t\"log\"\t\"strings\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// ActivityLog separates the steps of this scenario into individual functions so that// they are simpler to read and understand.type ActivityLog struct {\thelper       IScenarioHelper\tquestioner   demotools.IQuestioner\tresources    Resources\tcognitoActor *actions.CognitoActions}// NewActivityLog constructs a new activity log runner.func NewActivityLog(sdkConfig aws.Config, questioner demotools.IQuestioner, helper IScenarioHelper) ActivityLog {\tscenario := ActivityLog{\t\thelper:       helper,\t\tquestioner:   questioner,\t\tresources:    Resources{},\t\tcognitoActor: &actions.CognitoActions{CognitoClient: cognitoidentityprovider.NewFromConfig(sdkConfig)},\t}\tscenario.resources.init(scenario.cognitoActor, questioner)\treturn scenario}// AddUserToPool selects a user from the known users table and uses administrator credentials to add the user to the user pool.func (runner *ActivityLog) AddUserToPool(ctx context.Context, userPoolId string, tableName string) (string, string) {\tlog.Println(\"To facilitate this example, let's add a user to the user pool using administrator privileges.\")\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}\tuser := users.Users[0]\tlog.Printf(\"Adding known user %v to the user pool.\\n\", user.UserName)\terr = runner.cognitoActor.AdminCreateUser(ctx, userPoolId, user.UserName, user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\tpwSet := false\tpassword := runner.questioner.AskPassword(\"\\nEnter a password that has at least eight characters, uppercase, lowercase, numbers and symbols.\\n\"+\t\t\"(the password will not display as you type):\", 8)\tfor !pwSet {\t\tlog.Printf(\"\\nSetting password for user '%v'.\\n\", user.UserName)\t\terr = runner.cognitoActor.AdminSetUserPassword(ctx, userPoolId, user.UserName, password)\t\tif err != nil {\t\t\tvar invalidPassword *types.InvalidPasswordException\t\t\tif errors.As(err, &invalidPassword) {\t\t\t\tpassword = runner.questioner.AskPassword(\"\\nEnter another password:\", 8)\t\t\t} else {\t\t\t\tpanic(err)\t\t\t}\t\t} else {\t\t\tpwSet = true\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))\treturn user.UserName, password}// AddActivityLogTrigger adds a Lambda handler as an invocation target for the PostAuthentication trigger.func (runner *ActivityLog) AddActivityLogTrigger(ctx context.Context, userPoolId string, activityLogArn string) {\tlog.Println(\"Let's add a Lambda function to handle the PostAuthentication trigger from Cognito.\\n\" +\t\t\"This trigger happens after a user is authenticated, and lets your function take action, such as logging\\n\" +\t\t\"the outcome.\")\terr := runner.cognitoActor.UpdateTriggers(\t\tctx, userPoolId,\t\tactions.TriggerInfo{Trigger: actions.PostAuthentication, HandlerArn: aws.String(activityLogArn)})\tif err != nil {\t\tpanic(err)\t}\trunner.resources.triggers = append(runner.resources.triggers, actions.PostAuthentication)\tlog.Printf(\"Lambda function %v added to user pool %v to handle PostAuthentication Cognito trigger.\\n\",\t\tactivityLogArn, userPoolId)\tlog.Println(strings.Repeat(\"-\", 88))}// SignInUser signs in as the specified user.func (runner *ActivityLog) SignInUser(ctx context.Context, clientId string, userName string, password string) {\tlog.Printf(\"Now we'll sign in user %v and check the results in the logs and the DynamoDB table.\", userName)\trunner.questioner.Ask(\"Press Enter when you're ready.\")\tauthResult, err := runner.cognitoActor.SignIn(ctx, clientId, userName, password)\tif err != nil {\t\tpanic(err)\t}\tlog.Println(\"Sign in successful.\",\t\t\"The PostAuthentication Lambda handler writes custom information to CloudWatch Logs.\")\trunner.resources.userAccessTokens = append(runner.resources.userAccessTokens, *authResult.AccessToken)}// GetKnownUserLastLogin gets the login info for a user from the Amazon DynamoDB table and displays it.func (runner *ActivityLog) GetKnownUserLastLogin(ctx context.Context, tableName string, userName string) {\tlog.Println(\"The PostAuthentication handler also writes login data to the DynamoDB table.\")\trunner.questioner.Ask(\"Press Enter when you're ready to continue.\")\tusers, err := runner.helper.GetKnownUsers(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}\tfor _, user := range users.Users {\t\tif user.UserName == userName {\t\t\tlog.Println(\"The last login info for the user in the known users table is:\")\t\t\tlog.Printf(\"\\t%+v\", *user.LastLogin)\t\t}\t}\tlog.Println(strings.Repeat(\"-\", 88))}// Run runs the scenario.func (runner *ActivityLog) Run(ctx context.Context, stackName string) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Println(\"Something went wrong with the demo.\")\t\t\trunner.resources.Cleanup(ctx)\t\t}\t}()\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Printf(\"Welcome\\n\")\tlog.Println(strings.Repeat(\"-\", 88))\tstackOutputs, err := runner.helper.GetStackOutputs(ctx, stackName)\tif err != nil {\t\tpanic(err)\t}\trunner.resources.userPoolId = stackOutputs[\"UserPoolId\"]\trunner.helper.PopulateUserTable(ctx, stackOutputs[\"TableName\"])\tuserName, password := runner.AddUserToPool(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"TableName\"])\trunner.AddActivityLogTrigger(ctx, stackOutputs[\"UserPoolId\"], stackOutputs[\"ActivityLogFunctionArn\"])\trunner.SignInUser(ctx, stackOutputs[\"UserPoolClientId\"], userName, password)\trunner.helper.ListRecentLogEvents(ctx, stackOutputs[\"ActivityLogFunction\"])\trunner.GetKnownUserLastLogin(ctx, stackOutputs[\"TableName\"], userName)\trunner.resources.Cleanup(ctx)\tlog.Println(strings.Repeat(\"-\", 88))\tlog.Println(\"Thanks for watching!\")\tlog.Println(strings.Repeat(\"-\", 88))}Handle the PostAuthentication trigger with a Lambda function.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"os\"\t\"time\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\tdynamodbtypes \"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")const TABLE_NAME = \"TABLE_NAME\"// LoginInfo defines structured login data that can be marshalled to a DynamoDB format.type LoginInfo struct {\tUserPoolId string `dynamodbav:\"UserPoolId\"`\tClientId   string `dynamodbav:\"ClientId\"`\tTime       string `dynamodbav:\"Time\"`}// UserInfo defines structured user data that can be marshalled to a DynamoDB format.type UserInfo struct {\tUserName  string    `dynamodbav:\"UserName\"`\tUserEmail string    `dynamodbav:\"UserEmail\"`\tLastLogin LoginInfo `dynamodbav:\"LastLogin\"`}// GetKey marshals the user email value to a DynamoDB key format.func (user UserInfo) GetKey() map[string]dynamodbtypes.AttributeValue {\tuserEmail, err := attributevalue.Marshal(user.UserEmail)\tif err != nil {\t\tpanic(err)\t}\treturn map[string]dynamodbtypes.AttributeValue{\"UserEmail\": userEmail}}type handler struct {\tdynamoClient *dynamodb.Client}// HandleRequest handles the PostAuthentication event by writing custom data to the logs and// to an Amazon DynamoDB table.func (h *handler) HandleRequest(ctx context.Context, event events.CognitoEventUserPoolsPostAuthentication) (events.CognitoEventUserPoolsPostAuthentication, error) {\tlog.Printf(\"Received post authentication trigger from %v for user '%v'\", event.TriggerSource, event.UserName)\ttableName := os.Getenv(TABLE_NAME)\tuser := UserInfo{\t\tUserName:  event.UserName,\t\tUserEmail: event.Request.UserAttributes[\"email\"],\t\tLastLogin: LoginInfo{\t\t\tUserPoolId: event.UserPoolID,\t\t\tClientId:   event.CallerContext.ClientID,\t\t\tTime:       time.Now().Format(time.UnixDate),\t\t},\t}\t// Write to CloudWatch Logs.\tfmt.Printf(\"%#v\", user)\t// Also write to an external system. This examples uses DynamoDB to demonstrate.\tuserMap, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshal to DynamoDB map. Here's why: %v\\n\", err)\t} else if len(userMap) == 0 {\t\tlog.Printf(\"User info marshaled to an empty map.\")\t} else {\t\t_, err := h.dynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\t\tItem:      userMap,\t\t\tTableName: aws.String(tableName),\t\t})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't write to DynamoDB. Here's why: %v\\n\", err)\t\t} else {\t\t\tlog.Printf(\"Wrote user info to DynamoDB table %v.\\n\", tableName)\t\t}\t}\treturn event, nil}func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Panicln(err)\t}\th := handler{\t\tdynamoClient: dynamodb.NewFromConfig(sdkConfig),\t}\tlambda.Start(h.HandleRequest)}Create a struct that performs common tasks.import (\t\"context\"\t\"log\"\t\"strings\"\t\"time\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// IScenarioHelper defines common functions used by the workflows in this example.type IScenarioHelper interface {\tPause(secs int)\tGetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error)\tPopulateUserTable(ctx context.Context, tableName string)\tGetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error)\tAddKnownUser(ctx context.Context, tableName string, user actions.User)\tListRecentLogEvents(ctx context.Context, functionName string)}// ScenarioHelper contains AWS wrapper structs used by the workflows in this example.type ScenarioHelper struct {\tquestioner  demotools.IQuestioner\tdynamoActor *actions.DynamoActions\tcfnActor    *actions.CloudFormationActions\tcwlActor    *actions.CloudWatchLogsActions\tisTestRun   bool}// NewScenarioHelper constructs a new scenario helper.func NewScenarioHelper(sdkConfig aws.Config, questioner demotools.IQuestioner) ScenarioHelper {\tscenario := ScenarioHelper{\t\tquestioner:  questioner,\t\tdynamoActor: &actions.DynamoActions{DynamoClient: dynamodb.NewFromConfig(sdkConfig)},\t\tcfnActor:    &actions.CloudFormationActions{CfnClient: cloudformation.NewFromConfig(sdkConfig)},\t\tcwlActor:    &actions.CloudWatchLogsActions{CwlClient: cloudwatchlogs.NewFromConfig(sdkConfig)},\t}\treturn scenario}// Pause waits for the specified number of seconds.func (helper ScenarioHelper) Pause(secs int) {\tif !helper.isTestRun {\t\ttime.Sleep(time.Duration(secs) * time.Second)\t}}// GetStackOutputs gets the outputs from the specified CloudFormation stack in a structured format.func (helper ScenarioHelper) GetStackOutputs(ctx context.Context, stackName string) (actions.StackOutputs, error) {\treturn helper.cfnActor.GetOutputs(ctx, stackName), nil}// PopulateUserTable fills the known user table with example data.func (helper ScenarioHelper) PopulateUserTable(ctx context.Context, tableName string) {\tlog.Printf(\"First, let's add some users to the DynamoDB %v table we'll use for this example.\\n\", tableName)\terr := helper.dynamoActor.PopulateTable(ctx, tableName)\tif err != nil {\t\tpanic(err)\t}}// GetKnownUsers gets the users from the known users table in a structured format.func (helper ScenarioHelper) GetKnownUsers(ctx context.Context, tableName string) (actions.UserList, error) {\tknownUsers, err := helper.dynamoActor.Scan(ctx, tableName)\tif err != nil {\t\tlog.Printf(\"Couldn't get known users from table %v. Here's why: %v\\n\", tableName, err)\t}\treturn knownUsers, err}// AddKnownUser adds a user to the known users table.func (helper ScenarioHelper) AddKnownUser(ctx context.Context, tableName string, user actions.User) {\tlog.Printf(\"Adding user '%v' with email '%v' to the DynamoDB known users table...\\n\",\t\tuser.UserName, user.UserEmail)\terr := helper.dynamoActor.AddUser(ctx, tableName, user)\tif err != nil {\t\tpanic(err)\t}}// ListRecentLogEvents gets the most recent log stream and events for the specified Lambda function and displays them.func (helper ScenarioHelper) ListRecentLogEvents(ctx context.Context, functionName string) {\tlog.Println(\"Waiting a few seconds to let Lambda write to CloudWatch Logs...\")\thelper.Pause(10)\tlog.Println(\"Okay, let's check the logs to find what's happened recently with your Lambda function.\")\tlogStream, err := helper.cwlActor.GetLatestLogStream(ctx, functionName)\tif err != nil {\t\tpanic(err)\t}\tlog.Printf(\"Getting some recent events from log stream %v\\n\", *logStream.LogStreamName)\tevents, err := helper.cwlActor.GetLogEvents(ctx, functionName, *logStream.LogStreamName, 10)\tif err != nil {\t\tpanic(err)\t}\tfor _, event := range events {\t\tlog.Printf(\"\\t%v\", *event.Message)\t}\tlog.Println(strings.Repeat(\"-\", 88))}Create a struct that wraps Amazon Cognito actions.import (\t\"context\"\t\"errors\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\"\t\"github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\")type CognitoActions struct {\tCognitoClient *cognitoidentityprovider.Client}// Trigger and TriggerInfo define typed data for updating an Amazon Cognito trigger.type Trigger intconst (\tPreSignUp Trigger = iota\tUserMigration\tPostAuthentication)type TriggerInfo struct {\tTrigger    Trigger\tHandlerArn *string}// UpdateTriggers adds or removes Lambda triggers for a user pool. When a trigger is specified with a `nil` value,// it is removed from the user pool.func (actor CognitoActions) UpdateTriggers(ctx context.Context, userPoolId string, triggers ...TriggerInfo) error {\toutput, err := actor.CognitoClient.DescribeUserPool(ctx, &cognitoidentityprovider.DescribeUserPoolInput{\t\tUserPoolId: aws.String(userPoolId),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get info about user pool %v. Here's why: %v\\n\", userPoolId, err)\t\treturn err\t}\tlambdaConfig := output.UserPool.LambdaConfig\tfor _, trigger := range triggers {\t\tswitch trigger.Trigger {\t\tcase PreSignUp:\t\t\tlambdaConfig.PreSignUp = trigger.HandlerArn\t\tcase UserMigration:\t\t\tlambdaConfig.UserMigration = trigger.HandlerArn\t\tcase PostAuthentication:\t\t\tlambdaConfig.PostAuthentication = trigger.HandlerArn\t\t}\t}\t_, err = actor.CognitoClient.UpdateUserPool(ctx, &cognitoidentityprovider.UpdateUserPoolInput{\t\tUserPoolId:   aws.String(userPoolId),\t\tLambdaConfig: lambdaConfig,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't update user pool %v. Here's why: %v\\n\", userPoolId, err)\t}\treturn err}// SignUp signs up a user with Amazon Cognito.func (actor CognitoActions) SignUp(ctx context.Context, clientId string, userName string, password string, userEmail string) (bool, error) {\tconfirmed := false\toutput, err := actor.CognitoClient.SignUp(ctx, &cognitoidentityprovider.SignUpInput{\t\tClientId: aws.String(clientId),\t\tPassword: aws.String(password),\t\tUsername: aws.String(userName),\t\tUserAttributes: []types.AttributeType{\t\t\t{Name: aws.String(\"email\"), Value: aws.String(userEmail)},\t\t},\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign up user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tconfirmed = output.UserConfirmed\t}\treturn confirmed, err}// SignIn signs in a user to Amazon Cognito using a username and password authentication flow.func (actor CognitoActions) SignIn(ctx context.Context, clientId string, userName string, password string) (*types.AuthenticationResultType, error) {\tvar authResult *types.AuthenticationResultType\toutput, err := actor.CognitoClient.InitiateAuth(ctx, &cognitoidentityprovider.InitiateAuthInput{\t\tAuthFlow:       \"USER_PASSWORD_AUTH\",\t\tClientId:       aws.String(clientId),\t\tAuthParameters: map[string]string{\"USERNAME\": userName, \"PASSWORD\": password},\t})\tif err != nil {\t\tvar resetRequired *types.PasswordResetRequiredException\t\tif errors.As(err, &resetRequired) {\t\t\tlog.Println(*resetRequired.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't sign in user %v. Here's why: %v\\n\", userName, err)\t\t}\t} else {\t\tauthResult = output.AuthenticationResult\t}\treturn authResult, err}// ForgotPassword starts a password recovery flow for a user. This flow typically sends a confirmation code// to the user's configured notification destination, such as email.func (actor CognitoActions) ForgotPassword(ctx context.Context, clientId string, userName string) (*types.CodeDeliveryDetailsType, error) {\toutput, err := actor.CognitoClient.ForgotPassword(ctx, &cognitoidentityprovider.ForgotPasswordInput{\t\tClientId: aws.String(clientId),\t\tUsername: aws.String(userName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't start password reset for user '%v'. Here;s why: %v\\n\", userName, err)\t}\treturn output.CodeDeliveryDetails, err}// ConfirmForgotPassword confirms a user with a confirmation code and a new password.func (actor CognitoActions) ConfirmForgotPassword(ctx context.Context, clientId string, code string, userName string, password string) error {\t_, err := actor.CognitoClient.ConfirmForgotPassword(ctx, &cognitoidentityprovider.ConfirmForgotPasswordInput{\t\tClientId:         aws.String(clientId),\t\tConfirmationCode: aws.String(code),\t\tPassword:         aws.String(password),\t\tUsername:         aws.String(userName),\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't confirm user %v. Here's why: %v\", userName, err)\t\t}\t}\treturn err}// DeleteUser removes a user from the user pool.func (actor CognitoActions) DeleteUser(ctx context.Context, userAccessToken string) error {\t_, err := actor.CognitoClient.DeleteUser(ctx, &cognitoidentityprovider.DeleteUserInput{\t\tAccessToken: aws.String(userAccessToken),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't delete user. Here's why: %v\\n\", err)\t}\treturn err}// AdminCreateUser uses administrator credentials to add a user to a user pool. This method leaves the user// in a state that requires they enter a new password next time they sign in.func (actor CognitoActions) AdminCreateUser(ctx context.Context, userPoolId string, userName string, userEmail string) error {\t_, err := actor.CognitoClient.AdminCreateUser(ctx, &cognitoidentityprovider.AdminCreateUserInput{\t\tUserPoolId:     aws.String(userPoolId),\t\tUsername:       aws.String(userName),\t\tMessageAction:  types.MessageActionTypeSuppress,\t\tUserAttributes: []types.AttributeType{{Name: aws.String(\"email\"), Value: aws.String(userEmail)}},\t})\tif err != nil {\t\tvar userExists *types.UsernameExistsException\t\tif errors.As(err, &userExists) {\t\t\tlog.Printf(\"User %v already exists in the user pool.\", userName)\t\t\terr = nil\t\t} else {\t\t\tlog.Printf(\"Couldn't create user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}// AdminSetUserPassword uses administrator credentials to set a password for a user without requiring a// temporary password.func (actor CognitoActions) AdminSetUserPassword(ctx context.Context, userPoolId string, userName string, password string) error {\t_, err := actor.CognitoClient.AdminSetUserPassword(ctx, &cognitoidentityprovider.AdminSetUserPasswordInput{\t\tPassword:   aws.String(password),\t\tUserPoolId: aws.String(userPoolId),\t\tUsername:   aws.String(userName),\t\tPermanent:  true,\t})\tif err != nil {\t\tvar invalidPassword *types.InvalidPasswordException\t\tif errors.As(err, &invalidPassword) {\t\t\tlog.Println(*invalidPassword.Message)\t\t} else {\t\t\tlog.Printf(\"Couldn't set password for user %v. Here's why: %v\\n\", userName, err)\t\t}\t}\treturn err}Create a struct that wraps DynamoDB actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb\"\t\"github.com/aws/aws-sdk-go-v2/service/dynamodb/types\")// DynamoActions encapsulates the Amazon Simple Notification Service (Amazon SNS) actions// used in the examples.type DynamoActions struct {\tDynamoClient *dynamodb.Client}// User defines structured user data.type User struct {\tUserName  string\tUserEmail string\tLastLogin *LoginInfo `dynamodbav:\",omitempty\"`}// LoginInfo defines structured custom login data.type LoginInfo struct {\tUserPoolId string\tClientId   string\tTime       string}// UserList defines a list of users.type UserList struct {\tUsers []User}// UserNameList returns the usernames contained in a UserList as a list of strings.func (users *UserList) UserNameList() []string {\tnames := make([]string, len(users.Users))\tfor i := 0; i < len(users.Users); i++ {\t\tnames[i] = users.Users[i].UserName\t}\treturn names}// PopulateTable adds a set of test users to the table.func (actor DynamoActions) PopulateTable(ctx context.Context, tableName string) error {\tvar err error\tvar item map[string]types.AttributeValue\tvar writeReqs []types.WriteRequest\tfor i := 1; i < 4; i++ {\t\titem, err = attributevalue.MarshalMap(User{UserName: fmt.Sprintf(\"test_user_%v\", i), UserEmail: fmt.Sprintf(\"test_email_%v@example.com\", i)})\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't marshall user into DynamoDB format. Here's why: %v\\n\", err)\t\t\treturn err\t\t}\t\twriteReqs = append(writeReqs, types.WriteRequest{PutRequest: &types.PutRequest{Item: item}})\t}\t_, err = actor.DynamoClient.BatchWriteItem(ctx, &dynamodb.BatchWriteItemInput{\t\tRequestItems: map[string][]types.WriteRequest{tableName: writeReqs},\t})\tif err != nil {\t\tlog.Printf(\"Couldn't populate table %v with users. Here's why: %v\\n\", tableName, err)\t}\treturn err}// Scan scans the table for all items.func (actor DynamoActions) Scan(ctx context.Context, tableName string) (UserList, error) {\tvar userList UserList\toutput, err := actor.DynamoClient.Scan(ctx, &dynamodb.ScanInput{\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't scan table %v for items. Here's why: %v\\n\", tableName, err)\t} else {\t\terr = attributevalue.UnmarshalListOfMaps(output.Items, &userList.Users)\t\tif err != nil {\t\t\tlog.Printf(\"Couldn't unmarshal items into users. Here's why: %v\\n\", err)\t\t}\t}\treturn userList, err}// AddUser adds a user item to a table.func (actor DynamoActions) AddUser(ctx context.Context, tableName string, user User) error {\tuserItem, err := attributevalue.MarshalMap(user)\tif err != nil {\t\tlog.Printf(\"Couldn't marshall user to item. Here's why: %v\\n\", err)\t}\t_, err = actor.DynamoClient.PutItem(ctx, &dynamodb.PutItemInput{\t\tItem:      userItem,\t\tTableName: aws.String(tableName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't put item in table %v. Here's why: %v\", tableName, err)\t}\treturn err}Create a struct that wraps CloudWatch Logs actions.import (\t\"context\"\t\"fmt\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs/types\")type CloudWatchLogsActions struct {\tCwlClient *cloudwatchlogs.Client}// GetLatestLogStream gets the most recent log stream for a Lambda function.func (actor CloudWatchLogsActions) GetLatestLogStream(ctx context.Context, functionName string) (types.LogStream, error) {\tvar logStream types.LogStream\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.DescribeLogStreams(ctx, &cloudwatchlogs.DescribeLogStreamsInput{\t\tDescending:   aws.Bool(true),\t\tLimit:        aws.Int32(1),\t\tLogGroupName: aws.String(logGroupName),\t\tOrderBy:      types.OrderByLastEventTime,\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log streams for log group %v. Here's why: %v\\n\", logGroupName, err)\t} else {\t\tlogStream = output.LogStreams[0]\t}\treturn logStream, err}// GetLogEvents gets the most recent eventCount events from the specified log stream.func (actor CloudWatchLogsActions) GetLogEvents(ctx context.Context, functionName string, logStreamName string, eventCount int32) (\t[]types.OutputLogEvent, error) {\tvar events []types.OutputLogEvent\tlogGroupName := fmt.Sprintf(\"/aws/lambda/%s\", functionName)\toutput, err := actor.CwlClient.GetLogEvents(ctx, &cloudwatchlogs.GetLogEventsInput{\t\tLogStreamName: aws.String(logStreamName),\t\tLimit:         aws.Int32(eventCount),\t\tLogGroupName:  aws.String(logGroupName),\t})\tif err != nil {\t\tlog.Printf(\"Couldn't get log event for log stream %v. Here's why: %v\\n\", logStreamName, err)\t} else {\t\tevents = output.Events\t}\treturn events, err}Create a struct that wraps AWS CloudFormation actions.import (\t\"context\"\t\"log\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/service/cloudformation\")// StackOutputs defines a map of outputs from a specific stack.type StackOutputs map[string]stringtype CloudFormationActions struct {\tCfnClient *cloudformation.Client}// GetOutputs gets the outputs from a CloudFormation stack and puts them into a structured format.func (actor CloudFormationActions) GetOutputs(ctx context.Context, stackName string) StackOutputs {\toutput, err := actor.CfnClient.DescribeStacks(ctx, &cloudformation.DescribeStacksInput{\t\tStackName: aws.String(stackName),\t})\tif err != nil || len(output.Stacks) == 0 {\t\tlog.Panicf(\"Couldn't find a CloudFormation stack named %v. Here's why: %v\\n\", stackName, err)\t}\tstackOutputs := StackOutputs{}\tfor _, out := range output.Stacks[0].Outputs {\t\tstackOutputs[*out.OutputKey] = *out.OutputValue\t}\treturn stackOutputs}Clean up resources.import (\t\"context\"\t\"log\"\t\"user_pools_and_lambda_triggers/actions\"\t\"github.com/awsdocs/aws-doc-sdk-examples/gov2/demotools\")// Resources keeps track of AWS resources created during an example and handles// cleanup when the example finishes.type Resources struct {\tuserPoolId       string\tuserAccessTokens []string\ttriggers         []actions.Trigger\tcognitoActor *actions.CognitoActions\tquestioner   demotools.IQuestioner}func (resources *Resources) init(cognitoActor *actions.CognitoActions, questioner demotools.IQuestioner) {\tresources.userAccessTokens = []string{}\tresources.triggers = []actions.Trigger{}\tresources.cognitoActor = cognitoActor\tresources.questioner = questioner}// Cleanup deletes all AWS resources created during an example.func (resources *Resources) Cleanup(ctx context.Context) {\tdefer func() {\t\tif r := recover(); r != nil {\t\t\tlog.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r)\t\t\tlog.Println(\"Use the AWS Management Console to remove any remaining resources \\n\" +\t\t\t\t\"that were created for this scenario.\")\t\t}\t}()\twantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS resources that were created \"+\t\t\"during this demo (y/n)?\", \"y\")\tif wantDelete {\t\tfor _, accessToken := range resources.userAccessTokens {\t\t\terr := resources.cognitoActor.DeleteUser(ctx, accessToken)\t\t\tif err != nil {\t\t\t\tlog.Println(\"Couldn't delete user during cleanup.\")\t\t\t\tpanic(err)\t\t\t}\t\t\tlog.Println(\"Deleted user.\")\t\t}\t\ttriggerList := make([]actions.TriggerInfo, len(resources.triggers))\t\tfor i := 0; i < len(resources.triggers); i++ {\t\t\ttriggerList[i] = actions.TriggerInfo{Trigger: resources.triggers[i], HandlerArn: nil}\t\t}\t\terr := resources.cognitoActor.UpdateTriggers(ctx, resources.userPoolId, triggerList...)\t\tif err != nil {\t\t\tlog.Println(\"Couldn't update Cognito triggers during cleanup.\")\t\t\tpanic(err)\t\t}\t\tlog.Println(\"Removed Cognito triggers from user pool.\")\t} else {\t\tlog.Println(\"Be sure to remove resources when you're done with them to avoid unexpected charges!\")\t}}For API details, see the following topics in AWS SDK for Go API Reference.AdminCreateUserAdminSetUserPasswordDeleteUserInitiateAuthUpdateUserPool",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "The following code examples show you how to implement common scenarios in Lambda        with AWS SDKs. These scenarios show you how to accomplish specific tasks by calling multiple functions        within Lambda or combined with other AWS services.        Each scenario includes a link to the complete source code, where you can find instructions on how to set up and run the code.    ",
                    "Scenarios target an intermediate level of experience to help you understand service actions in context.",
                    "Examples"
                ]
            },
            {
                "title": "Serverless examples",
                "href": "https://docs.aws.amazon.com/lambda/latest/dg/service_code_examples_serverless_examples.html",
                "contents": [
                    {
                        "title": "Connecting to an Amazon RDS database in a Lambda function",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_connect_RDS_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that connects to an RDS database. The function makes a simple database request and returns the result.",
                            "  1.Go : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  2.SDK for Go V2 : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  3.Java : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;\nimport software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.rdsdata.RdsDataClient;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;\nimport software.amazon.awssdk.services.rdsdata.model.Field;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\n\npublic class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {\n\n    @Override\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {\n        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\n        try {\n            // Obtain auth token\n            String token = createAuthToken();\n\n            // Define connection configuration\n            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",\n                    System.getenv(\"ProxyHostName\"),\n                    System.getenv(\"Port\"),\n                    System.getenv(\"DBName\"));\n\n            // Establish a connection to the database\n            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);\n                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {\n\n                statement.setInt(1, 3);\n                statement.setInt(2, 2);\n\n                try (ResultSet resultSet = statement.executeQuery()) {\n                    if (resultSet.next()) {\n                        int sum = resultSet.getInt(\"sum\");\n                        response.setStatusCode(200);\n                        response.setBody(\"The selected sum is: \" + sum);\n                    }\n                }\n            }\n\n        } catch (Exception e) {\n            response.setStatusCode(500);\n            response.setBody(\"Error: \" + e.getMessage());\n        }\n\n        return response;\n    }\n\n    private String createAuthToken() {\n        // Create RDS Data Service client\n        RdsDataClient rdsDataClient = RdsDataClient.builder()\n                .region(Region.of(System.getenv(\"AWS_REGION\")))\n                .credentialsProvider(DefaultCredentialsProvider.create())\n                .build();\n\n        // Define authentication request\n        ExecuteStatementRequest request = ExecuteStatementRequest.builder()\n                .resourceArn(System.getenv(\"ProxyHostName\"))\n                .secretArn(System.getenv(\"DBUserName\"))\n                .database(System.getenv(\"DBName\"))\n                .sql(\"SELECT 'RDS IAM Authentication'\")\n                .build();\n\n        // Execute request and obtain authentication token\n        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);\n        Field tokenField = response.records().get(0).get(0);\n\n        return tokenField.stringValue();\n    }\n}\n\n",
                            "  4.SDK for Java 2.x : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;\nimport com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;\nimport software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.rdsdata.RdsDataClient;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;\nimport software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;\nimport software.amazon.awssdk.services.rdsdata.model.Field;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\n\npublic class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {\n\n    @Override\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {\n        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\n        try {\n            // Obtain auth token\n            String token = createAuthToken();\n\n            // Define connection configuration\n            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",\n                    System.getenv(\"ProxyHostName\"),\n                    System.getenv(\"Port\"),\n                    System.getenv(\"DBName\"));\n\n            // Establish a connection to the database\n            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);\n                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {\n\n                statement.setInt(1, 3);\n                statement.setInt(2, 2);\n\n                try (ResultSet resultSet = statement.executeQuery()) {\n                    if (resultSet.next()) {\n                        int sum = resultSet.getInt(\"sum\");\n                        response.setStatusCode(200);\n                        response.setBody(\"The selected sum is: \" + sum);\n                    }\n                }\n            }\n\n        } catch (Exception e) {\n            response.setStatusCode(500);\n            response.setBody(\"Error: \" + e.getMessage());\n        }\n\n        return response;\n    }\n\n    private String createAuthToken() {\n        // Create RDS Data Service client\n        RdsDataClient rdsDataClient = RdsDataClient.builder()\n                .region(Region.of(System.getenv(\"AWS_REGION\")))\n                .credentialsProvider(DefaultCredentialsProvider.create())\n                .build();\n\n        // Define authentication request\n        ExecuteStatementRequest request = ExecuteStatementRequest.builder()\n                .resourceArn(System.getenv(\"ProxyHostName\"))\n                .secretArn(System.getenv(\"DBUserName\"))\n                .database(System.getenv(\"DBName\"))\n                .sql(\"SELECT 'RDS IAM Authentication'\")\n                .build();\n\n        // Execute request and obtain authentication token\n        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);\n        Field tokenField = response.records().get(0).get(0);\n\n        return tokenField.stringValue();\n    }\n}\n\n",
                            "  5.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/* \nNode.js code here.\n*/\n// ES6+ example\nimport { Signer } from \"@aws-sdk/rds-signer\";\nimport mysql from 'mysql2/promise';\n\nasync function createAuthToken() {\n  // Define connection authentication parameters\n  const dbinfo = {\n\n    hostname: process.env.ProxyHostName,\n    port: process.env.Port,\n    username: process.env.DBUserName,\n    region: process.env.AWS_REGION,\n\n  }\n\n  // Create RDS Signer object\n  const signer = new Signer(dbinfo);\n\n  // Request authorization token from RDS, specifying the username\n  const token = await signer.getAuthToken();\n  return token;\n}\n\nasync function dbOps() {\n\n  // Obtain auth token\n  const token = await createAuthToken();\n  // Define connection configuration\n  let connectionConfig = {\n    host: process.env.ProxyHostName,\n    user: process.env.DBUserName,\n    password: token,\n    database: process.env.DBName,\n    ssl: 'Amazon RDS'\n  }\n  // Create the connection to the DB\n  const conn = await mysql.createConnection(connectionConfig);\n  // Obtain the result of the query\n  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);\n  return res;\n\n}\n\nexport const handler = async (event) => {\n  // Execute database flow\n  const result = await dbOps();\n  // Return result\n  return {\n    statusCode: 200,\n    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)\n  }\n};\n\n",
                            "  6.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/* \nNode.js code here.\n*/\n// ES6+ example\nimport { Signer } from \"@aws-sdk/rds-signer\";\nimport mysql from 'mysql2/promise';\n\nasync function createAuthToken() {\n  // Define connection authentication parameters\n  const dbinfo = {\n\n    hostname: process.env.ProxyHostName,\n    port: process.env.Port,\n    username: process.env.DBUserName,\n    region: process.env.AWS_REGION,\n\n  }\n\n  // Create RDS Signer object\n  const signer = new Signer(dbinfo);\n\n  // Request authorization token from RDS, specifying the username\n  const token = await signer.getAuthToken();\n  return token;\n}\n\nasync function dbOps() {\n\n  // Obtain auth token\n  const token = await createAuthToken();\n  // Define connection configuration\n  let connectionConfig = {\n    host: process.env.ProxyHostName,\n    user: process.env.DBUserName,\n    password: token,\n    database: process.env.DBName,\n    ssl: 'Amazon RDS'\n  }\n  // Create the connection to the DB\n  const conn = await mysql.createConnection(connectionConfig);\n  // Obtain the result of the query\n  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);\n  return res;\n\n}\n\nexport const handler = async (event) => {\n  // Execute database flow\n  const result = await dbOps();\n  // Return result\n  return {\n    statusCode: 200,\n    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)\n  }\n};\n\n",
                            "  7.PHP : <?php\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\nuse Aws\\Rds\\AuthTokenGenerator;\nuse Aws\\Credentials\\CredentialProvider;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n\n    private function getAuthToken(): string {\n        // Define connection authentication parameters\n        $dbConnection = [\n            'hostname' => getenv('DB_HOSTNAME'),\n            'port' => getenv('DB_PORT'),\n            'username' => getenv('DB_USERNAME'),\n            'region' => getenv('AWS_REGION'),\n        ];\n\n        // Create RDS AuthTokenGenerator object\n        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());\n\n        // Request authorization token from RDS, specifying the username\n        return $generator->createToken(\n            $dbConnection['hostname'] . ':' . $dbConnection['port'],\n            $dbConnection['region'],\n            $dbConnection['username']\n        );\n    }\n\n    private function getQueryResults() {\n        // Obtain auth token\n        $token = $this->getAuthToken();\n\n        // Define connection configuration\n        $connectionConfig = [\n            'host' => getenv('DB_HOSTNAME'),\n            'user' => getenv('DB_USERNAME'),\n            'password' => $token,\n            'database' => getenv('DB_NAME'),\n        ];\n\n        // Create the connection to the DB\n        $conn = new PDO(\n            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",\n            $connectionConfig['user'],\n            $connectionConfig['password'],\n            [\n                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',\n                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,\n            ]\n        );\n\n        // Obtain the result of the query\n        $stmt = $conn->prepare('SELECT ?+? AS sum');\n        $stmt->execute([3, 2]);\n\n        return $stmt->fetch(PDO::FETCH_ASSOC);\n    }\n\n    /**\n     * @param mixed $event\n     * @param Context $context\n     * @return array\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $this->logger->info(\"Processing query\");\n\n        // Execute database flow\n        $result = $this->getQueryResults();\n\n        return [\n            'sum' => $result['sum']\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  8.SDK for PHP : <?php\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\nuse Aws\\Rds\\AuthTokenGenerator;\nuse Aws\\Credentials\\CredentialProvider;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n\n    private function getAuthToken(): string {\n        // Define connection authentication parameters\n        $dbConnection = [\n            'hostname' => getenv('DB_HOSTNAME'),\n            'port' => getenv('DB_PORT'),\n            'username' => getenv('DB_USERNAME'),\n            'region' => getenv('AWS_REGION'),\n        ];\n\n        // Create RDS AuthTokenGenerator object\n        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());\n\n        // Request authorization token from RDS, specifying the username\n        return $generator->createToken(\n            $dbConnection['hostname'] . ':' . $dbConnection['port'],\n            $dbConnection['region'],\n            $dbConnection['username']\n        );\n    }\n\n    private function getQueryResults() {\n        // Obtain auth token\n        $token = $this->getAuthToken();\n\n        // Define connection configuration\n        $connectionConfig = [\n            'host' => getenv('DB_HOSTNAME'),\n            'user' => getenv('DB_USERNAME'),\n            'password' => $token,\n            'database' => getenv('DB_NAME'),\n        ];\n\n        // Create the connection to the DB\n        $conn = new PDO(\n            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",\n            $connectionConfig['user'],\n            $connectionConfig['password'],\n            [\n                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',\n                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,\n            ]\n        );\n\n        // Obtain the result of the query\n        $stmt = $conn->prepare('SELECT ?+? AS sum');\n        $stmt->execute([3, 2]);\n\n        return $stmt->fetch(PDO::FETCH_ASSOC);\n    }\n\n    /**\n     * @param mixed $event\n     * @param Context $context\n     * @return array\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $this->logger->info(\"Processing query\");\n\n        // Execute database flow\n        $result = $this->getQueryResults();\n\n        return [\n            'sum' => $result['sum']\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  9.Python : import json\nimport os\nimport boto3\nimport pymysql\n\n# RDS settings\nproxy_host_name = os.environ['PROXY_HOST_NAME']\nport = int(os.environ['PORT'])\ndb_name = os.environ['DB_NAME']\ndb_user_name = os.environ['DB_USER_NAME']\naws_region = os.environ['AWS_REGION']\n\n\n# Fetch RDS Auth Token\ndef get_auth_token():\n    client = boto3.client('rds')\n    token = client.generate_db_auth_token(\n        DBHostname=proxy_host_name,\n        Port=port\n        DBUsername=db_user_name\n        Region=aws_region\n    )\n    return token\n\ndef lambda_handler(event, context):\n    token = get_auth_token()\n    try:\n        connection = pymysql.connect(\n            host=proxy_host_name,\n            user=db_user_name,\n            password=token,\n            db=db_name,\n            port=port,\n            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection\n        )\n        \n        with connection.cursor() as cursor:\n            cursor.execute('SELECT %s + %s AS sum', (3, 2))\n            result = cursor.fetchone()\n\n        return result\n        \n    except Exception as e:\n        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs \n    \n",
                            "  10.SDK for Python (Boto3) : import json\nimport os\nimport boto3\nimport pymysql\n\n# RDS settings\nproxy_host_name = os.environ['PROXY_HOST_NAME']\nport = int(os.environ['PORT'])\ndb_name = os.environ['DB_NAME']\ndb_user_name = os.environ['DB_USER_NAME']\naws_region = os.environ['AWS_REGION']\n\n\n# Fetch RDS Auth Token\ndef get_auth_token():\n    client = boto3.client('rds')\n    token = client.generate_db_auth_token(\n        DBHostname=proxy_host_name,\n        Port=port\n        DBUsername=db_user_name\n        Region=aws_region\n    )\n    return token\n\ndef lambda_handler(event, context):\n    token = get_auth_token()\n    try:\n        connection = pymysql.connect(\n            host=proxy_host_name,\n            user=db_user_name,\n            password=token,\n            db=db_name,\n            port=port,\n            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection\n        )\n        \n        with connection.cursor() as cursor:\n            cursor.execute('SELECT %s + %s AS sum', (3, 2))\n            result = cursor.fetchone()\n\n        return result\n        \n    except Exception as e:\n        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs \n    \n",
                            "  11.Ruby : # Ruby code here.\n\nrequire 'aws-sdk-rds'\nrequire 'json'\nrequire 'mysql2'\n\ndef lambda_handler(event:, context:)\n  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"\n  port = ENV['Port']           # 3306\n  user = ENV['DBUser']\n  region = ENV['DBRegion']     # 'us-east-1'\n  db_name = ENV['DBName']\n\n  credentials = Aws::Credentials.new(\n    ENV['AWS_ACCESS_KEY_ID'],\n    ENV['AWS_SECRET_ACCESS_KEY'],\n    ENV['AWS_SESSION_TOKEN']\n  )\n  rds_client = Aws::RDS::AuthTokenGenerator.new(\n    region: region, \n    credentials: credentials\n  )\n\n  token = rds_client.auth_token(\n    endpoint: endpoint+ ':' + port,\n    user_name: user,\n    region: region\n  )\n\n  begin\n    conn = Mysql2::Client.new(\n      host: endpoint,\n      username: user,\n      password: token,\n      port: port,\n      database: db_name,\n      sslca: '/var/task/global-bundle.pem', \n      sslverify: true,\n      enable_cleartext_plugin: true\n    )\n    a = 3\n    b = 2\n    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']\n    puts result\n    conn.close\n    {\n      statusCode: 200,\n      body: result.to_json\n    }\n  rescue => e\n    puts \"Database connection failed due to #{e}\"\n  end\nend\n",
                            "  12.SDK for Ruby : # Ruby code here.\n\nrequire 'aws-sdk-rds'\nrequire 'json'\nrequire 'mysql2'\n\ndef lambda_handler(event:, context:)\n  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"\n  port = ENV['Port']           # 3306\n  user = ENV['DBUser']\n  region = ENV['DBRegion']     # 'us-east-1'\n  db_name = ENV['DBName']\n\n  credentials = Aws::Credentials.new(\n    ENV['AWS_ACCESS_KEY_ID'],\n    ENV['AWS_SECRET_ACCESS_KEY'],\n    ENV['AWS_SESSION_TOKEN']\n  )\n  rds_client = Aws::RDS::AuthTokenGenerator.new(\n    region: region, \n    credentials: credentials\n  )\n\n  token = rds_client.auth_token(\n    endpoint: endpoint+ ':' + port,\n    user_name: user,\n    region: region\n  )\n\n  begin\n    conn = Mysql2::Client.new(\n      host: endpoint,\n      username: user,\n      password: token,\n      port: port,\n      database: db_name,\n      sslca: '/var/task/global-bundle.pem', \n      sslverify: true,\n      enable_cleartext_plugin: true\n    )\n    a = 3\n    b = 2\n    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']\n    puts result\n    conn.close\n    {\n      statusCode: 200,\n      body: result.to_json\n    }\n  rescue => e\n    puts \"Database connection failed due to #{e}\"\n  end\nend\n",
                            "  13.Rust : use aws_config::BehaviorVersion;\nuse aws_credential_types::provider::ProvideCredentials;\nuse aws_sigv4::{\n    http_request::{sign, SignableBody, SignableRequest, SigningSettings},\n    sign::v4,\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse serde_json::{json, Value};\nuse sqlx::postgres::PgConnectOptions;\nuse std::env;\nuse std::time::{Duration, SystemTime};\n\nconst RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");\n\nasync fn generate_rds_iam_token(\n    db_hostname: &str,\n    port: u16,\n    db_username: &str,\n) -> Result<String, Error> {\n    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;\n\n    let credentials = config\n        .credentials_provider()\n        .expect(\"no credentials provider found\")\n        .provide_credentials()\n        .await\n        .expect(\"unable to load credentials\");\n    let identity = credentials.into();\n    let region = config.region().unwrap().to_string();\n\n    let mut signing_settings = SigningSettings::default();\n    signing_settings.expires_in = Some(Duration::from_secs(900));\n    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;\n\n    let signing_params = v4::SigningParams::builder()\n        .identity(&identity)\n        .region(&region)\n        .name(\"rds-db\")\n        .time(SystemTime::now())\n        .settings(signing_settings)\n        .build()?;\n\n    let url = format!(\n        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",\n        db_hostname = db_hostname,\n        port = port,\n        db_user = db_username\n    );\n\n    let signable_request =\n        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))\n            .expect(\"signable request\");\n\n    let (signing_instructions, _signature) =\n        sign(signable_request, &signing_params.into())?.into_parts();\n\n    let mut url = url::Url::parse(&url).unwrap();\n    for (name, value) in signing_instructions.params() {\n        url.query_pairs_mut().append_pair(name, &value);\n    }\n\n    let response = url.to_string().split_off(\"https://\".len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(handler)).await\n}\n\nasync fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {\n    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");\n    let db_port = env::var(\"DB_PORT\")\n        .expect(\"DB_PORT must be set\")\n        .parse::<u16>()\n        .expect(\"PORT must be a valid number\");\n    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");\n    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");\n\n    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;\n\n    let opts = PgConnectOptions::new()\n        .host(&db_host)\n        .port(db_port)\n        .username(&db_user_name)\n        .password(&token)\n        .database(&db_name)\n        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())\n        .ssl_mode(sqlx::postgres::PgSslMode::Require);\n\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .connect_with(opts)\n        .await?;\n\n    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")\n        .bind(3)\n        .bind(2)\n        .fetch_one(&pool)\n        .await?;\n\n    println!(\"Result: {:?}\", result);\n\n    Ok(json!({\n        \"statusCode\": 200,\n        \"content-type\": \"text/plain\",\n        \"body\": format!(\"The selected sum is: {result}\")\n    }))\n}\n\n",
                            "  14.SDK for Rust : use aws_config::BehaviorVersion;\nuse aws_credential_types::provider::ProvideCredentials;\nuse aws_sigv4::{\n    http_request::{sign, SignableBody, SignableRequest, SigningSettings},\n    sign::v4,\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse serde_json::{json, Value};\nuse sqlx::postgres::PgConnectOptions;\nuse std::env;\nuse std::time::{Duration, SystemTime};\n\nconst RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");\n\nasync fn generate_rds_iam_token(\n    db_hostname: &str,\n    port: u16,\n    db_username: &str,\n) -> Result<String, Error> {\n    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;\n\n    let credentials = config\n        .credentials_provider()\n        .expect(\"no credentials provider found\")\n        .provide_credentials()\n        .await\n        .expect(\"unable to load credentials\");\n    let identity = credentials.into();\n    let region = config.region().unwrap().to_string();\n\n    let mut signing_settings = SigningSettings::default();\n    signing_settings.expires_in = Some(Duration::from_secs(900));\n    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;\n\n    let signing_params = v4::SigningParams::builder()\n        .identity(&identity)\n        .region(&region)\n        .name(\"rds-db\")\n        .time(SystemTime::now())\n        .settings(signing_settings)\n        .build()?;\n\n    let url = format!(\n        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",\n        db_hostname = db_hostname,\n        port = port,\n        db_user = db_username\n    );\n\n    let signable_request =\n        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))\n            .expect(\"signable request\");\n\n    let (signing_instructions, _signature) =\n        sign(signable_request, &signing_params.into())?.into_parts();\n\n    let mut url = url::Url::parse(&url).unwrap();\n    for (name, value) in signing_instructions.params() {\n        url.query_pairs_mut().append_pair(name, &value);\n    }\n\n    let response = url.to_string().split_off(\"https://\".len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(handler)).await\n}\n\nasync fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {\n    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");\n    let db_port = env::var(\"DB_PORT\")\n        .expect(\"DB_PORT must be set\")\n        .parse::<u16>()\n        .expect(\"PORT must be a valid number\");\n    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");\n    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");\n\n    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;\n\n    let opts = PgConnectOptions::new()\n        .host(&db_host)\n        .port(db_port)\n        .username(&db_user_name)\n        .password(&token)\n        .database(&db_name)\n        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())\n        .ssl_mode(sqlx::postgres::PgSslMode::Require);\n\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .connect_with(opts)\n        .await?;\n\n    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")\n        .bind(3)\n        .bind(2)\n        .fetch_one(&pool)\n        .await?;\n\n    println!(\"Result: {:?}\", result);\n\n    Ok(json!({\n        \"statusCode\": 200,\n        \"content-type\": \"text/plain\",\n        \"body\": format!(\"The selected sum is: {result}\")\n    }))\n}\n\n",
                            "GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Go./*Golang v2 code here.*/package mainimport (\t\"context\"\t\"database/sql\"\t\"encoding/json\"\t\"fmt\"\t\"os\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\t_ \"github.com/go-sql-driver/mysql\")type MyEvent struct {\tName string `json:\"name\"`}func HandleRequest(event *MyEvent) (map[string]interface{}, error) {\tvar dbName string = os.Getenv(\"DatabaseName\")\tvar dbUser string = os.Getenv(\"DatabaseUser\")\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\tvar region string = os.Getenv(\"AWS_REGION\")\tcfg, err := config.LoadDefaultConfig(context.TODO())\tif err != nil {\t\tpanic(\"configuration error: \" + err.Error())\t}\tauthenticationToken, err := auth.BuildAuthToken(\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\tif err != nil {\t\tpanic(\"failed to create authentication token: \" + err.Error())\t}\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\t\tdbUser, authenticationToken, dbEndpoint, dbName,\t)\tdb, err := sql.Open(\"mysql\", dsn)\tif err != nil {\t\tpanic(err)\t}\tdefer db.Close()\tvar sum int\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\tif err != nil {\t\tpanic(err)\t}\ts := fmt.Sprint(sum)\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\tmessageBytes, err := json.Marshal(message)\tif err != nil {\t\treturn nil, err\t}\tmessageString := string(messageBytes)\treturn map[string]interface{}{\t\t\"statusCode\": 200,\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\t\t\"body\":       messageString,\t}, nil}func main() {\tlambda.Start(HandleRequest)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent;import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent;import software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;import software.amazon.awssdk.regions.Region;import software.amazon.awssdk.services.rdsdata.RdsDataClient;import software.amazon.awssdk.services.rdsdata.model.ExecuteStatementRequest;import software.amazon.awssdk.services.rdsdata.model.ExecuteStatementResponse;import software.amazon.awssdk.services.rdsdata.model.Field;import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;import java.sql.ResultSet;public class RdsLambdaHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {    @Override    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {        APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();        try {            // Obtain auth token            String token = createAuthToken();            // Define connection configuration            String connectionString = String.format(\"jdbc:mysql://%s:%s/%s?useSSL=true&requireSSL=true\",                    System.getenv(\"ProxyHostName\"),                    System.getenv(\"Port\"),                    System.getenv(\"DBName\"));            // Establish a connection to the database            try (Connection connection = DriverManager.getConnection(connectionString, System.getenv(\"DBUserName\"), token);                 PreparedStatement statement = connection.prepareStatement(\"SELECT ? + ? AS sum\")) {                statement.setInt(1, 3);                statement.setInt(2, 2);                try (ResultSet resultSet = statement.executeQuery()) {                    if (resultSet.next()) {                        int sum = resultSet.getInt(\"sum\");                        response.setStatusCode(200);                        response.setBody(\"The selected sum is: \" + sum);                    }                }            }        } catch (Exception e) {            response.setStatusCode(500);            response.setBody(\"Error: \" + e.getMessage());        }        return response;    }    private String createAuthToken() {        // Create RDS Data Service client        RdsDataClient rdsDataClient = RdsDataClient.builder()                .region(Region.of(System.getenv(\"AWS_REGION\")))                .credentialsProvider(DefaultCredentialsProvider.create())                .build();        // Define authentication request        ExecuteStatementRequest request = ExecuteStatementRequest.builder()                .resourceArn(System.getenv(\"ProxyHostName\"))                .secretArn(System.getenv(\"DBUserName\"))                .database(System.getenv(\"DBName\"))                .sql(\"SELECT 'RDS IAM Authentication'\")                .build();        // Execute request and obtain authentication token        ExecuteStatementResponse response = rdsDataClient.executeStatement(request);        Field tokenField = response.records().get(0).get(0);        return tokenField.stringValue();    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0/* Node.js code here.*/// ES6+ exampleimport { Signer } from \"@aws-sdk/rds-signer\";import mysql from 'mysql2/promise';async function createAuthToken() {  // Define connection authentication parameters  const dbinfo = {    hostname: process.env.ProxyHostName,    port: process.env.Port,    username: process.env.DBUserName,    region: process.env.AWS_REGION,  }  // Create RDS Signer object  const signer = new Signer(dbinfo);  // Request authorization token from RDS, specifying the username  const token = await signer.getAuthToken();  return token;}async function dbOps() {  // Obtain auth token  const token = await createAuthToken();  // Define connection configuration  let connectionConfig = {    host: process.env.ProxyHostName,    user: process.env.DBUserName,    password: token,    database: process.env.DBName,    ssl: 'Amazon RDS'  }  // Create the connection to the DB  const conn = await mysql.createConnection(connectionConfig);  // Obtain the result of the query  const [res,] = await conn.execute('select ?+? as sum', [3, 2]);  return res;}export const handler = async (event) => {  // Execute database flow  const result = await dbOps();  // Return result  return {    statusCode: 200,    body: JSON.stringify(\"The selected sum is: \" + result[0].sum)  }};Connecting to an Amazon RDS database in a Lambda function using TypeScript.import { Signer } from \"@aws-sdk/rds-signer\";import mysql from 'mysql2/promise';// RDS settings// Using '!' (non-null assertion operator) to tell the TypeScript compiler that the DB settings are not null or undefined,const proxy_host_name = process.env.PROXY_HOST_NAME!const port = parseInt(process.env.PORT!)const db_name = process.env.DB_NAME!const db_user_name = process.env.DB_USER_NAME!const aws_region = process.env.AWS_REGION!async function createAuthToken(): Promise<string> {    // Create RDS Signer object    const signer = new Signer({        hostname: proxy_host_name,        port: port,        region: aws_region,        username: db_user_name    });    // Request authorization token from RDS, specifying the username    const token = await signer.getAuthToken();    return token;}async function dbOps(): Promise<mysql.QueryResult | undefined> {    try {        // Obtain auth token        const token = await createAuthToken();        const conn = await mysql.createConnection({            host: proxy_host_name,            user: db_user_name,            password: token,            database: db_name,            ssl: 'Amazon RDS' // Ensure you have the CA bundle for SSL connection        });        const [rows, fields] = await conn.execute('SELECT ? + ? AS sum', [3, 2]);        console.log('result:', rows);        return rows;    }    catch (err) {        console.log(err);    }}export const lambdaHandler = async (event: any): Promise<{ statusCode: number; body: string }> => {    // Execute database flow    const result = await dbOps();    // Return error is result is undefined    if (result == undefined)        return {            statusCode: 500,            body: JSON.stringify(`Error with connection to DB host`)        }    // Return result    return {        statusCode: 200,        body: JSON.stringify(`The selected sum is: ${result[0].sum}`)    };};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using PHP.<?php# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;use Aws\\Rds\\AuthTokenGenerator;use Aws\\Credentials\\CredentialProvider;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    private function getAuthToken(): string {        // Define connection authentication parameters        $dbConnection = [            'hostname' => getenv('DB_HOSTNAME'),            'port' => getenv('DB_PORT'),            'username' => getenv('DB_USERNAME'),            'region' => getenv('AWS_REGION'),        ];        // Create RDS AuthTokenGenerator object        $generator = new AuthTokenGenerator(CredentialProvider::defaultProvider());        // Request authorization token from RDS, specifying the username        return $generator->createToken(            $dbConnection['hostname'] . ':' . $dbConnection['port'],            $dbConnection['region'],            $dbConnection['username']        );    }    private function getQueryResults() {        // Obtain auth token        $token = $this->getAuthToken();        // Define connection configuration        $connectionConfig = [            'host' => getenv('DB_HOSTNAME'),            'user' => getenv('DB_USERNAME'),            'password' => $token,            'database' => getenv('DB_NAME'),        ];        // Create the connection to the DB        $conn = new PDO(            \"mysql:host={$connectionConfig['host']};dbname={$connectionConfig['database']}\",            $connectionConfig['user'],            $connectionConfig['password'],            [                PDO::MYSQL_ATTR_SSL_CA => '/path/to/rds-ca-2019-root.pem',                PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT => true,            ]        );        // Obtain the result of the query        $stmt = $conn->prepare('SELECT ?+? AS sum');        $stmt->execute([3, 2]);        return $stmt->fetch(PDO::FETCH_ASSOC);    }    /**     * @param mixed $event     * @param Context $context     * @return array     */    public function handle(mixed $event, Context $context): array    {        $this->logger->info(\"Processing query\");        // Execute database flow        $result = $this->getQueryResults();        return [            'sum' => $result['sum']        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Python.import jsonimport osimport boto3import pymysql# RDS settingsproxy_host_name = os.environ['PROXY_HOST_NAME']port = int(os.environ['PORT'])db_name = os.environ['DB_NAME']db_user_name = os.environ['DB_USER_NAME']aws_region = os.environ['AWS_REGION']# Fetch RDS Auth Tokendef get_auth_token():    client = boto3.client('rds')    token = client.generate_db_auth_token(        DBHostname=proxy_host_name,        Port=port        DBUsername=db_user_name        Region=aws_region    )    return tokendef lambda_handler(event, context):    token = get_auth_token()    try:        connection = pymysql.connect(            host=proxy_host_name,            user=db_user_name,            password=token,            db=db_name,            port=port,            ssl={'ca': 'Amazon RDS'}  # Ensure you have the CA bundle for SSL connection        )                with connection.cursor() as cursor:            cursor.execute('SELECT %s + %s AS sum', (3, 2))            result = cursor.fetchone()        return result            except Exception as e:        return (f\"Error: {str(e)}\")  # Return an error message if an exception occurs     RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Ruby.# Ruby code here.require 'aws-sdk-rds'require 'json'require 'mysql2'def lambda_handler(event:, context:)  endpoint = ENV['DBEndpoint'] # Add the endpoint without https\"  port = ENV['Port']           # 3306  user = ENV['DBUser']  region = ENV['DBRegion']     # 'us-east-1'  db_name = ENV['DBName']  credentials = Aws::Credentials.new(    ENV['AWS_ACCESS_KEY_ID'],    ENV['AWS_SECRET_ACCESS_KEY'],    ENV['AWS_SESSION_TOKEN']  )  rds_client = Aws::RDS::AuthTokenGenerator.new(    region: region,     credentials: credentials  )  token = rds_client.auth_token(    endpoint: endpoint+ ':' + port,    user_name: user,    region: region  )  begin    conn = Mysql2::Client.new(      host: endpoint,      username: user,      password: token,      port: port,      database: db_name,      sslca: '/var/task/global-bundle.pem',       sslverify: true,      enable_cleartext_plugin: true    )    a = 3    b = 2    result = conn.query(\"SELECT #{a} + #{b} AS sum\").first['sum']    puts result    conn.close    {      statusCode: 200,      body: result.to_json    }  rescue => e    puts \"Database connection failed due to #{e}\"  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Rust.use aws_config::BehaviorVersion;use aws_credential_types::provider::ProvideCredentials;use aws_sigv4::{    http_request::{sign, SignableBody, SignableRequest, SigningSettings},    sign::v4,};use lambda_runtime::{run, service_fn, Error, LambdaEvent};use serde_json::{json, Value};use sqlx::postgres::PgConnectOptions;use std::env;use std::time::{Duration, SystemTime};const RDS_CERTS: &[u8] = include_bytes!(\"global-bundle.pem\");async fn generate_rds_iam_token(    db_hostname: &str,    port: u16,    db_username: &str,) -> Result<String, Error> {    let config = aws_config::load_defaults(BehaviorVersion::v2024_03_28()).await;    let credentials = config        .credentials_provider()        .expect(\"no credentials provider found\")        .provide_credentials()        .await        .expect(\"unable to load credentials\");    let identity = credentials.into();    let region = config.region().unwrap().to_string();    let mut signing_settings = SigningSettings::default();    signing_settings.expires_in = Some(Duration::from_secs(900));    signing_settings.signature_location = aws_sigv4::http_request::SignatureLocation::QueryParams;    let signing_params = v4::SigningParams::builder()        .identity(&identity)        .region(&region)        .name(\"rds-db\")        .time(SystemTime::now())        .settings(signing_settings)        .build()?;    let url = format!(        \"https://{db_hostname}:{port}/?Action=connect&DBUser={db_user}\",        db_hostname = db_hostname,        port = port,        db_user = db_username    );    let signable_request =        SignableRequest::new(\"GET\", &url, std::iter::empty(), SignableBody::Bytes(&[]))            .expect(\"signable request\");    let (signing_instructions, _signature) =        sign(signable_request, &signing_params.into())?.into_parts();    let mut url = url::Url::parse(&url).unwrap();    for (name, value) in signing_instructions.params() {        url.query_pairs_mut().append_pair(name, &value);    }    let response = url.to_string().split_off(\"https://\".len());    Ok(response)}#[tokio::main]async fn main() -> Result<(), Error> {    run(service_fn(handler)).await}async fn handler(_event: LambdaEvent<Value>) -> Result<Value, Error> {    let db_host = env::var(\"DB_HOSTNAME\").expect(\"DB_HOSTNAME must be set\");    let db_port = env::var(\"DB_PORT\")        .expect(\"DB_PORT must be set\")        .parse::<u16>()        .expect(\"PORT must be a valid number\");    let db_name = env::var(\"DB_NAME\").expect(\"DB_NAME must be set\");    let db_user_name = env::var(\"DB_USERNAME\").expect(\"DB_USERNAME must be set\");    let token = generate_rds_iam_token(&db_host, db_port, &db_user_name).await?;    let opts = PgConnectOptions::new()        .host(&db_host)        .port(db_port)        .username(&db_user_name)        .password(&token)        .database(&db_name)        .ssl_root_cert_from_pem(RDS_CERTS.to_vec())        .ssl_mode(sqlx::postgres::PgSslMode::Require);    let pool = sqlx::postgres::PgPoolOptions::new()        .connect_with(opts)        .await?;    let result: i32 = sqlx::query_scalar(\"SELECT $1 + $2\")        .bind(3)        .bind(2)        .fetch_one(&pool)        .await?;    println!(\"Result: {:?}\", result);    Ok(json!({        \"statusCode\": 200,        \"content-type\": \"text/plain\",        \"body\": format!(\"The selected sum is: {result}\")    }))}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.SDK for Go V2 : /*\nGolang v2 code here.\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\ntype MyEvent struct {\n\tName string `json:\"name\"`\n}\n\nfunc HandleRequest(event *MyEvent) (map[string]interface{}, error) {\n\n\tvar dbName string = os.Getenv(\"DatabaseName\")\n\tvar dbUser string = os.Getenv(\"DatabaseUser\")\n\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\n\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\n\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\n\tvar region string = os.Getenv(\"AWS_REGION\")\n\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\tpanic(\"configuration error: \" + err.Error())\n\t}\n\n\tauthenticationToken, err := auth.BuildAuthToken(\n\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\n\tif err != nil {\n\t\tpanic(\"failed to create authentication token: \" + err.Error())\n\t}\n\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\n\t\tdbUser, authenticationToken, dbEndpoint, dbName,\n\t)\n\n\tdb, err := sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer db.Close()\n\n\tvar sum int\n\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ts := fmt.Sprint(sum)\n\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\n\n\tmessageBytes, err := json.Marshal(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmessageString := string(messageBytes)\n\treturn map[string]interface{}{\n\t\t\"statusCode\": 200,\n\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\n\t\t\"body\":       messageString,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "SDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Connecting to an Amazon RDS database in a Lambda function using Go./*Golang v2 code here.*/package mainimport (\t\"context\"\t\"database/sql\"\t\"encoding/json\"\t\"fmt\"\t\"os\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/feature/rds/auth\"\t_ \"github.com/go-sql-driver/mysql\")type MyEvent struct {\tName string `json:\"name\"`}func HandleRequest(event *MyEvent) (map[string]interface{}, error) {\tvar dbName string = os.Getenv(\"DatabaseName\")\tvar dbUser string = os.Getenv(\"DatabaseUser\")\tvar dbHost string = os.Getenv(\"DBHost\") // Add hostname without https\tvar dbPort int = os.Getenv(\"Port\")      // Add port number\tvar dbEndpoint string = fmt.Sprintf(\"%s:%d\", dbHost, dbPort)\tvar region string = os.Getenv(\"AWS_REGION\")\tcfg, err := config.LoadDefaultConfig(context.TODO())\tif err != nil {\t\tpanic(\"configuration error: \" + err.Error())\t}\tauthenticationToken, err := auth.BuildAuthToken(\t\tcontext.TODO(), dbEndpoint, region, dbUser, cfg.Credentials)\tif err != nil {\t\tpanic(\"failed to create authentication token: \" + err.Error())\t}\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/%s?tls=true&allowCleartextPasswords=true\",\t\tdbUser, authenticationToken, dbEndpoint, dbName,\t)\tdb, err := sql.Open(\"mysql\", dsn)\tif err != nil {\t\tpanic(err)\t}\tdefer db.Close()\tvar sum int\terr = db.QueryRow(\"SELECT ?+? AS sum\", 3, 2).Scan(&sum)\tif err != nil {\t\tpanic(err)\t}\ts := fmt.Sprint(sum)\tmessage := fmt.Sprintf(\"The selected sum is: %s\", s)\tmessageBytes, err := json.Marshal(message)\tif err != nil {\t\treturn nil, err\t}\tmessageString := string(messageBytes)\treturn map[string]interface{}{\t\t\"statusCode\": 200,\t\t\"headers\":    map[string]string{\"Content-Type\": \"application/json\"},\t\t\"body\":       messageString,\t}, nil}func main() {\tlambda.Start(HandleRequest)}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from a Kinesis trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_Kinesis_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving records from a Kinesis stream. The function retrieves the Kinesis payload, decodes from Base64, and logs the record contents.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\n\tif len(kinesisEvent.Records) == 0 {\n\t\tlog.Printf(\"empty Kinesis event received\")\n\t\treturn nil\n\t}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\n\t\trecordDataBytes := record.Kinesis.Data\n\t\trecordDataText := string(recordDataBytes)\n\t\tlog.Printf(\"record data: %v\", recordDataText)\n\t\t// TODO: Do interesting work based on the new data\n\t}\n\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\n\tif len(kinesisEvent.Records) == 0 {\n\t\tlog.Printf(\"empty Kinesis event received\")\n\t\treturn nil\n\t}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\n\t\trecordDataBytes := record.Kinesis.Data\n\t\trecordDataText := string(recordDataBytes)\n\t\tlog.Printf(\"record data: %v\", recordDataText)\n\t\t// TODO: Do interesting work based on the new data\n\t}\n\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\n\npublic class Handler implements RequestHandler<KinesisEvent, Void> {\n    @Override\n    public Void handleRequest(final KinesisEvent event, final Context context) {\n        LambdaLogger logger = context.getLogger();\n        if (event.getRecords().isEmpty()) {\n            logger.log(\"Empty Kinesis Event received\");\n            return null;\n        }\n        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {\n            try {\n                logger.log(\"Processed Event with EventId: \"+record.getEventID());\n                String data = new String(record.getKinesis().getData().array());\n                logger.log(\"Data:\"+ data);\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex) {\n                logger.log(\"An error occurred:\"+ex.getMessage());\n                throw ex;\n            }\n        }\n        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");\n        return null;\n    }\n\n}\n\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\n\npublic class Handler implements RequestHandler<KinesisEvent, Void> {\n    @Override\n    public Void handleRequest(final KinesisEvent event, final Context context) {\n        LambdaLogger logger = context.getLogger();\n        if (event.getRecords().isEmpty()) {\n            logger.log(\"Empty Kinesis Event received\");\n            return null;\n        }\n        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {\n            try {\n                logger.log(\"Processed Event with EventId: \"+record.getEventID());\n                String data = new String(record.getKinesis().getData().array());\n                logger.log(\"Data:\"+ data);\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex) {\n                logger.log(\"An error occurred:\"+ex.getMessage());\n                throw ex;\n            }\n        }\n        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");\n        return null;\n    }\n\n}\n\n",
                            "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      throw err;\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                            "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      throw err;\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                            "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Kinesis\\KinesisHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends KinesisHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleKinesis(KinesisEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing records\");\n        $records = $event->getRecords();\n        foreach ($records as $record) {\n            $data = $record->getData();\n            $this->logger->info(json_encode($data));\n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Kinesis\\KinesisHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends KinesisHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleKinesis(KinesisEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing records\");\n        $records = $event->getRecords();\n        foreach ($records as $record) {\n            $data = $record->getData();\n            $this->logger->info(json_encode($data));\n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport base64\ndef lambda_handler(event, context):\n\n    for record in event['Records']:\n        try:\n            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")\n            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')\n            print(f\"Record Data: {record_data}\")\n            # TODO: Do interesting work based on the new data\n        except Exception as e:\n            print(f\"An error occurred {e}\")\n            raise e\n    print(f\"Successfully processed {len(event['Records'])} records.\")\n\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport base64\ndef lambda_handler(event, context):\n\n    for record in event['Records']:\n        try:\n            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")\n            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')\n            print(f\"Record Data: {record_data}\")\n            # TODO: Do interesting work based on the new data\n        except Exception as e:\n            print(f\"An error occurred {e}\")\n            raise e\n    print(f\"Successfully processed {len(event['Records'])} records.\")\n\n",
                            "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue => err\n      $stderr.puts \"An error occurred #{err}\"\n      raise err\n    end\n  end\n  puts \"Successfully processed #{event['Records'].length} records.\"\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('UTF-8')\n  # Placeholder for actual async work\n  # You can use Ruby's asynchronous programming tools like async/await or fibers here.\n  return data\nend\n",
                            "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue => err\n      $stderr.puts \"An error occurred #{err}\"\n      raise err\n    end\n  end\n  puts \"Successfully processed #{event['Records'].length} records.\"\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('UTF-8')\n  # Placeholder for actual async work\n  # You can use Ruby's asynchronous programming tools like async/await or fibers here.\n  return data\nend\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::kinesis::KinesisEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    event.payload.records.iter().for_each(|record| {\n        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());\n\n        let record_data = std::str::from_utf8(&record.kinesis.data);\n\n        match record_data {\n            Ok(data) => {\n                // log the record data\n                tracing::info!(\"Data: {}\", data);\n            }\n            Err(e) => {\n                tracing::error!(\"Error: {}\", e);\n            }\n        }\n    });\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::kinesis::KinesisEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    event.payload.records.iter().for_each(|record| {\n        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());\n\n        let record_data = std::str::from_utf8(&record.kinesis.data);\n\n        match record_data {\n            Ok(data) => {\n                // log the record data\n                tracing::info!(\"Data: {}\", data);\n            }\n            Err(e) => {\n                tracing::error!(\"Error: {}\", e);\n            }\n        }\n    });\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegrationSampleCode;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return;        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                throw;            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"log\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, kinesisEvent events.KinesisEvent) error {\tif len(kinesisEvent.Records) == 0 {\t\tlog.Printf(\"empty Kinesis event received\")\t\treturn nil\t}\tfor _, record := range kinesisEvent.Records {\t\tlog.Printf(\"processed Kinesis event with EventId: %v\", record.EventID)\t\trecordDataBytes := record.Kinesis.Data\t\trecordDataText := string(recordDataBytes)\t\tlog.Printf(\"record data: %v\", recordDataText)\t\t// TODO: Do interesting work based on the new data\t}\tlog.Printf(\"successfully processed %v records\", len(kinesisEvent.Records))\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.LambdaLogger;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KinesisEvent;public class Handler implements RequestHandler<KinesisEvent, Void> {    @Override    public Void handleRequest(final KinesisEvent event, final Context context) {        LambdaLogger logger = context.getLogger();        if (event.getRecords().isEmpty()) {            logger.log(\"Empty Kinesis Event received\");            return null;        }        for (KinesisEvent.KinesisEventRecord record : event.getRecords()) {            try {                logger.log(\"Processed Event with EventId: \"+record.getEventID());                String data = new String(record.getKinesis().getData().array());                logger.log(\"Data:\"+ data);                // TODO: Do interesting work based on the new data            }            catch (Exception ex) {                logger.log(\"An error occurred:\"+ex.getMessage());                throw ex;            }        }        logger.log(\"Successfully processed:\"+event.getRecords().size()+\" records\");        return null;    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    try {      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      console.log(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      console.error(`An error occurred ${err}`);      throw err;    }  }  console.log(`Successfully processed ${event.Records.length} records.`);};async function getRecordDataAsync(payload) {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}Consuming a Kinesis event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import {  KinesisStreamEvent,  Context,  KinesisStreamHandler,  KinesisStreamRecordPayload,} from \"aws-lambda\";import { Buffer } from \"buffer\";import { Logger } from \"@aws-lambda-powertools/logger\";const logger = new Logger({  logLevel: \"INFO\",  serviceName: \"kinesis-stream-handler-sample\",});export const functionHandler: KinesisStreamHandler = async (  event: KinesisStreamEvent,  context: Context): Promise<void> => {  for (const record of event.Records) {    try {      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      logger.info(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      logger.error(`An error occurred ${err}`);      throw err;    }    logger.info(`Successfully processed ${event.Records.length} records.`);  }};async function getRecordDataAsync(  payload: KinesisStreamRecordPayload): Promise<string> {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kinesis\\KinesisEvent;use Bref\\Event\\Kinesis\\KinesisHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends KinesisHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleKinesis(KinesisEvent $event, Context $context): void    {        $this->logger->info(\"Processing records\");        $records = $event->getRecords();        foreach ($records as $record) {            $data = $record->getData();            $this->logger->info(json_encode($data));            // TODO: Do interesting work based on the new data            // Any exception thrown will be logged and the invocation will be marked as failed        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0import base64def lambda_handler(event, context):    for record in event['Records']:        try:            print(f\"Processed Kinesis Event - EventID: {record['eventID']}\")            record_data = base64.b64decode(record['kinesis']['data']).decode('utf-8')            print(f\"Record Data: {record_data}\")            # TODO: Do interesting work based on the new data        except Exception as e:            print(f\"An error occurred {e}\")            raise e    print(f\"Successfully processed {len(event['Records'])} records.\")RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'aws-sdk'def lambda_handler(event:, context:)  event['Records'].each do |record|    begin      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"      record_data = get_record_data_async(record['kinesis'])      puts \"Record Data: #{record_data}\"      # TODO: Do interesting work based on the new data    rescue => err      $stderr.puts \"An error occurred #{err}\"      raise err    end  end  puts \"Successfully processed #{event['Records'].length} records.\"enddef get_record_data_async(payload)  data = Base64.decode64(payload['data']).force_encoding('UTF-8')  # Placeholder for actual async work  # You can use Ruby's asynchronous programming tools like async/await or fibers here.  return dataendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Kinesis event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::kinesis::KinesisEvent;use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<(), Error> {    if event.payload.records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    event.payload.records.iter().for_each(|record| {        tracing::info!(\"EventId: {}\",record.event_id.as_deref().unwrap_or_default());        let record_data = std::str::from_utf8(&record.kinesis.data);        match record_data {            Ok(data) => {                // log the record data                tracing::info!(\"Data: {}\", data);            }            Err(e) => {                tracing::error!(\"Error: {}\", e);            }        }    });    tracing::info!(        \"Successfully processed {} records\",        event.payload.records.len()    );    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegrationSampleCode;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return;\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                throw;\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Kinesis event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegrationSampleCode;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return;        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                throw;            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from a DynamoDB trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_DynamoDB_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving records from a DynamoDB stream. The function retrieves the DynamoDB payload and logs the record contents.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"fmt\"\n)\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\n\tif len(event.Records) == 0 {\n\t\treturn nil, fmt.Errorf(\"received empty event\")\n\t}\n\n\tfor _, record := range event.Records {\n\t \tLogDynamoDBRecord(record)\n\t}\n\n\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\n\treturn &message, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\nfunc LogDynamoDBRecord(record events.DynamoDBEventRecord){\n\tfmt.Println(record.EventID)\n\tfmt.Println(record.EventName)\n\tfmt.Printf(\"%+v\\n\", record.Change)\n}\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"fmt\"\n)\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\n\tif len(event.Records) == 0 {\n\t\treturn nil, fmt.Errorf(\"received empty event\")\n\t}\n\n\tfor _, record := range event.Records {\n\t \tLogDynamoDBRecord(record)\n\t}\n\n\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\n\treturn &message, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\nfunc LogDynamoDBRecord(record events.DynamoDBEventRecord){\n\tfmt.Println(record.EventID)\n\tfmt.Println(record.EventName)\n\tfmt.Printf(\"%+v\\n\", record.Change)\n}\n",
                            "  5.Java : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;\nimport com.google.gson.Gson;\nimport com.google.gson.GsonBuilder;\n\npublic class example implements RequestHandler<DynamodbEvent, Void> {\n\n    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();\n\n    @Override\n    public Void handleRequest(DynamodbEvent event, Context context) {\n        System.out.println(GSON.toJson(event));\n        event.getRecords().forEach(this::logDynamoDBRecord);\n        return null;\n    }\n\n    private void logDynamoDBRecord(DynamodbStreamRecord record) {\n        System.out.println(record.getEventID());\n        System.out.println(record.getEventName());\n        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));\n    }\n}\n",
                            "  6.SDK for Java 2.x : import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;\nimport com.google.gson.Gson;\nimport com.google.gson.GsonBuilder;\n\npublic class example implements RequestHandler<DynamodbEvent, Void> {\n\n    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();\n\n    @Override\n    public Void handleRequest(DynamodbEvent event, Context context) {\n        System.out.println(GSON.toJson(event));\n        event.getRecords().forEach(this::logDynamoDBRecord);\n        return null;\n    }\n\n    private void logDynamoDBRecord(DynamodbStreamRecord record) {\n        System.out.println(record.getEventID());\n        System.out.println(record.getEventName());\n        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));\n    }\n}\n",
                            "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n    console.log(JSON.stringify(event, null, 2));\n    event.Records.forEach(record => {\n        logDynamoDBRecord(record);\n    });\n};\n\nconst logDynamoDBRecord = (record) => {\n    console.log(record.eventID);\n    console.log(record.eventName);\n    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);\n};\n\n",
                            "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n    console.log(JSON.stringify(event, null, 2));\n    event.Records.forEach(record => {\n        logDynamoDBRecord(record);\n    });\n};\n\nconst logDynamoDBRecord = (record) => {\n    console.log(record.eventID);\n    console.log(record.eventName);\n    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);\n};\n\n",
                            "  9.PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\DynamoDb\\DynamoDbHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends DynamoDbHandler\n{\n    private StderrLogger $logger;\n\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing DynamoDb table items\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            $eventName = $record->getEventName();\n            $keys = $record->getKeys();\n            $old = $record->getOldImage();\n            $new = $record->getNewImage();\n            \n            $this->logger->info(\"Event Name:\".$eventName.\"\\n\");\n            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");\n            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");\n            $this->logger->info(\"New Image:\". json_encode($new));\n            \n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords items\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  10.SDK for PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\DynamoDb\\DynamoDbHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends DynamoDbHandler\n{\n    private StderrLogger $logger;\n\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing DynamoDb table items\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            $eventName = $record->getEventName();\n            $keys = $record->getKeys();\n            $old = $record->getOldImage();\n            $new = $record->getNewImage();\n            \n            $this->logger->info(\"Event Name:\".$eventName.\"\\n\");\n            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");\n            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");\n            $this->logger->info(\"New Image:\". json_encode($new));\n            \n            // TODO: Do interesting work based on the new data\n\n            // Any exception thrown will be logged and the invocation will be marked as failed\n        }\n\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords items\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n",
                            "  11.Python : \nimport json\n\ndef lambda_handler(event, context):\n    print(json.dumps(event, indent=2))\n\n    for record in event['Records']:\n        log_dynamodb_record(record)\n\ndef log_dynamodb_record(record):\n    print(record['eventID'])\n    print(record['eventName'])\n    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")\n\n",
                            "  12.SDK for Python (Boto3) : \nimport json\n\ndef lambda_handler(event, context):\n    print(json.dumps(event, indent=2))\n\n    for record in event['Records']:\n        log_dynamodb_record(record)\n\ndef log_dynamodb_record(record):\n    print(record['eventID'])\n    print(record['eventName'])\n    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")\n\n",
                            "  13.Ruby : \ndef lambda_handler(event:, context:)\n    return 'received empty event' if event['Records'].empty?\n  \n    event['Records'].each do |record|\n      log_dynamodb_record(record)\n    end\n  \n    \"Records processed: #{event['Records'].length}\"\n  end\n  \n  def log_dynamodb_record(record)\n    puts record['eventID']\n    puts record['eventName']\n    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"\n  end\n  \n",
                            "  14.SDK for Ruby : \ndef lambda_handler(event:, context:)\n    return 'received empty event' if event['Records'].empty?\n  \n    event['Records'].each do |record|\n      log_dynamodb_record(record)\n    end\n  \n    \"Records processed: #{event['Records'].length}\"\n  end\n  \n  def log_dynamodb_record(record)\n    puts record['eventID']\n    puts record['eventName']\n    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"\n  end\n  \n",
                            "  15.Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {\n    \n    let records = &event.payload.records;\n    tracing::info!(\"event payload: {:?}\",records);\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_dynamo_dbrecord(record);\n    }\n\n    tracing::info!(\"Dynamo db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{\n    tracing::info!(\"EventId: {}\", record.event_id);\n    tracing::info!(\"EventName: {}\", record.event_name);\n    tracing::info!(\"DynamoDB Record: {:?}\", record.change );\n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                            "  16.SDK for Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {\n    \n    let records = &event.payload.records;\n    tracing::info!(\"event payload: {:?}\",records);\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_dynamo_dbrecord(record);\n    }\n\n    tracing::info!(\"Dynamo db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{\n    tracing::info!(\"EventId: {}\", record.event_id);\n    tracing::info!(\"EventName: {}\", record.event_name);\n    tracing::info!(\"DynamoDB Record: {:?}\", record.change );\n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        foreach (var record in dynamoEvent.Records)        {            context.Logger.LogInformation($\"Event ID: {record.EventID}\");            context.Logger.LogInformation($\"Event Name: {record.EventName}\");            context.Logger.LogInformation(JsonSerializer.Serialize(record));        }        context.Logger.LogInformation(\"Stream processing complete.\");    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-lambda-go/events\"\t\"fmt\")func HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*string, error) {\tif len(event.Records) == 0 {\t\treturn nil, fmt.Errorf(\"received empty event\")\t}\tfor _, record := range event.Records {\t \tLogDynamoDBRecord(record)\t}\tmessage := fmt.Sprintf(\"Records processed: %d\", len(event.Records))\treturn &message, nil}func main() {\tlambda.Start(HandleRequest)}func LogDynamoDBRecord(record events.DynamoDBEventRecord){\tfmt.Println(record.EventID)\tfmt.Println(record.EventName)\tfmt.Printf(\"%+v\\n\", record.Change)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord;import com.google.gson.Gson;import com.google.gson.GsonBuilder;public class example implements RequestHandler<DynamodbEvent, Void> {    private static final Gson GSON = new GsonBuilder().setPrettyPrinting().create();    @Override    public Void handleRequest(DynamodbEvent event, Context context) {        System.out.println(GSON.toJson(event));        event.getRecords().forEach(this::logDynamoDBRecord);        return null;    }    private void logDynamoDBRecord(DynamodbStreamRecord record) {        System.out.println(record.getEventID());        System.out.println(record.getEventName());        System.out.println(\"DynamoDB Record: \" + GSON.toJson(record.getDynamodb()));    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {    console.log(JSON.stringify(event, null, 2));    event.Records.forEach(record => {        logDynamoDBRecord(record);    });};const logDynamoDBRecord = (record) => {    console.log(record.eventID);    console.log(record.eventName);    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);};Consuming a DynamoDB event with Lambda using TypeScript.export const handler = async (event, context) => {    console.log(JSON.stringify(event, null, 2));    event.Records.forEach(record => {        logDynamoDBRecord(record);    });}const logDynamoDBRecord = (record) => {    console.log(record.eventID);    console.log(record.eventName);    console.log(`DynamoDB Record: ${JSON.stringify(record.dynamodb)}`);};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using PHP.<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\DynamoDb\\DynamoDbEvent;use Bref\\Event\\DynamoDb\\DynamoDbHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends DynamoDbHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleDynamoDb(DynamoDbEvent $event, Context $context): void    {        $this->logger->info(\"Processing DynamoDb table items\");        $records = $event->getRecords();        foreach ($records as $record) {            $eventName = $record->getEventName();            $keys = $record->getKeys();            $old = $record->getOldImage();            $new = $record->getNewImage();                        $this->logger->info(\"Event Name:\".$eventName.\"\\n\");            $this->logger->info(\"Keys:\". json_encode($keys).\"\\n\");            $this->logger->info(\"Old Image:\". json_encode($old).\"\\n\");            $this->logger->info(\"New Image:\". json_encode($new));                        // TODO: Do interesting work based on the new data            // Any exception thrown will be logged and the invocation will be marked as failed        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords items\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Python.import jsondef lambda_handler(event, context):    print(json.dumps(event, indent=2))    for record in event['Records']:        log_dynamodb_record(record)def log_dynamodb_record(record):    print(record['eventID'])    print(record['eventName'])    print(f\"DynamoDB Record: {json.dumps(record['dynamodb'])}\")RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Ruby.def lambda_handler(event:, context:)    return 'received empty event' if event['Records'].empty?      event['Records'].each do |record|      log_dynamodb_record(record)    end      \"Records processed: #{event['Records'].length}\"  end    def log_dynamodb_record(record)    puts record['eventID']    puts record['eventName']    puts \"DynamoDB Record: #{JSON.generate(record['dynamodb'])}\"  end  RustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using Rust.use lambda_runtime::{service_fn, tracing, Error, LambdaEvent};use aws_lambda_events::{    event::dynamodb::{Event, EventRecord},   };// Built with the following dependencies://lambda_runtime = \"0.11.1\"//serde_json = \"1.0\"//tokio = { version = \"1\", features = [\"macros\"] }//tracing = { version = \"0.1\", features = [\"log\"] }//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }//aws_lambda_events = \"0.15.0\"async fn function_handler(event: LambdaEvent<Event>) ->Result<(), Error> {        let records = &event.payload.records;    tracing::info!(\"event payload: {:?}\",records);    if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    for record in records{        log_dynamo_dbrecord(record);    }    tracing::info!(\"Dynamo db records processed\");    // Prepare the response    Ok(())}fn log_dynamo_dbrecord(record: &EventRecord)-> Result<(), Error>{    tracing::info!(\"EventId: {}\", record.event_id);    tracing::info!(\"EventName: {}\", record.event_name);    tracing::info!(\"DynamoDB Record: {:?}\", record.change );    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()    .with_max_level(tracing::Level::INFO)    .with_target(false)    .without_time()    .init();    let func = service_fn(function_handler);    lambda_runtime::run(func).await?;    Ok(())    }",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            context.Logger.LogInformation($\"Event ID: {record.EventID}\");\n            context.Logger.LogInformation($\"Event Name: {record.EventName}\");\n\n            context.Logger.LogInformation(JsonSerializer.Serialize(record));\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n    }\n}\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a DynamoDB event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public void FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        foreach (var record in dynamoEvent.Records)        {            context.Logger.LogInformation($\"Event ID: {record.EventID}\");            context.Logger.LogInformation($\"Event Name: {record.EventName}\");            context.Logger.LogInformation(JsonSerializer.Serialize(record));        }        context.Logger.LogInformation(\"Stream processing complete.\");    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from a Amazon DocumentDB trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_DocumentDB_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving records from a DocumentDB change stream. The function retrieves the DocumentDB payload and logs the record contents.",
                            "  1..NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                            "  2.AWS SDK for .NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                            "  3.Go : \npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Event struct {\n\tEvents []Record `json:\"events\"`\n}\n\ntype Record struct {\n\tEvent struct {\n\t\tOperationType string `json:\"operationType\"`\n\t\tNS            struct {\n\t\t\tDB   string `json:\"db\"`\n\t\t\tColl string `json:\"coll\"`\n\t\t} `json:\"ns\"`\n\t\tFullDocument interface{} `json:\"fullDocument\"`\n\t} `json:\"event\"`\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\nfunc handler(ctx context.Context, event Event) (string, error) {\n\tfmt.Println(\"Loading function\")\n\tfor _, record := range event.Events {\n\t\tlogDocumentDBEvent(record)\n\t}\n\n\treturn \"OK\", nil\n}\n\nfunc logDocumentDBEvent(record Record) {\n\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\n\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\n\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\n\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\n\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))\n}\n\n",
                            "  4.SDK for Go V2 : \npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Event struct {\n\tEvents []Record `json:\"events\"`\n}\n\ntype Record struct {\n\tEvent struct {\n\t\tOperationType string `json:\"operationType\"`\n\t\tNS            struct {\n\t\t\tDB   string `json:\"db\"`\n\t\t\tColl string `json:\"coll\"`\n\t\t} `json:\"ns\"`\n\t\tFullDocument interface{} `json:\"fullDocument\"`\n\t} `json:\"event\"`\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\nfunc handler(ctx context.Context, event Event) (string, error) {\n\tfmt.Println(\"Loading function\")\n\tfor _, record := range event.Events {\n\t\tlogDocumentDBEvent(record)\n\t}\n\n\treturn \"OK\", nil\n}\n\nfunc logDocumentDBEvent(record Record) {\n\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\n\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\n\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\n\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\n\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))\n}\n\n",
                            "  5.JavaScript : console.log('Loading function');\nexports.handler = async (event, context) => {\n    event.events.forEach(record => {\n        logDocumentDBEvent(record);\n    });\n    return 'OK';\n};\n\nconst logDocumentDBEvent = (record) => {\n    console.log('Operation type: ' + record.event.operationType);\n    console.log('db: ' + record.event.ns.db);\n    console.log('collection: ' + record.event.ns.coll);\n    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));\n};\n\n\n",
                            "  6.SDK for JavaScript (v3) : console.log('Loading function');\nexports.handler = async (event, context) => {\n    event.events.forEach(record => {\n        logDocumentDBEvent(record);\n    });\n    return 'OK';\n};\n\nconst logDocumentDBEvent = (record) => {\n    console.log('Operation type: ' + record.event.operationType);\n    console.log('db: ' + record.event.ns.db);\n    console.log('collection: ' + record.event.ns.coll);\n    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));\n};\n\n\n",
                            "  7.PHP : <?php\n\nrequire __DIR__.'/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler;\n\nclass DocumentDBEventHandler implements Handler\n{\n    public function handle($event, Context $context): string\n    {\n\n        $events = $event['events'] ?? [];\n        foreach ($events as $record) {\n            $this->logDocumentDBEvent($record['event']);\n        }\n        return 'OK';\n    }\n\n    private function logDocumentDBEvent($event): void\n    {\n        // Extract information from the event record\n\n        $operationType = $event['operationType'] ?? 'Unknown';\n        $db = $event['ns']['db'] ?? 'Unknown';\n        $collection = $event['ns']['coll'] ?? 'Unknown';\n        $fullDocument = $event['fullDocument'] ?? [];\n\n        // Log the event details\n\n        echo \"Operation type: $operationType\\n\";\n        echo \"Database: $db\\n\";\n        echo \"Collection: $collection\\n\";\n        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";\n    }\n}\nreturn new DocumentDBEventHandler();\n",
                            "  8.SDK for PHP : <?php\n\nrequire __DIR__.'/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Handler;\n\nclass DocumentDBEventHandler implements Handler\n{\n    public function handle($event, Context $context): string\n    {\n\n        $events = $event['events'] ?? [];\n        foreach ($events as $record) {\n            $this->logDocumentDBEvent($record['event']);\n        }\n        return 'OK';\n    }\n\n    private function logDocumentDBEvent($event): void\n    {\n        // Extract information from the event record\n\n        $operationType = $event['operationType'] ?? 'Unknown';\n        $db = $event['ns']['db'] ?? 'Unknown';\n        $collection = $event['ns']['coll'] ?? 'Unknown';\n        $fullDocument = $event['fullDocument'] ?? [];\n\n        // Log the event details\n\n        echo \"Operation type: $operationType\\n\";\n        echo \"Database: $db\\n\";\n        echo \"Collection: $collection\\n\";\n        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";\n    }\n}\nreturn new DocumentDBEventHandler();\n",
                            "  9.Python : import json\n\ndef lambda_handler(event, context):\n    for record in event.get('events', []):\n        log_document_db_event(record)\n    return 'OK'\n\ndef log_document_db_event(record):\n    event_data = record.get('event', {})\n    operation_type = event_data.get('operationType', 'Unknown')\n    db = event_data.get('ns', {}).get('db', 'Unknown')\n    collection = event_data.get('ns', {}).get('coll', 'Unknown')\n    full_document = event_data.get('fullDocument', {})\n\n    print(f\"Operation type: {operation_type}\")\n    print(f\"db: {db}\")\n    print(f\"collection: {collection}\")\n    print(\"Full document:\", json.dumps(full_document, indent=2))\n",
                            "  10.SDK for Python (Boto3) : import json\n\ndef lambda_handler(event, context):\n    for record in event.get('events', []):\n        log_document_db_event(record)\n    return 'OK'\n\ndef log_document_db_event(record):\n    event_data = record.get('event', {})\n    operation_type = event_data.get('operationType', 'Unknown')\n    db = event_data.get('ns', {}).get('db', 'Unknown')\n    collection = event_data.get('ns', {}).get('coll', 'Unknown')\n    full_document = event_data.get('fullDocument', {})\n\n    print(f\"Operation type: {operation_type}\")\n    print(f\"db: {db}\")\n    print(f\"collection: {collection}\")\n    print(\"Full document:\", json.dumps(full_document, indent=2))\n",
                            "  11.Ruby : require 'json'\n\ndef lambda_handler(event:, context:)\n  event['events'].each do |record|\n    log_document_db_event(record)\n  end\n  'OK'\nend\n\ndef log_document_db_event(record)\n  event_data = record['event'] || {}\n  operation_type = event_data['operationType'] || 'Unknown'\n  db = event_data.dig('ns', 'db') || 'Unknown'\n  collection = event_data.dig('ns', 'coll') || 'Unknown'\n  full_document = event_data['fullDocument'] || {}\n\n  puts \"Operation type: #{operation_type}\"\n  puts \"db: #{db}\"\n  puts \"collection: #{collection}\"\n  puts \"Full document: #{JSON.pretty_generate(full_document)}\"\nend\n",
                            "  12.SDK for Ruby : require 'json'\n\ndef lambda_handler(event:, context:)\n  event['events'].each do |record|\n    log_document_db_event(record)\n  end\n  'OK'\nend\n\ndef log_document_db_event(record)\n  event_data = record['event'] || {}\n  operation_type = event_data['operationType'] || 'Unknown'\n  db = event_data.dig('ns', 'db') || 'Unknown'\n  collection = event_data.dig('ns', 'coll') || 'Unknown'\n  full_document = event_data['fullDocument'] || {}\n\n  puts \"Operation type: #{operation_type}\"\n  puts \"db: #{db}\"\n  puts \"collection: #{collection}\"\n  puts \"Full document: #{JSON.pretty_generate(full_document)}\"\nend\n",
                            "  13.Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {\n    \n    tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);\n    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);\n  \n    let records = &event.payload.events;\n   \n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_document_db_event(record);\n    }\n\n    tracing::info!(\"Document db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{\n    tracing::info!(\"Change Event: {:?}\", record.event);\n    \n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                            "  14.SDK for Rust : \nuse lambda_runtime::{service_fn, tracing, Error, LambdaEvent};\nuse aws_lambda_events::{\n    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},\n   };\n\n\n// Built with the following dependencies:\n//lambda_runtime = \"0.11.1\"\n//serde_json = \"1.0\"\n//tokio = { version = \"1\", features = [\"macros\"] }\n//tracing = { version = \"0.1\", features = [\"log\"] }\n//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n//aws_lambda_events = \"0.15.0\"\n\nasync fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {\n    \n    tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);\n    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);\n  \n    let records = &event.payload.events;\n   \n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(());\n    }\n\n    for record in records{\n        log_document_db_event(record);\n    }\n\n    tracing::info!(\"Document db records processed\");\n\n    // Prepare the response\n    Ok(())\n\n}\n\nfn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{\n    tracing::info!(\"Change Event: {:?}\", record.event);\n    \n    Ok(())\n\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n    .with_max_level(tracing::Level::INFO)\n    .with_target(false)\n    .without_time()\n    .init();\n\n    let func = service_fn(function_handler);\n    lambda_runtime::run(func).await?;\n    Ok(())\n    \n}\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using .NET.using Amazon.Lambda.Core;using System.Text.Json;using System;using System.Collections.Generic;using System.Text.Json.Serialization;//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaDocDb;public class Function{         /// <summary>    /// Lambda function entry point to process Amazon DocumentDB events.    /// </summary>    /// <param name=\"event\">The Amazon DocumentDB event.</param>    /// <param name=\"context\">The Lambda context object.</param>    /// <returns>A string to indicate successful processing.</returns>    public string FunctionHandler(Event evnt, ILambdaContext context)    {                foreach (var record in evnt.Events)        {            ProcessDocumentDBEvent(record, context);        }        return \"OK\";    }     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)    {                var eventData = record.Event;        var operationType = eventData.OperationType;        var databaseName = eventData.Ns.Db;        var collectionName = eventData.Ns.Coll;        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });        context.Logger.LogLine($\"Operation type: {operationType}\");        context.Logger.LogLine($\"Database: {databaseName}\");        context.Logger.LogLine($\"Collection: {collectionName}\");        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");    }    public class Event    {        [JsonPropertyName(\"eventSourceArn\")]        public string EventSourceArn { get; set; }        [JsonPropertyName(\"events\")]        public List<DocumentDBEventRecord> Events { get; set; }        [JsonPropertyName(\"eventSource\")]        public string EventSource { get; set; }    }    public class DocumentDBEventRecord    {        [JsonPropertyName(\"event\")]        public EventData Event { get; set; }    }    public class EventData    {        [JsonPropertyName(\"_id\")]        public IdData Id { get; set; }        [JsonPropertyName(\"clusterTime\")]        public ClusterTime ClusterTime { get; set; }        [JsonPropertyName(\"documentKey\")]        public DocumentKey DocumentKey { get; set; }        [JsonPropertyName(\"fullDocument\")]        public Dictionary<string, object> FullDocument { get; set; }        [JsonPropertyName(\"ns\")]        public Namespace Ns { get; set; }        [JsonPropertyName(\"operationType\")]        public string OperationType { get; set; }    }    public class IdData    {        [JsonPropertyName(\"_data\")]        public string Data { get; set; }    }    public class ClusterTime    {        [JsonPropertyName(\"$timestamp\")]        public Timestamp Timestamp { get; set; }    }    public class Timestamp    {        [JsonPropertyName(\"t\")]        public long T { get; set; }        [JsonPropertyName(\"i\")]        public int I { get; set; }    }    public class DocumentKey    {        [JsonPropertyName(\"_id\")]        public Id Id { get; set; }    }    public class Id    {        [JsonPropertyName(\"$oid\")]        public string Oid { get; set; }    }    public class Namespace    {        [JsonPropertyName(\"db\")]        public string Db { get; set; }        [JsonPropertyName(\"coll\")]        public string Coll { get; set; }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Go.package mainimport (\t\"context\"\t\"encoding/json\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/lambda\")type Event struct {\tEvents []Record `json:\"events\"`}type Record struct {\tEvent struct {\t\tOperationType string `json:\"operationType\"`\t\tNS            struct {\t\t\tDB   string `json:\"db\"`\t\t\tColl string `json:\"coll\"`\t\t} `json:\"ns\"`\t\tFullDocument interface{} `json:\"fullDocument\"`\t} `json:\"event\"`}func main() {\tlambda.Start(handler)}func handler(ctx context.Context, event Event) (string, error) {\tfmt.Println(\"Loading function\")\tfor _, record := range event.Events {\t\tlogDocumentDBEvent(record)\t}\treturn \"OK\", nil}func logDocumentDBEvent(record Record) {\tfmt.Printf(\"Operation type: %s\\n\", record.Event.OperationType)\tfmt.Printf(\"db: %s\\n\", record.Event.NS.DB)\tfmt.Printf(\"collection: %s\\n\", record.Event.NS.Coll)\tdocBytes, _ := json.MarshalIndent(record.Event.FullDocument, \"\", \"  \")\tfmt.Printf(\"Full document: %s\\n\", string(docBytes))}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using JavaScript.console.log('Loading function');exports.handler = async (event, context) => {    event.events.forEach(record => {        logDocumentDBEvent(record);    });    return 'OK';};const logDocumentDBEvent = (record) => {    console.log('Operation type: ' + record.event.operationType);    console.log('db: ' + record.event.ns.db);    console.log('collection: ' + record.event.ns.coll);    console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));};Consuming a Amazon DocumentDB event with Lambda using TypeScriptimport { DocumentDBEventRecord, DocumentDBEventSubscriptionContext } from 'aws-lambda';console.log('Loading function');export const handler = async (  event: DocumentDBEventSubscriptionContext,  context: any): Promise<string> => {  event.events.forEach((record: DocumentDBEventRecord) => {    logDocumentDBEvent(record);  });  return 'OK';};const logDocumentDBEvent = (record: DocumentDBEventRecord): void => {  console.log('Operation type: ' + record.event.operationType);  console.log('db: ' + record.event.ns.db);  console.log('collection: ' + record.event.ns.coll);  console.log('Full document:', JSON.stringify(record.event.fullDocument, null, 2));};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using PHP.<?phprequire __DIR__.'/vendor/autoload.php';use Bref\\Context\\Context;use Bref\\Event\\Handler;class DocumentDBEventHandler implements Handler{    public function handle($event, Context $context): string    {        $events = $event['events'] ?? [];        foreach ($events as $record) {            $this->logDocumentDBEvent($record['event']);        }        return 'OK';    }    private function logDocumentDBEvent($event): void    {        // Extract information from the event record        $operationType = $event['operationType'] ?? 'Unknown';        $db = $event['ns']['db'] ?? 'Unknown';        $collection = $event['ns']['coll'] ?? 'Unknown';        $fullDocument = $event['fullDocument'] ?? [];        // Log the event details        echo \"Operation type: $operationType\\n\";        echo \"Database: $db\\n\";        echo \"Collection: $collection\\n\";        echo \"Full document: \" . json_encode($fullDocument, JSON_PRETTY_PRINT) . \"\\n\";    }}return new DocumentDBEventHandler();PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Python.import jsondef lambda_handler(event, context):    for record in event.get('events', []):        log_document_db_event(record)    return 'OK'def log_document_db_event(record):    event_data = record.get('event', {})    operation_type = event_data.get('operationType', 'Unknown')    db = event_data.get('ns', {}).get('db', 'Unknown')    collection = event_data.get('ns', {}).get('coll', 'Unknown')    full_document = event_data.get('fullDocument', {})    print(f\"Operation type: {operation_type}\")    print(f\"db: {db}\")    print(f\"collection: {collection}\")    print(\"Full document:\", json.dumps(full_document, indent=2))RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Ruby.require 'json'def lambda_handler(event:, context:)  event['events'].each do |record|    log_document_db_event(record)  end  'OK'enddef log_document_db_event(record)  event_data = record['event'] || {}  operation_type = event_data['operationType'] || 'Unknown'  db = event_data.dig('ns', 'db') || 'Unknown'  collection = event_data.dig('ns', 'coll') || 'Unknown'  full_document = event_data['fullDocument'] || {}  puts \"Operation type: #{operation_type}\"  puts \"db: #{db}\"  puts \"collection: #{collection}\"  puts \"Full document: #{JSON.pretty_generate(full_document)}\"endRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using Rust.use lambda_runtime::{service_fn, tracing, Error, LambdaEvent};use aws_lambda_events::{    event::documentdb::{DocumentDbEvent, DocumentDbInnerEvent},   };// Built with the following dependencies://lambda_runtime = \"0.11.1\"//serde_json = \"1.0\"//tokio = { version = \"1\", features = [\"macros\"] }//tracing = { version = \"0.1\", features = [\"log\"] }//tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }//aws_lambda_events = \"0.15.0\"async fn function_handler(event: LambdaEvent<DocumentDbEvent>) ->Result<(), Error> {        tracing::info!(\"Event Source ARN: {:?}\", event.payload.event_source_arn);    tracing::info!(\"Event Source: {:?}\", event.payload.event_source);      let records = &event.payload.events;       if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(());    }    for record in records{        log_document_db_event(record);    }    tracing::info!(\"Document db records processed\");    // Prepare the response    Ok(())}fn log_document_db_event(record: &DocumentDbInnerEvent)-> Result<(), Error>{    tracing::info!(\"Change Event: {:?}\", record.event);        Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()    .with_max_level(tracing::Level::INFO)    .with_target(false)    .without_time()    .init();    let func = service_fn(function_handler);    lambda_runtime::run(func).await?;    Ok(())    }",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : using Amazon.Lambda.Core;\nusing System.Text.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Text.Json.Serialization;\n//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace LambdaDocDb;\n\npublic class Function\n{\n    \n     /// <summary>\n    /// Lambda function entry point to process Amazon DocumentDB events.\n    /// </summary>\n    /// <param name=\"event\">The Amazon DocumentDB event.</param>\n    /// <param name=\"context\">The Lambda context object.</param>\n    /// <returns>A string to indicate successful processing.</returns>\n    public string FunctionHandler(Event evnt, ILambdaContext context)\n    {\n        \n        foreach (var record in evnt.Events)\n        {\n            ProcessDocumentDBEvent(record, context);\n        }\n\n        return \"OK\";\n    }\n\n     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)\n    {\n        \n        var eventData = record.Event;\n        var operationType = eventData.OperationType;\n        var databaseName = eventData.Ns.Db;\n        var collectionName = eventData.Ns.Coll;\n        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });\n\n        context.Logger.LogLine($\"Operation type: {operationType}\");\n        context.Logger.LogLine($\"Database: {databaseName}\");\n        context.Logger.LogLine($\"Collection: {collectionName}\");\n        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");\n    }\n\n\n\n    public class Event\n    {\n        [JsonPropertyName(\"eventSourceArn\")]\n        public string EventSourceArn { get; set; }\n\n        [JsonPropertyName(\"events\")]\n        public List<DocumentDBEventRecord> Events { get; set; }\n\n        [JsonPropertyName(\"eventSource\")]\n        public string EventSource { get; set; }\n    }\n\n    public class DocumentDBEventRecord\n    {\n        [JsonPropertyName(\"event\")]\n        public EventData Event { get; set; }\n    }\n\n    public class EventData\n    {\n        [JsonPropertyName(\"_id\")]\n        public IdData Id { get; set; }\n\n        [JsonPropertyName(\"clusterTime\")]\n        public ClusterTime ClusterTime { get; set; }\n\n        [JsonPropertyName(\"documentKey\")]\n        public DocumentKey DocumentKey { get; set; }\n\n        [JsonPropertyName(\"fullDocument\")]\n        public Dictionary<string, object> FullDocument { get; set; }\n\n        [JsonPropertyName(\"ns\")]\n        public Namespace Ns { get; set; }\n\n        [JsonPropertyName(\"operationType\")]\n        public string OperationType { get; set; }\n    }\n\n    public class IdData\n    {\n        [JsonPropertyName(\"_data\")]\n        public string Data { get; set; }\n    }\n\n    public class ClusterTime\n    {\n        [JsonPropertyName(\"$timestamp\")]\n        public Timestamp Timestamp { get; set; }\n    }\n\n    public class Timestamp\n    {\n        [JsonPropertyName(\"t\")]\n        public long T { get; set; }\n\n        [JsonPropertyName(\"i\")]\n        public int I { get; set; }\n    }\n\n    public class DocumentKey\n    {\n        [JsonPropertyName(\"_id\")]\n        public Id Id { get; set; }\n    }\n\n    public class Id\n    {\n        [JsonPropertyName(\"$oid\")]\n        public string Oid { get; set; }\n    }\n\n    public class Namespace\n    {\n        [JsonPropertyName(\"db\")]\n        public string Db { get; set; }\n\n        [JsonPropertyName(\"coll\")]\n        public string Coll { get; set; }\n    }\n}\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming a Amazon DocumentDB event with Lambda using .NET.using Amazon.Lambda.Core;using System.Text.Json;using System;using System.Collections.Generic;using System.Text.Json.Serialization;//Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace LambdaDocDb;public class Function{         /// <summary>    /// Lambda function entry point to process Amazon DocumentDB events.    /// </summary>    /// <param name=\"event\">The Amazon DocumentDB event.</param>    /// <param name=\"context\">The Lambda context object.</param>    /// <returns>A string to indicate successful processing.</returns>    public string FunctionHandler(Event evnt, ILambdaContext context)    {                foreach (var record in evnt.Events)        {            ProcessDocumentDBEvent(record, context);        }        return \"OK\";    }     private void ProcessDocumentDBEvent(DocumentDBEventRecord record, ILambdaContext context)    {                var eventData = record.Event;        var operationType = eventData.OperationType;        var databaseName = eventData.Ns.Db;        var collectionName = eventData.Ns.Coll;        var fullDocument = JsonSerializer.Serialize(eventData.FullDocument, new JsonSerializerOptions { WriteIndented = true });        context.Logger.LogLine($\"Operation type: {operationType}\");        context.Logger.LogLine($\"Database: {databaseName}\");        context.Logger.LogLine($\"Collection: {collectionName}\");        context.Logger.LogLine($\"Full document:\\n{fullDocument}\");    }    public class Event    {        [JsonPropertyName(\"eventSourceArn\")]        public string EventSourceArn { get; set; }        [JsonPropertyName(\"events\")]        public List<DocumentDBEventRecord> Events { get; set; }        [JsonPropertyName(\"eventSource\")]        public string EventSource { get; set; }    }    public class DocumentDBEventRecord    {        [JsonPropertyName(\"event\")]        public EventData Event { get; set; }    }    public class EventData    {        [JsonPropertyName(\"_id\")]        public IdData Id { get; set; }        [JsonPropertyName(\"clusterTime\")]        public ClusterTime ClusterTime { get; set; }        [JsonPropertyName(\"documentKey\")]        public DocumentKey DocumentKey { get; set; }        [JsonPropertyName(\"fullDocument\")]        public Dictionary<string, object> FullDocument { get; set; }        [JsonPropertyName(\"ns\")]        public Namespace Ns { get; set; }        [JsonPropertyName(\"operationType\")]        public string OperationType { get; set; }    }    public class IdData    {        [JsonPropertyName(\"_data\")]        public string Data { get; set; }    }    public class ClusterTime    {        [JsonPropertyName(\"$timestamp\")]        public Timestamp Timestamp { get; set; }    }    public class Timestamp    {        [JsonPropertyName(\"t\")]        public long T { get; set; }        [JsonPropertyName(\"i\")]        public int I { get; set; }    }    public class DocumentKey    {        [JsonPropertyName(\"_id\")]        public Id Id { get; set; }    }    public class Id    {        [JsonPropertyName(\"$oid\")]        public string Oid { get; set; }    }    public class Namespace    {        [JsonPropertyName(\"db\")]        public string Db { get; set; }        [JsonPropertyName(\"coll\")]        public string Coll { get; set; }    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from an Amazon MSK trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_MSK_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving records from an Amazon MSK cluster. The function retrieves the MSK payload and logs the record contents.",
                            "  1..NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                            "  2.AWS SDK for .NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                            "  3.Go : \npackage main\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.KafkaEvent) {\n\tfor key, records := range event.Records {\n\t\tfmt.Println(\"Key:\", key)\n\n\t\tfor _, record := range records {\n\t\t\tfmt.Println(\"Record:\", record)\n\n\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\n\t\t\tmessage := string(decodedValue)\n\t\t\tfmt.Println(\"Message:\", message)\n\t\t}\n\t}\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n",
                            "  4.SDK for Go V2 : \npackage main\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.KafkaEvent) {\n\tfor key, records := range event.Records {\n\t\tfmt.Println(\"Key:\", key)\n\n\t\tfor _, record := range records {\n\t\t\tfmt.Println(\"Record:\", record)\n\n\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\n\t\t\tmessage := string(decodedValue)\n\t\t\tfmt.Println(\"Message:\", message)\n\t\t}\n\t}\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n",
                            "  5.Java : \nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;\n\nimport java.util.Base64;\nimport java.util.Map;\n\npublic class Example implements RequestHandler<KafkaEvent, Void> {\n\n    @Override\n    public Void handleRequest(KafkaEvent event, Context context) {\n        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {\n            String key = entry.getKey();\n            System.out.println(\"Key: \" + key);\n\n            for (KafkaEventRecord record : entry.getValue()) {\n                System.out.println(\"Record: \" + record);\n\n                byte[] value = Base64.getDecoder().decode(record.getValue());\n                String message = new String(value);\n                System.out.println(\"Message: \" + message);\n            }\n        }\n\n        return null;\n    }\n}\n\n",
                            "  6.SDK for Java 2.x : \nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent;\nimport com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;\n\nimport java.util.Base64;\nimport java.util.Map;\n\npublic class Example implements RequestHandler<KafkaEvent, Void> {\n\n    @Override\n    public Void handleRequest(KafkaEvent event, Context context) {\n        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {\n            String key = entry.getKey();\n            System.out.println(\"Key: \" + key);\n\n            for (KafkaEventRecord record : entry.getValue()) {\n                System.out.println(\"Record: \" + record);\n\n                byte[] value = Base64.getDecoder().decode(record.getValue());\n                String message = new String(value);\n                System.out.println(\"Message: \" + message);\n            }\n        }\n\n        return null;\n    }\n}\n\n",
                            "  7.JavaScript : \nexports.handler = async (event) => {\n    // Iterate through keys\n    for (let key in event.records) {\n      console.log('Key: ', key)\n      // Iterate through records\n      event.records[key].map((record) => {\n        console.log('Record: ', record)\n        // Decode base64\n        const msg = Buffer.from(record.value, 'base64').toString()\n        console.log('Message:', msg)\n      }) \n    }\n}\n",
                            "  8.SDK for JavaScript (v3) : \nexports.handler = async (event) => {\n    // Iterate through keys\n    for (let key in event.records) {\n      console.log('Key: ', key)\n      // Iterate through records\n      event.records[key].map((record) => {\n        console.log('Record: ', record)\n        // Decode base64\n        const msg = Buffer.from(record.value, 'base64').toString()\n        console.log('Message:', msg)\n      }) \n    }\n}\n",
                            "  9.PHP : <?php\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n\n// using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kafka\\KafkaEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): void\n    {\n        $kafkaEvent = new KafkaEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kafkaEvent->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                $key = $record->getKey();\n                $this->logger->info(\"Key: $key\");\n\n                $values = $record->getValue();\n                $this->logger->info(json_encode($values));\n\n                foreach ($values as $value) {\n                    $this->logger->info(\"Value: $value\");\n                }\n                \n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : <?php\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n\n// using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kafka\\KafkaEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): void\n    {\n        $kafkaEvent = new KafkaEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kafkaEvent->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                $key = $record->getKey();\n                $this->logger->info(\"Key: $key\");\n\n                $values = $record->getValue();\n                $this->logger->info(json_encode($values));\n\n                foreach ($values as $value) {\n                    $this->logger->info(\"Value: $value\");\n                }\n                \n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : \nimport base64\n\ndef lambda_handler(event, context):\n    # Iterate through keys\n    for key in event['records']:\n        print('Key:', key)\n        # Iterate through records\n        for record in event['records'][key]:\n            print('Record:', record)\n            # Decode base64\n            msg = base64.b64decode(record['value']).decode('utf-8')\n            print('Message:', msg)\n",
                            "  12.SDK for Python (Boto3) : \nimport base64\n\ndef lambda_handler(event, context):\n    # Iterate through keys\n    for key in event['records']:\n        print('Key:', key)\n        # Iterate through records\n        for record in event['records'][key]:\n            print('Record:', record)\n            # Decode base64\n            msg = base64.b64decode(record['value']).decode('utf-8')\n            print('Message:', msg)\n",
                            "  13.Ruby : \nrequire 'base64'\n\ndef lambda_handler(event:, context:)\n  # Iterate through keys\n  event['records'].each do |key, records|\n    puts \"Key: #{key}\"\n\n    # Iterate through records\n    records.each do |record|\n      puts \"Record: #{record}\"\n\n      # Decode base64\n      msg = Base64.decode64(record['value'])\n      puts \"Message: #{msg}\"\n    end\n  end\nend\n",
                            "  14.SDK for Ruby : \nrequire 'base64'\n\ndef lambda_handler(event:, context:)\n  # Iterate through keys\n  event['records'].each do |key, records|\n    puts \"Key: #{key}\"\n\n    # Iterate through records\n    records.each do |record|\n      puts \"Record: #{record}\"\n\n      # Decode base64\n      msg = Base64.decode64(record['value'])\n      puts \"Message: #{msg}\"\n    end\n  end\nend\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using .NET.using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KafkaEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace MSKLambda;public class Function{            /// <param name=\"input\">The event for the Lambda function handler to process.</param>    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>    /// <returns></returns>    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            Console.WriteLine(\"Key:\" + record.Key);             foreach (var eventRecord in record.Value)            {                var valueBytes = eventRecord.Value.ToArray();                    var valueText = Encoding.UTF8.GetString(valueBytes);                                Console.WriteLine(\"Message:\" + valueText);            }        }    }    }GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Go.package mainimport (\t\"encoding/base64\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(event events.KafkaEvent) {\tfor key, records := range event.Records {\t\tfmt.Println(\"Key:\", key)\t\tfor _, record := range records {\t\t\tfmt.Println(\"Record:\", record)\t\t\tdecodedValue, _ := base64.StdEncoding.DecodeString(record.Value)\t\t\tmessage := string(decodedValue)\t\t\tfmt.Println(\"Message:\", message)\t\t}\t}}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Java.import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KafkaEvent;import com.amazonaws.services.lambda.runtime.events.KafkaEvent.KafkaEventRecord;import java.util.Base64;import java.util.Map;public class Example implements RequestHandler<KafkaEvent, Void> {    @Override    public Void handleRequest(KafkaEvent event, Context context) {        for (Map.Entry<String, java.util.List<KafkaEventRecord>> entry : event.getRecords().entrySet()) {            String key = entry.getKey();            System.out.println(\"Key: \" + key);            for (KafkaEventRecord record : entry.getValue()) {                System.out.println(\"Record: \" + record);                byte[] value = Base64.getDecoder().decode(record.getValue());                String message = new String(value);                System.out.println(\"Message: \" + message);            }        }        return null;    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using JavaScript.exports.handler = async (event) => {    // Iterate through keys    for (let key in event.records) {      console.log('Key: ', key)      // Iterate through records      event.records[key].map((record) => {        console.log('Record: ', record)        // Decode base64        const msg = Buffer.from(record.value, 'base64').toString()        console.log('Message:', msg)      })     }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using PHP.<?php// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0// using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kafka\\KafkaEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): void    {        $kafkaEvent = new KafkaEvent($event);        $this->logger->info(\"Processing records\");        $records = $kafkaEvent->getRecords();        foreach ($records as $record) {            try {                $key = $record->getKey();                $this->logger->info(\"Key: $key\");                $values = $record->getValue();                $this->logger->info(json_encode($values));                foreach ($values as $value) {                    $this->logger->info(\"Value: $value\");                }                            } catch (Exception $e) {                $this->logger->error($e->getMessage());            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Python.import base64def lambda_handler(event, context):    # Iterate through keys    for key in event['records']:        print('Key:', key)        # Iterate through records        for record in event['records'][key]:            print('Record:', record)            # Decode base64            msg = base64.b64decode(record['value']).decode('utf-8')            print('Message:', msg)RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using Ruby.require 'base64'def lambda_handler(event:, context:)  # Iterate through keys  event['records'].each do |key, records|    puts \"Key: #{key}\"    # Iterate through records    records.each do |record|      puts \"Record: #{record}\"      # Decode base64      msg = Base64.decode64(record['value'])      puts \"Message: #{msg}\"    end  endend",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : using System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KafkaEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace MSKLambda;\n\npublic class Function\n{\n    \n    \n    /// <param name=\"input\">The event for the Lambda function handler to process.</param>\n    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>\n    /// <returns></returns>\n    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)\n    {\n\n        foreach (var record in evnt.Records)\n        {\n            Console.WriteLine(\"Key:\" + record.Key); \n            foreach (var eventRecord in record.Value)\n            {\n                var valueBytes = eventRecord.Value.ToArray();    \n                var valueText = Encoding.UTF8.GetString(valueBytes);\n                \n                Console.WriteLine(\"Message:\" + valueText);\n            }\n        }\n    }\n    \n\n}\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an Amazon MSK event with Lambda using .NET.using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.KafkaEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace MSKLambda;public class Function{            /// <param name=\"input\">The event for the Lambda function handler to process.</param>    /// <param name=\"context\">The ILambdaContext that provides methods for logging and describing the Lambda environment.</param>    /// <returns></returns>    public void FunctionHandler(KafkaEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            Console.WriteLine(\"Key:\" + record.Key);             foreach (var eventRecord in record.Value)            {                var valueBytes = eventRecord.Value.ToArray();                    var valueText = Encoding.UTF8.GetString(valueBytes);                                Console.WriteLine(\"Message:\" + valueText);            }        }    }    }",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from an Amazon S3 trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_S3_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by uploading an object to an S3 bucket. The function retrieves the S3 bucket name and object key from the event parameter and calls the Amazon S3 API to retrieve and log the content type of the object.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nusing Amazon.Lambda.S3Events;\nusing System.Web;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace S3Integration\n{\n    public class Function\n    {\n        private static AmazonS3Client _s3Client;\n        public Function() : this(null)\n        {\n        }\n\n        internal Function(AmazonS3Client s3Client)\n        {\n            _s3Client = s3Client ?? new AmazonS3Client();\n        }\n\n        public async Task<string> Handler(S3Event evt, ILambdaContext context)\n        {\n            try\n            {\n                if (evt.Records.Count <= 0)\n                {\n                    context.Logger.LogLine(\"Empty S3 Event received\");\n                    return string.Empty;\n                }\n\n                var bucket = evt.Records[0].S3.Bucket.Name;\n                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);\n\n                context.Logger.LogLine($\"Request is for {bucket} and {key}\");\n\n                var objectResult = await _s3Client.GetObjectAsync(bucket, key);\n\n                context.Logger.LogLine($\"Returning {objectResult.Key}\");\n\n                return objectResult.Key;\n            }\n            catch (Exception e)\n            {\n                context.Logger.LogLine($\"Error processing request - {e.Message}\");\n\n                return string.Empty;\n            }\n        }\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nusing Amazon.Lambda.S3Events;\nusing System.Web;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace S3Integration\n{\n    public class Function\n    {\n        private static AmazonS3Client _s3Client;\n        public Function() : this(null)\n        {\n        }\n\n        internal Function(AmazonS3Client s3Client)\n        {\n            _s3Client = s3Client ?? new AmazonS3Client();\n        }\n\n        public async Task<string> Handler(S3Event evt, ILambdaContext context)\n        {\n            try\n            {\n                if (evt.Records.Count <= 0)\n                {\n                    context.Logger.LogLine(\"Empty S3 Event received\");\n                    return string.Empty;\n                }\n\n                var bucket = evt.Records[0].S3.Bucket.Name;\n                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);\n\n                context.Logger.LogLine($\"Request is for {bucket} and {key}\");\n\n                var objectResult = await _s3Client.GetObjectAsync(bucket, key);\n\n                context.Logger.LogLine($\"Returning {objectResult.Key}\");\n\n                return objectResult.Key;\n            }\n            catch (Exception e)\n            {\n                context.Logger.LogLine($\"Error processing request - {e.Message}\");\n\n                return string.Empty;\n            }\n        }\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n\nfunc handler(ctx context.Context, s3Event events.S3Event) error {\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to load default config: %s\", err)\n\t\treturn err\n\t}\n\ts3Client := s3.NewFromConfig(sdkConfig)\n\n\tfor _, record := range s3Event.Records {\n\t\tbucket := record.S3.Bucket.Name\n\t\tkey := record.S3.Object.URLDecodedKey\n\t\theadOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{\n\t\t\tBucket: &bucket,\n\t\t\tKey:    &key,\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err)\n\t\t\treturn err\n\t\t}\n\t\tlog.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key, *headOutput.ContentType)\n\t}\n\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n\nfunc handler(ctx context.Context, s3Event events.S3Event) error {\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to load default config: %s\", err)\n\t\treturn err\n\t}\n\ts3Client := s3.NewFromConfig(sdkConfig)\n\n\tfor _, record := range s3Event.Records {\n\t\tbucket := record.S3.Bucket.Name\n\t\tkey := record.S3.Object.URLDecodedKey\n\t\theadOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{\n\t\t\tBucket: &bucket,\n\t\t\tKey:    &key,\n\t\t})\n\t\tif err != nil {\n\t\t\tlog.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err)\n\t\t\treturn err\n\t\t}\n\t\tlog.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key, *headOutput.ContentType)\n\t}\n\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.S3Client;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.S3Event;\nimport com.amazonaws.services.lambda.runtime.events.models.s3.S3EventNotification.S3EventNotificationRecord;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class Handler implements RequestHandler<S3Event, String> {\n    private static final Logger logger = LoggerFactory.getLogger(Handler.class);\n    @Override\n    public String handleRequest(S3Event s3event, Context context) {\n        try {\n          S3EventNotificationRecord record = s3event.getRecords().get(0);\n          String srcBucket = record.getS3().getBucket().getName();\n          String srcKey = record.getS3().getObject().getUrlDecodedKey();\n\n          S3Client s3Client = S3Client.builder().build();\n          HeadObjectResponse headObject = getHeadObject(s3Client, srcBucket, srcKey);\n\n          logger.info(\"Successfully retrieved \" + srcBucket + \"/\" + srcKey + \" of type \" + headObject.contentType());\n\n          return \"Ok\";\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n    }\n\n    private HeadObjectResponse getHeadObject(S3Client s3Client, String bucket, String key) {\n        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n                .bucket(bucket)\n                .key(key)\n                .build();\n        return s3Client.headObject(headObjectRequest);\n    }\n}\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.S3Client;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.S3Event;\nimport com.amazonaws.services.lambda.runtime.events.models.s3.S3EventNotification.S3EventNotificationRecord;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class Handler implements RequestHandler<S3Event, String> {\n    private static final Logger logger = LoggerFactory.getLogger(Handler.class);\n    @Override\n    public String handleRequest(S3Event s3event, Context context) {\n        try {\n          S3EventNotificationRecord record = s3event.getRecords().get(0);\n          String srcBucket = record.getS3().getBucket().getName();\n          String srcKey = record.getS3().getObject().getUrlDecodedKey();\n\n          S3Client s3Client = S3Client.builder().build();\n          HeadObjectResponse headObject = getHeadObject(s3Client, srcBucket, srcKey);\n\n          logger.info(\"Successfully retrieved \" + srcBucket + \"/\" + srcKey + \" of type \" + headObject.contentType());\n\n          return \"Ok\";\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n    }\n\n    private HeadObjectResponse getHeadObject(S3Client s3Client, String bucket, String key) {\n        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n                .bucket(bucket)\n                .key(key)\n                .build();\n        return s3Client.headObject(headObjectRequest);\n    }\n}\n",
                            "  7.JavaScript : import { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";\n\nconst client = new S3Client();\n\nexport const handler = async (event, context) => {\n\n    // Get the object from the event and show its content type\n    const bucket = event.Records[0].s3.bucket.name;\n    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));\n\n    try {\n        const { ContentType } = await client.send(new HeadObjectCommand({\n            Bucket: bucket,\n            Key: key,\n        }));\n\n        console.log('CONTENT TYPE:', ContentType);\n        return ContentType;\n\n    } catch (err) {\n        console.log(err);\n        const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;\n        console.log(message);\n        throw new Error(message);\n    }\n};\n\n",
                            "  8.SDK for JavaScript (v3) : import { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";\n\nconst client = new S3Client();\n\nexport const handler = async (event, context) => {\n\n    // Get the object from the event and show its content type\n    const bucket = event.Records[0].s3.bucket.name;\n    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));\n\n    try {\n        const { ContentType } = await client.send(new HeadObjectCommand({\n            Bucket: bucket,\n            Key: key,\n        }));\n\n        console.log('CONTENT TYPE:', ContentType);\n        return ContentType;\n\n    } catch (err) {\n        console.log(err);\n        const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;\n        console.log(message);\n        throw new Error(message);\n    }\n};\n\n",
                            "  9.PHP : <?php\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\S3\\S3Event;\nuse Bref\\Event\\S3\\S3Handler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\n\nclass Handler extends S3Handler \n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n    \n    public function handleS3(S3Event $event, Context $context) : void\n    {\n        $this->logger->info(\"Processing S3 records\");\n\n        // Get the object from the event and show its content type\n        $records = $event->getRecords();\n        \n        foreach ($records as $record) \n        {\n            $bucket = $record->getBucket()->getName();\n            $key = urldecode($record->getObject()->getKey());\n\n            try {\n                $fileSize = urldecode($record->getObject()->getSize());\n                echo \"File Size: \" . $fileSize . \"\\n\";\n                // TODO: Implement your custom processing logic here\n            } catch (Exception $e) {\n                echo $e->getMessage() . \"\\n\";\n                echo 'Error getting object ' . $key . ' from bucket ' . $bucket . '. Make sure they exist and your bucket is in the same region as this function.' . \"\\n\";\n                throw $e;\n            }\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : <?php\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\S3\\S3Event;\nuse Bref\\Event\\S3\\S3Handler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\n\nclass Handler extends S3Handler \n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n    \n    public function handleS3(S3Event $event, Context $context) : void\n    {\n        $this->logger->info(\"Processing S3 records\");\n\n        // Get the object from the event and show its content type\n        $records = $event->getRecords();\n        \n        foreach ($records as $record) \n        {\n            $bucket = $record->getBucket()->getName();\n            $key = urldecode($record->getObject()->getKey());\n\n            try {\n                $fileSize = urldecode($record->getObject()->getSize());\n                echo \"File Size: \" . $fileSize . \"\\n\";\n                // TODO: Implement your custom processing logic here\n            } catch (Exception $e) {\n                echo $e->getMessage() . \"\\n\";\n                echo 'Error getting object ' . $key . ' from bucket ' . $bucket . '. Make sure they exist and your bucket is in the same region as this function.' . \"\\n\";\n                throw $e;\n            }\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport json\nimport urllib.parse\nimport boto3\n\nprint('Loading function')\n\ns3 = boto3.client('s3')\n\n\ndef lambda_handler(event, context):\n    #print(\"Received event: \" + json.dumps(event, indent=2))\n\n    # Get the object from the event and show its content type\n    bucket = event['Records'][0]['s3']['bucket']['name']\n    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n    try:\n        response = s3.get_object(Bucket=bucket, Key=key)\n        print(\"CONTENT TYPE: \" + response['ContentType'])\n        return response['ContentType']\n    except Exception as e:\n        print(e)\n        print('Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))\n        raise e\n              \n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport json\nimport urllib.parse\nimport boto3\n\nprint('Loading function')\n\ns3 = boto3.client('s3')\n\n\ndef lambda_handler(event, context):\n    #print(\"Received event: \" + json.dumps(event, indent=2))\n\n    # Get the object from the event and show its content type\n    bucket = event['Records'][0]['s3']['bucket']['name']\n    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n    try:\n        response = s3.get_object(Bucket=bucket, Key=key)\n        print(\"CONTENT TYPE: \" + response['ContentType'])\n        return response['ContentType']\n    except Exception as e:\n        print(e)\n        print('Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))\n        raise e\n              \n",
                            "  13.Ruby : require 'json'\nrequire 'uri'\nrequire 'aws-sdk'\n\nputs 'Loading function'\n\ndef lambda_handler(event:, context:)\n  s3 = Aws::S3::Client.new(region: 'region') # Your AWS region\n  # puts \"Received event: #{JSON.dump(event)}\"\n\n  # Get the object from the event and show its content type\n  bucket = event['Records'][0]['s3']['bucket']['name']\n  key = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'], Encoding::UTF_8)\n  begin\n    response = s3.get_object(bucket: bucket, key: key)\n    puts \"CONTENT TYPE: #{response.content_type}\"\n    return response.content_type\n  rescue StandardError => e\n    puts e.message\n    puts \"Error getting object #{key} from bucket #{bucket}. Make sure they exist and your bucket is in the same region as this function.\"\n    raise e\n  end\nend\n\n",
                            "  14.SDK for Ruby : require 'json'\nrequire 'uri'\nrequire 'aws-sdk'\n\nputs 'Loading function'\n\ndef lambda_handler(event:, context:)\n  s3 = Aws::S3::Client.new(region: 'region') # Your AWS region\n  # puts \"Received event: #{JSON.dump(event)}\"\n\n  # Get the object from the event and show its content type\n  bucket = event['Records'][0]['s3']['bucket']['name']\n  key = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'], Encoding::UTF_8)\n  begin\n    response = s3.get_object(bucket: bucket, key: key)\n    puts \"CONTENT TYPE: #{response.content_type}\"\n    return response.content_type\n  rescue StandardError => e\n    puts e.message\n    puts \"Error getting object #{key} from bucket #{bucket}. Make sure they exist and your bucket is in the same region as this function.\"\n    raise e\n  end\nend\n\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::s3::S3Event;\nuse aws_sdk_s3::{Client};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n\n/// Main function\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    // Initialize the AWS SDK for Rust\n    let config = aws_config::load_from_env().await;\n    let s3_client = Client::new(&config);\n\n    let res = run(service_fn(|request: LambdaEvent<S3Event>| {\n        function_handler(&s3_client, request)\n    })).await;\n\n    res\n}\n\nasync fn function_handler(\n    s3_client: &Client,\n    evt: LambdaEvent<S3Event>\n) -> Result<(), Error> {\n    tracing::info!(records = ?evt.payload.records.len(), \"Received request from SQS\");\n\n    if evt.payload.records.len() == 0 {\n        tracing::info!(\"Empty S3 event received\");\n    }\n\n    let bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket name to exist\");\n    let key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to exist\");\n\n    tracing::info!(\"Request is for {} and object {}\", bucket, key);\n\n    let s3_get_object_result = s3_client\n        .get_object()\n        .bucket(bucket)\n        .key(key)\n        .send()\n        .await;\n\n    match s3_get_object_result {\n        Ok(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult contains a 'body' property of type ByteStream\"),\n        Err(_) => tracing::info!(\"Failure with S3 Get Object request\")\n    }\n\n    Ok(())\n}\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::s3::S3Event;\nuse aws_sdk_s3::{Client};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n\n/// Main function\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    // Initialize the AWS SDK for Rust\n    let config = aws_config::load_from_env().await;\n    let s3_client = Client::new(&config);\n\n    let res = run(service_fn(|request: LambdaEvent<S3Event>| {\n        function_handler(&s3_client, request)\n    })).await;\n\n    res\n}\n\nasync fn function_handler(\n    s3_client: &Client,\n    evt: LambdaEvent<S3Event>\n) -> Result<(), Error> {\n    tracing::info!(records = ?evt.payload.records.len(), \"Received request from SQS\");\n\n    if evt.payload.records.len() == 0 {\n        tracing::info!(\"Empty S3 event received\");\n    }\n\n    let bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket name to exist\");\n    let key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to exist\");\n\n    tracing::info!(\"Request is for {} and object {}\", bucket, key);\n\n    let s3_get_object_result = s3_client\n        .get_object()\n        .bucket(bucket)\n        .key(key)\n        .send()\n        .await;\n\n    match s3_get_object_result {\n        Ok(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult contains a 'body' property of type ByteStream\"),\n        Err(_) => tracing::info!(\"Failure with S3 Get Object request\")\n    }\n\n    Ok(())\n}\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Threading.Tasks;using Amazon.Lambda.Core;using Amazon.S3;using System;using Amazon.Lambda.S3Events;using System.Web;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace S3Integration{    public class Function    {        private static AmazonS3Client _s3Client;        public Function() : this(null)        {        }        internal Function(AmazonS3Client s3Client)        {            _s3Client = s3Client ?? new AmazonS3Client();        }        public async Task<string> Handler(S3Event evt, ILambdaContext context)        {            try            {                if (evt.Records.Count <= 0)                {                    context.Logger.LogLine(\"Empty S3 Event received\");                    return string.Empty;                }                var bucket = evt.Records[0].S3.Bucket.Name;                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);                context.Logger.LogLine($\"Request is for {bucket} and {key}\");                var objectResult = await _s3Client.GetObjectAsync(bucket, key);                context.Logger.LogLine($\"Returning {objectResult.Key}\");                return objectResult.Key;            }            catch (Exception e)            {                context.Logger.LogLine($\"Error processing request - {e.Message}\");                return string.Empty;            }        }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"log\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/s3\")func handler(ctx context.Context, s3Event events.S3Event) error {\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tlog.Printf(\"failed to load default config: %s\", err)\t\treturn err\t}\ts3Client := s3.NewFromConfig(sdkConfig)\tfor _, record := range s3Event.Records {\t\tbucket := record.S3.Bucket.Name\t\tkey := record.S3.Object.URLDecodedKey\t\theadOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{\t\t\tBucket: &bucket,\t\t\tKey:    &key,\t\t})\t\tif err != nil {\t\t\tlog.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err)\t\t\treturn err\t\t}\t\tlog.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key, *headOutput.ContentType)\t}\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import software.amazon.awssdk.services.s3.model.HeadObjectRequest;import software.amazon.awssdk.services.s3.model.HeadObjectResponse;import software.amazon.awssdk.services.s3.S3Client;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.S3Event;import com.amazonaws.services.lambda.runtime.events.models.s3.S3EventNotification.S3EventNotificationRecord;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Handler implements RequestHandler<S3Event, String> {    private static final Logger logger = LoggerFactory.getLogger(Handler.class);    @Override    public String handleRequest(S3Event s3event, Context context) {        try {          S3EventNotificationRecord record = s3event.getRecords().get(0);          String srcBucket = record.getS3().getBucket().getName();          String srcKey = record.getS3().getObject().getUrlDecodedKey();          S3Client s3Client = S3Client.builder().build();          HeadObjectResponse headObject = getHeadObject(s3Client, srcBucket, srcKey);          logger.info(\"Successfully retrieved \" + srcBucket + \"/\" + srcKey + \" of type \" + headObject.contentType());          return \"Ok\";        } catch (Exception e) {          throw new RuntimeException(e);        }    }    private HeadObjectResponse getHeadObject(S3Client s3Client, String bucket, String key) {        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()                .bucket(bucket)                .key(key)                .build();        return s3Client.headObject(headObjectRequest);    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using JavaScript.import { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";const client = new S3Client();export const handler = async (event, context) => {    // Get the object from the event and show its content type    const bucket = event.Records[0].s3.bucket.name;    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));    try {        const { ContentType } = await client.send(new HeadObjectCommand({            Bucket: bucket,            Key: key,        }));        console.log('CONTENT TYPE:', ContentType);        return ContentType;    } catch (err) {        console.log(err);        const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;        console.log(message);        throw new Error(message);    }};Consuming an S3 event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { S3Event } from 'aws-lambda';import { S3Client, HeadObjectCommand } from '@aws-sdk/client-s3';const s3 = new S3Client({ region: process.env.AWS_REGION });export const handler = async (event: S3Event): Promise<string | undefined> => {  // Get the object from the event and show its content type  const bucket = event.Records[0].s3.bucket.name;  const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' '));  const params = {    Bucket: bucket,    Key: key,  };  try {    const { ContentType } = await s3.send(new HeadObjectCommand(params));    console.log('CONTENT TYPE:', ContentType);    return ContentType;  } catch (err) {    console.log(err);    const message = `Error getting object ${key} from bucket ${bucket}. Make sure they exist and your bucket is in the same region as this function.`;    console.log(message);    throw new Error(message);  }};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using PHP.<?phpuse Bref\\Context\\Context;use Bref\\Event\\S3\\S3Event;use Bref\\Event\\S3\\S3Handler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends S3Handler {    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }        public function handleS3(S3Event $event, Context $context) : void    {        $this->logger->info(\"Processing S3 records\");        // Get the object from the event and show its content type        $records = $event->getRecords();                foreach ($records as $record)         {            $bucket = $record->getBucket()->getName();            $key = urldecode($record->getObject()->getKey());            try {                $fileSize = urldecode($record->getObject()->getSize());                echo \"File Size: \" . $fileSize . \"\\n\";                // TODO: Implement your custom processing logic here            } catch (Exception $e) {                echo $e->getMessage() . \"\\n\";                echo 'Error getting object ' . $key . ' from bucket ' . $bucket . '. Make sure they exist and your bucket is in the same region as this function.' . \"\\n\";                throw $e;            }        }    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0import jsonimport urllib.parseimport boto3print('Loading function')s3 = boto3.client('s3')def lambda_handler(event, context):    #print(\"Received event: \" + json.dumps(event, indent=2))    # Get the object from the event and show its content type    bucket = event['Records'][0]['s3']['bucket']['name']    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')    try:        response = s3.get_object(Bucket=bucket, Key=key)        print(\"CONTENT TYPE: \" + response['ContentType'])        return response['ContentType']    except Exception as e:        print(e)        print('Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))        raise e              RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Ruby.require 'json'require 'uri'require 'aws-sdk'puts 'Loading function'def lambda_handler(event:, context:)  s3 = Aws::S3::Client.new(region: 'region') # Your AWS region  # puts \"Received event: #{JSON.dump(event)}\"  # Get the object from the event and show its content type  bucket = event['Records'][0]['s3']['bucket']['name']  key = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'], Encoding::UTF_8)  begin    response = s3.get_object(bucket: bucket, key: key)    puts \"CONTENT TYPE: #{response.content_type}\"    return response.content_type  rescue StandardError => e    puts e.message    puts \"Error getting object #{key} from bucket #{bucket}. Make sure they exist and your bucket is in the same region as this function.\"    raise e  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::s3::S3Event;use aws_sdk_s3::{Client};use lambda_runtime::{run, service_fn, Error, LambdaEvent};/// Main function#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        .with_target(false)        .without_time()        .init();    // Initialize the AWS SDK for Rust    let config = aws_config::load_from_env().await;    let s3_client = Client::new(&config);    let res = run(service_fn(|request: LambdaEvent<S3Event>| {        function_handler(&s3_client, request)    })).await;    res}async fn function_handler(    s3_client: &Client,    evt: LambdaEvent<S3Event>) -> Result<(), Error> {    tracing::info!(records = ?evt.payload.records.len(), \"Received request from SQS\");    if evt.payload.records.len() == 0 {        tracing::info!(\"Empty S3 event received\");    }    let bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket name to exist\");    let key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to exist\");    tracing::info!(\"Request is for {} and object {}\", bucket, key);    let s3_get_object_result = s3_client        .get_object()        .bucket(bucket)        .key(key)        .send()        .await;    match s3_get_object_result {        Ok(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult contains a 'body' property of type ByteStream\"),        Err(_) => tracing::info!(\"Failure with S3 Get Object request\")    }    Ok(())}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nusing Amazon.Lambda.S3Events;\nusing System.Web;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace S3Integration\n{\n    public class Function\n    {\n        private static AmazonS3Client _s3Client;\n        public Function() : this(null)\n        {\n        }\n\n        internal Function(AmazonS3Client s3Client)\n        {\n            _s3Client = s3Client ?? new AmazonS3Client();\n        }\n\n        public async Task<string> Handler(S3Event evt, ILambdaContext context)\n        {\n            try\n            {\n                if (evt.Records.Count <= 0)\n                {\n                    context.Logger.LogLine(\"Empty S3 Event received\");\n                    return string.Empty;\n                }\n\n                var bucket = evt.Records[0].S3.Bucket.Name;\n                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);\n\n                context.Logger.LogLine($\"Request is for {bucket} and {key}\");\n\n                var objectResult = await _s3Client.GetObjectAsync(bucket, key);\n\n                context.Logger.LogLine($\"Returning {objectResult.Key}\");\n\n                return objectResult.Key;\n            }\n            catch (Exception e)\n            {\n                context.Logger.LogLine($\"Error processing request - {e.Message}\");\n\n                return string.Empty;\n            }\n        }\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an S3 event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Threading.Tasks;using Amazon.Lambda.Core;using Amazon.S3;using System;using Amazon.Lambda.S3Events;using System.Web;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace S3Integration{    public class Function    {        private static AmazonS3Client _s3Client;        public Function() : this(null)        {        }        internal Function(AmazonS3Client s3Client)        {            _s3Client = s3Client ?? new AmazonS3Client();        }        public async Task<string> Handler(S3Event evt, ILambdaContext context)        {            try            {                if (evt.Records.Count <= 0)                {                    context.Logger.LogLine(\"Empty S3 Event received\");                    return string.Empty;                }                var bucket = evt.Records[0].S3.Bucket.Name;                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key);                context.Logger.LogLine($\"Request is for {bucket} and {key}\");                var objectResult = await _s3Client.GetObjectAsync(bucket, key);                context.Logger.LogLine($\"Returning {objectResult.Key}\");                return objectResult.Key;            }            catch (Exception e)            {                context.Logger.LogLine($\"Error processing request - {e.Message}\");                return string.Empty;            }        }    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from an Amazon SNS trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_SNS_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving messages from an SNS topic. The function retrieves the messages from the event parameter and logs the content of each message.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, snsEvent events.SNSEvent) {\n\tfor _, record := range snsEvent.Records {\n\t\tprocessMessage(record)\n\t}\n\tfmt.Println(\"done\")\n}\n\nfunc processMessage(record events.SNSEventRecord) {\n\tmessage := record.SNS.Message\n\tfmt.Printf(\"Processed message: %s\\n\", message)\n\t// TODO: Process your record here\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, snsEvent events.SNSEvent) {\n\tfor _, record := range snsEvent.Records {\n\t\tprocessMessage(record)\n\t}\n\tfmt.Println(\"done\")\n}\n\nfunc processMessage(record events.SNSEventRecord) {\n\tmessage := record.SNS.Message\n\tfmt.Printf(\"Processed message: %s\\n\", message)\n\t// TODO: Process your record here\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;\n\n\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {\n    LambdaLogger logger;\n\n    @Override\n    public Boolean handleRequest(SNSEvent event, Context context) {\n        logger = context.getLogger();\n        List<SNSRecord> records = event.getRecords();\n        if (!records.isEmpty()) {\n            Iterator<SNSRecord> recordsIter = records.iterator();\n            while (recordsIter.hasNext()) {\n                processRecord(recordsIter.next());\n            }\n        }\n        return Boolean.TRUE;\n    }\n\n    public void processRecord(SNSRecord record) {\n        try {\n            String message = record.getSNS().getMessage();\n            logger.log(\"message: \" + message);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n\n\n\n\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\n\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;\n\n\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {\n    LambdaLogger logger;\n\n    @Override\n    public Boolean handleRequest(SNSEvent event, Context context) {\n        logger = context.getLogger();\n        List<SNSRecord> records = event.getRecords();\n        if (!records.isEmpty()) {\n            Iterator<SNSRecord> recordsIter = records.iterator();\n            while (recordsIter.hasNext()) {\n                processRecord(recordsIter.next());\n            }\n        }\n        return Boolean.TRUE;\n    }\n\n    public void processRecord(SNSRecord record) {\n        try {\n            String message = record.getSNS().getMessage();\n            logger.log(\"message: \" + message);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n\n\n\n\n",
                            "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    await processMessageAsync(record);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(record) {\n  try {\n    const message = JSON.stringify(record.Sns.Message);\n    console.log(`Processed message ${message}`);\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                            "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    await processMessageAsync(record);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(record) {\n  try {\n    const message = JSON.stringify(record.Sns.Message);\n    console.log(`Processed message ${message}`);\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                            "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n/* \nSince native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.\nFor more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/function\n\nAnother approach would be to create a custom runtime. \nA practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/\n*/\n\n// Additional composer packages may be required when using Bref or any other PHP functions runtime.\n// require __DIR__ . '/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sns\\SnsEvent;\nuse Bref\\Event\\Sns\\SnsHandler;\n\nclass Handler extends SnsHandler\n{\n    public function handleSns(SnsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $message = $record->getMessage();\n\n            // TODO: Implement your custom processing logic here\n            // Any exception thrown will be logged and the invocation will be marked as failed\n\n            echo \"Processed Message: $message\" . PHP_EOL;\n        }\n    }\n}\n\nreturn new Handler();\n\n",
                            "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n/* \nSince native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.\nFor more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/function\n\nAnother approach would be to create a custom runtime. \nA practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/\n*/\n\n// Additional composer packages may be required when using Bref or any other PHP functions runtime.\n// require __DIR__ . '/vendor/autoload.php';\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sns\\SnsEvent;\nuse Bref\\Event\\Sns\\SnsHandler;\n\nclass Handler extends SnsHandler\n{\n    public function handleSns(SnsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $message = $record->getMessage();\n\n            // TODO: Implement your custom processing logic here\n            // Any exception thrown will be logged and the invocation will be marked as failed\n\n            echo \"Processed Message: $message\" . PHP_EOL;\n        }\n    }\n}\n\nreturn new Handler();\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        process_message(record)\n    print(\"done\")\n\ndef process_message(record):\n    try:\n        message = record['Sns']['Message']\n        print(f\"Processed message {message}\")\n        # TODO; Process your record here\n        \n    except Exception as e:\n        print(\"An error occurred\")\n        raise e\n\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        process_message(record)\n    print(\"done\")\n\ndef process_message(record):\n    try:\n        message = record['Sns']['Message']\n        print(f\"Processed message {message}\")\n        # TODO; Process your record here\n        \n    except Exception as e:\n        print(\"An error occurred\")\n        raise e\n\n",
                            "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].map { |record| process_message(record) }\nend\n\ndef process_message(record)\n  message = record['Sns']['Message']\n  puts(\"Processing message: #{message}\")\nrescue StandardError => e\n  puts(\"Error processing message: #{e}\")\n  raise\nend\n\n",
                            "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].map { |record| process_message(record) }\nend\n\ndef process_message(record)\n  message = record['Sns']['Message']\n  puts(\"Processing message: #{message}\")\nrescue StandardError => e\n  puts(\"Error processing message: #{e}\")\n  raise\nend\n\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sns::SnsEvent;\nuse aws_lambda_events::sns::SnsRecord;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse tracing::info;\n\n// Built with the following dependencies:\n//  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }\n//  lambda_runtime = \"0.8.1\"\n//  tokio = { version = \"1\", features = [\"macros\"] }\n//  tracing = { version = \"0.1\", features = [\"log\"] }\n//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n\nasync fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {\n    for event in event.payload.records {\n        process_record(&event)?;\n    }\n    \n    Ok(())\n}\n\nfn process_record(record: &SnsRecord) -> Result<(), Error> {\n    info!(\"Processing SNS Message: {}\", record.sns.message);\n\n    // Implement your record handling code here.\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sns::SnsEvent;\nuse aws_lambda_events::sns::SnsRecord;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\nuse tracing::info;\n\n// Built with the following dependencies:\n//  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }\n//  lambda_runtime = \"0.8.1\"\n//  tokio = { version = \"1\", features = [\"macros\"] }\n//  tracing = { version = \"0.1\", features = [\"log\"] }\n//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }\n\nasync fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {\n    for event in event.payload.records {\n        process_record(&event)?;\n    }\n    \n    Ok(())\n}\n\nfn process_record(record: &SnsRecord) -> Result<(), Error> {\n    info!(\"Processing SNS Message: {}\", record.sns.message);\n\n    // Implement your record handling code here.\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .with_target(false)\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SNSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SnsIntegration;public class Function{    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            await ProcessRecordAsync(record, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, snsEvent events.SNSEvent) {\tfor _, record := range snsEvent.Records {\t\tprocessMessage(record)\t}\tfmt.Println(\"done\")}func processMessage(record events.SNSEventRecord) {\tmessage := record.SNS.Message\tfmt.Printf(\"Processed message: %s\\n\", message)\t// TODO: Process your record here}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package example;import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.LambdaLogger;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SNSEvent;import com.amazonaws.services.lambda.runtime.events.SNSEvent.SNSRecord;import java.util.Iterator;import java.util.List;public class SNSEventHandler implements RequestHandler<SNSEvent, Boolean> {    LambdaLogger logger;    @Override    public Boolean handleRequest(SNSEvent event, Context context) {        logger = context.getLogger();        List<SNSRecord> records = event.getRecords();        if (!records.isEmpty()) {            Iterator<SNSRecord> recordsIter = records.iterator();            while (recordsIter.hasNext()) {                processRecord(recordsIter.next());            }        }        return Boolean.TRUE;    }    public void processRecord(SNSRecord record) {        try {            String message = record.getSNS().getMessage();            logger.log(\"message: \" + message);        } catch (Exception e) {            throw new RuntimeException(e);        }    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    await processMessageAsync(record);  }  console.info(\"done\");};async function processMessageAsync(record) {  try {    const message = JSON.stringify(record.Sns.Message);    console.log(`Processed message ${message}`);    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}Consuming an SNS event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SNSEvent, Context, SNSHandler, SNSEventRecord } from \"aws-lambda\";export const functionHandler: SNSHandler = async (  event: SNSEvent,  context: Context): Promise<void> => {  for (const record of event.Records) {    await processMessageAsync(record);  }  console.info(\"done\");};async function processMessageAsync(record: SNSEventRecord): Promise<any> {  try {    const message: string = JSON.stringify(record.Sns.Message);    console.log(`Processed message ${message}`);    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php/* Since native PHP support for AWS Lambda is not available, we are utilizing Bref's PHP functions runtime for AWS Lambda.For more information on Bref's PHP runtime for Lambda, refer to: https://bref.sh/docs/runtimes/functionAnother approach would be to create a custom runtime. A practical example can be found here: https://aws.amazon.com/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/*/// Additional composer packages may be required when using Bref or any other PHP functions runtime.// require __DIR__ . '/vendor/autoload.php';use Bref\\Context\\Context;use Bref\\Event\\Sns\\SnsEvent;use Bref\\Event\\Sns\\SnsHandler;class Handler extends SnsHandler{    public function handleSns(SnsEvent $event, Context $context): void    {        foreach ($event->getRecords() as $record) {            $message = $record->getMessage();            // TODO: Implement your custom processing logic here            // Any exception thrown will be logged and the invocation will be marked as failed            echo \"Processed Message: $message\" . PHP_EOL;        }    }}return new Handler();PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    for record in event['Records']:        process_message(record)    print(\"done\")def process_message(record):    try:        message = record['Sns']['Message']        print(f\"Processed message {message}\")        # TODO; Process your record here            except Exception as e:        print(\"An error occurred\")        raise eRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event:, context:)  event['Records'].map { |record| process_message(record) }enddef process_message(record)  message = record['Sns']['Message']  puts(\"Processing message: #{message}\")rescue StandardError => e  puts(\"Error processing message: #{e}\")  raiseendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::sns::SnsEvent;use aws_lambda_events::sns::SnsRecord;use lambda_runtime::{run, service_fn, Error, LambdaEvent};use tracing::info;// Built with the following dependencies://  aws_lambda_events = { version = \"0.10.0\", default-features = false, features = [\"sns\"] }//  lambda_runtime = \"0.8.1\"//  tokio = { version = \"1\", features = [\"macros\"] }//  tracing = { version = \"0.1\", features = [\"log\"] }//  tracing-subscriber = { version = \"0.3\", default-features = false, features = [\"fmt\"] }async fn function_handler(event: LambdaEvent<SnsEvent>) -> Result<(), Error> {    for event in event.payload.records {        process_record(&event)?;    }        Ok(())}fn process_record(record: &SnsRecord) -> Result<(), Error> {    info!(\"Processing SNS Message: {}\", record.sns.message);    // Implement your record handling code here.    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        .with_target(false)        .without_time()        .init();    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SNSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SnsIntegration;\n\npublic class Function\n{\n    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)\n    {\n        foreach (var record in evnt.Records)\n        {\n            await ProcessRecordAsync(record, context);\n        }\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SNS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SNSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SnsIntegration;public class Function{    public async Task FunctionHandler(SNSEvent evnt, ILambdaContext context)    {        foreach (var record in evnt.Records)        {            await ProcessRecordAsync(record, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessRecordAsync(SNSEvent.SNSRecord record, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed record {record.Sns.Message}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Invoke a Lambda function from an Amazon SQS trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_SQS_Lambda_section.html",
                        "sections": [
                            "The following code examples show how to implement a Lambda function that receives an event triggered by receiving messages from an SQS queue. The function retrieves the messages from the event parameter and logs the content of each message.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage integration_sqs_to_lambda\n\nimport (\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.SQSEvent) error {\n\tfor _, record := range event.Records {\n\t\terr := processMessage(record)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfmt.Println(\"done\")\n\treturn nil\n}\n\nfunc processMessage(record events.SQSMessage) error {\n\tfmt.Printf(\"Processed message %s\\n\", record.Body)\n\t// TODO: Do interesting work based on the new message\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage integration_sqs_to_lambda\n\nimport (\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(event events.SQSEvent) error {\n\tfor _, record := range event.Records {\n\t\terr := processMessage(record)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfmt.Println(\"done\")\n\treturn nil\n}\n\nfunc processMessage(record events.SQSMessage) error {\n\tfmt.Printf(\"Processed message %s\\n\", record.Body)\n\t// TODO: Do interesting work based on the new message\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;\n\npublic class Function implements RequestHandler<SQSEvent, Void> {\n    @Override\n    public Void handleRequest(SQSEvent sqsEvent, Context context) {\n        for (SQSMessage msg : sqsEvent.getRecords()) {\n            processMessage(msg, context);\n        }\n        context.getLogger().log(\"done\");\n        return null;\n    }\n\n    private void processMessage(SQSMessage msg, Context context) {\n        try {\n            context.getLogger().log(\"Processed message \" + msg.getBody());\n\n            // TODO: Do interesting work based on the new message\n\n        } catch (Exception e) {\n            context.getLogger().log(\"An error occurred\");\n            throw e;\n        }\n\n    }\n}\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;\n\npublic class Function implements RequestHandler<SQSEvent, Void> {\n    @Override\n    public Void handleRequest(SQSEvent sqsEvent, Context context) {\n        for (SQSMessage msg : sqsEvent.getRecords()) {\n            processMessage(msg, context);\n        }\n        context.getLogger().log(\"done\");\n        return null;\n    }\n\n    private void processMessage(SQSMessage msg, Context context) {\n        try {\n            context.getLogger().log(\"Processed message \" + msg.getBody());\n\n            // TODO: Do interesting work based on the new message\n\n        } catch (Exception e) {\n            context.getLogger().log(\"An error occurred\");\n            throw e;\n        }\n\n    }\n}\n",
                            "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const message of event.Records) {\n    await processMessageAsync(message);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(message) {\n  try {\n    console.log(`Processed message ${message.body}`);\n    // TODO: Do interesting work based on the new message\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                            "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const message of event.Records) {\n    await processMessageAsync(message);\n  }\n  console.info(\"done\");\n};\n\nasync function processMessageAsync(message) {\n  try {\n    console.log(`Processed message ${message.body}`);\n    // TODO: Do interesting work based on the new message\n    await Promise.resolve(1); //Placeholder for actual async work\n  } catch (err) {\n    console.error(\"An error occurred\");\n    throw err;\n  }\n}\n\n",
                            "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\InvalidLambdaEvent;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $body = $record->getBody();\n            // TODO: Do interesting work based on the new message\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\InvalidLambdaEvent;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        foreach ($event->getRecords() as $record) {\n            $body = $record->getBody();\n            // TODO: Do interesting work based on the new message\n        }\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for message in event['Records']:\n        process_message(message)\n    print(\"done\")\n\ndef process_message(message):\n    try:\n        print(f\"Processed message {message['body']}\")\n        # TODO: Do interesting work based on the new message\n    except Exception as err:\n        print(\"An error occurred\")\n        raise err\n\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event, context):\n    for message in event['Records']:\n        process_message(message)\n    print(\"done\")\n\ndef process_message(message):\n    try:\n        print(f\"Processed message {message['body']}\")\n        # TODO: Do interesting work based on the new message\n    except Exception as err:\n        print(\"An error occurred\")\n        raise err\n\n",
                            "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].each do |message|\n    process_message(message)\n  end\n  puts \"done\"\nend\n\ndef process_message(message)\n  begin\n    puts \"Processed message #{message['body']}\"\n    # TODO: Do interesting work based on the new message\n  rescue StandardError => err\n    puts \"An error occurred\"\n    raise err\n  end\nend\n",
                            "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef lambda_handler(event:, context:)\n  event['Records'].each do |message|\n    process_message(message)\n  end\n  puts \"done\"\nend\n\ndef process_message(message)\n  begin\n    puts \"Processed message #{message['body']}\"\n    # TODO: Do interesting work based on the new message\n  rescue StandardError => err\n    puts \"An error occurred\"\n    raise err\n  end\nend\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sqs::SqsEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {\n    event.payload.records.iter().for_each(|record| {\n        // process the record\n        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())\n    });\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::sqs::SqsEvent;\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {\n    event.payload.records.iter().for_each(|record| {\n        // process the record\n        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())\n    });\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SqsIntegrationSampleCode{    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        foreach (var message in evnt.Records)        {            await ProcessMessageAsync(message, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed message {message.Body}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package integration_sqs_to_lambdaimport (\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(event events.SQSEvent) error {\tfor _, record := range event.Records {\t\terr := processMessage(record)\t\tif err != nil {\t\t\treturn err\t\t}\t}\tfmt.Println(\"done\")\treturn nil}func processMessage(record events.SQSMessage) error {\tfmt.Printf(\"Processed message %s\\n\", record.Body)\t// TODO: Do interesting work based on the new message\treturn nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SQSEvent;import com.amazonaws.services.lambda.runtime.events.SQSEvent.SQSMessage;public class Function implements RequestHandler<SQSEvent, Void> {    @Override    public Void handleRequest(SQSEvent sqsEvent, Context context) {        for (SQSMessage msg : sqsEvent.getRecords()) {            processMessage(msg, context);        }        context.getLogger().log(\"done\");        return null;    }    private void processMessage(SQSMessage msg, Context context) {        try {            context.getLogger().log(\"Processed message \" + msg.getBody());            // TODO: Do interesting work based on the new message        } catch (Exception e) {            context.getLogger().log(\"An error occurred\");            throw e;        }    }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using JavaScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const message of event.Records) {    await processMessageAsync(message);  }  console.info(\"done\");};async function processMessageAsync(message) {  try {    console.log(`Processed message ${message.body}`);    // TODO: Do interesting work based on the new message    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}Consuming an SQS event with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SQSEvent, Context, SQSHandler, SQSRecord } from \"aws-lambda\";export const functionHandler: SQSHandler = async (  event: SQSEvent,  context: Context): Promise<void> => {  for (const message of event.Records) {    await processMessageAsync(message);  }  console.info(\"done\");};async function processMessageAsync(message: SQSRecord): Promise<any> {  try {    console.log(`Processed message ${message.body}`);    // TODO: Do interesting work based on the new message    await Promise.resolve(1); //Placeholder for actual async work  } catch (err) {    console.error(\"An error occurred\");    throw err;  }}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\InvalidLambdaEvent;use Bref\\Event\\Sqs\\SqsEvent;use Bref\\Event\\Sqs\\SqsHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends SqsHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws InvalidLambdaEvent     */    public function handleSqs(SqsEvent $event, Context $context): void    {        foreach ($event->getRecords() as $record) {            $body = $record->getBody();            // TODO: Do interesting work based on the new message        }    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    for message in event['Records']:        process_message(message)    print(\"done\")def process_message(message):    try:        print(f\"Processed message {message['body']}\")        # TODO: Do interesting work based on the new message    except Exception as err:        print(\"An error occurred\")        raise errRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event:, context:)  event['Records'].each do |message|    process_message(message)  end  puts \"done\"enddef process_message(message)  begin    puts \"Processed message #{message['body']}\"    # TODO: Do interesting work based on the new message  rescue StandardError => err    puts \"An error occurred\"    raise err  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::event::sqs::SqsEvent;use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<(), Error> {    event.payload.records.iter().for_each(|record| {        // process the record        tracing::info!(\"Message body: {}\", record.body.as_deref().unwrap_or_default())    });    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace SqsIntegrationSampleCode\n{\n    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        foreach (var message in evnt.Records)\n        {\n            await ProcessMessageAsync(message, context);\n        }\n\n        context.Logger.LogInformation(\"done\");\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        try\n        {\n            context.Logger.LogInformation($\"Processed message {message.Body}\");\n\n            // TODO: Do interesting work based on the new message\n            await Task.CompletedTask;\n        }\n        catch (Exception e)\n        {\n            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.\n            context.Logger.LogError($\"An error occurred\");\n            throw;\n        }\n\n    }\n}\n\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Consuming an SQS event with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace SqsIntegrationSampleCode{    public async Task FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        foreach (var message in evnt.Records)        {            await ProcessMessageAsync(message, context);        }        context.Logger.LogInformation(\"done\");    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        try        {            context.Logger.LogInformation($\"Processed message {message.Body}\");            // TODO: Do interesting work based on the new message            await Task.CompletedTask;        }        catch (Exception e)        {            //You can use Dead Letter Queue to handle failures. By configuring a Lambda DLQ.            context.Logger.LogError($\"An error occurred\");            throw;        }    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Reporting batch item failures for Lambda functions with a Kinesis trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_Kinesis_Lambda_batch_item_failures_section.html",
                        "sections": [
                            "The following code examples show how to implement partial batch response for Lambda functions that receive events from a Kinesis stream. The function reports the batch item failures in the response, signaling to Lambda to retry those messages later.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tcurRecordSequenceNumber := \"\"\n\n\t\t// Process your record\n\t\tif /* Your record processing condition here */ {\n\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\n\t\t}\n\n\t\t// Add a condition to check if the record processing failed\n\t\tif curRecordSequenceNumber != \"\" {\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\n\t\t}\n\t}\n\n\tkinesisBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn kinesisBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, record := range kinesisEvent.Records {\n\t\tcurRecordSequenceNumber := \"\"\n\n\t\t// Process your record\n\t\tif /* Your record processing condition here */ {\n\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\n\t\t}\n\n\t\t// Add a condition to check if the record processing failed\n\t\tif curRecordSequenceNumber != \"\" {\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\n\t\t}\n\t}\n\n\tkinesisBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn kinesisBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {\n\n    @Override\n    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {\n            try {\n                //Process your record\n                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();\n                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();\n\n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse(batchItemFailures);   \n    }\n}\n\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {\n\n    @Override\n    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {\n            try {\n                //Process your record\n                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();\n                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();\n\n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse(batchItemFailures);   \n    }\n}\n\n",
                            "  7.JavaScript : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n      return {\n        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],\n      };\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n  return { batchItemFailures: [] };\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                            "  8.SDK for JavaScript (v3) : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexports.handler = async (event, context) => {\n  for (const record of event.Records) {\n    try {\n      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      console.log(`Record Data: ${recordData}`);\n      // TODO: Do interesting work based on the new data\n    } catch (err) {\n      console.error(`An error occurred ${err}`);\n      /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n      return {\n        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],\n      };\n    }\n  }\n  console.log(`Successfully processed ${event.Records.length} records.`);\n  return { batchItemFailures: [] };\n};\n\nasync function getRecordDataAsync(payload) {\n  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); //Placeholder for actual async work\n  return data;\n}\n\n",
                            "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $kinesisEvent = new KinesisEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kinesisEvent->getRecords();\n\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Kinesis\\KinesisEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $kinesisEvent = new KinesisEvent($event);\n        $this->logger->info(\"Processing records\");\n        $records = $kinesisEvent->getRecords();\n\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                            "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  batch_item_failures = []\n\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue StandardError => err\n      puts \"An error occurred #{err}\"\n      # Since we are working with streams, we can return the failed item immediately.\n      # Lambda will immediately begin to retry processing from this failed item onwards.\n      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }\n    end\n  end\n\n  puts \"Successfully processed #{event['Records'].length} records.\"\n  { batchItemFailures: batch_item_failures }\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('utf-8')\n  # Placeholder for actual async work\n  sleep(1)\n  data\nend\n",
                            "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'aws-sdk'\n\ndef lambda_handler(event:, context:)\n  batch_item_failures = []\n\n  event['Records'].each do |record|\n    begin\n      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"\n      record_data = get_record_data_async(record['kinesis'])\n      puts \"Record Data: #{record_data}\"\n      # TODO: Do interesting work based on the new data\n    rescue StandardError => err\n      puts \"An error occurred #{err}\"\n      # Since we are working with streams, we can return the failed item immediately.\n      # Lambda will immediately begin to retry processing from this failed item onwards.\n      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }\n    end\n  end\n\n  puts \"Successfully processed #{event['Records'].length} records.\"\n  { batchItemFailures: batch_item_failures }\nend\n\ndef get_record_data_async(payload)\n  data = Base64.decode64(payload['data']).force_encoding('utf-8')\n  # Placeholder for actual async work\n  sleep(1)\n  data\nend\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::kinesis::KinesisEvent,\n    kinesis::KinesisEventRecord,\n    streams::{KinesisBatchItemFailure, KinesisEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {\n    let mut response = KinesisEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in &event.payload.records {\n        tracing::info!(\n            \"EventId: {}\",\n            record.event_id.as_deref().unwrap_or_default()\n        );\n\n        let record_processing_result = process_record(record);\n\n        if record_processing_result.is_err() {\n            response.batch_item_failures.push(KinesisBatchItemFailure {\n                item_identifier: record.kinesis.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(response)\n}\n\nfn process_record(record: &KinesisEventRecord) -> Result<(), Error> {\n    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());\n\n    if let Some(err) = record_data.err() {\n        tracing::error!(\"Error: {}\", err);\n        return Err(Error::from(err));\n    }\n\n    let record_data = record_data.unwrap_or_default();\n\n    // do something interesting with the data\n    tracing::info!(\"Data: {}\", record_data);\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::kinesis::KinesisEvent,\n    kinesis::KinesisEventRecord,\n    streams::{KinesisBatchItemFailure, KinesisEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {\n    let mut response = KinesisEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    if event.payload.records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in &event.payload.records {\n        tracing::info!(\n            \"EventId: {}\",\n            record.event_id.as_deref().unwrap_or_default()\n        );\n\n        let record_processing_result = process_record(record);\n\n        if record_processing_result.is_err() {\n            response.batch_item_failures.push(KinesisBatchItemFailure {\n                item_identifier: record.kinesis.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\n        \"Successfully processed {} records\",\n        event.payload.records.len()\n    );\n\n    Ok(response)\n}\n\nfn process_record(record: &KinesisEventRecord) -> Result<(), Error> {\n    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());\n\n    if let Some(err) = record_data.err() {\n        tracing::error!(\"Error: {}\", err);\n        return Err(Error::from(err));\n    }\n\n    let record_data = record_data.unwrap_or_default();\n\n    // do something interesting with the data\n    tracing::info!(\"Data: {}\", record_data);\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using System.Text.Json.Serialization;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegration;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return new StreamsEventResponse();        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                return new StreamsEventResponse                {                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>                    {                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }                    }                };            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");        return new StreamsEventResponse();    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}public class StreamsEventResponse{    [JsonPropertyName(\"batchItemFailures\")]    public IList<BatchItemFailure> BatchItemFailures { get; set; }    public class BatchItemFailure    {        [JsonPropertyName(\"itemIdentifier\")]        public string ItemIdentifier { get; set; }    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, kinesisEvent events.KinesisEvent) (map[string]interface{}, error) {\tbatchItemFailures := []map[string]interface{}{}\tfor _, record := range kinesisEvent.Records {\t\tcurRecordSequenceNumber := \"\"\t\t// Process your record\t\tif /* Your record processing condition here */ {\t\t\tcurRecordSequenceNumber = record.Kinesis.SequenceNumber\t\t}\t\t// Add a condition to check if the record processing failed\t\tif curRecordSequenceNumber != \"\" {\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": curRecordSequenceNumber})\t\t}\t}\tkinesisBatchResponse := map[string]interface{}{\t\t\"batchItemFailures\": batchItemFailures,\t}\treturn kinesisBatchResponse, nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.KinesisEvent;import com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;import java.io.Serializable;import java.util.ArrayList;import java.util.List;public class ProcessKinesisRecords implements RequestHandler<KinesisEvent, StreamsEventResponse> {    @Override    public StreamsEventResponse handleRequest(KinesisEvent input, Context context) {        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();        String curRecordSequenceNumber = \"\";        for (KinesisEvent.KinesisEventRecord kinesisEventRecord : input.getRecords()) {            try {                //Process your record                KinesisEvent.Record kinesisRecord = kinesisEventRecord.getKinesis();                curRecordSequenceNumber = kinesisRecord.getSequenceNumber();            } catch (Exception e) {                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));                return new StreamsEventResponse(batchItemFailures);            }        }              return new StreamsEventResponse(batchItemFailures);       }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Javascript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0exports.handler = async (event, context) => {  for (const record of event.Records) {    try {      console.log(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      console.log(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      console.error(`An error occurred ${err}`);      /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */      return {        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],      };    }  }  console.log(`Successfully processed ${event.Records.length} records.`);  return { batchItemFailures: [] };};async function getRecordDataAsync(payload) {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}Reporting Kinesis batch item failures with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import {  KinesisStreamEvent,  Context,  KinesisStreamHandler,  KinesisStreamRecordPayload,  KinesisStreamBatchResponse,} from \"aws-lambda\";import { Buffer } from \"buffer\";import { Logger } from \"@aws-lambda-powertools/logger\";const logger = new Logger({  logLevel: \"INFO\",  serviceName: \"kinesis-stream-handler-sample\",});export const functionHandler: KinesisStreamHandler = async (  event: KinesisStreamEvent,  context: Context): Promise<KinesisStreamBatchResponse> => {  for (const record of event.Records) {    try {      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);      const recordData = await getRecordDataAsync(record.kinesis);      logger.info(`Record Data: ${recordData}`);      // TODO: Do interesting work based on the new data    } catch (err) {      logger.error(`An error occurred ${err}`);      /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */      return {        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],      };    }  }  logger.info(`Successfully processed ${event.Records.length} records.`);  return { batchItemFailures: [] };};async function getRecordDataAsync(  payload: KinesisStreamRecordPayload): Promise<string> {  var data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");  await Promise.resolve(1); //Placeholder for actual async work  return data;}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\Kinesis\\KinesisEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): array    {        $kinesisEvent = new KinesisEvent($event);        $this->logger->info(\"Processing records\");        $records = $kinesisEvent->getRecords();        $failedRecords = [];        foreach ($records as $record) {            try {                $data = $record->getData();                $this->logger->info(json_encode($data));                // TODO: Do interesting work based on the new data            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $failedRecords[] = $record->getSequenceNumber();            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");        // change format for the response        $failures = array_map(            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],            $failedRecords        );        return [            'batchItemFailures' => $failures        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def handler(event, context):    records = event.get(\"Records\")    curRecordSequenceNumber = \"\"        for record in records:        try:            # Process your record            curRecordSequenceNumber = record[\"kinesis\"][\"sequenceNumber\"]        except Exception as e:            # Return failed record's sequence number            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}    return {\"batchItemFailures\":[]}RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'aws-sdk'def lambda_handler(event:, context:)  batch_item_failures = []  event['Records'].each do |record|    begin      puts \"Processed Kinesis Event - EventID: #{record['eventID']}\"      record_data = get_record_data_async(record['kinesis'])      puts \"Record Data: #{record_data}\"      # TODO: Do interesting work based on the new data    rescue StandardError => err      puts \"An error occurred #{err}\"      # Since we are working with streams, we can return the failed item immediately.      # Lambda will immediately begin to retry processing from this failed item onwards.      return { batchItemFailures: [{ itemIdentifier: record['kinesis']['sequenceNumber'] }] }    end  end  puts \"Successfully processed #{event['Records'].length} records.\"  { batchItemFailures: batch_item_failures }enddef get_record_data_async(payload)  data = Base64.decode64(payload['data']).force_encoding('utf-8')  # Placeholder for actual async work  sleep(1)  dataendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::{    event::kinesis::KinesisEvent,    kinesis::KinesisEventRecord,    streams::{KinesisBatchItemFailure, KinesisEventResponse},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn function_handler(event: LambdaEvent<KinesisEvent>) -> Result<KinesisEventResponse, Error> {    let mut response = KinesisEventResponse {        batch_item_failures: vec![],    };    if event.payload.records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(response);    }    for record in &event.payload.records {        tracing::info!(            \"EventId: {}\",            record.event_id.as_deref().unwrap_or_default()        );        let record_processing_result = process_record(record);        if record_processing_result.is_err() {            response.batch_item_failures.push(KinesisBatchItemFailure {                item_identifier: record.kinesis.sequence_number.clone(),            });            /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */            return Ok(response);        }    }    tracing::info!(        \"Successfully processed {} records\",        event.payload.records.len()    );    Ok(response)}fn process_record(record: &KinesisEventRecord) -> Result<(), Error> {    let record_data = std::str::from_utf8(record.kinesis.data.as_slice());    if let Some(err) = record_data.err() {        tracing::error!(\"Error: {}\", err);        return Err(Error::from(err));    }    let record_data = record_data.unwrap_or_default();    // do something interesting with the data    tracing::info!(\"Data: {}\", record_data);    Ok(())}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n﻿using System.Text;\nusing System.Text.Json.Serialization;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.KinesisEvents;\nusing AWS.Lambda.Powertools.Logging;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace KinesisIntegration;\n\npublic class Function\n{\n    // Powertools Logger requires an environment variables against your function\n    // POWERTOOLS_SERVICE_NAME\n    [Logging(LogEvent = true)]\n    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)\n    {\n        if (evnt.Records.Count == 0)\n        {\n            Logger.LogInformation(\"Empty Kinesis Event received\");\n            return new StreamsEventResponse();\n        }\n\n        foreach (var record in evnt.Records)\n        {\n            try\n            {\n                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");\n                string data = await GetRecordDataAsync(record.Kinesis, context);\n                Logger.LogInformation($\"Data: {data}\");\n                // TODO: Do interesting work based on the new data\n            }\n            catch (Exception ex)\n            {\n                Logger.LogError($\"An error occurred {ex.Message}\");\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                return new StreamsEventResponse\n                {\n                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>\n                    {\n                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }\n                    }\n                };\n            }\n        }\n        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");\n        return new StreamsEventResponse();\n    }\n\n    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)\n    {\n        byte[] bytes = record.Data.ToArray();\n        string data = Encoding.UTF8.GetString(bytes);\n        await Task.CompletedTask; //Placeholder for actual async work\n        return data;\n    }\n}\n\npublic class StreamsEventResponse\n{\n    [JsonPropertyName(\"batchItemFailures\")]\n    public IList<BatchItemFailure> BatchItemFailures { get; set; }\n    public class BatchItemFailure\n    {\n        [JsonPropertyName(\"itemIdentifier\")]\n        public string ItemIdentifier { get; set; }\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting Kinesis batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0﻿using System.Text;using System.Text.Json.Serialization;using Amazon.Lambda.Core;using Amazon.Lambda.KinesisEvents;using AWS.Lambda.Powertools.Logging;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace KinesisIntegration;public class Function{    // Powertools Logger requires an environment variables against your function    // POWERTOOLS_SERVICE_NAME    [Logging(LogEvent = true)]    public async Task<StreamsEventResponse> FunctionHandler(KinesisEvent evnt, ILambdaContext context)    {        if (evnt.Records.Count == 0)        {            Logger.LogInformation(\"Empty Kinesis Event received\");            return new StreamsEventResponse();        }        foreach (var record in evnt.Records)        {            try            {                Logger.LogInformation($\"Processed Event with EventId: {record.EventId}\");                string data = await GetRecordDataAsync(record.Kinesis, context);                Logger.LogInformation($\"Data: {data}\");                // TODO: Do interesting work based on the new data            }            catch (Exception ex)            {                Logger.LogError($\"An error occurred {ex.Message}\");                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                return new StreamsEventResponse                {                    BatchItemFailures = new List<StreamsEventResponse.BatchItemFailure>                    {                        new StreamsEventResponse.BatchItemFailure { ItemIdentifier = record.Kinesis.SequenceNumber }                    }                };            }        }        Logger.LogInformation($\"Successfully processed {evnt.Records.Count} records.\");        return new StreamsEventResponse();    }    private async Task<string> GetRecordDataAsync(KinesisEvent.Record record, ILambdaContext context)    {        byte[] bytes = record.Data.ToArray();        string data = Encoding.UTF8.GetString(bytes);        await Task.CompletedTask; //Placeholder for actual async work        return data;    }}public class StreamsEventResponse{    [JsonPropertyName(\"batchItemFailures\")]    public IList<BatchItemFailure> BatchItemFailures { get; set; }    public class BatchItemFailure    {        [JsonPropertyName(\"itemIdentifier\")]        public string ItemIdentifier { get; set; }    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Reporting batch item failures for Lambda functions with a DynamoDB trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_DynamoDB_Lambda_batch_item_failures_section.html",
                        "sections": [
                            "The following code examples show how to implement partial batch response for Lambda functions that receive events from a DynamoDB stream. The function reports the batch item failures in the response, signaling to Lambda to retry those messages later.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype BatchItemFailure struct {\n\tItemIdentifier string `json:\"ItemIdentifier\"`\n}\n\ntype BatchResult struct {\n\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`\n}\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\n\tvar batchItemFailures []BatchItemFailure\n\tcurRecordSequenceNumber := \"\"\n\n\tfor _, record := range event.Records {\n\t\t// Process your record\n\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\n\t}\n\n\tif curRecordSequenceNumber != \"\" {\n\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\n\t}\n\t\n\tbatchResult := BatchResult{\n\t\tBatchItemFailures: batchItemFailures,\n\t}\n\n\treturn &batchResult, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype BatchItemFailure struct {\n\tItemIdentifier string `json:\"ItemIdentifier\"`\n}\n\ntype BatchResult struct {\n\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`\n}\n\nfunc HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\n\tvar batchItemFailures []BatchItemFailure\n\tcurRecordSequenceNumber := \"\"\n\n\tfor _, record := range event.Records {\n\t\t// Process your record\n\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\n\t}\n\n\tif curRecordSequenceNumber != \"\" {\n\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\n\t}\n\t\n\tbatchResult := BatchResult{\n\t\tBatchItemFailures: batchItemFailures,\n\t}\n\n\treturn &batchResult, nil\n}\n\nfunc main() {\n\tlambda.Start(HandleRequest)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {\n\n    @Override\n    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {\n          try {\n                //Process your record\n                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();\n                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();\n                \n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse();   \n    }\n}\n\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {\n\n    @Override\n    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {\n\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();\n        String curRecordSequenceNumber = \"\";\n\n        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {\n          try {\n                //Process your record\n                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();\n                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();\n                \n            } catch (Exception e) {\n                /* Since we are working with streams, we can return the failed item immediately.\n                   Lambda will immediately begin to retry processing from this failed item onwards. */\n                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));\n                return new StreamsEventResponse(batchItemFailures);\n            }\n        }\n       \n       return new StreamsEventResponse();   \n    }\n}\n\n",
                            "  7.JavaScript : export const handler = async (event) => {\n  const records = event.Records;\n  let curRecordSequenceNumber = \"\";\n\n  for (const record of records) {\n    try {\n      // Process your record\n      curRecordSequenceNumber = record.dynamodb.SequenceNumber;\n    } catch (e) {\n      // Return failed record's sequence number\n      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };\n    }\n  }\n\n  return { batchItemFailures: [] };\n};\n\n",
                            "  8.SDK for JavaScript (v3) : export const handler = async (event) => {\n  const records = event.Records;\n  let curRecordSequenceNumber = \"\";\n\n  for (const record of records) {\n    try {\n      // Process your record\n      curRecordSequenceNumber = record.dynamodb.SequenceNumber;\n    } catch (e) {\n      // Return failed record's sequence number\n      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };\n    }\n  }\n\n  return { batchItemFailures: [] };\n};\n\n",
                            "  9.PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $dynamoDbEvent = new DynamoDbEvent($event);\n        $this->logger->info(\"Processing records\");\n\n        $records = $dynamoDbEvent->getRecords();\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : <?php\n\n# using bref/bref and bref/logger for simplicity\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\DynamoDb\\DynamoDbEvent;\nuse Bref\\Event\\Handler as StdHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler implements StdHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handle(mixed $event, Context $context): array\n    {\n        $dynamoDbEvent = new DynamoDbEvent($event);\n        $this->logger->info(\"Processing records\");\n\n        $records = $dynamoDbEvent->getRecords();\n        $failedRecords = [];\n        foreach ($records as $record) {\n            try {\n                $data = $record->getData();\n                $this->logger->info(json_encode($data));\n                // TODO: Do interesting work based on the new data\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $failedRecords[] = $record->getSequenceNumber();\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords records\");\n\n        // change format for the response\n        $failures = array_map(\n            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],\n            $failedRecords\n        );\n\n        return [\n            'batchItemFailures' => $failures\n        ];\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\ndef handler(event, context):\n    records = event.get(\"Records\")\n    curRecordSequenceNumber = \"\"\n    \n    for record in records:\n        try:\n            # Process your record\n            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]\n        except Exception as e:\n            # Return failed record's sequence number\n            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}\n\n    return {\"batchItemFailures\":[]}\n\n",
                            "  13.Ruby : def lambda_handler(event:, context:)\n    records = event[\"Records\"]\n    cur_record_sequence_number = \"\"\n  \n    records.each do |record|\n      begin\n        # Process your record\n        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]\n      rescue StandardError => e\n        # Return failed record's sequence number\n        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}\n      end\n    end\n  \n    {\"batchItemFailures\" => []}\n  end\n",
                            "  14.SDK for Ruby : def lambda_handler(event:, context:)\n    records = event[\"Records\"]\n    cur_record_sequence_number = \"\"\n  \n    records.each do |record|\n      begin\n        # Process your record\n        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]\n      rescue StandardError => e\n        # Return failed record's sequence number\n        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}\n      end\n    end\n  \n    {\"batchItemFailures\" => []}\n  end\n",
                            "  15.Rust : use aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord, StreamRecord},\n    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n/// Process the stream record\nfn process_record(record: &EventRecord) -> Result<(), Error> {\n    let stream_record: &StreamRecord = &record.change;\n\n    // process your stream record here...\n    tracing::info!(\"Data: {:?}\", stream_record);\n\n    Ok(())\n}\n\n/// Main Lambda handler here...\nasync fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {\n    let mut response = DynamoDbEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    let records = &event.payload.records;\n\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in records {\n        tracing::info!(\"EventId: {}\", record.event_id);\n\n        // Couldn't find a sequence number\n        if record.change.sequence_number.is_none() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: Some(\"\".to_string()),\n            });\n            return Ok(response);\n        }\n\n        // Process your record here...\n        if process_record(record).is_err() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: record.change.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\"Successfully processed {} record(s)\", records.len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n",
                            "  16.SDK for Rust : use aws_lambda_events::{\n    event::dynamodb::{Event, EventRecord, StreamRecord},\n    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\n/// Process the stream record\nfn process_record(record: &EventRecord) -> Result<(), Error> {\n    let stream_record: &StreamRecord = &record.change;\n\n    // process your stream record here...\n    tracing::info!(\"Data: {:?}\", stream_record);\n\n    Ok(())\n}\n\n/// Main Lambda handler here...\nasync fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {\n    let mut response = DynamoDbEventResponse {\n        batch_item_failures: vec![],\n    };\n\n    let records = &event.payload.records;\n\n    if records.is_empty() {\n        tracing::info!(\"No records found. Exiting.\");\n        return Ok(response);\n    }\n\n    for record in records {\n        tracing::info!(\"EventId: {}\", record.event_id);\n\n        // Couldn't find a sequence number\n        if record.change.sequence_number.is_none() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: Some(\"\".to_string()),\n            });\n            return Ok(response);\n        }\n\n        // Process your record here...\n        if process_record(record).is_err() {\n            response.batch_item_failures.push(DynamoDbBatchItemFailure {\n                item_identifier: record.change.sequence_number.clone(),\n            });\n            /* Since we are working with streams, we can return the failed item immediately.\n            Lambda will immediately begin to retry processing from this failed item onwards. */\n            return Ok(response);\n        }\n    }\n\n    tracing::info!(\"Successfully processed {} record(s)\", records.len());\n\n    Ok(response)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disable printing the name of the module in every log line.\n        .with_target(false)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();        foreach (var record in dynamoEvent.Records)        {            try            {                var sequenceNumber = record.Dynamodb.SequenceNumber;                context.Logger.LogInformation(sequenceNumber);            }            catch (Exception ex)            {                context.Logger.LogError(ex.Message);                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });            }        }        if (batchItemFailures.Count > 0)        {            streamsEventResponse.BatchItemFailures = batchItemFailures;        }        context.Logger.LogInformation(\"Stream processing complete.\");        return streamsEventResponse;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")type BatchItemFailure struct {\tItemIdentifier string `json:\"ItemIdentifier\"`}type BatchResult struct {\tBatchItemFailures []BatchItemFailure `json:\"BatchItemFailures\"`}func HandleRequest(ctx context.Context, event events.DynamoDBEvent) (*BatchResult, error) {\tvar batchItemFailures []BatchItemFailure\tcurRecordSequenceNumber := \"\"\tfor _, record := range event.Records {\t\t// Process your record\t\tcurRecordSequenceNumber = record.Change.SequenceNumber\t}\tif curRecordSequenceNumber != \"\" {\t\tbatchItemFailures = append(batchItemFailures, BatchItemFailure{ItemIdentifier: curRecordSequenceNumber})\t}\t\tbatchResult := BatchResult{\t\tBatchItemFailures: batchItemFailures,\t}\treturn &batchResult, nil}func main() {\tlambda.Start(HandleRequest)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.DynamodbEvent;import com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;import com.amazonaws.services.lambda.runtime.events.models.dynamodb.StreamRecord;import java.io.Serializable;import java.util.ArrayList;import java.util.List;public class ProcessDynamodbRecords implements RequestHandler<DynamodbEvent, Serializable> {    @Override    public StreamsEventResponse handleRequest(DynamodbEvent input, Context context) {        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new ArrayList<>();        String curRecordSequenceNumber = \"\";        for (DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord : input.getRecords()) {          try {                //Process your record                StreamRecord dynamodbRecord = dynamodbStreamRecord.getDynamodb();                curRecordSequenceNumber = dynamodbRecord.getSequenceNumber();                            } catch (Exception e) {                /* Since we are working with streams, we can return the failed item immediately.                   Lambda will immediately begin to retry processing from this failed item onwards. */                batchItemFailures.add(new StreamsEventResponse.BatchItemFailure(curRecordSequenceNumber));                return new StreamsEventResponse(batchItemFailures);            }        }              return new StreamsEventResponse();       }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using JavaScript.export const handler = async (event) => {  const records = event.Records;  let curRecordSequenceNumber = \"\";  for (const record of records) {    try {      // Process your record      curRecordSequenceNumber = record.dynamodb.SequenceNumber;    } catch (e) {      // Return failed record's sequence number      return { batchItemFailures: [{ itemIdentifier: curRecordSequenceNumber }] };    }  }  return { batchItemFailures: [] };};Reporting DynamoDB batch item failures with Lambda using TypeScript.import {  DynamoDBBatchResponse,  DynamoDBBatchItemFailure,  DynamoDBStreamEvent,} from \"aws-lambda\";export const handler = async (  event: DynamoDBStreamEvent): Promise<DynamoDBBatchResponse> => {  const batchItemFailures: DynamoDBBatchItemFailure[] = [];  let curRecordSequenceNumber;  for (const record of event.Records) {    curRecordSequenceNumber = record.dynamodb?.SequenceNumber;    if (curRecordSequenceNumber) {      batchItemFailures.push({        itemIdentifier: curRecordSequenceNumber,      });    }  }  return { batchItemFailures: batchItemFailures };};PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using PHP.<?php# using bref/bref and bref/logger for simplicityuse Bref\\Context\\Context;use Bref\\Event\\DynamoDb\\DynamoDbEvent;use Bref\\Event\\Handler as StdHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler implements StdHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handle(mixed $event, Context $context): array    {        $dynamoDbEvent = new DynamoDbEvent($event);        $this->logger->info(\"Processing records\");        $records = $dynamoDbEvent->getRecords();        $failedRecords = [];        foreach ($records as $record) {            try {                $data = $record->getData();                $this->logger->info(json_encode($data));                // TODO: Do interesting work based on the new data            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $failedRecords[] = $record->getSequenceNumber();            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords records\");        // change format for the response        $failures = array_map(            fn(string $sequenceNumber) => ['itemIdentifier' => $sequenceNumber],            $failedRecords        );        return [            'batchItemFailures' => $failures        ];    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def handler(event, context):    records = event.get(\"Records\")    curRecordSequenceNumber = \"\"        for record in records:        try:            # Process your record            curRecordSequenceNumber = record[\"dynamodb\"][\"SequenceNumber\"]        except Exception as e:            # Return failed record's sequence number            return {\"batchItemFailures\":[{\"itemIdentifier\": curRecordSequenceNumber}]}    return {\"batchItemFailures\":[]}RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Ruby.def lambda_handler(event:, context:)    records = event[\"Records\"]    cur_record_sequence_number = \"\"      records.each do |record|      begin        # Process your record        cur_record_sequence_number = record[\"dynamodb\"][\"SequenceNumber\"]      rescue StandardError => e        # Return failed record's sequence number        return {\"batchItemFailures\" => [{\"itemIdentifier\" => cur_record_sequence_number}]}      end    end      {\"batchItemFailures\" => []}  endRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using Rust.use aws_lambda_events::{    event::dynamodb::{Event, EventRecord, StreamRecord},    streams::{DynamoDbBatchItemFailure, DynamoDbEventResponse},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};/// Process the stream recordfn process_record(record: &EventRecord) -> Result<(), Error> {    let stream_record: &StreamRecord = &record.change;    // process your stream record here...    tracing::info!(\"Data: {:?}\", stream_record);    Ok(())}/// Main Lambda handler here...async fn function_handler(event: LambdaEvent<Event>) -> Result<DynamoDbEventResponse, Error> {    let mut response = DynamoDbEventResponse {        batch_item_failures: vec![],    };    let records = &event.payload.records;    if records.is_empty() {        tracing::info!(\"No records found. Exiting.\");        return Ok(response);    }    for record in records {        tracing::info!(\"EventId: {}\", record.event_id);        // Couldn't find a sequence number        if record.change.sequence_number.is_none() {            response.batch_item_failures.push(DynamoDbBatchItemFailure {                item_identifier: Some(\"\".to_string()),            });            return Ok(response);        }        // Process your record here...        if process_record(record).is_err() {            response.batch_item_failures.push(DynamoDbBatchItemFailure {                item_identifier: record.change.sequence_number.clone(),            });            /* Since we are working with streams, we can return the failed item immediately.            Lambda will immediately begin to retry processing from this failed item onwards. */            return Ok(response);        }    }    tracing::info!(\"Successfully processed {} record(s)\", records.len());    Ok(response)}#[tokio::main]async fn main() -> Result<(), Error> {    tracing_subscriber::fmt()        .with_max_level(tracing::Level::INFO)        // disable printing the name of the module in every log line.        .with_target(false)        // disabling time is handy because CloudWatch will add the ingestion time.        .without_time()        .init();    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Text.Json;\nusing System.Text;\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.DynamoDBEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\n\nnamespace AWSLambda_DDB;\n\npublic class Function\n{\n    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)\n\n    {\n        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");\n        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();\n        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();\n\n        foreach (var record in dynamoEvent.Records)\n        {\n            try\n            {\n                var sequenceNumber = record.Dynamodb.SequenceNumber;\n                context.Logger.LogInformation(sequenceNumber);\n            }\n            catch (Exception ex)\n            {\n                context.Logger.LogError(ex.Message);\n                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });\n            }\n        }\n\n        if (batchItemFailures.Count > 0)\n        {\n            streamsEventResponse.BatchItemFailures = batchItemFailures;\n        }\n\n        context.Logger.LogInformation(\"Stream processing complete.\");\n        return streamsEventResponse;\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting DynamoDB batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using System.Text.Json;using System.Text;using Amazon.Lambda.Core;using Amazon.Lambda.DynamoDBEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace AWSLambda_DDB;public class Function{    public StreamsEventResponse FunctionHandler(DynamoDBEvent dynamoEvent, ILambdaContext context)    {        context.Logger.LogInformation($\"Beginning to process {dynamoEvent.Records.Count} records...\");        List<StreamsEventResponse.BatchItemFailure> batchItemFailures = new List<StreamsEventResponse.BatchItemFailure>();        StreamsEventResponse streamsEventResponse = new StreamsEventResponse();        foreach (var record in dynamoEvent.Records)        {            try            {                var sequenceNumber = record.Dynamodb.SequenceNumber;                context.Logger.LogInformation(sequenceNumber);            }            catch (Exception ex)            {                context.Logger.LogError(ex.Message);                batchItemFailures.Add(new StreamsEventResponse.BatchItemFailure() { ItemIdentifier = record.Dynamodb.SequenceNumber });            }        }        if (batchItemFailures.Count > 0)        {            streamsEventResponse.BatchItemFailures = batchItemFailures;        }        context.Logger.LogInformation(\"Stream processing complete.\");        return streamsEventResponse;    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    },
                    {
                        "title": "Reporting batch item failures for Lambda functions with an Amazon SQS trigger",
                        "href": "https://docs.aws.amazon.com/lambda/latest/dg/example_serverless_SQS_Lambda_batch_item_failures_section.html",
                        "sections": [
                            "The following code examples show how to implement partial batch response for Lambda functions that receive events from an SQS queue. The function reports the batch item failures in the response, signaling to Lambda to retry those messages later.",
                            "  1..NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\nnamespace sqsSample;\n\npublic class Function\n{\n    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();\n        foreach(var message in evnt.Records)\n        {\n            try\n            {\n                //process your message\n                await ProcessMessageAsync(message, context);\n            }\n            catch (System.Exception)\n            {\n                //Add failed message identifier to the batchItemFailures list\n                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId}); \n            }\n        }\n        return new SQSBatchResponse(batchItemFailures);\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        if (String.IsNullOrEmpty(message.Body))\n        {\n            throw new Exception(\"No Body in SQS Message.\");\n        }\n        context.Logger.LogInformation($\"Processed message {message.Body}\");\n        // TODO: Do interesting work based on the new message\n        await Task.CompletedTask;\n    }\n}\n",
                            "  2.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\nnamespace sqsSample;\n\npublic class Function\n{\n    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();\n        foreach(var message in evnt.Records)\n        {\n            try\n            {\n                //process your message\n                await ProcessMessageAsync(message, context);\n            }\n            catch (System.Exception)\n            {\n                //Add failed message identifier to the batchItemFailures list\n                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId}); \n            }\n        }\n        return new SQSBatchResponse(batchItemFailures);\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        if (String.IsNullOrEmpty(message.Body))\n        {\n            throw new Exception(\"No Body in SQS Message.\");\n        }\n        context.Logger.LogInformation($\"Processed message {message.Body}\");\n        // TODO: Do interesting work based on the new message\n        await Task.CompletedTask;\n    }\n}\n",
                            "  3.Go : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, sqsEvent events.SQSEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, message := range sqsEvent.Records {\n\t\t\n\t\tif /* Your message processing condition here */ {\t\t\t\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": message.MessageId})\n\t\t}\n\t}\n\n\tsqsBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn sqsBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  4.SDK for Go V2 : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, sqsEvent events.SQSEvent) (map[string]interface{}, error) {\n\tbatchItemFailures := []map[string]interface{}{}\n\n\tfor _, message := range sqsEvent.Records {\n\t\t\n\t\tif /* Your message processing condition here */ {\t\t\t\n\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": message.MessageId})\n\t\t}\n\t}\n\n\tsqsBatchResponse := map[string]interface{}{\n\t\t\"batchItemFailures\": batchItemFailures,\n\t}\n\treturn sqsBatchResponse, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n\n",
                            "  5.Java : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSBatchResponse;\n \nimport java.util.ArrayList;\nimport java.util.List;\n \npublic class ProcessSQSMessageBatch implements RequestHandler<SQSEvent, SQSBatchResponse> {\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {\n \n         List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new ArrayList<SQSBatchResponse.BatchItemFailure>();\n         String messageId = \"\";\n         for (SQSEvent.SQSMessage message : sqsEvent.getRecords()) {\n             try {\n                 //process your message\n                 messageId = message.getMessageId();\n             } catch (Exception e) {\n                 //Add failed message identifier to the batchItemFailures list\n                 batchItemFailures.add(new SQSBatchResponse.BatchItemFailure(messageId));\n             }\n         }\n         return new SQSBatchResponse(batchItemFailures);\n     }\n}\n",
                            "  6.SDK for Java 2.x : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport com.amazonaws.services.lambda.runtime.events.SQSBatchResponse;\n \nimport java.util.ArrayList;\nimport java.util.List;\n \npublic class ProcessSQSMessageBatch implements RequestHandler<SQSEvent, SQSBatchResponse> {\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {\n \n         List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new ArrayList<SQSBatchResponse.BatchItemFailure>();\n         String messageId = \"\";\n         for (SQSEvent.SQSMessage message : sqsEvent.getRecords()) {\n             try {\n                 //process your message\n                 messageId = message.getMessageId();\n             } catch (Exception e) {\n                 //Add failed message identifier to the batchItemFailures list\n                 batchItemFailures.add(new SQSBatchResponse.BatchItemFailure(messageId));\n             }\n         }\n         return new SQSBatchResponse(batchItemFailures);\n     }\n}\n",
                            "  7.JavaScript : // Node.js 20.x Lambda runtime, AWS SDK for Javascript V3\nexport const handler = async (event, context) => {\n    const batchItemFailures = [];\n    for (const record of event.Records) {\n        try {\n            await processMessageAsync(record, context);\n        } catch (error) {\n            batchItemFailures.push({ itemIdentifier: record.messageId });\n        }\n    }\n    return { batchItemFailures };\n};\n\nasync function processMessageAsync(record, context) {\n    if (record.body && record.body.includes(\"error\")) {\n        throw new Error(\"There is an error in the SQS Message.\");\n    }\n    console.log(`Processed message: ${record.body}`);\n}\n",
                            "  8.SDK for JavaScript (v3) : // Node.js 20.x Lambda runtime, AWS SDK for Javascript V3\nexport const handler = async (event, context) => {\n    const batchItemFailures = [];\n    for (const record of event.Records) {\n        try {\n            await processMessageAsync(record, context);\n        } catch (error) {\n            batchItemFailures.push({ itemIdentifier: record.messageId });\n        }\n    }\n    return { batchItemFailures };\n};\n\nasync function processMessageAsync(record, context) {\n    if (record.body && record.body.includes(\"error\")) {\n        throw new Error(\"There is an error in the SQS Message.\");\n    }\n    console.log(`Processed message: ${record.body}`);\n}\n",
                            "  9.PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing SQS records\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                // Assuming the SQS message is in JSON format\n                $message = json_decode($record->getBody(), true);\n                $this->logger->info(json_encode($message));\n                // TODO: Implement your custom processing logic here\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $this->markAsFailed($record);\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords SQS records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  10.SDK for PHP : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n<?php\n\nuse Bref\\Context\\Context;\nuse Bref\\Event\\Sqs\\SqsEvent;\nuse Bref\\Event\\Sqs\\SqsHandler;\nuse Bref\\Logger\\StderrLogger;\n\nrequire __DIR__ . '/vendor/autoload.php';\n\nclass Handler extends SqsHandler\n{\n    private StderrLogger $logger;\n    public function __construct(StderrLogger $logger)\n    {\n        $this->logger = $logger;\n    }\n\n    /**\n     * @throws JsonException\n     * @throws \\Bref\\Event\\InvalidLambdaEvent\n     */\n    public function handleSqs(SqsEvent $event, Context $context): void\n    {\n        $this->logger->info(\"Processing SQS records\");\n        $records = $event->getRecords();\n\n        foreach ($records as $record) {\n            try {\n                // Assuming the SQS message is in JSON format\n                $message = json_decode($record->getBody(), true);\n                $this->logger->info(json_encode($message));\n                // TODO: Implement your custom processing logic here\n            } catch (Exception $e) {\n                $this->logger->error($e->getMessage());\n                // failed processing the record\n                $this->markAsFailed($record);\n            }\n        }\n        $totalRecords = count($records);\n        $this->logger->info(\"Successfully processed $totalRecords SQS records\");\n    }\n}\n\n$logger = new StderrLogger();\nreturn new Handler($logger);\n\n",
                            "  11.Python : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\ndef lambda_handler(event, context):\n    if event:\n        batch_item_failures = []\n        sqs_batch_response = {}\n     \n        for record in event[\"Records\"]:\n            try:\n                # process message\n            except Exception as e:\n                batch_item_failures.append({\"itemIdentifier\": record['messageId']})\n        \n        sqs_batch_response[\"batchItemFailures\"] = batch_item_failures\n        return sqs_batch_response\n",
                            "  12.SDK for Python (Boto3) : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\ndef lambda_handler(event, context):\n    if event:\n        batch_item_failures = []\n        sqs_batch_response = {}\n     \n        for record in event[\"Records\"]:\n            try:\n                # process message\n            except Exception as e:\n                batch_item_failures.append({\"itemIdentifier\": record['messageId']})\n        \n        sqs_batch_response[\"batchItemFailures\"] = batch_item_failures\n        return sqs_batch_response\n",
                            "  13.Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'json'\n\ndef lambda_handler(event:, context:)\n  if event\n    batch_item_failures = []\n    sqs_batch_response = {}\n\n    event[\"Records\"].each do |record|\n      begin\n        # process message\n      rescue StandardError => e\n        batch_item_failures << {\"itemIdentifier\" => record['messageId']}\n      end\n    end\n\n    sqs_batch_response[\"batchItemFailures\"] = batch_item_failures\n    return sqs_batch_response\n  end\nend\n\n",
                            "  14.SDK for Ruby : # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nrequire 'json'\n\ndef lambda_handler(event:, context:)\n  if event\n    batch_item_failures = []\n    sqs_batch_response = {}\n\n    event[\"Records\"].each do |record|\n      begin\n        # process message\n      rescue StandardError => e\n        batch_item_failures << {\"itemIdentifier\" => record['messageId']}\n      end\n    end\n\n    sqs_batch_response[\"batchItemFailures\"] = batch_item_failures\n    return sqs_batch_response\n  end\nend\n\n",
                            "  15.Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::sqs::{SqsBatchResponse, SqsEvent},\n    sqs::{BatchItemFailure, SqsMessage},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn process_record(_: &SqsMessage) -> Result<(), Error> {\n    Err(Error::from(\"Error processing message\"))\n}\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<SqsBatchResponse, Error> {\n    let mut batch_item_failures = Vec::new();\n    for record in event.payload.records {\n        match process_record(&record).await {\n            Ok(_) => (),\n            Err(_) => batch_item_failures.push(BatchItemFailure {\n                item_identifier: record.message_id.unwrap(),\n            }),\n        }\n    }\n\n    Ok(SqsBatchResponse {\n        batch_item_failures,\n    })\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(function_handler)).await\n}\n\n",
                            "  16.SDK for Rust : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::{\n    event::sqs::{SqsBatchResponse, SqsEvent},\n    sqs::{BatchItemFailure, SqsMessage},\n};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n\nasync fn process_record(_: &SqsMessage) -> Result<(), Error> {\n    Err(Error::from(\"Error processing message\"))\n}\n\nasync fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<SqsBatchResponse, Error> {\n    let mut batch_item_failures = Vec::new();\n    for record in event.payload.records {\n        match process_record(&record).await {\n            Ok(_) => (),\n            Err(_) => batch_item_failures.push(BatchItemFailure {\n                item_identifier: record.message_id.unwrap(),\n            }),\n        }\n    }\n\n    Ok(SqsBatchResponse {\n        batch_item_failures,\n    })\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    run(service_fn(function_handler)).await\n}\n\n",
                            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace sqsSample;public class Function{    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();        foreach(var message in evnt.Records)        {            try            {                //process your message                await ProcessMessageAsync(message, context);            }            catch (System.Exception)            {                //Add failed message identifier to the batchItemFailures list                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId});             }        }        return new SQSBatchResponse(batchItemFailures);    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        if (String.IsNullOrEmpty(message.Body))        {            throw new Exception(\"No Body in SQS Message.\");        }        context.Logger.LogInformation($\"Processed message {message.Body}\");        // TODO: Do interesting work based on the new message        await Task.CompletedTask;    }}GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Go.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0package mainimport (\t\"context\"\t\"encoding/json\"\t\"fmt\"\t\"github.com/aws/aws-lambda-go/events\"\t\"github.com/aws/aws-lambda-go/lambda\")func handler(ctx context.Context, sqsEvent events.SQSEvent) (map[string]interface{}, error) {\tbatchItemFailures := []map[string]interface{}{}\tfor _, message := range sqsEvent.Records {\t\t\t\tif /* Your message processing condition here */ {\t\t\t\t\t\tbatchItemFailures = append(batchItemFailures, map[string]interface{}{\"itemIdentifier\": message.MessageId})\t\t}\t}\tsqsBatchResponse := map[string]interface{}{\t\t\"batchItemFailures\": batchItemFailures,\t}\treturn sqsBatchResponse, nil}func main() {\tlambda.Start(handler)}JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Java.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import com.amazonaws.services.lambda.runtime.Context;import com.amazonaws.services.lambda.runtime.RequestHandler;import com.amazonaws.services.lambda.runtime.events.SQSEvent;import com.amazonaws.services.lambda.runtime.events.SQSBatchResponse; import java.util.ArrayList;import java.util.List; public class ProcessSQSMessageBatch implements RequestHandler<SQSEvent, SQSBatchResponse> {    @Override    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {          List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new ArrayList<SQSBatchResponse.BatchItemFailure>();         String messageId = \"\";         for (SQSEvent.SQSMessage message : sqsEvent.getRecords()) {             try {                 //process your message                 messageId = message.getMessageId();             } catch (Exception e) {                 //Add failed message identifier to the batchItemFailures list                 batchItemFailures.add(new SQSBatchResponse.BatchItemFailure(messageId));             }         }         return new SQSBatchResponse(batchItemFailures);     }}JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using JavaScript.// Node.js 20.x Lambda runtime, AWS SDK for Javascript V3export const handler = async (event, context) => {    const batchItemFailures = [];    for (const record of event.Records) {        try {            await processMessageAsync(record, context);        } catch (error) {            batchItemFailures.push({ itemIdentifier: record.messageId });        }    }    return { batchItemFailures };};async function processMessageAsync(record, context) {    if (record.body && record.body.includes(\"error\")) {        throw new Error(\"There is an error in the SQS Message.\");    }    console.log(`Processed message: ${record.body}`);}Reporting SQS batch item failures with Lambda using TypeScript.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0import { SQSEvent, SQSBatchResponse, Context, SQSBatchItemFailure, SQSRecord } from 'aws-lambda';export const handler = async (event: SQSEvent, context: Context): Promise<SQSBatchResponse> => {    const batchItemFailures: SQSBatchItemFailure[] = [];    for (const record of event.Records) {        try {            await processMessageAsync(record);        } catch (error) {            batchItemFailures.push({ itemIdentifier: record.messageId });        }    }    return {batchItemFailures: batchItemFailures};};async function processMessageAsync(record: SQSRecord): Promise<void> {    if (record.body && record.body.includes(\"error\")) {        throw new Error('There is an error in the SQS Message.');    }    console.log(`Processed message ${record.body}`);}PHPSDK for PHPNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using PHP.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0<?phpuse Bref\\Context\\Context;use Bref\\Event\\Sqs\\SqsEvent;use Bref\\Event\\Sqs\\SqsHandler;use Bref\\Logger\\StderrLogger;require __DIR__ . '/vendor/autoload.php';class Handler extends SqsHandler{    private StderrLogger $logger;    public function __construct(StderrLogger $logger)    {        $this->logger = $logger;    }    /**     * @throws JsonException     * @throws \\Bref\\Event\\InvalidLambdaEvent     */    public function handleSqs(SqsEvent $event, Context $context): void    {        $this->logger->info(\"Processing SQS records\");        $records = $event->getRecords();        foreach ($records as $record) {            try {                // Assuming the SQS message is in JSON format                $message = json_decode($record->getBody(), true);                $this->logger->info(json_encode($message));                // TODO: Implement your custom processing logic here            } catch (Exception $e) {                $this->logger->error($e->getMessage());                // failed processing the record                $this->markAsFailed($record);            }        }        $totalRecords = count($records);        $this->logger->info(\"Successfully processed $totalRecords SQS records\");    }}$logger = new StderrLogger();return new Handler($logger);PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Python.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0def lambda_handler(event, context):    if event:        batch_item_failures = []        sqs_batch_response = {}             for record in event[\"Records\"]:            try:                # process message            except Exception as e:                batch_item_failures.append({\"itemIdentifier\": record['messageId']})                sqs_batch_response[\"batchItemFailures\"] = batch_item_failures        return sqs_batch_responseRubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Ruby.# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.# SPDX-License-Identifier: Apache-2.0require 'json'def lambda_handler(event:, context:)  if event    batch_item_failures = []    sqs_batch_response = {}    event[\"Records\"].each do |record|      begin        # process message      rescue StandardError => e        batch_item_failures << {\"itemIdentifier\" => record['messageId']}      end    end    sqs_batch_response[\"batchItemFailures\"] = batch_item_failures    return sqs_batch_response  endendRustSDK for RustNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using Rust.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0use aws_lambda_events::{    event::sqs::{SqsBatchResponse, SqsEvent},    sqs::{BatchItemFailure, SqsMessage},};use lambda_runtime::{run, service_fn, Error, LambdaEvent};async fn process_record(_: &SqsMessage) -> Result<(), Error> {    Err(Error::from(\"Error processing message\"))}async fn function_handler(event: LambdaEvent<SqsEvent>) -> Result<SqsBatchResponse, Error> {    let mut batch_item_failures = Vec::new();    for record in event.payload.records {        match process_record(&record).await {            Ok(_) => (),            Err(_) => batch_item_failures.push(BatchItemFailure {                item_identifier: record.message_id.unwrap(),            }),        }    }    Ok(SqsBatchResponse {        batch_item_failures,    })}#[tokio::main]async fn main() -> Result<(), Error> {    run(service_fn(function_handler)).await}",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "anchor",
                            "  1.AWS SDK for .NET : // Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing Amazon.Lambda.Core;\nusing Amazon.Lambda.SQSEvents;\n\n// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.\n[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\nnamespace sqsSample;\n\npublic class Function\n{\n    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)\n    {\n        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();\n        foreach(var message in evnt.Records)\n        {\n            try\n            {\n                //process your message\n                await ProcessMessageAsync(message, context);\n            }\n            catch (System.Exception)\n            {\n                //Add failed message identifier to the batchItemFailures list\n                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId}); \n            }\n        }\n        return new SQSBatchResponse(batchItemFailures);\n    }\n\n    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)\n    {\n        if (String.IsNullOrEmpty(message.Body))\n        {\n            throw new Exception(\"No Body in SQS Message.\");\n        }\n        context.Logger.LogInformation($\"Processed message {message.Body}\");\n        // TODO: Do interesting work based on the new message\n        await Task.CompletedTask;\n    }\n}\n",
                            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        Serverless examples        repository.    Reporting SQS batch item failures with Lambda using .NET.// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.// SPDX-License-Identifier: Apache-2.0using Amazon.Lambda.Core;using Amazon.Lambda.SQSEvents;// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]namespace sqsSample;public class Function{    public async Task<SQSBatchResponse> FunctionHandler(SQSEvent evnt, ILambdaContext context)    {        List<SQSBatchResponse.BatchItemFailure> batchItemFailures = new List<SQSBatchResponse.BatchItemFailure>();        foreach(var message in evnt.Records)        {            try            {                //process your message                await ProcessMessageAsync(message, context);            }            catch (System.Exception)            {                //Add failed message identifier to the batchItemFailures list                batchItemFailures.Add(new SQSBatchResponse.BatchItemFailure{ItemIdentifier=message.MessageId});             }        }        return new SQSBatchResponse(batchItemFailures);    }    private async Task ProcessMessageAsync(SQSEvent.SQSMessage message, ILambdaContext context)    {        if (String.IsNullOrEmpty(message.Body))        {            throw new Exception(\"No Body in SQS Message.\");        }        context.Logger.LogInformation($\"Processed message {message.Body}\");        // TODO: Do interesting work based on the new message        await Task.CompletedTask;    }}",
                            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions."
                        ]
                    }
                ],
                "source": "Aws",
                "sections": [
                    "The following code examples show how to use Lambda with AWS SDKs.",
                    "Examples"
                ]
            }
        ],
        "sections": [
            "The following code examples show how to use Lambda with an AWS software development kit (SDK).        ",
            "Basics are code examples that show you how to perform the essential operations within a service.",
            "Actions are code excerpts from larger programs and must be run in context. While actions    show you how to call individual service functions, you can see actions in context in their related scenarios.",
            "Scenarios are code examples that show you how to accomplish specific tasks by    calling multiple functions within a service or combined with other AWS services.",
            "For a complete list of AWS SDK developer guides and code examples, see    Using Lambda with an AWS SDK.    This topic also includes information about getting started and details about previous SDK versions.",
            "Get started",
            "The following code examples show how to get started using Lambda.",
            "  1..NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
            "  2.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
            "  3.C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
            "  4.SDK for C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
            "  5.Go : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
            "  6.SDK for Go V2 : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
            "  7.Java :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
            "  8.SDK for Java 2.x :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
            "  9.JavaScript : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
            "  10.SDK for JavaScript (v3) : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
            "  11.Python : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
            "  12.SDK for Python (Boto3) : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
            "  13.Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
            "  14.SDK for Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    ",
            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    ",
            "Hello Lambda",
            "The following code examples show how to get started using Lambda.",
            "  1..NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
            "  2.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
            "  3.C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
            "  4.SDK for C++ : # Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS lambda)\n\n# Set this project's name.\nproject(\"hello_lambda\")\n\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\n\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.\n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\n\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.\n\n     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this \n                                    # and set the proper subdirectory to the executables' location.\n\n     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\n\nadd_executable(${PROJECT_NAME}\n        hello_lambda.cpp)\n\ntarget_link_libraries(${PROJECT_NAME}\n        ${AWSSDK_LINK_LIBRARIES})\n\n",
            "  5.Go : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
            "  6.SDK for Go V2 : \npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/lambda\"\n)\n\n// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10\n// functions in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\n\tctx := context.Background()\n\tsdkConfig, err := config.LoadDefaultConfig(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tlambdaClient := lambda.NewFromConfig(sdkConfig)\n\n\tmaxItems := 10\n\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\n\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\n\t\tMaxItems: aws.Int32(int32(maxItems)),\n\t})\n\tif err != nil {\n\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\n\t\treturn\n\t}\n\tif len(result.Functions) == 0 {\n\t\tfmt.Println(\"You don't have any functions!\")\n\t} else {\n\t\tfor _, function := range result.Functions {\n\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\n\t\t}\n\t}\n}\n\n\n",
            "  7.Java :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
            "  8.SDK for Java 2.x :     /**\n     * Lists the AWS Lambda functions associated with the current AWS account.\n     *\n     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service\n     *\n     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service\n     */\n    public static void listFunctions(LambdaClient awsLambda) {\n        try {\n            ListFunctionsResponse functionResult = awsLambda.listFunctions();\n            List<FunctionConfiguration> list = functionResult.functions();\n            for (FunctionConfiguration config : list) {\n                System.out.println(\"The function name is \" + config.functionName());\n            }\n\n        } catch (LambdaException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n\n",
            "  9.JavaScript : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
            "  10.SDK for JavaScript (v3) : import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";\n\nconst client = new LambdaClient({});\n\nexport const helloLambda = async () => {\n  const paginator = paginateListFunctions({ client }, {});\n  const functions = [];\n\n  for await (const page of paginator) {\n    const funcNames = page.Functions.map((f) => f.FunctionName);\n    functions.push(...funcNames);\n  }\n\n  console.log(\"Functions:\");\n  console.log(functions.join(\"\\n\"));\n  return functions;\n};\n\n",
            "  11.Python : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
            "  12.SDK for Python (Boto3) : \nimport boto3\n\n\ndef main():\n    \"\"\"\n    List the Lambda functions in your AWS account.\n    \"\"\"\n    # Create the Lambda client\n    lambda_client = boto3.client(\"lambda\")\n\n    # Use the paginator to list the functions\n    paginator = lambda_client.get_paginator(\"list_functions\")\n    response_iterator = paginator.paginate()\n\n    print(\"Here are the Lambda functions in your account:\")\n    for page in response_iterator:\n        for function in page[\"Functions\"]:\n            print(f\"  {function['FunctionName']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
            "  13.Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
            "  14.SDK for Ruby : \nrequire 'aws-sdk-lambda'\n\n# Creates an AWS Lambda client using the default credentials and configuration\ndef lambda_client\n  Aws::Lambda::Client.new\nend\n\n# Lists the Lambda functions in your AWS account, paginating the results if necessary\ndef list_lambda_functions\n  lambda = lambda_client\n\n  # Use a pagination iterator to list all functions\n  functions = []\n  lambda.list_functions.each_page do |page|\n    functions.concat(page.functions)\n  end\n\n  # Print the name and ARN of each function\n  functions.each do |function|\n    puts \"Function name: #{function.function_name}\"\n    puts \"Function ARN: #{function.function_arn}\"\n    puts\n  end\n\n  puts \"Total functions: #{functions.count}\"\nend\n\nlist_lambda_functions if __FILE__ == $PROGRAM_NAME\n\n\n",
            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    ",
            "anchor",
            "anchor",
            "anchor",
            "anchor",
            "anchor",
            "anchor",
            "anchor",
            "  1.AWS SDK for .NET : namespace LambdaActions;\n\nusing Amazon.Lambda;\n\npublic class HelloLambda\n{\n    static async Task Main(string[] args)\n    {\n        var lambdaClient = new AmazonLambdaClient();\n\n        Console.WriteLine(\"Hello AWS Lambda\");\n        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");\n\n        var response = await lambdaClient.ListFunctionsAsync();\n        response.Functions.ForEach(function =>\n        {\n            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");\n        });\n    }\n}\n\n\n",
            "AWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    ",
            ".NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    anchoranchoranchoranchoranchoranchoranchor.NETC++GoJavaJavaScriptPythonRubyAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    ",
            "The following code examples show how to get started using Lambda..NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    Hello LambdaThe following code examples show how to get started using Lambda..NETAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    C++SDK for C++Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    Code for the CMakeLists.txt CMake file.# Set the minimum required version of CMake for this project.cmake_minimum_required(VERSION 3.13)# Set the AWS service components used by this project.set(SERVICE_COMPONENTS lambda)# Set this project's name.project(\"hello_lambda\")# Set the C++ standard to use to build this target.# At least C++ 11 is required for the AWS SDK for C++.set(CMAKE_CXX_STANDARD 11)# Use the MSVC variable to determine if this is a Windows build.set(WINDOWS_BUILD ${MSVC})if (WINDOWS_BUILD) # Set the location where CMake can find the installed libraries for the AWS SDK.    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})endif ()# Find the AWS SDK for C++ package.find_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})if (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)     # Copy relevant AWS SDK for C++ libraries into the current binary directory for running and debugging.     # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you may need to uncomment this                                     # and set the proper subdirectory to the executables' location.     AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})endif ()add_executable(${PROJECT_NAME}        hello_lambda.cpp)target_link_libraries(${PROJECT_NAME}        ${AWSSDK_LINK_LIBRARIES})Code for the hello_lambda.cpp source file.#include <aws/core/Aws.h>#include <aws/lambda/LambdaClient.h>#include <aws/lambda/model/ListFunctionsRequest.h>#include <iostream>/* *  A \"Hello Lambda\" starter application which initializes an AWS Lambda (Lambda) client and lists the Lambda functions. * *  main function * *  Usage: 'hello_lambda' * */int main(int argc, char **argv) {    Aws::SDKOptions options;    // Optionally change the log level for debugging.//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;    Aws::InitAPI(options); // Should only be called once.    int result = 0;    {        Aws::Client::ClientConfiguration clientConfig;        // Optional: Set to the AWS Region (overrides config file).        // clientConfig.region = \"us-east-1\";        Aws::Lambda::LambdaClient lambdaClient(clientConfig);        std::vector<Aws::String> functions;        Aws::String marker; // Used for pagination.        do {            Aws::Lambda::Model::ListFunctionsRequest request;            if (!marker.empty()) {                request.SetMarker(marker);            }            Aws::Lambda::Model::ListFunctionsOutcome outcome = lambdaClient.ListFunctions(                    request);            if (outcome.IsSuccess()) {                const Aws::Lambda::Model::ListFunctionsResult &listFunctionsResult = outcome.GetResult();                std::cout << listFunctionsResult.GetFunctions().size()                          << \" lambda functions were retrieved.\" << std::endl;                for (const Aws::Lambda::Model::FunctionConfiguration &functionConfiguration: listFunctionsResult.GetFunctions()) {                    functions.push_back(functionConfiguration.GetFunctionName());                    std::cout << functions.size() << \"  \"                              << functionConfiguration.GetDescription() << std::endl;                    std::cout << \"   \"                              << Aws::Lambda::Model::RuntimeMapper::GetNameForRuntime(                                      functionConfiguration.GetRuntime()) << \": \"                              << functionConfiguration.GetHandler()                              << std::endl;                }                marker = listFunctionsResult.GetNextMarker();            } else {                std::cerr << \"Error with Lambda::ListFunctions. \"                          << outcome.GetError().GetMessage()                          << std::endl;                result = 1;                break;            }        } while (!marker.empty());    }    Aws::ShutdownAPI(options); // Should only be called once.    return result;}                        For API details, see                        ListFunctions                        in AWS SDK for C++ API Reference.                    GoSDK for Go V2Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    package mainimport (\t\"context\"\t\"fmt\"\t\"github.com/aws/aws-sdk-go-v2/aws\"\t\"github.com/aws/aws-sdk-go-v2/config\"\t\"github.com/aws/aws-sdk-go-v2/service/lambda\")// main uses the AWS SDK for Go (v2) to create an AWS Lambda client and list up to 10// functions in your account.// This example uses the default settings specified in your shared credentials// and config files.func main() {\tctx := context.Background()\tsdkConfig, err := config.LoadDefaultConfig(ctx)\tif err != nil {\t\tfmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\")\t\tfmt.Println(err)\t\treturn\t}\tlambdaClient := lambda.NewFromConfig(sdkConfig)\tmaxItems := 10\tfmt.Printf(\"Let's list up to %v functions for your account.\\n\", maxItems)\tresult, err := lambdaClient.ListFunctions(ctx, &lambda.ListFunctionsInput{\t\tMaxItems: aws.Int32(int32(maxItems)),\t})\tif err != nil {\t\tfmt.Printf(\"Couldn't list functions for your account. Here's why: %v\\n\", err)\t\treturn\t}\tif len(result.Functions) == 0 {\t\tfmt.Println(\"You don't have any functions!\")\t} else {\t\tfor _, function := range result.Functions {\t\t\tfmt.Printf(\"\\t%v\\n\", *function.FunctionName)\t\t}\t}}                        For API details, see                        ListFunctions                        in AWS SDK for Go API Reference.                    JavaSDK for Java 2.xNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.        /**     * Lists the AWS Lambda functions associated with the current AWS account.     *     * @param awsLambda an instance of the {@link LambdaClient} class, which is used to interact with the AWS Lambda service     *     * @throws LambdaException if an error occurs while interacting with the AWS Lambda service     */    public static void listFunctions(LambdaClient awsLambda) {        try {            ListFunctionsResponse functionResult = awsLambda.listFunctions();            List<FunctionConfiguration> list = functionResult.functions();            for (FunctionConfiguration config : list) {                System.out.println(\"The function name is \" + config.functionName());            }        } catch (LambdaException e) {            System.err.println(e.getMessage());            System.exit(1);        }    }                        For API details, see                        ListFunctions                        in AWS SDK for Java 2.x API Reference.                    JavaScriptSDK for JavaScript (v3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import { LambdaClient, paginateListFunctions } from \"@aws-sdk/client-lambda\";const client = new LambdaClient({});export const helloLambda = async () => {  const paginator = paginateListFunctions({ client }, {});  const functions = [];  for await (const page of paginator) {    const funcNames = page.Functions.map((f) => f.FunctionName);    functions.push(...funcNames);  }  console.log(\"Functions:\");  console.log(functions.join(\"\\n\"));  return functions;};                        For API details, see                        ListFunctions                        in AWS SDK for JavaScript API Reference.                    PythonSDK for Python (Boto3)Note        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    import boto3def main():    \"\"\"    List the Lambda functions in your AWS account.    \"\"\"    # Create the Lambda client    lambda_client = boto3.client(\"lambda\")    # Use the paginator to list the functions    paginator = lambda_client.get_paginator(\"list_functions\")    response_iterator = paginator.paginate()    print(\"Here are the Lambda functions in your account:\")    for page in response_iterator:        for function in page[\"Functions\"]:            print(f\"  {function['FunctionName']}\")if __name__ == \"__main__\":    main()                        For API details, see                        ListFunctions                        in AWS SDK for Python (Boto3) API Reference.                    RubySDK for RubyNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    require 'aws-sdk-lambda'# Creates an AWS Lambda client using the default credentials and configurationdef lambda_client  Aws::Lambda::Client.newend# Lists the Lambda functions in your AWS account, paginating the results if necessarydef list_lambda_functions  lambda = lambda_client  # Use a pagination iterator to list all functions  functions = []  lambda.list_functions.each_page do |page|    functions.concat(page.functions)  end  # Print the name and ARN of each function  functions.each do |function|    puts \"Function name: #{function.function_name}\"    puts \"Function ARN: #{function.function_arn}\"    puts  end  puts \"Total functions: #{functions.count}\"endlist_lambda_functions if __FILE__ == $PROGRAM_NAME                        For API details, see                        ListFunctions                        in AWS SDK for Ruby API Reference.                    anchoranchoranchoranchoranchoranchoranchor.NETC++GoJavaJavaScriptPythonRubyAWS SDK for .NETNote        There's more on GitHub. Find the complete example and learn how to set up and run in the        AWS Code            Examples Repository.    namespace LambdaActions;using Amazon.Lambda;public class HelloLambda{    static async Task Main(string[] args)    {        var lambdaClient = new AmazonLambdaClient();        Console.WriteLine(\"Hello AWS Lambda\");        Console.WriteLine(\"Let's get started with AWS Lambda by listing your existing Lambda functions:\");        var response = await lambdaClient.ListFunctionsAsync();        response.Functions.ForEach(function =>        {            Console.WriteLine($\"{function.FunctionName}\\t{function.Description}\");        });    }}                        For API details, see                        ListFunctions                        in AWS SDK for .NET API Reference.                    ",
            "Code examples"
        ]
    }
]